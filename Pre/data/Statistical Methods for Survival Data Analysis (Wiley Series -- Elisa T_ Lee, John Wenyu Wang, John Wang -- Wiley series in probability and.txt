Statistical Methods for Survival Data Analysis Statistical Methods for Survival Data Analysis Third Edition ELISA T. LEE JOHN WENYUWANG Department of Biostatistics and Epidemiology and Center for American Indian Health Research College of Public Health University of Oklahoma Health Sciences Center Oklahoma City, Oklahoma A JOHN WILEY & SONS, INC., PUBLICATION Copyright 2003 by John Wiley & Sons, Inc. All rights reserved.

Published by John Wiley & Sons, Inc., Hoboken, New Jersey.

Published simultaneously in Canada.

No part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400, fax 978-750-4470, or on the web at www.copyright.com.

Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, e-mail: permreqwiley.com.

Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in preparing this book, they make no representations or warranties with respect to the accuracy or completeness of the contents of this book and specifically disclaim any implied warranties of merchantability or fitness for a particular purpose. No warranty may be created or extended by sales representatives or written sales materials. The advice and strategies contained herein may not be suitable for your situation You should consult with a professional where appropriate. Neither the publisher nor author shall be liable for any loss of profit or any other commercial damages, including but not limited to special, incidental, consequential, or other damages.

For general information on our other products and services please contact our Customer Care Department within the U.S. at 877-762-2974, outside the U.S. at 317-572-3993 or fax 317-572-4002.

Wiley also publishes its books in a variety of electronic formats. Some content that appears in print, however, may not be available in electronic format.

Library of Congress Cataloging-in-Publication Data: Lee, Elisa T.

Statistical methods for survival data analysis.--3rd ed./Elisa T. Lee and John Wenyu Wang.

p. cm.--(Wiley series in probability and statistics) Includes bibliographical references and index.

ISBN 0-471-36997-7 (cloth : alk. paper) 1. Medicine--Research--Statistical methods. 2. Failure time data analysis. 3.

Prognosis--Statistical methods. I. Wang, John Wenyu. II. Title. III. Series.

R853.S7 L43 2003 610.72--dc21 2002027025 Printed in the United States of America.

10 9 8 7 6 5 4 3 2 1 To the memory of our parents Mr. Chi-Lan Tan and Mrs. Hwei-Chi Lee Tan (E.T.L.) Mr. Beijun Zhang and Mrs. Xiangyi Wang (J.W.W.) Contents Preface xi 1 Introduction 1.1 Preliminaries, 1 1.2 Censored Data, 1 1.3 Scope of the Book, 5 Bibliographical Remarks, 7 2 Functions of Survival Time 8 2.1 Definitions, 8 2.2 Relationships of the Survival Functions, 15 Bibliographical Remarks, 17 Exercises, 17 3 Examples of Survival Data Analysis 19 3.1 Example 3.1: Comparison of Two Treatments and Three Diets, 19 3.2 Example 3.2: Comparison of Two Survival Patterns Using Life Tables, 26 3.3 Example 3.3: Fitting Survival Distributions to Remission Data, 29 3.4 Example 3.4: Relative Mortality and Identification of Prognostic Factors, 32 3.5 Example 3.5: Identification of Risk Factors, 40 Bibliographical Remarks, 47 Exercises, 47 vii viii  4 Nonparametric Methods of Estimating Survival Functions 64 4.1 Product-Limit Estimates of Survivorship Function, 65 4.2 Life-Table Analysis, 77 4.3 Relative, Five-Year, and Corrected Survival Rates, 94 4.4 Standardized Rates and Ratios, 97 Bibliographical Remarks, 102 Exercises, 102 5 Nonparametric Methods for Comparing Survival Distributions 106 5.1 Comparison of Two Survival Distributions, 106 5.2 Mantel  Haenszel Test, 121 5.3 Comparison of K ( K 9 2) Samples, 125 Bibliographical Remarks, 131 Exercises, 131 6 Some Well-Known Parametric Survival Distributions and Their Applications 134 6.1 Exponential Distribution, 134 6.2 Weibull Distribution, 138 6.3 Lognormal Distribution, 143 6.4 Gamma and Generalized Gamma Distributions, 148 6.5 Log-Logistic Distribution, 154 6.6 Other Survival Distributions, 155 Bibliographical Remarks, 160 Exercises, 160 7 Estimation Procedures for Parametric Survival Distributions without Covariates 162 7.1 General Maximum Likelihood Estimation Procedure, 162 7.2 Exponential Distribution, 166 7.3 Weibull Distribution, 178 7.4 Lognormal Distribution, 180 7.5 Standard and Generalized Gamma Distributions, 188 7.6 Log-Logistic Distribution, 195 7.7 Other Parametric Survival Distributions, 196 Bibliographical Remarks, 196 Exercises, 197  ix 8 Graphical Methods for Survival Distribution Fitting 198 8.1 Introduction, 198 8.2 Probability Plotting, 200 8.3 Hazard Plotting, 209 8.4 Cox  Snell Residual Method, 215 Bibliographical Remarks, 219 Exercises, 219 9 Tests of Goodness of Fit and Distribution Selection 221 9.1 Goodness-of-Fit Test Statistics Based on Asymptotic Likelihood Inferences, 222 9.2 Tests for Appropriateness of a Family of Distributions, 225 9.3 Selection of a Distribution Using BIC or AIC Procedures, 230 9.4 Tests for a Specific Distribution with Known Parameters, 233 9.5 Hollander and Proschans Test for Appropriateness of a Given Distribution with Known Parameters, 236 Bibliographical Remarks, 238 Exercises, 240 10 Parametric Methods for Comparing Two Survival Distributions 243 10.1 Likelihood Ratio Test for Comparing Two Survival Distributions, 243 10.2 Comparison of Two Exponential Distributions, 246 10.3 Comparison of Two Weibull Distributions, 251 10.4 Comparison of Two Gamma Distributions, 252 Bibliographical Remarks, 254 Exercises, 254 11 Parametric Methods for Regression Model Fitting and Identification of Prognostic Factors 256 11.1 Preliminary Examination of Data, 257 11.2 General Structure of Parametric Regression Models and Their Asymptotic Likelihood Inference, 259 11.3 Exponential Regression Model, 263 11.4 Weibull Regression Model, 269 11.5 Lognormal Regression Model, 274 11.6 Extended Generalized Gamma Regression Model, 277 x  11.7 Log-Logistic Regression Model, 280 11.8 Other Parametric Regression Models, 283 11.9 Model Selection Methods, 286 Bibliographical Remarks, 295 Exercises, 295 12 Identification of Prognostic Factors Related to Survival Time: Cox Proportional Hazards Model 298 12.1 Partial Likelihood Function for Survival Times, 298 12.2 Identification of Significant Covariates, 314 12.3 Estimation of the Survivorship Function with Covariates, 319 12.4 Adequacy Assessment of the Proportional Hazards Model, 326 Bibliographical Remarks, 336 Exercises, 337 13 Identification of Prognostic Factors Related to Survival Time: Nonproportional Hazards Models 339 13.1 Models with Time-Dependent Covariates, 339 13.2 Stratified Proportional Hazards Models, 348 13.3 Competing Risks Model, 352 13.4 Recurrent Events Models, 356 13.5 Models for Related Observations, 374 Bibliographical Remarks, 376 Exercises, 376 14 Identification of Risk Factors Related to Dichotomous and Polychotomous Outcomes 377 14.1 Univariate Analysis, 378 14.2 Logistic and Conditional Logistic Regression Models for Dichotomous Responses, 385 14.3 Models for Polychotomous Outcomes, 413 Bibliographical Remarks, 425 Exercises, 425 Appendix A Newton--Raphson Method 428 Appendix B Statistical Tables 433 References 488 Index 511 Preface Statistical methods for survival data analysis have continued to flourish in the last two decades. Applications of the methods have been widened from their historical use in cancer and reliability research to business, criminology, epidemiology, and social and behavioral sciences. The third edition of Statistical Methods for Survival Data Analysis is intended to provide a comprehensive introduction of the most commonly used methods for analyzing survival data.

It begins with basic definitions and interpretations of survival functions. From there, the reader is guided through methods, parametric and nonparametric, for estimating and comparing these functions and the search for a theoretical distribution (or model) to fit the data. Parametric and nonparametric approaches to the identification of prognostic factors that are related to survival are then discussed. Finally, regression methods, primarily linear logistic regression models, to identify risk factors for dichotomous and polychotomous outcomes are introduced.

The third edition continues to be application-oriented, with a minimum level of mathematics. In a few chapters, some knowledge of calculus and matrix algebra is needed. The few sections that introduce the general mathematical structure for the methods can be skipped without loss of continuity. A large number of practical examples are given to assist the reader in understanding the methods and applications and in interpreting the results. Readers with only college algebra should find the book readable and understandable.

There are many excellent books on clinical trials. We therefore have deleted the two chapters on the subject that were in the second edition. Instead, we have included discussions of more statistical methods for survival data analysis.

A brief summary of the improvements made for the third edition is given below.

1. Two additional distributions, the log-logistic distribution and a generalized gamma distribution, have been added to the application of paramet- ric models that can be used in model fitting and prognostic factor identification (Chapters 6, 7, and 11).

xi xii  2. In several sections (Sections 7.1, 9.1, 10.1, 11.2, and 12.1), discussions of the asymptotic likelihood inference of the methods covered in the chapters are given. These sections are intended to provide a more general mathematical structure for statisticians.

3. The Cox  Snell residual method has been added to the chapter on graphical methods for survival distribution fitting (Chapter 8). In addition, the sections on probability and hazard plotting have been revised so that no special graphical papers are required to make the plots.

4. More tests of goodness of fit are given, including the BIC and AIC procedures (Chapters 9 and 11).

5. For Coxs proportional hazards model (Chapter 12), we have now included methods to assess its adequency and procedures to estimate the survivorship function with covariates.

6. The concept of nonproportional hazards models is introduced (Chapter 13), which includes models with time-dependent covariates, stratified models, competing risks models, recurrent event models, and models for related observations.

7. The chapter on linear logistic regression (Chapter 14) has been expanded to cover regression models for polychotomous outcomes. In addition, methods for a general m : n matching design have been added to the section on conditional logistic regression for case  control studies.

8. Computer programming codes for software packages BMDP, SAS, and SPSS are provided for most examples in the text.

We would like to thank the many researchers, teachers, and students who have used the second edition of the book. The suggestions for improvement that many of them have provided are invaluable. Special thanks go to Xing Wang, Linda Hutton, Tracy Mankin, and Imran Ahmed for typing the manuscript. Steve Quigley of John Wiley convinced us to work on a third edition. We thank him for his enthusiasm.

Finally, we are most grateful to our families, Sam, Vivian, Benedict, Jennifer, and Annelisa (E.T.L.), and Alice and Xing (J.W.W.), for the constant joy, love, and support they have given us.

E T. L J W W Oklahoma City, OK April 18, 2001 C H A P T E R 1 Introduction 1.1 PRELIMINARIES This book is for biomedical researchers, epidemiologists, consulting statisticians, students taking a first course on survival data analysis, and others interested in survival time study. It deals with statistical methods for analyzing survival data derived from laboratory studies of animals, clinical and epidemiologic studies of humans, and other appropriate applications.

Survival time can be defined broadly as the time to the occurrence of a given event. This event can be the development of a disease, response to a treatment, relapse, or death. Therefore, survival time can be tumor-free time, the time from the start of treatment to response, length of remission, and time to death.

Survival data can include survival time, response to a given treatment, and patient characteristics related to response, survival, and the development of a disease. The study of survival data has focused on predicting the probability of response, survival, or mean lifetime, comparing the survival distributions of experimental animals or of human patients and the identification of risk and/or prognostic factors related to response, survival, and the development of a disease. In this book, special consideration is given to the study of survival data in biomedical sciences, although all the methods are suitable for applications in industrial reliability, social sciences, and business. Examples of survival data in these fields are the lifetime of electronic devices, components, or systems (reliability engineering); felons time to parole (criminology); duration of first marriage (sociology); length of newspaper or magazine subscription (market-ing); and workers compensation claims (insurance) and their various influencing risk or prognostic factors.

1.2 CENSORED DATA Many researchers consider survival data analysis to be merely the application of two conventional statistical methods to a special type of problem: parametric if the distribution of survival times is known to be normal and nonparametric 1 2  if the distribution is unknown. This assumption would be true if the survival times of all the subjects were exact and known; however, some survival times are not. Further, the survival distribution is often skewed, or far from being normal. Thus there is a need for new statistical techniques. One of the most important developments is due to a special feature of survival data in the life sciences that occurs when some subjects in the study have not experienced the event of interest at the end of the study or time of analysis. For example, some patients may still be alive or disease-free at the end of the study period. The exact survival times of these subjects are unknown. These are called censored observations or censored times and can also occur when people are lost to follow-up after a period of study. When these are not censored observations, the set of survival times is complete. There are three types of censoring.

Type I Censoring Animal studies usually start with a fixed number of animals, to which the treatment or treatments is given. Because of time and/or cost limitations, the researcher often cannot wait for the death of all the animals. One option is to observe for a fixed period of time, say six months, after which the surviving animals are sacrificed. Survival times recorded for the animals that died during the study period are the times from the start of the experiment to their death.

These are called exact or uncensored observations. The survival times of the sacrificed animals are not known exactly but are recorded as at least the length of the study period. These are called censored observations. Some animals could be lost or die accidentally. Their survival times, from the start of experiment to loss or death, are also censored observations. In type I censoring, if there are no accidental losses, all censored observations equal the length of the study period.

For example, suppose that six rats have been exposed to carcinogens by injecting tumor cells into their foot pads. The times to develop a tumor of a given size are observed. The investigator decides to terminate the experiment after 30 weeks. Figure 1.1 is a plot of the development times of the tumors.

Rats A, B, and D developed tumors after 10, 15, and 25 weeks, respectively.

Rats C and E did not develop tumors by the end of the study; their tumor-free times are thus 30-plus weeks. Rat F died accidentally without tumors after 19 weeks of observation. The survival data (tumor-free times) are 10, 15, 30;, 25, 30;, and 19; weeks. (The plus indicates a censored observation.) Type II Censoring Another option in animal studies is to wait until a fixed portion of the animals have died, say 80 of 100, after which the surviving animals are sacrificed. In this case, type II censoring, if there are no accidental losses, the censored observations equal the largest uncensored observation. For example, in an experiment of six rats (Figure 1.2), the investigator may decide to terminate the study after four of the six rats have developed tumors. The survival or tumor-free times are then 10, 15, 35;, 25, 35, and 19; weeks.

3 Figure 1.1 Example of type I censored data.

Figure 1.2 Example of type II censored data.

Type III Censoring In most clinical and epidemiologic studies the period of study is fixed and patients enter the study at different times during that period. Some may die before the end of the study; their exact survival times are known. Others may withdraw before the end of the study and are lost to follow-up. Still others may be alive at the end of the study. For lost patients, survival times are at least from their entrance to the last contact. For patients still alive, survival times are at least from entry to the end of the study. The latter two kinds of observations are censored observations. Since the entry times are not simultaneous, the censored times are also different. This is type III censoring. For example, suppose that six patients with acute leukemia enter a clinical study 4  Figure 1.3 Example of type III censored data.

during a total study period of one year. Suppose also that all six respond to treatment and achieve remission. The remission times are plotted in Figure 1.3.

Patients A, C, and E achieve remission at the beginning of the second, fourth, and ninth months, and relapse after four, six, and three months, respectively.

Patient B achieves remission at the beginning of the third month but is lost to follow-up four months later; the remission duration is thus at least four months. Patients D and F achieve remission at the beginning of the fifth and tenth months, respectively, and are still in remission at the end of the study; their remission times are thus at least eight and three months. The respective remission times of the six patients are 4, 4;, 6, 8;, 3, and 3; months.

Type I and type II censored observations are also called singly censored data, and type III, progressively censored data, by Cohen (1965). Another commonly used name for type III censoring is random censoring. All of these types of censoring are right censoring or censoring to the right. There are also left censoring and interval censoring cases. L eft censoring occurs when it is known that the event of interest occurred prior to a certain time t, but the exact time of occurrence is unknown. For example, an epidemiologist wishes to know the age at diagnosis in a follow-up study of diabetic retinopathy. At the time of the examination, a 50-year-old participant was found to have already developed retinopathy, but there is no record of the exact time at which initial evidence was found. Thus the age at examination (i.e., 50) is a left-censored observation.

It means that the age of diagnosis for this patient is at most 50 years.

Interval censoring occurs when the event of interest is known to have occurred between times a and b. For example, if medical records indicate that at age 45, the patient in the example above did not have retinopathy, his age at diagnosis is between 45 and 50 years.

We will study descriptive and analytic methods for complete, singly cen- sored, and progressively censored survival data using numerical and graphical     5 techniques. Analytic methods discussed include parametric and nonparametric.

Parametric approaches are used either when a suitable model or distribution is fitted to the data or when a distribution can be assumed for the population from which the sample is drawn. Commonly used survival distributions are the exponential, Weibull, lognormal, and gamma. If a survival distribution is found to fit the data properly, the survival pattern can then be described by the parameters in a compact way. Statistical inference can be based on the distribution chosen. If the search for an appropriate model or distribution is too time consuming or not economical or no theoretical distribution adequately fits the data, nonparametric methods, which are generally easy to apply, should be considered.

1.3 SCOPE OF THE BOOK This book is divided into four parts.

Part I (Chapters 1, 2, and 3) defines survival functions and gives examples of survival data analysis. Survival distribution is most commonly described by three functions: the survivorship function (also called the cumulative survival rate or survival function), the probability density function, and the hazard function (hazard rate or age-specific rate). In Chapter 2 we define these three functions and their equivalence relationships. Chapter 3 illustrates survival data analysis with five examples taken from actual research situations. Clinical and laboratory data are systematically analyzed in progressive steps and the results are interpreted. Section and chapter numbers are given for quick reference. The actual calculations are given as examples or left as exercises in the chapters where the methods are discussed. Four sets of data are provided in the exercise section for the reader to analyze. These data are referred to in the various chapters.

In Part II (Chapters 4 and 5) we introduce some of the most widely used nonparametric methods for estimating and comparing survival distributions.

Chapter 4 deals with the nonparametric methods for estimating the three survival functions: the Kaplan and Meier product-limit (PL) estimate and the life-table technique (population life tables and clinical life tables). Also covered is standardization of rates by direct and indirect methods, including the standardized mortality ratio. Chapter 5 is devoted to nonparametric techniques for comparing survival distributions. A common practice is to compare the survival experiences of two or more groups differing in their treatment or in a given characteristic. Several nonparametric tests are described.

Part III (Chapters 6 to 10) introduces the parametric approach to survival data analysis. Although nonparametric methods play an important role in survival studies, parametric techniques cannot be ignored. In Chapter 6 we introduce and discuss the exponential, Weibull, lognormal, gamma, and log-logistic survival distributions. Practical applications of these distributions taken from the literature are included.

6  An important part of survival data analysis is model or distribution fitting.

Once an appropriate statistical model for survival time has been constructed and its parameters estimated, its information can help predict survival, develop optimal treatment regimens, plan future clinical or laboratory studies, and so on. The graphical technique is a simple informal way to select a statistical model and estimate its parameters. When a statistical distribution is found to fit the data well, the parameters can be estimated by analytical methods. In Chapter 7 we discuss analytical estimation procedures for survival distributions. Most of the estimation procedures are based on the maximum likelihood method. Mathematical derivations are omitted; only formulas for the estimates and examples are given. In Chapter 8 we introduce three kinds of graphical methods: probability plotting, hazard plotting, and the Cox  Snell residual method for survival distribution fitting. In Chapter 9 we discuss several tests of goodness of fit and distribution selection. In Chapter 10 we describe several parametric methods for comparing survival distributions.

A topic that has received increasing attention is the identification of prognostic factors related to survival time. For example, who is likely to survive longest after mastectomy, and what are the most important factors that influence that survival? Another subject important to both biomedical researchers and epidemiologists is identification of the risk factors related to the development of a given disease and the response to a given treatment. What are the factors most closely related to the development of a given disease? Who is more likely to develop lung cancer, diabetes, or coronary disease? In many diseases, such as cancer, patients who respond to treatment have a better prognosis than patients who do not. The question, then, relates to what the factors are that influence response. Who is more likely to respond to treatment and thus perhaps survive longer?

Part IV (Chapters 11 to 14) deals with prognostic/risk factors and survival times. In Chapter 11 we introduce parametric methods for identifying important prognostic factors. Chapters 12 and 13 cover, respectively, the Cox proportional hazards model and several nonproportional hazards models for the identification of prognostic factors. In the final chapter, Chapter 14, we introduce the linear logistic regression model for binary outcome variables and its extension to handle polychotomous outcomes.

In Appendix A we describe a numerical procedure for solving nonlinear equations, the Newton  Raphson method. This method is suggested in Chapters 7, 11, 12, and 13. Appendix B comprises a number of statistical tables.

Most nonparametric techniques discussed here are easy to understand and simple to apply. Parametric methods require an understanding of survival distributions. Unfortunately, most of survival distributions are not simple.

Readers without calculus may find it difficult to apply them on their own.

However, if the main purpose is not model fitting, most parametric techniques can be substituted for by their nonparametric competitors. In fact, a large percentage of survival studies in clinical or epidemiological journals are analyzed by nonparametric methods. Researchers not interested in survival     7 model fitting should read the chapters and sections on nonparametric methods.

Computer programs for survival data analysis are available in several commercially available software packages: for example, BMDP, SAS, and SPSS. These computer programs are referred to in various chapters when applicable.

Computer programming codes are given for many of the examples.

Bibliographical Remarks Cross and Clark (1975) was the first book to discuss parametric models and nonparametric and graphical techniques for both complete and censored survival data. Since then, several other books have been published in addition to the first edition of this book (Lee, 1980, 1992). Elandt-Johnson and Johnson (1980) discuss extensively the construction of life tables, model fitting, competing risk, and mathematical models of biological processes of disease progression and aging. Kalbfleisch and Prentice (1980) focus on regression problems with survival data, particularly Coxs proportional hazards model.

Miller (1981) covers a number of parametric and nonparametric methods for survival analysis. Cox and Oakes (1984) also cover the topic concisely with an emphasis on the examination of explanatory variables.

Nelson (1982) provides a good discussion of parametric, nonparametric, and graphical methods. The book is more suited for industrial reliability engineers than for biomedical researchers, as are Hahn and Shapiro (1967) and Mann et al. (1974). In addition, Lawless (1982) gives a broad coverage of the area with applications in engineering and biomedical sciences.

More recent publications include Marubini and Valsecchi (1994), Klein- baum (1995), Klein and Moeschberger (1997), and Hosmer and Lemeshow (1999). Most of these books take a more rigorous mathematical approach and require knowledge of mathematical statistics.

C H A P T E R 2 Functions of Survival Time Survival time data measure the time to a certain event, such as failure, death, response, relapse, the development of a given disease, parole, or divorce. These times are subject to random variations, and like any random variables, form a distribution. The distribution of survival times is usually described or characterized by three functions: (1) the survivorship function, (2) the probability density function, and (3) the hazard function. These three functions are mathematically equivalent  if one of them is given, the other two can be derived.

In practice, the three functions can be used to illustrate different aspects of the data. A basic problem in survival data analysis is to estimate from the sampled data one or more of these three functions and to draw inferences about the survival pattern in the population. In Section 2.1 we define the three functions and in Section 2.2, discuss the equivalence relationship among the three functions.

2.1 DEFINITIONS Let T denote the survival time. The distribution of T can be characterized by three equivalent functions.

Survivorship Function (or Survival Function) This function, denoted by S( t), is defined as the probability that an individual survives longer than t: S( t) : P (an individual survives longer than t) : P( T t) (2.1.1) From the definition of the cumulative distribution function F( t) of T, S( t) : 1 -P (an individual fails before t) : 1 9 F( t) (2 . 1 . 2) 8  9 Here S( t) is a nonincreasing function of time t with the properties S( t) : 1 for t:0 0 for t : - That is, the probability of surviving at least at the time zero is 1 and that of surviving an infinite time is zero.

The function S( t) is also known as the cumulative survival rate. To depict the course of survival, Berkson (1942) recommended a graphic presentation of S( t).

The graph of S( t) is called the survival curve. A steep survival curve, such as the one shown in Figure 2.1 a, represents low survival rate or short survival time. A gradual or flat survival curve such as in Figure 2.1 b represents high survival rate or longer survival.

The survivorship function or the survival curve is used to find the 50th percentile (the median) and other percentiles (e.g., 25th and 75th) of survival time and to compare survival distributions of two or more groups. The median survival times in Figure 2.1 a and b are approximately 5 and 36 units of time, respectively. The mean is generally used to describe the central tendency of a distribution, but in survival distributions the median is often better because a small number of individuals with exceptionally long or short lifetimes will cause the mean survival time to be disproportionately large or small.

In practice, if there are no censored observations, the survivorship function is estimated as the proportion of patients surviving longer than t : S( t) : number of patients surviving longer than t (2.1.3) total number of patients where the circumflex denotes an estimate of the function. When censored observations are present, the numerator of (2.1.3) cannot always be determined.

For example, consider the following set of survival data: 4, 6, 6;, 10;, 15, 20.

Figure 2.1 Two examples of survival curves.

10     Using (2.1.3), we can compute S(5) : 5 / 6 : 0 . 833. However, we cannot obtain S(11) since the exact number of patients surviving longer than 11 is unknown.

Either the third or the fourth patient (6; and 10;) could survive longer than or less than 11. Thus, when censored observations are present, (2.1.3) is no longer appropriate for estimating S( t). Nonparametric methods of estimating S( t) for censored data are discussed in Chapter 4.

Probability Density Function (or Density Function) Like any other continuous random variable, the survival time T has a probability density function defined as the limit of the probability that an individual fails in the short interval t to t ; t per unit width t, or simply the probability of failure in a small interval per unit time. It can be expressed as f ( t) : lim R P[an individual dying in the interval ( t, t ; t)] (2 . 1 . 4) t The graph of f ( t) is called the density curve. Figure 2.2 a and b give two examples of the density curve. The density function has the following two properties: 1. f ( t) is a nonnegative function: f ( t) 0 for all t 0 : 0 for t 0 2. The area between the density curve and the t axis is equal to 1.

In practice, if there are no censored observations, the probability density function f ( t) is estimated as the proportion of patients dying in an interval per Figure 2.2 Two examples of density curves.

11 unit width: f ( t) : number of patients dying in the interval beginning at time t (2.1.5) (total number of patients);(interval width) Similar to the estimation of S( t), when censored observations are present, (2.1.5) is not applicable. We discuss an appropriate method in Chapter 4.

The proportion of individuals that fail in any time interval and the peaks of high frequency of failure can be found from the density function. The density curve in Figure 2.2 a gives a pattern of high failure rate at the beginning of the study and decreasing failure rate as time increases. In Figure 2.2 b, the peak of high failure frequency occurs at approximately 1.7 units of time. The proportion of individuals that fail between 1 and 2 units of time is equal to the shaded area between the density curve and the axis. The density function is also known as the unconditional failure rate.

Hazard Function The hazard function h( t) of survival time T gives the conditional failure rate.

This is defined as the probability of failure during a very small time interval, assuming that the individual has survived to the beginning of the interval, or as the limit of the probability that an individual fails in a very short interval, t ; t, given that the individual has survived to time t: lim R P an individual fails in the time interval ( t, t; t) given the individual has survived to t h( t) : (2 . 1 . 6) t The hazard function can also be defined in terms of the cumulative distribution function F( t) and the probability density function f ( t): f ( t) h( t) : (2 . 1 . 7) 1 9 F( t) The hazard function is also known as the instantaneous failure rate, force of mortality, conditional mortality rate, and age-specific failure rate. If t in (2.1.6) is age, it is a measure of the proneness to failure as a function of the age of the individual in the sense that the quantity th( t) is the expected proportion of age t individuals who will fail in the short time interval t ; t. The hazard function thus gives the risk of failure per unit time during the aging process. It plays an important role in survival data analysis.

In practice, when there are no censored observations the hazard function is estimated as the proportion of patients dying in an interval per unit time, given 12     that they have survived to the beginning of the interval: h( t) : number of patients dying in the interval beginning at time t (number of patients surviving at t);(interval width) : number of patients dying per unit time in the interval (2.1.8) number of patients surviving at t Actuaries usually use the average hazard rate of the interval in which the number of patients dying per unit time in the interval is divided by the average number of survivors at the midpoint of the interval: h( t) : number of patients dying per unit time in the interval (number of patients surviving at t) 9 (number of deaths in the interval)/2 (2.1.9) The actuarial estimate in (2.1.9) gives a higher hazard rate than (2.1.8) and thus a more conservative estimate.

The hazard function may increase, decrease, remain constant, or indicate a more complicated process. Figure 2.3 is a plot of several kinds of hazard function. For example, patients with acute leukemia who do not respond to treatment have an increasing hazard rate, h( t), h( t) is a decreasing hazard function that, for example, indicates the risk of soldiers wounded by bullets who undergo surgery. The main danger is the operation itself and this danger decreases if the surgery is successful. An example of a constant hazard function, h( t), is the risk of healthy persons between 18 and 40 years of age whose main risks of death are accidents. The bathtub curve, h( t), describes the process of Figure 2.3 Examples of the hazard function.

13 human life. During an initial period, the risk is high (high infant mortality).

Subsequently, h( t) stays approximately constant until a certain time, after which it increases because of wear-out failures. Finally, patients with tubercu-losis have risks that increase initially, then decrease after treatment. Such an increasing, then decreasing hazard function is described by h( t).

The cumulative hazard function is defined as H( t) : R h( x) dx (2 . 1 . 10) It will be shown in Section 2.2 that H( t) : 9log S( t) (2.1.11) Thus, at t : 0, S( t) : 1, H( t) : 0, and at t : -, S( t) : 0, H( t) : -. The cumulative hazard function can be any value between zero and infinity. All log functions in this book are natural logs (base e) unless otherwise indicated.

The following example illustrates how these functions can be estimated from a complete sample of grouped survival times without censored observations.

Example 2.1 The first three columns of Table 2.1 give the survival data of 40 patients with myeloma. The survival times are grouped into intervals of five months. The estimated survivorship function, density function, and hazard function are also given, with the corresponding graphs plotted in Figure 2.4 ac.

Table 2.1 Survival Data and Estimated Survival Functions of40 Myeloma Patients Number of Patients Surviving at Number of Patients Survival Time Beginning of Dying in t (months) Interval Interval S( t) f ( t) h( t) 0  5 40 5 1.000 0.025 0.027 5  10 35 7 0.875 0.035 0.044 10  15 28 6 0.700 0.030 0.048 15  20 22 4 0.550 0.020 0.040 20  25 18 5 0.450 0.025 0.065 25  30 13 4 0.325 0.020 0.072 30  35 9 4 0.225 0.020 0.114 35  40 5 0 0.125 0.000 0.000 40  45 5 2 0.125 0.010 0.100 45  50 3 1 0.075 0.005 0.080 50 2 2 0.050   14     Figure 2.4 Estimated survival functions of myeloma patients.

15 Figure 2.4 (Continued).

The estimated survivorship function, S( t), is calculated following (2.1.3) at the beginning or the end of each interval. For example, at the beginning of the first interval, all 40 patients are alive, S(0) : 1, and at the beginning of the second interval, 35 of the 40 patients are still alive, S(5) : 35 / 40 : 0 . 875. Similarly, S(10) : 28 / 40 : 0 . 700. The estimated density function f ( t) is computed following (2.1.5). For example, the density function of the first interval (0  5) is 5/(40;5) : 0.025, and that of the second interval (5  10) is 7/(40;5) : 0.035.

The estimated density function is plotted at the midpoint of each interval (Figure 2.4 b). The estimated hazard function, h( t), is computed following the actuarial method given in (2.1.9). For example, the hazard function of the first interval 5/[5(40 9 5/2)] : 0.027 and that of the second interval is 7/[5(35 9 7/ 2)] : 0.044. The estimated hazard function is also plotted at the midpoint of each interval (Figure 2.4 c).

From Table 2.1 or Figure 2.4 a, the median survival time of myeloma patients is approximately 17.5 months, and the peak of high frequency of death occurs in 5 to 10 months. In addition, the hazard function shows an increasing trend and reaches its peak at approximately 32.5 months and then fluctuates.

2.2 RELATIONSHIPS OF THE SURVIVAL FUNCTIONS The three functions defined in Section 2.1 are mathematically equivalent. Given any one of them, the other two can be derived. Readers not interested in the mathematical relationship among the three survival functions can skip this 16     section without loss of continuity.

1. From (2.1.2) and (2.1.7), h( t) : f ( t) (2 . 2 . 1) S( t) This relationship can also be derived from (2.1.6) using basic definitions of conditional probabilities.

2. Since the probability density function is the derivative of the cumulative distribution function, d f ( t) : [1 9 S( t)] : 9 S( t) (2 . 2 . 2) dt 3. Substituting (2.2.2) into (2.2.1) yields S( t) d h( t) : 9 : 9 log S( t) (2 . 2 . 3) S( t) dt 4 . Integrating (2.2.3) from zero to t and using S(0) : 1, we have 9 R h( x) dx:log S( t) or H( t) : 9log S( t) or S( t) : exp[9 H( t)] : exp 9 R h( x) dx (2.2.4) 5. From (2.2.1) and (2.2.4) we obtain f ( t) : h( t) exp[9 H( t)] (2 . 2 . 5) Hence, if f ( t) is known, the survivorship function can be obtained from the basic relationship between f ( t), F( t), and (2.1.2). The hazard function can then be determined from (2.2.1). If S( t) is known, f ( t) and h( t) can be determined from (2.2.2) and (2.2.1), respectively, or h( t) can be derived first from (2.2.3) and then f ( t) from (2.2.1). If h( t) is given, S( t) and f ( t) can be obtained, respectively, from (2.2.4) and (2.2.5). Thus, given any one of the three survival functions, the other two can easily be derived. The following example illustrates these equivalence relationships.

17 Example 2.2 Suppose that the survival time of a population has the following density function: f ( t) : e\ R t 0 Using the definition of the cumulative distribution function, F( t) : R f( x) dx: R e\ Vdx:9 e\ V R :19 e\ R From (2.1.2) we obtain the survivorship function S( t) : e\ R The hazard function can then be obtained from (2.2.1): e\ R h( t) : : 1 e\ R A complete treatment of this distribution is given in Section 6.1.

Bibliographical Remarks The three survival functions and their equivalents are discussed in every text cited in the Bibliographical Remarks in Chapter 1.

EXERCISES 2.1 Consider the survival data given in Exercise Table 2.1. Compute and plot the estimated survivorship function, the probability density function, and the hazard function.

Exercise Table 2.1 Year of Number Alive at Number Dying in Follow-up Beginning of Interval Interval 0  1 1100 240 1  2 860 180 2  3 680 184 3  4 496 138 4  5 358 118 5  6 240 60 6  7 180 52 7  8 128 44 8  9 84 32 9 52 28 18     2.2 Exercise Table 2.2 is a life table for the total population (of 100,000 live births) in the United States, 1959  1961. Compute and plot the estimated survivorship function, the probability density function, and the hazard function.

Exercise Table 2.2 Age Number Living at Number Dying in Interval Beginning of Age Interval Age Interval 0  1 100,000 2,593 1  5 97,407 409 5  10 96,998 233 10  15 96,765 214 15  20 96,551 440 20  25 96,111 594 25  30 95,517 612 30  35 94,905 761 35  40 94,144 1,080 40  45 93,064 1.686 45  50 91,378 2,622 50  55 88,756 4,045 55  60 84,711 5,644 60  65 79,067 7,920 65  70 71,147 10,290 70  75 60,857 12,687 75  80 48,170 14,594 80  85 33,576 15,034 85 and over 18,542 18,542 Source: U.S. National Center for Health Statistics, Life Tables 1959  1961, Vol. 1, No. 1, United States Life Tables 1959  61, December 1964, pp. 8  9.

2.3 Derive (2.2.1) using (2.1.6) and basic definitions of conditional probability.

2.4 Given the hazard function h( t) : c derive the survivorship function and the probability density function.

2.5 Given the survivorship function S( t) : exp(9 t A) derive the probability density function and the hazard function.

C H A P T E R 3 Examples of Survival Data Analysis The investigator who has assembled a large amount of data must decide what to do with it and what it indicates. In this chapter we take several sets of survival data from actual research situations and analyze them. In Example 3.1 we analyze two sets of data obtained, respectively, from two and three treatment groups to compare the treatments abilities to prolong life. Example 3.2 is an example of the life-table technique for large samples. Example 3.3 gives remission data from two treatments; the investigator seeks a well-known distribution for the remission patterns to compare the two groups. In Example 3.4 we study survival data and several other patient characteristics to identify important prognostic factors; the patient characteristics are analyzed individually and simultaneously for their prognosticvalues. In Example 3.5 we introduce a case in which the interest is to identify risk factors in the development of a given disease. Four sets of real data are presented in the exercises so that the reader can plan analysis.

3.1 EXAMPLE 3.1: COMPARISON OF TWO TREATMENTS AND THREE DIETS 3.1.1 Comparison of Two Treatments Thirty melanoma patients (stages 2 to 4) were studied to compare the immunotherapies BCG ( Bacillus Calmette-Guerin) and Corynebacterium parvum for their abilities to prolong remission duration and survival time. The age, gender, disease stage, treatment received, remission duration, and survival time are given in Table 3.1. All the patients were resected before treatment began and thus had no evidence of melanoma at the time of first treatment.

The usual objective with this type of data is to determine the length of remission and survival and to compare the distributions of remission and survival time in each group. Before comparing the remission and survival 19 20 EXAMPLES OF SURVIVAL DATA ANALYSIS Table 3.1 Data for 30 Resected Melanoma Patients Initial Treatment Remission Survival Patient Age Gender ?

Stage Received @ Duration A Time A 1 59 2 3B 1 33.7; 33.7; 2 50 2 3B 1 3.8 3.9 3 76 1 3B 1 6.3 10.5 4 66 2 3B 1 2.3 5.4 5 33 1 3B 1 6.4 19.5 6 23 2 3B 1 23.8; 23.8; 7 40 2 3B 1 1.8 7.9 8 34 1 3B 1 5.5 16.9; 9 34 1 3B 1 16.6; 16.6; 10 38 2 2 1 33.7; 33.7; 11 54 2 2 1 17.1; 17.1; 12 49 1 3B 2 4.3 8.0 13 35 1 3B 2 26.9; 26.9; 14 22 1 3B 2 21.4; 21.4; f15 30 1 3B 2 18.1; 18.1; 16 26 2 3B 2 5.8 16.0; 17 27 1 3B 2 3.0 6.9 18 45 2 3B 2 11.0; 11.0; 19 76 2 3A 2 22.1 24.8; 20 48 1 3A 2 23.0; 23.0; 21 91 1 4A 2 6.8 8.3 22 82 2 4A 2 10.8; 10.8; 23 50 2 4A 2 2.8 12.2; 24 40 1 4A 2 9.2 12.5; 25 34 1 3A 2 15.9 24.4 26 38 1 4A 2 4.5 7.7 27 50 1 2 2 9.2 14.8; 28 53 2 2 2 8.2; 8.2; 29 48 2 2 2 8.2; 8.2; 30 40 2 2 2 7.8; 7.8; Source: Data courtesy of Richard Ishmael.

? 1, male; 2, female.

@ 1, BCG; 2, C. parvum.

A Remission and survival times are in months.

distributions, we attempt to determine if the two treatment groups are comparable with respect to prognostic factors. Let us use the survival time to illustrate the steps. (The remission time could be analyzed similarly.) 1. Estimate and plot the survival function of the two treatment groups. The resulting curves are called survival curves. Points on the curve estimate the proportion of patients who will survive at least a given period of time. For such small samples with progressively censored observations, the Kaplan  Meier product-limit (PL) method is appropriate for estimating the survival function.

EXAMPLE 3.1: COMPARISON OF TWO TREATMENTS AND THREE DIETS 21 Table 3.2 Kaplan--Meier Product-Limit Estimate of Survival Function S( t) BCG Patients Death time ( t) 3.9 5.4 7.9 10.5 19.5 S( t) 0.909 0.818 0.727 0.636 0.477 C. parvum Patients Death time ( t) 6.9 7.7 8.0 S( t) 0.947 0.895 0.839 It does not require any assumptions about the form of the function that is being estimated. We discuss this method in detail in Section 4.1. Computer programs for the method can be found in BMDP (Dixon et al. 1990), SPSS Version 10.1 (2000), and SAS Version 8.1 (2000). Examples for computer codes will be given in Section 4.1.

Table 3.2 gives the PL estimate of the survival function S( t) for the two treatment groups. Note that S( t) is estimated only at death times; however, the censored observations were used to estimate S( t). The median survival time can be estimated by linear interpolation. For BCG patients the median survival time was about 18.2 months. The median survival time for the C. parvum group cannot be calculated since 15 of the 19 patients were still alive. Most computer programs give not only S( t) but also the standard error of S( t), and the 75-, 50-, and 25-percentile points.

Figure 3.1 plots the estimated survival function S( t) for patients receiving the two treatments: The median survival time (50-percentile point) for the BCG group can also be determined graphically. The survival curves clearly show that C. parvum patients had slightly better survival experience than BCG patients. For example, 50% of the BCG patients survived at least 18.2 months, whereas about 61% of the C. parvum patients survived that long.

2. Examine the prognostic homogeneity of the two groups. The next question to ask is whether the difference in survival between the two treatment groups is statistically significant. Is the difference shown by the data significant or simply random variation in the sample? A statistical test of significance is needed. However, a statistical test without considering patient characteristics makes sense only if the two groups of patients are homogeneous with respect to prognosticfactors. It has been assumed thus far that the patients in the two groups are comparable and that the only difference between them is treatment.

Thus, before performing a statistical test it is necessary to examine the homogeneity between the two groups.

Although prognosticfactors for melanoma patients are not well established, it has been reported that women and the young have a better survival 22 EXAMPLES OF SURVIVAL DATA ANALYSIS Figure3.1 Survival curves of patients receiving BCG and C. parvum.

experience than men and the elderly. Also, the disease stage plays an important role in survival. Let us check the homogeneity of the two treatment groups with respect to age, gender, and disease stage.

The age distributions are estimated and plotted in Figure 3.2. The median age is 39 for the BCG group and 43 for the C. parvum patients. To test the significance of the difference between the two age distributions, the two-sample t-test (Armitage, 1971; Daniel, 1987) or nonparametrictests suc h as the Mann  Whitney U-test or the Kolmogorov  Smirnov test (Marascuilo and McSweeney, 1977) are appropriate. However, the generalized Wilcoxon tests given in Section 5.1 can also be used, since they reduce to the Mann  Whitney U-test. Using Gehams generalized Wilcoxon test, the difference between the two age distributions is not found to be statistically significant. More about the test will be given in Section 5.1.

The number of male and female patients in the two treatment groups is given in Table 3.3. Sixty-four percent of the BCG patients and 42% of the C.

parvum patients are women. A chi-square test can be used to compare the two proportions (see Section 14.1). It can be used only for r; c tables in which the entries are frequencies, not for tables in which the entries are mean values or medians of a certain variable. For a 2;2 table, the chi-square value can be computed by hand. Computer programs for the test can be found in many computer program packages, such as BMDP (Dixon et al., 1990), SPSS Version 10.1 (2000), and SAS Version 8.1 (SAS Institute, 2000).

The chi-square value for treatment by gender in Table 3.3 is 1.29 with 1 degree of freedom, which is not significant at the 0.05 or 0.10 level. Therefore, the difference between the two proportions is not statistically significant. The number of stage 2 patients and the number of patients with more advanced EXAMPLE 3.1: COMPARISON OF TWO TREATMENTS AND THREE DIETS 23 Figure3.2 Age distribution of two treatment groups.

disease in the two treatment groups are also given in Table 3.3. Eighteen percent of the BCG patients are at stage 2 against 21% of the C. parvum patients. However, a chi-square test result shows that the difference is not significant.

Thus we can say that the data do not show heterogeneity between the two treatment groups. If heterogeneity is found, the groups can be divided into subgroups of members who are similar in their prognoses.

Table 3.3 Treatment by Gender and Disease Stage BCG C. parvum BCG C. Parvum Disease Gender Number % Number % Total Stage Number % Number % Total Male 4 36 11 58 15 2 2 18 4 21 6 Female 7 64 8 42 15 3 and 4 9 82 15 79 24       11 19 30 11 19 30 24 EXAMPLES OF SURVIVAL DATA ANALYSIS 3. Compare the two survival distributions. There are several parametricand nonparametric tests to compare two survival distributions. They are described in Chapters 5 and 10. Since we have no information of the survival distribution that the data follow, we would continue to use nonparametric methods to compare the two survival distributions. The four tests described in Sections 5.1.1 to 5.1.4 are suitable. The performance of these tests is discussed at the end of Section 5.1. We chose Gehans generalized Wilcoxon test here to demonstrate the analysis procedure only because of its simplicity of calculation.

In testing the significance of the difference between two survival distributions, the hypothesis is that the survival distribution of the BCG patients is the same as that of the C. parvum patients. Let S( t) and S( t) be the survival function of the BCG and C. parvum groups, respectively. The null hypothesis is H: S( t) : S( t) The alternative hypothesis chosen is two-sided: H: S( t) " S( t) since we have no prior information concerning the superiority of either of the two treatments. The slight difference between the two estimated survival curves could be due to random variation. The one-sided alternative H: S( t) S( t) should be considered inappropriate.

Using Gehans generalized Wilcoxon test, the difference in survival distribution of the two treatment groups is found to be insignificant ( p : 0.33).

Therefore, we do not reject the null hypothesis that the two survival distributions are equal. Although our conclusion is that the data do not provide enough evidence to reject the hypothesis, not to reject the null hypothesis does not automatically mean to accept the null hypothesis. The difference between the two statements is that the error probability of the latter statement is usually much larger than that of the former.

3.1.2 Comparison of Three Diets A laboratory investigator interested in the relationship between diet and the development of tumors divided 90 rats into three groups and fed them low-fat, saturated fat, and unsaturated fat diets, respectively (King et al., 1979). The rats were of the same age and species and were in similar physical condition. An identical amount of tumor cells were injected into a foot pad of each rat. The rats were observed for 200 days. Many developed a recognizable tumor early in the study period. Some were tumor-free at the end of the 200 days. Rat 16 in the low-fat group and rat 24 in the saturated group died accidentally after 140 days and 170 days, respectively, with no evidence of tumor. Table 3.4 gives the tumor-free time, the time from injection to the time that a tumor develops or to the end of the study. Fifteen of the 30 rats on the low-fat diet developed a tumor before the experiment was terminated. The rat that died had a tumor-free time of at least 140 days. The other 14 rats did not develop any EXAMPLE 3.1: COMPARISON OF TWO TREATMENTS AND THREE DIETS 25 Table 3.4 Tumor-Free Time (Days) of 90 Rats on Three Different Diets Rat Low-Fat Rat Saturated Fat Rat Unsaturated Fat 1 140 1 124 1 112 2 177 2 58 2 68 3 50 3 56 3 84 4 65 4 68 4 109 5 86 5 79 5 153 6 153 6 89 6 143 7 181 7 107 7 60 8 191 8 86 8 70 9 77 9 142 9 98 10 84 10 110 10 164 11 87 11 96 11 63 12 56 12 142 12 63 13 66 13 86 13 77 14 73 14 75 14 91 15 119 15 117 15 91 16 140; 16 98 16 66 17 200; 17 105 17 70 18 200; 18 126 18 77 19 200; 19 43 19 63 20 200; 20 46 20 66 21 200; 21 81 21 66 22 200; 22 133 22 94 23 200; 23 165 23 101 24 200; 24 170; 24 105 25 200; 25 200; 25 108 26 200; 26 200; 26 112 27 200; 27 200; 27 115 28 200; 28 200; 28 126 29 200; 29 200; 29 161 30 200; 30 200; 30 178 Source: King et al. (1979). Data are used by permission of the author.

tumor by the end of the experiment; their tumor-free times were at least 200 days. Among the 30 rats in the saturated fat diet group, 23 developed a tumor, one died tumor-free after 170 days, and six were tumor-free at the end of the experiment. All 30 rats in the unsaturated fat diet group developed tumors within 200 days. The two early deaths can be considered losses to follow-up.

The data are singly censored if the two early deaths are excluded.

The investigators main interest here is to compare the three diets abilities to keep the rats tumor-free. To obtain information about the distribution of the tumor-free time, we can first estimate the survival (tumor-free) function of the three diet groups. The three survival functions were estimated using the 26 EXAMPLES OF SURVIVAL DATA ANALYSIS Figure3.3 Survival curves of rats in three diet groups.

Kaplan  Meier PL method and plotted in Figure 3.3. The median tumor-free times for the low-fat, saturated fat, and unsaturated fat groups were 188, 107, and 91 days, respectively. Since the three groups are homogeneous, we can skip the step that checks for homogeneity and compare the three distributions of tumor-free time.

The K-sample test described in Section 5.3.3 can be used to test the significance of the differences among the three diet groups. Using this test, the investigator finds that the differences among the three groups are highly significant ( p : 0.002). Note that the K-sample test can tell the investigator only that the differences among the groups are statistically significant. It cannot tell which two groups contribute the most to the differences  whether the low-fat diet produces a significantly different tumor-free time than the saturated fat diet or whether the saturated fat diet is significantly different from the unsaturated fat diet. All one can conclude is that the data show a significant difference among the tumor-free times produced by the three diets.

3.2 EXAMPLE 3.2: COMPARISON OF TWO SURVIVAL PATTERNS USING LIFE TABLES When the sample of patients is so large that their groupings are meaningful, the life-table technique can be used to estimate the survival distribution.

A method developed by Mantel and Haenszel (1959) and applied to life EXAMPLE 3.2: COMPARISON OF TWO SURVIVAL PATTERNS 27 tables by Mantel (1966) can be used to compare two survival patterns in the life-table analysis.

Consider the data of male patients with localized cancer of the rectum diagnosed in Connecticut from 1935 to 1954 (Myers, 1969). A total of 388 patients were diagnosed between 1935 and 1944, and 749 patients were diagnosed between 1945 and 1954. For such large sample sizes the data can be grouped and tabulated as shown in Table 3.5. The 10 intervals indicate the number of years after diagnosis. For the tabulated life tables the survival function S( tG) can be estimated for each interval tG. In Section 4.2 we discuss the estimation procedures of S( tG) and density and hazard functions. The survival, density, and hazard functions are the three most important functions that characterize a survival distribution.

The S( tG) column in Table 3.5 gives the estimated survival function for the two time periods; these are plotted in Figure 3.4. Patients diagnosed in the 1945  1954 period had considerably longer survival times (median 3.87 years) than did patients diagnosed in the 1935  1944 period (median 1.58 years). The five-year survival rate is frequently used by cancer researchers and can easily be determined from a life table. Patients diagnosed in 1935  1944 had a five-year survival rate of 0.2390, or 23.9%. The patients diagnosed in 1945  1954 had a rate of 0.4446, or 44.5%. In comparing two sets of survival data, one can compare the proportions of patients surviving some stated period, such as five years, or the five-year survival rates. However, one cannot anticipate that two survival patterns will always stand in a superior  inferior Table 3.5 Life Table for Male Patients with Localized Cancer of Rectum Diagnosed in Connecticut, 1935--1944 and 1945--1954 ?

1935  1944 1945  1954 Interval ( tG) n G dG wG; lG nG S( tG) n G dG wG; lG nG S( tG) 1 388 167 2 387.0 0.5685 749 185 10 744.0 0.7513 2 219 45 1 218.5 0.4514 554 88 10 549.0 0.6309 3 173 45 1 172.5 0.3336 456 55 10 451.0 0.5539 4 127 19 0 127.0 0.2837 391 43 10 386.0 0.4922 5 108 17 0 108.0 0.2390 338 32 14 331.0 0.4446 6 91 11 1 90.5 0.2100 292 31 52 266.0 0.3928 7 79 8 0 79.0 0.1887 209 20 38 190.0 0.3514 8 71 5 0 71.0 0.1754 151 7 24 139.0 0.3337 9 66 6 1 65.5 0.1593 120 6 25 107.5 0.3151 10 59 7 0 59.0 0.1404 89 6 24 77.0 0.2905 Source: Myers (1969).

? Symbols: n G, number of patients alive at beginning of interval tG; dG, number of patients dying during interval tG; wG; lG, number of patients withdrawn alive or lost to follow-up during interval tG; nG: n G 9( wG; lG); S( tG), cumulative proportion surviving from beginning of study to end of interval tG.

28 EXAMPLES OF SURVIVAL DATA ANALYSIS Figure3.4 Survival curves for male patients with localized cancer of the rectum, diagnosed in Connecticut, 1935  1944 versus 1945  1954.

relationship. It is more desirable to make a whole-pattern comparison (see Sections 4.3 and 5.2).

The Mantel  Haenszel method described in Section 5.2 is a whole-pattern comparison and can be used to compare two survival patterns in life tables.

Application of this method to the data in Table 3.5 results in a chi-square value of 51.996 with 1 degree of freedom. We can conclude that the difference between the two survival patterns is highly significant ( p 0.001).

Estimates of the survival function or survival rate depend on the life-table interval used. If each interval is very short, resulting in a large number of intervals, the computation becomes very tedious and the life-table advantage is not fully taken. One assumption underlying the life table is that the population has the same survival probability in each interval. If the interval length is long, this assumption may be violated and the estimates inaccurate; this should be avoided except for rough calculations. Although the length of each interval and the total number of intervals are important, they will not cause trouble in most clinical studies since the study periods normally cover a short period of time, such as one, two, or three years. Life tables with about 10 to 20 intervals of several months to one year each are reasonable. The investigator should also consider the disease under study. If the variation in survival is large in a short period of time, the interval length should be short.

However, in some demographicor other studies it is often of interest to cover a life span from birth to age 85 or more. The number of intervals would be EXAMPLE 3.3: FITTING SURVIVAL DISTRIBUTIONS 29 very large if short intervals were used. In this case five-year intervals are sufficient to take into account the important variations in survival rate estimates (Shryock et al., 1971).

3.3 EXAMPLE 3.3: FITTING SURVIVAL DISTRIBUTIONS TO REMISSION DATA The remission times of 42 patients with acute leukemia were reported by Freireich et al. (1963) in a clinical trial undertaken to assess the ability of 6-mercaptopurine (6-MP) to maintain remission. Each patient was randomized to receive 6-MP or a placebo. The study was terminated after one year. The following remission times, in weeks, were recorded: 6-MP (21 patients): 6, 6, 6, 7, 10, 13, 16, 22, 23, 6;, 9;, 10;, 11;, 17;, 19;, 20;, 25;, 32;, 32;, 34;, 35; Placebo (21 patients): 1, 1, 2, 2, 3, 4, 4, 5, 5, 8, 8, 8, 8, 11, 11, 12, 12, 15, 17, 22, 23 Suppose that we are interested in a distribution to describe the remission times of these patients but that no information is available as to which distribution will fit. We need to find a distribution that fits the data well. If we can find one, the remission experience can then be described by the properties of the distribution, and the remission time of new patients can be predicted. Parametric tests can be used to compare the effectiveness of the two treatments, but since there are a large number of well-known functions and distributions to choose from, the search becomes an art as much as a scientific task.

The simplest and most efficient tool is the graph. Probability plotting can be done for complete data; for data that include censored observations, hazard plotting and the Cox  Snell method are more appropriate. It is not difficult to use the computer to generate these plots. Detailed discussions of probability plotting and hazard plotting are presented in Chapter 8. In both probability and hazard plotting, a linear configuration indicates that the distribution fits well and its parameters can be estimated from the graph.

Let us begin by trying to fit a distribution to the remission duration of 6-MP patients. Since the data consist of both censored and uncensored observations, we use the technique of hazard plotting. In this example we limit ourselves to three distributions: the exponential, Weibull, and lognormal. In practice, more distributions may need to be considered. Figures 3.5, 3.6, and 3.7 give the hazard plots for the exponential, Weibull, and lognormal distributions, respectively. A straight line is fitted to the points by eye in each of the plots. Among these graphs, the Weibull distribution appears to provide the best fit to the remission data. The straight line fits the points fairly closely. The estimates of Data are used by permission of the publisher.

30 EXAMPLES OF SURVIVAL DATA ANALYSIS Figure3.5 Exponential hazard plot of the remission times of 21 leukemia patients who received 6-MP.

Figure3.6 Weibull hazard plot of the remission times of 21 leukemia patients who received 6-MP.

EXAMPLE 3.3: FITTING SURVIVAL DISTRIBUTIONS 31 \1 9 exp[ H( t)] Figure3.7 Log-normal hazard plot of the remission times of 21 leukemia patients who received 6-MP.

the parameters and of the Weibull distribution obtained from the line are equal to 0.033 and 1.143, respectively (methods discussed in Chapter 8). After knowing that the Weibull distribution provides a good fit, we can use an analytical method, the maximum likelihood method, to obtain a more accurate estimate of the parameters. Following the procedures discussed in Chapter 7, the maximum likelihood estimates of and are : 0.03 and : 1.354, which are quite close to the graphical estimates.

After an appropriate distribution has been identified and parameters es- timated, we can estimate the probability of having a given duration of remission and other probabilities. For example, the probability of having a remission time longer than 10 weeks can be predicted as P( T 10) : e\A : e 9(10 * 0 . 03) : 0 . 822 For the placebo group, we can use the probability plotting technique since the data are complete. Figures 3.8, 3.9, and 3.10 give the exponential, Weibull, and lognormal probability plots. Comparing the three graphs, again, the straight line in the Weibull plot appears to give the best fit. From the Weibull plot, estimates of and are found to be 0.111 and 1.250, respectively. The maximum likelihood estimates of and are, respectively, 0.105 and 1.371.

Again, the graphical estimates are very close to the maximum likelihood estimates. Based on the maximum likelihood estimates of the parameters, we 32 EXAMPLES OF SURVIVAL DATA ANALYSIS log1/[1 9 F(t )] Figure3.8 Exponential probability plot of the remission times of 21 leukemia patients who received placebo.

can estimate the probability of having a remission time longer than 10 weeks.

Using the same formula as given above, the probability for a patient receiving placebo to have a remission duration longer than 10 weeks is found to be 0.34, which is smaller than that of a patient receiving 6-MP.

These graphical methods are subjective. The judgment as to whether the assumed distribution fits the data is based on a visual examination rather than on an objective statistical test. However, the methods are very simple and do provide a great deal of information. Even in a case where none of the distributions discussed in this book fit well, graphs can help find the reasons and thus help modify the model. Therefore, graphical methods are usually recommended as the first thing to try.

3.4 EXAMPLE 3.4: RELATIVE MORTALITY AND IDENTIFICATION OF PROGNOSTIC FACTORS One thousand and twelve Oklahoma Indians (379 men and 633 women) with non-insulin-dependent diabetes mellitus (NIDDM) were examined in EXAMPLE 3.4: RELATIVE MORTALITY 33 log log1/[1 9 F(t)] Figure3.9 Weibull probability plot of the remission times of 21 leukemia patients who received placebo.

\(F(t)) Figure3.10 Log-normal probability plot of the remission times of 21 leukemia patients who received placebo.

34 EXAMPLES OF SURVIVAL DATA ANALYSIS 1972  1980 and a mortality follow-up study was conducted in 1986  1989 (Lee et al., 1993). The mean [standard deviation (SD)] age and duration of diabetes at baseline examination were 52 (11) and 7 (6) years. The average duration of follow-up was 10 (SD 4) years. As of December 31, 1989, 548 patients were alive, 452 (187 men and 265 women) were dead, and 12 could not be traced.

Table 3.6 gives the survival time in years ( T ) of the first 40 male patients along with 12 potential prognosticfactors: age, duration of diabetes (DUR) in years, family history of diabetes (FAM), use of insulin within one year of diagnosis (INS), use of diuretics (DIU), hypertension (HBP), retinopathy (EVD), proteinuria (PRO), fasting plasma glucose (GLU) in milligrams per deciliter, cholesterol (TC) in milligrams per deciliter, triglyceride (TG) in milligrams per deciliter, and body mass index (BMI), which is defined as weight in kilograms divided by height in meters squared.

Among other things, the authors compared the mortality experience of the diabeticpatients with that of the general population in Oklahoma over the follow-up period. Taking changes in age distribution into consideration, the patients were divided into five groups according to their age at baseline examination: 35, 35  44, 45  54, 55  64, and 65. The expected survival rates were calculated on a yearly basis following the methods described in Section 4.3 and using the death rates given in the 1970 and 1980 Oklahoma population life tables. Death rates for the years between 1970 and 1980 and between 1980 and 1989 were estimated based on the 1970 and 1980 statistics and the assumption that changes in death rates between 1970 and 1980 and after 1980 follow a linear trend. The observed and expected survival curves for the groups were plotted (Figure 3.11), and ratios of the observed and expected number of deaths (O/E ratios) by age were tabulated (Table 3.7).

Figure 3.11 shows that the diabeticpatients had a much lower survivorship than the general Oklahoma population for this age  gender distribution. At the beginning of the fifteenth year after baseline examination, the relative survival for the diabeticOklahoma Indians was only 60%. The overall O/E ratios in Table 3.7 are 2.92 [or standardized mortality ratio (SMR) 292] for men and 4.09 (or SMR 409) for women, which indicates a significantly higher mortality rate in the diabeticOklahoma Indians than in the general population.

Although patients in every group experienced excessive mortality, the younger patients had the highest rate.

The relationship between the 12 potential prognosticvariables and the survival time of men was examined using univariate and multivariate methods.

The procedures are summarized below.

1. Examine the individual relationship of each variable to survival. One way to analyze the data is first to determine which of the 12 variables could be considered of significant prognostic importance. In addition to correlation analysis of these variables, the survival times in subcategories are compared (Table 3.8). Patients are grouped into subgroups in a meaningful way or in a way that maximizes the observed difference in survival time between the EXAMPLE 3.4: RELATIVE MORTALITY 35 Figure3.11 Observed and expected survivorship from baseline examination for dabeticOklahoma Indians.

subgroups (subject to the constraint that each subgroup contains at least 10% of the total number of patients).

The survivorship function for every subgroup of each variable was estimated using the Kaplan  Meier method (discussed in Chapter 4) and plotted. Figure 3.12 gives an example. Survival functions among the subgroups were compared by the logrank test (one of the available tests discussed in Chapter 5). Table 3.8 shows that except cholesterol and triglyceride, every one of the 12 variables is significant. The median survival time decreases as age and duration of diabetes increase. Patients with a family history of diabetes, elevated fasting plasma glucose, hypertension, or retinopathy have significantly shorter survival durations than those without these characteristics. Patients with baseline BMI values greater than or equal to 30 had much better survivorship than did patients with a lower BMI value.

I .2 .2 .1 .5 .7 .5 .5 .7 .5 .4 .4 .5 .5 .9 .2 .2 .7 .5 .2 .7 M 4 2 3 8 1 1 9 9 7 4 2 6 4 8 1 9 2 3 4 0 B 3 4 3 3 3 4 3 2 2 2 3 2 3 1 3 3 3 3 2 3 G 8 4 5 8 7 8 0 9 1 2 9 8 0 7 0 7 2 8 2 5 3 9 0 1 7 7 0 9 0 9 4 1 8 7 8 3 3 3 6 2 T 5 4 2 1 1 3 3 1 4 1 1 3 3 2 1 1 C 2 8 5 2 4 6 8 9 1 3 7 4 6 8 4 9 3 1 6 0 T 9 5 9 1 0 0 7 8 4 8 3 1 0 3 0 5 9 7 9 7 3 1 1 2 2 2 1 1 2 1 2 1 2 2 2 1 1 1 1 1 U 2 4 0 1 2 3 4 1 2 5 8 4 6 5 0 7 2 4 8 4 4 0 7 1 0 6 6 1 0 8 2 1 1 2 8 8 3 8 GL 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 2 2 @ ans Indi PRO tic @ iabeD EVD ma @ klaho HBP Ofo @ y U d DI Stuy @ lit S rtao IN M @ ind M 100001 0000009 101100 100000 000000 1010008 100000 000001 100110 101010 100101 100001 001001 001100 100000 101111 100000 101111 100000 100010 FA ollenrEs UR 3 1 4 3 7 4 2 8 4 4 3 4 6 5 2 5 9 5 6 3 1 D ient e .0 .5 .6 .3 .4 .8 .0 .9 .2 .1 .9 .2 .0 .0 .3 .0 .4 .2 .3 .9 4 3 7 6 4 0 0 6 0 4 8 1 3 5 8 0 4 8 6 1 Ag 4 4 4 3 5 5 5 6 4 5 3 5 5 4 3 4 4 4 3 4 MalePat 40t .4 .1 .4 .2 .4 .4 .4 .0 .6 .4 .4 .8 .0 .1 .4 .4 .4 .2 .4 .7 irs T 2 4 4 4 4 2 2 7 3 4 2 9 0 2 4 2 4 4 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Ffoa s ? u at 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 D tatS 6 tn ble3.

tie 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 Ta Pa 1 1 1 1 1 1 1 1 1 1 2 36 .0 .2 .3 .1 .7 .1 .7 .8 .2 .1 .1 .0 .1 .1 .7 .2 .0 .8 .1 .6 8 4 3 0 7 8 1 0 4 3 5 6 8 6 9 0 6 1 4 5 2 2 3 3 2 2 3 3 2 4 2 2 2 2 4 6 2 2 3 2 4 4 3 6 3 9 2 0 9 3 4 7 8 6 4 7 1 1 6 4 3 4 5 7 2 5 1 4 0 4 2 3 0 6 6 5 4 3 6 6 2 1 1 1 1 5 2 3 1 1 3 1 3 1 1 1 4 3 7 4 1 9 0 7 2 0 2 3 7 7 8 0 2 4 6 0 6 8 1 7 5 2 9 0 5 9 6 8 1 2 8 0 9 5 0 8 8 8 2 1 2 1 1 2 2 4 1 1 2 2 1 2 6 1 2 1 7 4 8 6 6 0 8 5 9 4 2 5 1 0 0 0 1 7 1 7 3 9 4 1 2 2 0 2 2 1 5 8 0 8 6 5 2 5 7 2 1 1 1 1 1 2 2 1 1 4 2 1 3 1 1 1 000000 1011109 100000 100000 000100 0011009 0000008 010100 101100 101101 000110 100000 101100 100000 100101 100001 000010 100101 100110 111111 5 9 1 3 1 1 3 0 6 0 8 2 3 1 8 1 8 4 7 8 1 1 1 1 1 1 1 .7 .5 .1 .9 .4 .0 .1 .5 .3 .5 .7 .8 .5 .1 .4 .6 .2 .9 .4 .3 9 1 4 5 0 8 0 4 9 8 3 1 9 0 5 9 0 3 7 1 4 5 4 3 5 4 4 5 6 3 6 7 5 5 7 2 6 6 5 7 .4 .6 .0 .4 .9 .4 .5 .4 .9 .0 .6 .4 .3 .8 .5 .0 .5 .5 .8 .6 3 2 4 2 2 2 4 3 3 2 3 5 0 5 2 5 5 4 6 3 1 1 1 1 1 1 1 1 1 1 1 1 1 ve.

1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 lia,0 no.;0,ades;dey 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 ? 1, @ 1, 37 38 EXAMPLES OF SURVIVAL DATA ANALYSIS Table 3.7 Observed and Expected Number of Deaths and O/E Ratios During Follow-up Period by Gender and Age at Baseline Age at Males Females Baseline (yr) Observed Expected O/E Observed Expected O/E 44 34 6.48 5.25 31 5.51 5.63 45  54 79 25.64 3.08 85 18.40 4.62 55  64 32 11.67 2.74 69 15.03 4.59 65; 42 20.32 2.06 80 25.86 3.09 Total 187 64.11 2.92 265 64.80 4.09 2. Examine the simultaneous relationship of the variables to survival. Examination of each variable can give only a preliminary idea of which variables might be of prognostic importance. The simultaneous effect of the variables must be analyzed by an appropriate multivariate statistical method to determine the relative importance of each. Coxs (1972) proportional hazards model Figure3.12 Survival curves of diabetic patients by hypertension status at baseline.

EXAMPLE 3.4: RELATIVE MORTALITY 39 Table 3.8 Survival Time by Potential Prognostic Variable for Male Diabetic Patients Number of Number of Median Variable Patients Deaths Survival Time (yr) p Value Age (yr) 45 102 34 15.2 45  54 173 79 14.2 0.001 55  64 53 31 9.1 65 46 43 5.1 Family history of diabetes No 104 62 11.4 0.01 Yes 238 104 14.8 Duration of diabetes (yr) 7 207 84 15.2 7  13 91 49 12.2 0.001 14 58 48 7.9 Use of diuretics No 254 117 14.5 0.001 Yes 102 64 10.0 Use of insulin 1 year of diagnosis No 317 157 13.9 0.05 Yes 39 24 11.9 Hypertension No 211 84 15.3 0.001 Yes 151 99 9.8 Retinopathy No 332 163 13.9 0.001 Yes 24 18 6.5 Proteinuria Negative 250 112 14.5 Slight 54 27 12.4 0.001 Heavy 57 44 8.0 Fasting plasma glucose 200 235 106 11.9 0.05 200 139 81 8.4 Cholesterol 240 300 144 14.8 0.12 240 64 38 12.2 Triglyceride 220 223 105 14.1 0.44 220 141 77 13.2 BMI 30 189 114 11.8 0.001 30 184 73 15.4 40 EXAMPLES OF SURVIVAL DATA ANALYSIS can be applied. This model, presented in Chapter 12, is a regression model that relates patient characteristics directly to the risk of failure and thus indirectly to survival. The assumption of this model is that the hazards for different strata of each independent (or prognostic) variable are proportional over time. This assumption was verified by a graphical method (discussed in Chapter 12) using each of the variables. Figure 3.13 gives an example of the graph of log[9 S( t)] versus t for the two hypertension groups. The two almost parallel curves indicate that the hazards of dying are proportional. Therefore, the assumption of the proportional hazards model is satisfied and the model appropriate.

This model can be fitted by a stepwise procedure that results in a ranking of the prognosticvariables. The first variable selected to enter the model is the most important single variable in predicting the risk of dying. The second variable is the second most important, and so on. A significance level can be obtained from a likelihood ratio test at each step, which indicates the level of contribution given by the additional variable.

Using the proportional hazards model and a stepwise procedure, seven of the 12 variables were identified as significant at the 0.05 level based on the likelihood ratio test at each step. These variables, the regression coefficients, and the significance levels based on the Ward test, which uses the regression coefficient and its standard error (S.E.) are given in Table 3.9. The sign of the coefficient indicates whether the variable is positively or negatively related to the hazard of dying. For example, age and duration of diabetes are both positively related to the risk of dying and therefore negatively related to the survival time. Table 3.9 also gives the ratio of risk (or hazard) for values of each variable unfavorable to survival to values of that variable favorable to survival. For example, patients who were 60 years of age at baseline had a 3.05 times higher risk of dying during the follow-up period (10  16 years, average 13 years) than did patients who were only 40 years old at baseline. For dichotomous variables, the ratio of risk is equal to exp(coefficient), which is also interpreted as the relative risk of the variable adjusting for the other variables. Consequently, the confidence interval for the relative risk can be calculated (not shown in Table 3.9). Based on this set of data, the authors conclude that age, hypertension, duration of diabetes, fasting plasma glucose, BMI, proteinuria, and use of diuretics are significantly related to survival. The multivariate method also showed that high values of BMI might be protective.

3.5 EXAMPLE 3.5: IDENTIFICATION OF RISK FACTORS A study of the incidence of retinopathy in Oklahoma Indians with NIDDM was conducted in 1987  1990 as part of a prospective study of diabetic complications (Lee et al., 1992). Among the 312 patients who were free of retinopathy at initial examination in the 1970s, 228 were found to have EXAMPLE 3.5: IDENTIFICATION OF RISK FACTORS 41 Figure3.13 Curves of log[9log S( t)] for the two hypertension groups.

Table 3.9 Significant Variables (at 0.05 Level) Identified by Proportional Hazards Model Relative Risk @ Ratio Regression p Value of Variable ?

Coefficient (Ward Test) Favorable Unfavorable Risk Age 0.0558 0.001 9.32 28.45 3.05 Hypertension: 0.6360 0.001 1.00 1.89 1.89 1, yes, 0, no Duration of 0.0559 0.001 1.32 2.19 1.66 diabetes Fasting plasma 0.0023 0.010 1.35 1.58 1.17 glucose BMI 90.0330 0.035 0.32 0.44 0.72 Proteinuria: 0.3744 0.025 1.00 1.45 1.45 1, yes, 0, no Use of diuretics: 0.4191 0.030 1.00 1.52 1.52 1, yes; 0, no ? Variables are listed in order of entry into model with a p-value limit for entry of 0.05.

@ Favorable categories are 40 years of age, no hypertension, duration of diabetes 5 years, fasting plasma glucose 130 mg/dL, BMI 35, no proteinuria, and no diuretics use. Unfavorable categories are 60 years of age, hypertensive, duration of diabetes 14 years, fasting plasma glucose 200 mg/dL, BMI 25, having proteinuria, and diuretics use.

42 EXAMPLES OF SURVIVAL DATA ANALYSIS developed the eye disease during the 10 to 16-year follow-up period (average follow-up time 12.7 years). Twelve potential factors (assessed at time of baseline examination) were examined by univariate and multivariate methods for their relationship to retinopathy (RET): age, gender, duration of diabetes (DUR), fasting plasma glucose (GLU), initial treatment (TRT), systolic (SBP) and diastolicblood pressure (DBP), body mass index (BMI), plasma cholesterol (TC), plasma triglyceride (TG), and presence of macrovascular disease (LVD) or renal disease (RD). Table 3.10 gives the data for the first 40 patients. Among other things, the authors related these variables to the development of retinopathy.

1. Examine the individual relationship of each variable to the development of diabetic retinopathy. Table 3.11 gives some summary statistics of the eight continuous variables for patients who have developed retinopathy and for those who have not. Notice that patients who have developed the disease were younger at baseline and had much higher fasting plasma glucose, systolic and diastolicblood pressure, and plasma triglyceride than did patients who have not. Table 3.12 summarizes the contingency table analysis of retinopathy incidence rates. The number of patients at risk of developing retinopathy and the number of patients who developed the disease (and rate) are given by subcategory of each potential risk factor. Using the chi-square test, it is found that there was a significant difference in the retinopathy rate among the subcategories of several variables using a significance level of 0.05: duration of diabetes, fasting plasma glucose, systolic and diastolic blood pressure, and treatment. It appears that patients with poor glucose control or high blood pressure or treated with oral agents or insulin have a higher incidence of retinopathy. In addition, patients with high triglyceride levels tend to have higher incidence of retinopathy ( p : 0 . 064). However, patients who had developed macrovascular disease at the time of baseline examination had a lower retinopathy incidence. The authors state that this may be due to the fact that 68% of the patients who had macrovascular disease either died (54%) during the follow-up period or were lost to follow-up (14%). Many of these patients may have developed retinopathy, particularly the patients who have died, but were not included. Therefore, the lower incidence of retinopathy in patients who had macrovascular disease at baseline is probably the result of a selection bias. Similarly, the large number of death plus the losses to follow-up may also contribute to the drop in retinopathy rate in patients who had had diabetes for more than 12 years at baseline. Among the 80 patients in this duration of diabetes category, 56% have died and 10% did not participate in the follow-up examination. The large number of deaths may also be responsible for the finding that patients who survived long enough to develop retinopathy were younger at baseline. The deceased patients were significantly older (mean 57 years) than the survivors who participated in the follow-up examination (mean 48 years).

) ?

f 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 rlea RD veo ed ?

uin 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 nt LVD ( Co 1 7 5 1 5 6 0 8 9 2 6 2 2 0 7 7 3 1 7 1 6 5 MIB 33.

31.

41.

24.

39.

31.

47.

29.

18.

31.

26.

31.

24.

32.

32.

26.

33.

30.

27.

28.

31.

30.

G 5 7 8 2 0 8 4 8 7 0 6 7 2 1 1 2 3 6 3 9 0 5 7 7 7 5 y T 40 17 22 10 26 56 12 17 18 31 16 16 21 13 15 12 19 13 ath C etinop T 195 204 206 190 178 217 390 174 238 204 185 152 194 132 133 151 251 129 190 207 161 181 R etic iab 8 8 0 0 6 8 0 0 0 0 8 8 4 0 0 6 6 0 0 4 2 2 9 7 8 7 8 7 8 7 8 6 7 9 9 9 7 7 8 9 7 8 7 D DBP 10 of nt BP opme S 156 112 134 102 142 142 134 100 134 132 118 112 142 152 136 140 126 132 144 128 124 106 elevD U 0 2 3 6 4 2 0 0 5 0 0 1 8 0 6 9 6 0 8 5 5 8 in L 0 1 8 7 0 4 3 3 1 9 9 8 1 1 2 1 2 1 1 1 11 13 14 23 1 12 15 11 12 12 13 rs G ctoa @ F T k 2 1 2 2 2 2 2 2 2 2 3 2 2 2 2 2 1 1 2 2 2 2 TR Risfoy RU 4 7 4 5 2 7 2 5 5 2 5 3 6 6 1 9 1 3 1 1 1 6 tud 1 S D ind r lve de M M M F M F F F M M F F M F F F M M M M F F vo en In G ts 3 8 6 3 7 2 6 1 9 4 0 5 1 tien .6 .4 .8 .4 .0 .7 .3 .2 .0 a 7 4 0 9 0 0 5 0 5 8.

5.

1.

6.

4.

7.

2.

4.

5.

0.

8.

7.

0.

Age 4 5 5 4 5 5 3 5 4 3 4 5 3 4 3 5 4 3 5 4 4 5 P04 st ?

1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 Fir ETR 103.

ble tient 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 Ta Pa 1 1 1 1 1 1 1 1 1 1 2 2 2 43 ?

0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 RD ?

0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 LVD 1 8 9 5 1 1 0 5 0 1 6 1 2 7 6 1 3 5 MIB 26.

30.

36.

35.

30.

36.

39.

34.

32.

28.

37.

44.

25.

33.

33.

37.

35.

26.

G 8 0 9 5 4 1 9 7 2 8 8 9 2 4 7 5 8 7 8 6 9 6 9 T 19 54 11 11 15 18 30 18 11 29 15 64 20 CT 204 490 192 120 145 156 198 238 185 188 175 179 195 219 224 390 175 146 6 4 4 2 0 0 4 8 8 8 4 0 0 8 8 4 0 0 8 8 8 7 8 8 8 7 7 7 8 8 6 8 8 7 DBP 10 10 BPS 128 142 132 128 138 112 130 128 128 132 142 138 158 172 106 142 154 116 U 4 4 4 9 7 9 9 9 7 0 3 0 7 9 8 1 7 8 L 6 9 G 10 10 30 24 29 13 16 15 14 18 18 18 2 15 15 21 17 @ T 1 3 3 2 2 1 2 1 1 2 2 2 2 1 2 2 1 1 TR RU 1 0 3 3 6 4 2 7 3 3 6 6 8 0 4 1 0 1 1 D r de en F M F F F F F F F M F F F M F F F M .

G lin suin 3 5 2 3 3 6 1 5 5 5 0 7 2 4 0 7 8 9 , 3.

4.

2.

3.

4.

4.

7.

6.

1.

9.

2.

5.

8.

7.

2.

0.

3.

6.

3 Age 4 5 5 5 6 4 4 4 5 5 5 4 4 5 4 5 5 5 ed gent;a inu ?

lra 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 o Cont ET , R .

2 o ; n ly 10 n 0, o ; iet ble3.

tient yes d 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 Ta Pa 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 ? 1, @ 1, 44 EXAMPLE 3.5: IDENTIFICATION OF RISK FACTORS 45 Table 3.11 Summary Statistics for Eight Variables by Retinopathy Status at Follow-up Retinopathy Status No Yes Variable Mean S.D.

Mean S.D.

p Value Age 50.0 9.0 47.2 7.4 0.01 Duration of diabetes 4.2 4.5 4.8 4.4 0.34 Fasting plasma glucose 141.8 65.6 196.3 76.6 0.0001 Systolicblood pressure 128.0 15.7 132.6 17.3 0.04 Diastolicblood pressure 80.3 10.8 84.9 10.1 0.001 Body mass index 32.3 6.3 32.5 5.9 0.76 Cholesterol 204.4 66.0 206.8 58.7 0.76 Triglyceride 180.5 111.1 234.4 273.3 0.01 2. Examine the simultaneous relationship of the variables to the development of retinopathy. Univariate analysis of each variable using the contingency table or the chi-square test gives a preliminary idea of which individual variable might be of prognostic importance. The simultaneous effect of all the variables can be analyzed by the linear logistic regression model (discussed in Section 14.2) to determine the relative importance of each.

The 12 variables were fitted to the linear logisticregression model using a stepwise selection procedure. The variables most significantly related to the development of retinopathy were found to be initial treatment, fasting plasma glucose, age, and diastolic blood pressure ( p 0 . 001). Table 3.13 gives the regression coefficients of the four most significant variables ( p 0.05), the standard errors, and adjusted odds ratios [exp(coefficient)]. The p values used here are the significance levels based on the likelihood ratio test or the improvement in the maximum likelihood due to the addition of the variable in the stepwise procedure. This method is more powerful than the Wald test, which is based on the standardized regression coefficients (Chapter 14). The results are consistent with those in the univariate analysis.

On the basis of the regression coefficients, the probability of developing retinopathy during a 10 to 16-year follow-up can be estimated by substituting values of the risk factors into the regression equation, P log : 9 2 . 373 ; 1 . 495 (oral agent) ; 0.882 (insulin) 1 9 P ; 0.014 (GLU) 9 0.074 (age) ; 0.048 (DBP) For example, for a 50-year-old patient who is on oral agents and whose fasting plasma glucose and diastolic blood pressure are 170 mg/dl and 95 mmHg, 46 EXAMPLES OF SURVIVAL DATA ANALYSIS Table 3.12 Cumulative Incidence Rates of Retinopathy by Baseline Variables Developed Retinopathy Number of Variable Persons at Risk Number Percent p value Gender Female 211 151 71.6 0.384 Male 101 77 76.2 Age (yr) 35 13 10 76.9 35  44 101 77 76.2 0.242 45  54 155 115 74.2 55 43 26 60.5 Duration of diabetes (yr) 4 153 105 68.6 4  7 113 86 76.1 0.033 8  11 23 22 95.7 12 23 15 65.2 Fasting plama glucose (mg/dl) 140 117 62 53.0 140  199 90 74 82.2 0.001 200 105 92 87.6 Systolicblood pressure (mmHg) 130 145 95 65.5 130  159 149 115 78.8 0.016 160 20 18 85.7 Diastolicblood pressure (mmHg) 85 179 118 65.9 85  94 87 73 83.9 0.004 95 46 37 80.4 Plasma cholesterol (mg/dl) 240 267 193 72.3 0.442 240 45 35 77.8 Plasma triglyceride (mg/dl) 250 237 167 70.5 0.064 250 75 61 81.3 Body mass index (kg/m) 28 73 49 67.1 28  33 121 94 77.7 0.261 34 118 85 72.0 Renal disease No 251 179 71.3 0.155 Yes 61 49 80.3 Macrovascular disease No 205 157 76.6 0.053 Yes 107 71 66.4 Treatment (initial) Diet alone 115 62 53.9 Oral agent 158 136 86.1 0.001 Insulin 37 29 78.4 EXERCISES 47 Table 3.13 Results of Logistic Regression Analysis Standard Variable Coefficient Error exp(coefficient) Coefficient/S.E.

Constant 92.373 1.557 Initial treatment Oral agent 1.495 0.330 4.459 4.53 Insulin 0.882 0.488 2.416 1.81 Fasting plasma glucose 0.014 0003 1.014 4.67 Age 90.074 0019 0.929 93.89 Diastolicblood pressure 0.048 0.015 1.049 3.20 respectively, the chance of developing retinopathy in the next 10 to 16 years is 91%.

The linear logisticregression model is useful in identifying important risk factors. However, complete measurements of all the variables are needed; missing data are a problem. In this example, complete data are available on most of the patients. This may not always be the case. Although there are methods of coping with missing data (discussed in Section 11.1), none is perfect. Thus it is extremely important for investigators to make every effort to obtain complete data on every subject.

Bibliographical Remarks It is impossible to cite all the published examples of survival data analysis similar to those in this chapter. Other similar studies can be found in the literature: for example, Biometrics, Biometrika, Cancer, Journal of Chronic Disease, Journal of the National Cancer Institute, American Journal of Epidemiology, Journal of the American Medical Association, and New England Journal of Medicine. An easy way to find examples is to use the National Library of Medicines Web site and search the file PubMed with appropriate keywords.

EXERCISES The four sets of data below are taken from actual research situations. Although the data can be used for various analyses throughout the book, the reader is asked here only to describe in detail how the data can be analyzed. The data appear in examples and other exercises in subsequent chapters.

3.1 Thirty-three patients with hypernephroma were treated with combined chemotherapy, immunotherapy, and hormonal therapy. Exercise Table 3.1 D 0 9 0 0 5 5 10 0 0 0 0 0 0 0 21 0 -S ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; K 0 9 0 0 0 0 0 0 0 0 S 21 A 25 13 25 00 85 75 01 12 00 23 11 20 00 10 32 12 ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; PH 5 3 5 8 2 0 2 2 23 11 10 lts A u 02 01 02 00 10 07 00 01 00 22 17 02 00 15 53 01 esR ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; 0 0 0 0 7 0 5 5 t PPD 10 22 esT in ps 23 20 70 00 50 15 40 13 81 12 00 01 14 70 k D D S ; ; ; ; ; ; ; ; ; ; ; ; ; ; 3 N 5 2 4 7 Mum 15 15 13 ilia 72 10 07 00 12 10 15 0N 44 13 08 91 00 00 01 11 no ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; 7 0 0 0 2 0 6 3 0 9 0 0 0 1 M 1 1 10 15 1 1 s @ u 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 tatS f r o o t -up 5 e h 77 76 77 76 76 5 77 77 77 77 77 75 77 77 77 as /7 L 1/ 1/ /7 1/ 1/ 1/ 1/ 1/ 1/ ma llow /5 11/ 26/ Dat /21/ /15/ /15/ /6 /18/ 10/ 8 10/ 1 1 4 1 6 10/ 2/ 10/ 10/ 9/ 10/ 10/ 10/ ro Deat Fo h ? e ernepp ns y 1 0 3 2 0 2 0 2 0 3 3 1 0 2 3 0 H espo ith R w t nts e en d 74 75 74 te 77 76 7 74 75 77 6 7 76 5 77 77 76 tm Patie 19/ 10/ 7/ 28/ 6/ /7 /7 /7 Dat ea tar 31/ 18/ 1/7 11/ S /4 /1 /25/ /8 /27/ /20/ /24/ 33 Tr 3/ 6/ 2/ 12/ 11/ 10/ 10/ 10/ 4/ 8 1 7 5 4 4 8 rfo ta er a d F F F F D en M M M M M M M M M M M M G 13.

ge 3 1 3 8 5 2 7 3 5 A 5 6 5 4 5 6 5 5 4 58 61 61 77 55 50 42 Table t cise en er 1 2 3 4 5 6 7 8 9 Ex Pati 10 11 12 13 14 15 16 48 0 11 2 0 0 0 0 0 0 0 0 0 0 0 0 0 ; ; D ; ; ; ; ; ; ; ; ; ; ; ; ; ; 0 0 0 0 0 0 0 0 0 0 0 11 00 15 0N 32 12 20 25 00 20 15 26 18 10 00 15 10 16 ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; 5 3 2 0 0 5 6 0 5 0 6 25 18 00 61 00 01 02 25 00 02 01 02 10 71 00 02 01 01 ; ; ; D ; ; ; ; ; ; ; ; ; ; ; ; ; 6 N 0 0 0 25 10 00 10 00 60 10 15 70 50 00 00 20 07 80 15 00 ; ; ; D ; ; ; ; ; ; ; ; ; D ; ; ; 0 6 5 5 0 5 10 20 00 91 00 2N 10 10 01 07 11 00 00 11 10 0N 58 01 00 ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; 0 9 0 2 0 0 0 0 1 0 0 1 0 0 5 0 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 76 76 76 76 75 75 77 77 77 77 77 7 77 75 77 77 7 1/ 1/ 17/ 12/ 1/ 13/ 1/ 10/ /7 1/ 18/ 1/ 1/ 30/ /25/ /7 23/ 2/7 6/ 10/ 10/ 10/ 12/ 10/ 10/ 10/ 12/ 7 7 10/ 10/ 4/ 10/ 10/ 4/ le.bast,3 0 3 0 0 3 3 0 2 0 0 0 3 0 0 2 3 0 se;no respl rtia 76 76 .

a 5 6 75 76 7 76 7 77 77 75 75 5 77 77 7 el p a , /7 /7 22/ /7 /7 16/ /7 /7 2 /8 /8 /18/ /12/ /6 /21/ /7 /10/ /29/ /21/ /19/ /3 /24/ /15/ /4 e; 1 9 2 5 10/ 6 6 6 11/ 5 6 7 7 3 2 6 3 Ishm nso rda resp ich F F R ete M M F M M M M M M M M F M M M fo pl esy com rt , u 1 .d 50 66 58 62 71 44 69 56 57 69 60 60 72 42 57 66 59 co se; e.

n ea n ta o d a 1, do D resp e; ot v n, rce: no ali u , D 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 So ? 0 @ 0, A N 49 50 EXAMPLES OF SURVIVAL DATA ANALYSIS gives the age, gender, date treatment began, response status, date of death or last follow-up, survival status, and results of five pretreatment skin tests. The investigator is interested in the response and survival of the patients and in identifying prognosticfactors. How would you analyze the data?

3.2 In a study undertaken to compare the treatments given to hyperneph- roma patients and to relate response and survival to surgery, metastasis, and treatment time, data from 58 patients were collected (Exercise Table 3.2). How would you analyze the data to answer these questions?

(a) Do patients who had nephrectomy have a higher response rate?

(b) Is the time of nephrectomy related to response and survival?

(c) Are there significant differences between the treatments?

(d) What are the most important variables related to response and survival?

3.3 Exercise Table 3.3 gives the age, gender, family history of melanoma, remission duration, survival time, stage, and results of six pretreatment skin tests (the larger diameter is given) of 102 stage 3 and 4 melanoma patients (Lee et al., 1982).

(a) Study the immunocompetence of melanoma patients by investigating skin test results.

(b) Determine if age, gender, or pretreatment skin test results are predictive to remission and survival time.

(c) Find theoretical distributions that describe the survival and remission patterns.

3.4 One hundred and forty-nine diabeticpatients were followed for 17 years (a subset of data from Lee et al., 1988). Exercise Table 3.4 gives the survival time from baseline examination, survival status, and several potential prognosticfactors at baseline: age, body mass index (BMI), age at diagnosis of diabetes, smoking status, systolicblood pressure (SBP), diastolicblood pressure (DBP), electrocardiogram reading (ECG), and whether the patient had any coronary heart disease (CHD). Identify the important prognostic factors that are associated with survival.

) f s @ rlea tasi ve 0 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 o Bone tas edu Me innt @ is ( Co g 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 Lun Metastas D 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 9 1 1 1 1 1 1 1 1 Status alv e 7 8 8 8 5 8 6 4 7 2 6 8 2 8 9 6 6 0 6 6 9 m 7 1 6 3 2 8 1 5 2 08 1 7 3 99 5 3 08 1 3 rvi 1 1 Ti 9 Su A senop 1 2 0 2 2 0 2 2 0 3 0 1 0 3 2 3 0 3 2 2 2 2 0 0 Res t B en tm 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ea Tr A oma my of 0 0 0 5 0 ephr .0 .0 .0 .0 .0 .0 .0 .0 .5 .0 .0 .0 .0 .0 .0 .0 .0 .0 .0 n 0 4 9.

2 2 0 0 0 9.

0 1 5.

4 0 0 4 0 2 1 1.

0 0 9.

8 me recto 9 9 9 Ti hp yperH Ne hitw @ y s m ient cto at 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 re P85 eph f N oaat ge 3 9 1 2 6 5 2 3 0 8 8 1 7 6 5 0 5 3 9 9 1 6 7 9 5 6 6 5 4 5 6 5 7 4 5 6 7 5 5 5 7 4 6 5 7 5 5 6 D A .2 r 3 de le 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 enG Tab t cise en 12 21 31 42 51 61 72 81 91 2 0 Exer Pati 10 11 1 13 14 15 16 17 18 19 2 21 22 23 24 51 s @ tasi 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 Bone tas Me @ is g 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 Lun Metastas D 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 Status alv e 2 5 6 9 1 4 2 9 8 5 5 8 5 5 0 6 8 m 1 04 15 2 1 5 4 1 2 2 2 4 1 rvi 1 1 Ti Su A senop 0 9 2 0 3 0 0 0 0 0 2 0 0 3 2 3 3 0 0 Res t B en tm 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 ea Tr A my of 0 .0 0 0 0 0 0 .0 .0 0 .0 0 .0 .0 .0 .0 .0 .0 0 9.

0 2.

2.

9.

5 0 9.

0 9.

0 0 0 5 8 8 9.

me recto 9 10.

12.

9 9 9 9 Ti hp Ne @ ym cto 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 0 re ephN nued ntio ge 2 7 1 7 3 2 9 2 5 3 7 0 9 5 3 7 8 2 9 7 6 4 7 6 4 5 6 6 5 5 6 5 7 5 6 5 6 6 C A .2 r 3 de le 1 1 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 1 1 enG Tab t cise en 7 8 9 0 Exer Pati 25 26 2 2 2 3 31 32 33 34 35 36 37 38 39 40 41 42 43 52 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 6 8 2 0 8 2 0 4 6 6 0 0 7 1 2 99 1 81 2 1 2 1 3 2 9 1 .

nownkn 2 0 0 4 4 4 3 3 1 0 0 3 0 2 0 u,9 e; iseasdg 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 .

creasin y in m ,4 e; recto abl .0 .0 0 .0 .0 0 .0 .0 0 .5 .0 .0 .0 .0 .0 st 0 1 9.

2 1 9.

0 3 0.

0 3 0 2 2 8 ephn 9 9 3, on ers.h nse;  ot o e , u 2, resp val yp lia ive era rta l.

tho p 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 ae egat n 2, m n u ; h t; m Is n im nseo tme nd ea a resp ichard tr y wn.

4 0 7 5 0 8 1 9 3 0 9 2 2 7 1 p o 4 6 5 4 5 5 5 5 5 7 6 6 5 7 6 R ete f to n o era k y or n ri th u p o compl , rtes m , 9 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 ale.

ars ; e; cou che v .

ye se lia ta fem o d on , a ,2 n of ine 0 D 0, b ; : ; erb respo ead rce male; yes mu com n d 2 , 44 45 46 47 48 49 50 51 5 53 54 55 56 57 58 Sou ? 1, @ 1, A N B 1 C 0, D 1, 53 phyton 0 0 0 9 9 0 0 0 0 0 7 0 5 0 0 0 4 0 0 2 0 5 2 99 99 9 9 17 20 3 2 1 Trico -SD 7 9 0 9 0 0 0 0 0 0 0 0 5 0 0 0 8 0 0 14 9 18 9 9 3 10 1 25 10 10 2 15 3 1 15 1 KS D A ts 0 0 0 5 9 8 7 6 0 7 5 6 7 5 5 3 7 4 8 0 20 1 9 42 10 1 1 17 1 88 10 1 10 1 1 es PH T 0 0 0 0 0 9 0 0 0 0 0 0 0 9 0 0 0 0 0 0 8 0 4 0 5 0 Skin 9 9 99 1 PPD spm 6 8 5 0 9 5 0 9 9 9 9 0 9 9 9 5 0 5 7 u 1 1 10 9 2 99 99 9 9 9 9 99 99 99 20 9 9 9 2 10 M lia 8 7 0 8 9 7 0 8 5 0 5 0 0 9 0 5 0 0 6 1 1 17 9 1 15 1 1 1 25 12 13 1 1 10 15 1 Moni B B B B B B B B B B B B A B B B A A B A B Stage 3 3 3 3 3B 4 3 3 3 3B 3 3 3A 4 3 4 4B 4B 4B 4 3 3B 3 3 4B 4B 4 val s C tua 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 Survi St ) ma l hs .0 .9 .5 .0 .6 .8 .5 .3 .7 .7 .3 .3 .9 .0 .6 .6 .9 .3 .8 .5 .4 .0 .8 .5 .3 .2 .0 ime 3 0 6 0 7 6 3 7 9 8 9 1 T ont 42 1 2 21 36 24 28 29 19 18 14 23 26 25 13 21 20 Surviva (m Melano4d B an ission tusa 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 9 9 9 9 0 1 1 1 0 9 9 9 3 em St s R geta n ) A S o hs 0 .3 .1 .3 .1 1 5 3 7 7 3 9 6 7 6 0 0 0 0 5 0 3 3 5 0 0 0 ssi 3 6 2 5 7.

5.

2.

4.

0.

ith ime 42.

11.

36.

24.

28.

29.

16.

14.

99.

99.

99.

99.

26.

18.

21.

99.

99.

99.

ont w T 9 9 9 9 9 9 9 s Remi (m ient f @ o a Pat ily y or nom 9 0 0 9 9 0 0 0 0 9 0 0 9 9 0 0 9 9 9 0 9 9 0 1 9 9 0 ist 102 Fam ela f H M oaat erd D 2 2 1 2 1 2 2 1 1 1 1 2 1 2 2 2 1 1 1 1 1 1 1 2 2 1 2 enG .33 le e 8 0 6 6 3 5 5 3 0 g 5 3 5 2 2 3 34 34 26 27 72 70 82 43 52 34 48 62 49 46 53 21 25 35 A Tab cise tient 1 25 37 46 5 6 7 8 9 Exer 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Pa 54 ) f rlea 9 9 0 0 0 5 0 0 2 3 0 0 0 0 0 0 0 0 9 0 9 8 0 0 0 0 0 0 8 5 0 5 9 9 9 3 1 3 1 2 3 9 2 9 1 1 5 2 9 veO ed 0 0 0 0 5 0 0 0 0 5 0 0 0 0 6 0 3 0 0 3 0 0 5 5 7 0 ontinu 99 99 3 10 99 17 99 2 2 1 1 1 3 99 ( C 9 9 1 2 0 8 0 2 5 0 0 0 0 5 5 2 0 5 9 5 9 0 6 5 9 8 6 2 0 7 0 5 9 9 9 1 1 1 1 1 3 1 1 4 1 1 1 3 2 2 9 1 9 1 1 9 2 1 1 1 2 9 9 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 99 99 25 1 10 11 99 99 15 99 9 9 9 5 0 9 7 4 5 2 0 9 8 0 6 8 4 5 9 5 9 4 1 9 9 0 9  0 9 5 7 9 9 9 1 1 9 1 7 1 1 1 2 9 1 9 1 9 9 0 2 9 1 1 9 0 7 0 8 9 0 0 0 6 0 0 0 0 0 0 0 8 0 0 0 99 99 13 30 10 20 99 99 25 20 28 10 99 B B 4B 4B 4B 3B 3B 4B 3B 4B 4B 4B 4B 4B 3B 4B 4B 3A 3A 3B 4B 4A 4B 3B 3A 3B 4A 4B 4B 4B 4B 4B 4B 3B 4B 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 7.4 4.7 0.0 2.5 4.2 5.8 2.7 0.9 8.0 0.0 0.0 8.4 7.7 7.4 1.3 6.3 8.5 5.8 12.5 13.3 25.8 16.5 13.8 11.4 13.5 16.1 13.3 10.1 24.4 10.5 22.2 20.5 13.8 9 9 9 0 0 9 0 9 9 9 1 9 0 9 9 1 9 1 9 0 9 0 0 1 1 9 9 9 0 9 9 9 9 0 0 0 3 0 0 5 0 0 0 4 0 5 0 0 1 0 1 0 1 0 4 7 1 1 0 0 0 1 0 0 0 0 0.

5.

2.

8.

7.

1.

99.

99.

99.

13.

99.

16.

99.

99.

99.

99.

13.

99.

99.

99.

12.

99.

10.

99.

15.

99.

99.

99.

11.

99.

99.

99.

99.

9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 9 9 8 0 0 9 0 0 0 0 9 0 1 0 0 0 0 0 9 9 9 9 0 0 0 9 9 2 2 2 1 1 1 1 1 2 1 2 1 2 2 1 2 1 2 2 2 2 1 2 1 2 2 1 2 1 2 1 1 1 66 54 43 40 16 59 64 52 99 27 60 73 50 63 56 62 57 56 41 40 81 61 62 34 62 63 56 66 62 68 45 58 55 9 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 55 phyton 5 0 0 6 5 9 0 0 0 0 0 2 0 0 1 9 99 1 99 20 1 99 2 99 99 99 99 Trico -SD 2 6 0 0 0 9 0 0 0 0 0 2 0 0 1 2 9 15 99 2 99 1 99 2 99 99 99 99 KS D A ts 3 0 5 7 9 6 7 0 0 5 9 2 17 9 20 18 99 2 99 4 1 99 1 10 99 99 99 99 es PH T 0 0 0 0 9 0 0 0 0 0 9 0 0 Skin 20 9 99 2 99 9 99 15 99 99 99 99 PPD spm 9 0 9 0 9 9 0 5 5 0 0 0 u 35 9 9 9 99 1 99 2 99 20 15 99 99 99 99 M lia 0 5 0 0 9 0 0 0 8 0 0 0 25 9 99 99 99 28 15 99 99 99 99 Moni B B B B Stage 3B 3 4B 4B 4B 4 4B 3 3A 4B 3B 4B 3A 4B 4B 4A 4B 4B 3B 4B 4A 3B val s C tua 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 Survi St l ) hs .7 .4 .9 .7 .9 .0 .8 .9 .7 .6 .0 .1 .8 .2 .0 .2 .1 .1 .9 .6 .3 .6 ime 8 5 1 3 3 6 1 6 4 2 0 7 6 6 2 4 1 8 4 T ont 36 11 15 Surviva (m B ission tusa 1 0 9 9 9 0 9 1 0 9 0 9 9 9 9 0 0 9 0 9 0 1 em St R no ) A hs 3 4 0 0 0 8 0 0 7 0 0 0 0 0 0 2 1 0 9 0 5 7 ssi 7.

5.

6.

6.

6.

6.

4.

6.

1.

ime 36.

99.

99.

99.

99.

99.

99.

99.

99.

99.

99.

99.

99.

T ont 9 9 9 9 9 9 9 9 9 9 9 9 Remi (m f @ o a ily y or nom 1 9 0 0 9 0 9 9 9 9 0 9 9 9 9 9 0 0 9 0 0 0 Fam ist ela H M nued ntio erd C 2 1 1 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 2 2 1 2 enG .33 le eg 63 53 45 41 43 80 75 47 64 38 27 56 60 80 38 71 57 69 17 64 91 40 A Tab cise tient Exer 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 Pa 56 9 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 9 99 99 9 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 9 99 99 9 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 9 99 99 9 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 9 99 99 9 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 9 99 99 9 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 99 9 99 99 B 3A 4B 4B 3A 4B 4B 4B 4B 4B 4B 4B 4B 4B 4B 3B 3A 3B 3A 4B 3B 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 0 4.5 4.0 7.8 4.4 4.2 1.5 3.5 0.4 2.5 1.1 1.2 1.9 6.7 0.9 4.3 5.2 28.0 16.1 21.2 11.1 od.

eri 0 9 9 0 9 9 9 9 9 9 9 9 9 9 0 9 1 0 9 0 p udyst ring 3 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 6 9 0 2 7.

1.

4.

0.

5.

du 99.

99.

21.

99.

99.

99.

99.

99.

99.

99.

99.

99.

99.

99.

99.

9 9 9 9 9 9 9 9 9 9 9 9 9 9 ssion remi od.

in 0 9 9 0 9 9 9 9 9 9 9 9 9 9 0 0 9 9 0 peri evern n.

study 9, g sion; n.

1 1 1 1 1 90 2 2 1 1 1 1 2 1 2 2 9 2 2 1 nknow durin u 9 9 ) 9, own.

on remis 9 siis in e. unknow (1979 le; unkn ll liv 99, 63 40 53 41 27 99 45 50 47 63 52 53 60 35 24 80 99 60 60 35 l.

, a a a 9 rem sti l ; 9 9 ; , et em o in 0 stil ers ,f N er , et , ed; 0 Lee 0 im le;2 ; nev ps e: a a ad; ill m yes rel de m , 99; 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 Sourc ? 1 @ 1, A 9 B 1, C 1, D In 57 B D 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 CH A 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 ECG ) P 8 6 8 4 4 6 8 8 8 6 8 8 B 96 72 5 7 80 94 86 88 78 6 8 7 8 5 9 6 7 82 9 7 76 92 D mmHg )( 8 8 2 2 8 6 2 6 0 2 0 4 BP 32 30 0 2 42 56 40 44 34 0 4 2 5 0 4 2 4 44 5 3 30 22 seline S 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Ba (mmHg at le gin s @ ko 0 2 2 0 2 0 0 2 1 0 2 0 2 2 2 0 1 1 2 1 2 0 m Statu Variab S t is a os ) 5 5 5 8 3 6 3 6 8 4 6 3 (yr 41 48 3 4 42 44 48 33 47 4 4 4 3 4 2 4 4 38 3 3 47 34 Age iagnD sntie .2 .6 0 9 .2 .1 .5 .5 .5 1 5 9 8 2 5 3 6 .3 4 0 .5 .9 at 4 2 2.

7.

2 3 6 8 1 4.

9.

2.

9.

3.

7.

5.

1.

6 2.

7.

6 3 P BMI 3 3 2 3 4 3 3 3 4 3 3 4 2 3 2 2 3 2 3 4 2 4 eticb ) 9 7 9 0 4 2 4 0 8 0 8 5 ia Age yr 44 49 4 4 43 47 50 36 50 4 5 5 4 4 4 4 5 47 3 3 51 40 D 491 al f v e o )( 6 2 5 4 8 9 3 6 9 5 4 1 m .4 .4 .1 .1 .4 .2 .4 .9 .8 .2 2 2 9.

7.

4 4 2 4 2 4.

2.

0.

0.

0.

3.

1.

2.

5 2.

4.

9 7 a rvi Ti (yr 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 at Su D .4 s ? u 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 le3b tat a S eTis tn ercx 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 E Patie 58 ) f 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 ea verlod 1 3 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 2 2 1 ntinue ( Co 8 0 0 6 8 2 4 0 6 4 4 8 8 0 8 2 8 8 0 2 0 0 0 8 80 88 9 90 66 6 8 6 08 7 9 7 9 9 7 8 8 8 9 7 7 66 7 8 68 7 8 8 8 8 7 1 4 2 4 8 2 2 2 2 2 2 2 8 2 6 4 0 8 2 4 8 2 8 2 2 8 32 50 3 42 24 0 3 1 9 2 2 1 4 5 1 1 5 3 3 3 0 26 3 4 26 2 3 2 4 3 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 0 0 2 2 2 1 2 2 1 2 2 0 2 2 0 0 2 0 1 2 1 2 2 1 1 1 0 8 3 1 5 6 3 9 0 8 9 5 9 6 2 2 6 3 9 7 7 2 4 0 3 52 47 4 31 30 2 4 4 3 3 4 4 3 4 3 3 2 3 4 4 3 27 3 4 49 4 3 4 5 5 6 .3 .5 9 .0 .9 7 8 6 2 7 5 2 2 6 7 0 0 7 2 7 6 .8 1 7 .6 1 7 1 8 9 2 2 4 8.

2 3 3.

4.

6.

9.

2.

3.

2.

4.

1.

0.

8.

2.

2.

4.

8.

5.

2 0.

7.

7 8.

1.

6.

0.

6.

4.

3 3 1 3 3 2 2 2 3 3 3 3 2 3 3 2 3 3 2 1 2 2 3 2 2 2 3 2 3 3 2 5 8 3 5 0 4 8 1 6 2 1 9 4 7 1 7 5 5 0 8 0 3 4 2 9 54 53 4 41 34 3 4 4 4 4 4 5 3 5 4 4 4 3 5 4 4 38 3 5 53 4 4 4 5 5 6 .5 .0 1 .9 .6 0 3 4 4 4 2 5 4 3 7 4 5 4 6 8 0 .8 4 9 .9 4 5 0 4 6 9 3 0 2.

1 8 4.

4.

2.

2.

4.

4.

4.

2.

4.

3.

3.

2.

4.

2.

3.

4.

6 2.

2.

8 2.

4.

3.

3.

0.

3.

1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 59 B D 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 CH A 1 1 2 1 1 3 1 2 1 3 1 1 1 1 1 1 2 1 1 1 1 1 2 ECG ) P 6 8 8 2 0 8 6 6 0 6 0 6 4 B 00 90 7 7 7 78 8 86 8 88 8 7 7 80 92 8 7 96 60 8 7 6 82 D 1 mmHg )( 0 8 2 0 0 8 6 8 2 2 4 2 0 4 BP 7 40 3 1 4 38 3 78 5 68 4 2 3 54 54 2 4 78 62 4 2 2 74 seline S 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Ba (mmHg at le gin s @ ko 2 1 0 0 2 0 0 0 2 1 0 2 1 1 0 1 2 0 0 1 0 0 1 m Statu Variab S t is a os ) 6 8 1 9 5 3 9 9 7 1 6 6 7 0 (yr 2 44 5 4 3 58 4 77 4 46 5 4 5 49 49 4 3 61 61 4 3 6 57 Age iagnD 5 .3 1 1 1 .6 0 .7 2 .1 0 0 1 .1 .3 0 7 .1 .9 6 4 4 .7 7.

7 0.

6.

3.

4 9.

8 8.

5 6.

2.

8.

6 5 0.

5.

8 2 7.

3.

5.

9 BMI 2 2 3 3 4 3 3 2 2 2 2 3 2 2 4 3 3 2 3 3 4 2 4 ) 8 4 4 8 7 9 1 1 9 2 0 2 2 0 Age yr 3 50 6 4 3 62 4 78 4 63 7 5 5 50 66 4 4 67 86 5 4 6 75 ed alv e )( 9 .6 2 7 0 .7 6 .0 2 .6 4 3 3 .8 .0 6 4 .2 .5 1 5 9 .5 inu m rvi 6.

3 0.

5.

2.

6 1.

2 0.

3 5.

1.

0.

5 8 4.

1.

7 5 1.

6.

0.

2 Ti (yr 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Su Cont 4 s ? u 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 tatS tn erciseTable3.

54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 Ex Patie 60 ) f 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 ea verlod 1 1 3 1 2 3 3 2 3 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 3 2 2 1 1 ntinue ( Co 8 8 8 6 8 2 8 0 6 0 2 0 2 2 0 8 8 78 68 98 72 60 84 6 6 7 78 80 9 96 7 9 00 90 8 7 6 0 8 66 8 76 88 8 7 6 1 1 2 4 8 8 8 8 2 2 2 4 2 0 8 2 2 2 4 60 22 62 32 16 52 4 9 3 38 84 5 76 1 7 8 44 4 5 2 22 5 42 2 22 62 7 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 0 0 0 2 0 2 1 0 1 0 1 0 2 0 1 2 1 0 0 2 0 2 0 2 2 0 1 0 2 0 1 5 0 0 4 7 5 0 3 0 3 5 4 6 6 8 39 42 60 43 41 54 4 28 4 59 54 3 50 3 5 5 48 5 5 7 33 4 55 4 67 80 5 4 4 2 .3 .0 .8 .2 .1 .6 1 .5 1 .7 .2 2 .3 8 7 5 .9 1 3 3 .1 6 .1 5 .8 .4 3 8 4 5.

7 6 1 8 4 5 5.

2 4.

9 9 5.

5 5.

3.

9.

2 7.

5.

9.

2 3.

6 2.

9 4 6.

0.

9.

3 3 2 2 1 3 2 3 3 4 2 2 2 2 2 3 3 3 3 3 2 2 2 2 3 2 2 2 3 2 1 8 5 8 5 7 6 0 3 1 9 7 7 2 8 8 60 60 63 62 57 71 5 42 4 66 61 4 82 3 5 5 49 5 5 7 55 6 59 4 75 80 5 5 4 8 .7 .5 .5 .0 .8 .6 1 .1 1 .0 .5 7 .3 6 0 2 .0 7 2 4 .1 3 .7 4 .6 .6 5 5 6 0.

4 5 4 9 6 3 2.

8 1.

7 1 1.

0 3.

5.

1.

3 3.

0.

2.

1 6.

6 5.

7 3 1.

3.

0.

1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 61 B D 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 CH A 2 1 1 1 1 1 3 1 3 1 1 1 1 3 1 1 1 2 1 1 ECG ) P 4 8 8 0 8 6 0 8 6 0 8 0 6 B 92 7 7 7 7 9 88 7 74 8 5 82 7 58 7 6 7 84 82 7 D mmHg )( 8 2 0 2 0 6 6 4 8 2 2 2 6 BP 38 2 3 2 2 4 72 3 52 2 0 42 2 22 2 2 2 68 62 1 seline S 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 Ba (mmHg at le gin s @ ko 1 0 2 2 1 0 2 1 0 0 2 1 0 1 1 2 0 1 0 0 m Statu Variab S t is a os ) 6 7 3 3 6 9 8 8 1 1 2 4 1 (yr 47 5 3 3 3 4 57 2 56 5 3 49 4 66 4 3 5 54 51 5 Age iagnD .1 1 0 0 1 0 .2 8 .3 0 3 .7 0 .4 2 1 0 .1 .6 2 9 0.

1.

4.

8.

7.

1 8.

2 5.

1.

9 4.

9 3.

5.

7.

7 7 5.

BMI 2 3 3 3 3 3 3 3 2 2 3 5 3 2 4 3 3 2 2 2 ) 8 1 3 6 2 1 9 8 9 0 6 0 4 Age yr 57 5 5 3 3 5 64 3 69 5 3 49 4 68 4 3 6 74 61 5 ed alv e )( .5 3 6 4 0 0 .8 8 .8 8 1 .6 5 .2 5 5 3 .2 .0 4 inu m rvi 6 4.

1.

5.

1.

1.

4 4.

1 5.

4.

4 5.

7 4.

0.

4.

2 5 2.

Ti (yr 1 1 1 1 1 1 1 1 1 1 1 1 1 Su Cont 4 s ? u 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 tatS tn erciseTable3.

Ex Patie 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 62 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 2 3 2 1 2 1 1 1 1 2 2 1 8 8 8 0 8 6 8 8 6 0 8 6 6 0 8 6 6 6 82 9 9 8 7 8 7 6 5 8 60 8 7 92 9 7 7 7 78 7 60 8 8 0 2 0 6 4 2 0 0 4 8 0 4 4 0 6 2 0 6 26 8 3 5 0 5 2 3 2 4 34 4 7 60 5 2 3 5 62 3 20 6 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 0 1 0 1 2 2 1 1 1 1 0 0 2 1 1 0 2 0 0 1 2 1 2 4 5 8 1 8 5 0 8 6 8 7 7 8 9 7 34 4 4 5 5 5 3 5 3 4 79 6 6 33 3 4 5 4 66 3 37 4 4 .8 2 6 8 6 3 7 6 0 3 .4 1 3 .9 2 7 2 4 .8 0 .9 6 8 5 2.

1.

9.

6.

3.

7.

6.

5.

4.

9 3.

7.

6 0.

2.

3.

1.

5 4.

9 0.

0.

2 3 4 3 2 3 2 2 2 5 2 3 2 3 4 3 3 4 3 3 1 3 3 6 0 3 6 1 1 4 1 6 3 2 2 3 1 3 0 2 9 35 4 4 5 6 6 4 6 4 4 80 6 7 41 5 5 6 5 75 4 61 6 4 l.a rmo .1 4 3 6 5 3 8 2 3 3 .5 2 0 .3 3 0 8 4 .5 0 .3 6 5 1 5.

4.

5.

2.

2.

4.

0.

2.

0.

8 0.

0.

7 5.

4.

5.

1.

5 1.

7 0.

0.

1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 t.

abn 3, ren e.

e; v cur ali , , 2 erlin 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1 rd er; ob ead; ok , d m 2 es.

, y 0 al; , ex-s 1 us: ; rm ; o o o at n n n 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 ? St @ 0, A 1, B 0, 63 C H A P T E R 4 Nonparametric Methods of Estimating Survival Functions In this chapter we discuss methods of estimating the three survival (survivorship, density, and hazard) functions for censored data. Unfortunately, the simple method of Example 2.1 cannot be applied if some of the patients are alive at the time of analysis and therefore their exact survival times are unknown. Nonparametric or distribution-free methods are quite easy to understand and apply. They are less efficient than parametric methods when survival times followa theoretical distribution and more efficient w hen no suitable theoretical distributions are known. Therefore, we suggest using nonparametric methods to analyze survival data before attempting to fit a theoretical distribution. If the main objective is to find a model for the data, estimates obtained by nonparametric methods and graphs can be helpful in choosing a distribution.

Of the three survival functions, survivorship or its graphical presentation, the survival curve, is the most widely used. Section 4.1 introduces the product-limit (PL) method of estimating the survivorship function developed by Kaplan and Meier (1958). With the increased availability of computers, this method is applicable to small, moderate, and large samples. However, if the data have already been grouped into intervals, or the sample size is very large, say in the thousands, or the interest is in a large population, it may be more convenient to perform a life-table analysis. Section 4.2 is devoted to the discussion of population and clinical life tables. The PL estimates and life-table estimates of the survivorship function are essentially the same. Many authors use the term life-table estimates for the PL estimates. The only difference is that the PL estimate is based on individual survival times, whereas in the life-table method, survival times are grouped into intervals. The PL estimate can be considered as a special case of the life-table estimate where each interval contains only one observation.

64 -     65 In Section 4.3 we discuss three other measures that describe the survival experience: the relative survival rate, the five-year survival rate, and the corrected survival rate. In Section 4.4 we describe two methods, direct and indirect standardization, to adjust rates to eliminate the effect of differences in population composition with respect to age and other variables. In addition, it introduces the standardized mortality rate and standardized incidence rate.

4.1 PRODUCT-LIMIT ESTIMATES OF SURVIVORSHIP FUNCTION Let us first consider the simple case where all the patients are observed to death so that the survival times are exact and known. Let t, t, .. . , tL be the exact survival times of the n individuals under study. Conceptually, we consider this group of patients as a random sample from a much larger population of similar patients. We relabel the n survival times t, t, . .. , tL in ascending order such that t t   t L. Following (2.1.2) and (2.1.3), the survivorship function at t G can be estimated as n 9 i i S( t G) : : 1 9 (4 . 1 . 1) n n where n 9 i is the number of people in the sample surviving longer than t G . If two or more t G are equal (tied observations), the largest i value is used. For example, if t: t : t, then n 9 4 S( t) : S( t) : S( t) : n This gives a conservative estimate for the tied observations.

Since every person is alive at the beginning of the study and no one survives longer than t L, S( t) : 1 and S( t L) :0 (4 . 1 . 2) In practice, S( t) is computed at every distinct survival time. We do not have to worry about the intervals between the distinct survival times in which no one dies and S( t) remains constant. Equations (4.1.1) and (4.1.2) showthat S( t) is a step function starting at 1.0 and decreasing in steps of 1/ n (if there are no ties) to zero. When S( t) is plotted versus t, the various percentiles of survival time can be read from the graph or calculated from S( t). The following example illustrates the method.

Example 4.1 Consider a clinical trial in which 10 lung cancer patients are followed to death. Table 4.1 lists the survival times t in months. The function 66       Table 4.1 Computation of S( t) for 10 Lung Cancer Patients t i S( t) 4 1 : 0.9 5 2 : 0.8 6 3 : 0.7 8 4 : 0.4 8 5 : 0.4 8 6 : 0.4 10 7 : 0.2 10 8 : 0.2 11 9 : 0.1 12 10 : 0.0 S( t) is computed following (4.1.1) and plotted as a step function in Figure 4.1 a and as a smooth curve in Figure 4.1 b. The estimated median survival time is 8 months from Figure 4.1 a or 7.6 months from Figure 4.1 b. A more accurate estimate can be obtained using linear interpolation: t S( t) 6 0 . 7 m 0 . 5 8 0 . 4 8 9 6 : 89 m 0 . 4 9 0 . 7 0 . 4 9 0 . 5 m : 8 9 2(0 . 1) : 7 . 3(months) 0 . 3 Theoretically, S( t) should be plotted as a step function since it remains constant between two observed exact survival times. However, when the median survival time must be estimated from a survival curve, a smooth curve (such as Figure 4.1 b) may give a much better estimate than a step function, as indicated in the example.

This method can be applied only if all the patients are followed to death. If some of the patients are still alive at the end of the study, a different method of estimating S( t), such as the PL estimate given by Kaplan and Meier (1958), is required. The rationale can be illustrated by the following simple example.

Suppose that 10 patients join a clinical study at the beginning of 2000; -     67 Figure 4.1 Function S( t) of lung cancer patients in Example 4.1.

during that year 6 patients die and 4 survive. At the end of the year, 20 additional patients join the study. In 2001, 3 patients who entered in the beginning of 2000 and 15 patients who entered later die, leaving one and five survivors, respectively. Suppose that the study terminates at the end of 2001 and you want to estimate the proportion of patients in the population surviving for two years or more, that is, S(2).

The first group of patients in this example is followed for two years; the second group is followed for only one year. One possible estimate, the reduced-sample estimate, is S(2) : 1 / 10 : 0 . 1, which ignores the 20 patients who are followed only for one year. Kaplan and Meier believe that the second sample, under observation for only one year, can contribute to the estimate of S(2).

Patients who survived two years may be considered as surviving the first year and then surviving one more year. Thus, the probability of surviving for two years or more is equal to the probability of surviving the first year and then surviving one more year. That is, S(2) : P(surviving first year and then surviving one more year) which can be written as S(2) : P(surviving two years given patient has survived first year) ; P(surviving first year) (4.1.3) The Kaplan  Meier estimate of S(2) following (4.1.3) is S(2) : proportion of patients surviving two years given they survive for one year ;(proportion of patients surviving one year) (4.1.4) 68       For the data given above, one of the four patients who survived the first year survived two years, so the first proportion in (4.1.4) is . Four of the 10 patients who entered at the beginning of 2000 and 5 of the 20 patients who entered at the end of 2000 survived one year. Therefore, the second proportion in (4.1.4) is (4 ; 5)/(10 ; 20). The PL estimate of S(2) is S(2) : 1 ; 4 ; 5 : 0 . 25 ; 0 . 3 : 0 . 075 4 10 ; 20 This simple rule may be generalized as follows: The probability of surviving k (2) or more years from the beginning of the study is a product of k observed survival rates: S( k) : p ; p; p;    ; pI (4.1.5) where p denotes the proportion of patients surviving at least one year, p the proportion of patients surviving the second year after they have survived one year, p the proportion of patients surviving the third year after they have survived two years, and pI the proportion of patients surviving the k th year after they have survived k 9 1 years.

Therefore, the PL estimate of the probability of surviving any particular number of years from the beginning of study is the product of the same estimate up to the preceding year, and the observed survival rate for the particular year, that is, S( t) : S( t 9 1) pR (4 . 1 . 6) The PL estimates are maximum likelihood estimates.

In practice, the PL estimates can be calculated by constructing a table with five columns following the outline below.

1. Column 1 contains all the survival times, both censored and uncensored, in order from smallest to largest. Affix a plus sign to the censored observation. If a censored observation has the same value as an uncen- sored observations, the latter should appear first.

2. The second column, labeled i, consists of the corresponding rank of each observation in column 1.

3. The third column, labeled r, pertains to uncensored observations only.

Let r : i.

4. Compute ( n 9 r) /( n 9 r ; 1), or pG, for every uncensored observation t G in column 4 to give the proportion of patients surviving up to and then through t G.

-     69 5. In column 5, S( t) is the product of all values of ( n 9 r) /( n 9 r ; 1) up to and including t. If some uncensored observations are ties, the smallest S( t) should be used.

To summarize this procedure, let n be the total number of patients whose survival times, censored or not, are available. Relabel the n survival times in order of increasing magnitude such that t t  t L. Then n 9 r S( t) : (4 . 1 . 7) n 9 r ; 1 t P t where r runs through those positive integers for which t P t and t P is uncensored. The values of r are consecutive integers 1, 2, . . . , n if there are no censored observations; if there are censored observations, they are not.

The estimated median survival time is the 50th percentile, which is the value of t at S( t) : 0 . 50. The following example illustrates the calculation procedures.

Example 4.2 Suppose that the following remission durations are observed from 10 patients ( n : 10) with solid tumors. Six patients relapse at 3.0, 6.5, 6.5, 10, 12, and 15 months; 1 patient is lost to follow-up at 8.4 months; and 3 patients are still in remission at the end of the study after 4.0, 5.7, and 10 months. The calculation of S( t) is shown in Table 4.2.

The survivorship function S( t) is plotted in Figure 4.2; the estimated median remission time is m : 9 . 8 months. From the calculation we notice that S( t) at Table 4.2 Calculation of the PL Estimate of S( t) for Data in Example 4.2 Remission Time Rank t i r ( n 9 r) /( n 9 r ; 1) S( t) 3 . 0 1 1 : 0 . 900 4 . 0; 2    5.7; 3    6.5 4 4 ; : 0.771 ?

6.5 5 5 ;; : 0.643 ?

8.4; 6    10.0 7 7 ;;; : 0.482 10.0; 8    12.0 9 9 ;;;; : 0.241 15.0 10 10 0 0 ? 0.643 is used as S(6 . 5) . It is a conservative estimate.

70       Figure 4.2 Function S( t) of Example 4.2.

t : t G is related to S( t) at t: t G\ and (4.1.6) can be rewritten as n 9 i S( t G) : S( t G\) (4.1.8) n 9 i ; 1 where t G and t G\ are uncensored observations. For example, S(12) : S(10) ; :0 . 482;:0 . 241 If there are no censored observations or losses before t, (4.1.7) is equivalent to (4.1.1).

The variance of the PL estimate of S( t) is approximated by 1 Var[ S( t)] < [ S( t)] (4 . 1 . 9) P ( n 9 r)( n 9 r ; 1) where r includes those positive integers for which t P t and t P corresponds to a death. For the data in Example 4.2, for example, Var[ S(10)] : (0 . 482) 1 ; 1 ; 1 ; 1 9 ; 10 6 ; 7 5 ; 6 3 ; 4 : 0 . 0352 and the estimated standard error is 0.1876. In Example 4.1, Var[ S(6)] : (0 . 7) 1 ; 1 ; 1 :0 . 0210 9 ; 10 8 ; 9 7 ; 8 -     71 and the estimated standard error is 0.145. The variance may be used to obtain confidence intervals for S( t).

Calculation of the PL estimate of S( t) in Example 4.2 can also be obtained by using statistical software. Let t denote the observed remission time (uncensored or censored) in Table 4.2 and CENS denote an index (or dummy) variable with CENS : 0 if t is censored and 1 otherwise. Assume that the data have been saved in C:D4d2.DAT as a text file, which contains two columns, t and CENS, separated by a space.

The following SAS code can be used to obtain the PL estimate of S( t) in Table 4.2. One can adopt this code to obtain the PL estimate of S( t) for any observed uncensored or censored survival time data.

data w1; infile c:d4d2.dat missover; input t cens; run; proc lifetest data : w1 outsurv : wa; time t*cens(0); run; title PL estimate of survival function; proc print data : wa; run; If BMDP 1L is used, the following code can be used.

/input file : c:d4d2.dat.

variables : 2.

format : free.

/variable names : t, cens.

/form time : t.

status : cens.

response : 1.

/estimate method : product.

Print.

/end If the SPSS KM procedure is used, the following code can be used.

data list file : c:d4d2.dat free / t cens.

km t /status : cens event (1) /print.

Example 4.3 Consider the tumor-free time in days of the 30 rats on a low-fat diet in Table 3.4. Table 4.3 gives the calculations of the PL estimates of S( t) and the standard error of S( t). The estimated S( t) is plotted in Figure 3.3.

The median tumor-free time is approximately 189 days.

.0550 6 : 040.

28 S( t) 1 : ; of 27 or .033 ; rr 0 29 29 E 1 ; 1 ; ard : 28 28 ; ; .43 tand 30 30 30 S 1 ; 1 ; 1 ; ble 29 29 29 Tan ) ) ) 7 3 0 96 93 90 2 8 3 7 1 4 6 8 6 6 7 7 8 8 8 8 (0.

(0.

(0. .0 .0 .0 .0 .0 .0 .0 .0 0 0 0 0 0 0 0 0 atDietiF ow- 7 3 0 7 L 6 a 9 93 90 86 0.

0.

0.

0.

no : : : : ts a S( t) R ; ; ; 7 3 0 3 0 7 3 0 7 3 30 96 93 90 83 80 76 73 70 66 63 0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

for S( t) 1 r of ; 9 r  or n 9 rr n E ard r 1 2 3 4 5 6 7 8 9 01 11  tandS 1 2 3 4 5 6 7 8 9 0 and 1 11 12 S( t)fo ree ti r-f ; ation o me 0 5 7 6 9 0 0 56 66 73 84 87 1 4 4 Ti 1 1 1 lcul umT Ca .34 er ble t mb a 35 46 97 58 1 Ta R Nu 12 13 14 10 11 15 16 72 0 1 2 2 9 9 9 9 .0 .0 .0 .0 0 0 0 0               8 3 59 56 0.

0.

: : ; ; 3 8 8 3 63 59 52 49 0.

0.

0.

0.

13 14 15 16               13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ; ; ; ; ; ; ; ; ; ; ; ; ; ; 3 7 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 7 8 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 7 8 17 18 19 20 21 22 23 24 25 26 27 28 29 30 73 74       The mean survival time can be shown to equal the area under the estimated survivorship function. To estimate , we can use : S( t) dt that is, is equal to the area under the estimated survivorship function. Thus, if the times to death are ordered as t t    t K (if there are m uncensored observations) and t K is the largest observation of all n observations [i.e., t K : t L when t L is an uncensored observation], can be estimated as : 1.000 t ; S( t)( t 9 t) ; S( t)( t 9 t) ;    ; S( t K\)( t K 9 t K\) (4.1.10) which is the sum of the areas of the rectangles under the survival curve formed by the uncensored observations. Consider the data in Example 4.2: m : 6, t : 3 . 0, t : 6 . 5, t : 6 . 5, t : 10, t : 12, and t : 15 . The mean survival time is estimated using (4.1.10) as : 1.000 ; 3.0 ; 0.900(6.5 9 3.0) ; 0.643(10 9 6.5) ; 0.482(12 9 10) ; 0.241(15 9 12) : 3.000 ; 3.150 ; 2.251 ; 0.964 ; 0.723 : 10.088 months However, if the largest observation in the data is censored and is used as t K in (4.10), so obtained may be a lowestimate. In such cases, Irwin (1949) suggests that instead of estimating the mean survival time, one should choose a time limit L and estimate the mean survival time limited to a time L , say *, by using L for t K in (4.1.10). For example, if in Example 4.2 the largest observation is censored, that is, 15;, and if we let L : 16, then :3.000;3.150;;2.251;0.964;0.241(16912) : 10.329 months which is the mean survival time limited to 16 months.

The variance of is estimated by A Var() : P (4 . 1 . 11) P ( n 9 r)( n 9 r ; 1) where r runs through those integers for which tP corresponds to a death, and -     75 AP is the area under the curve S( t) to the right of t P. The k th AP in terms of the m uncensored observations is S( t I)( t I> 9 k I) ; S( t I> )( t I> 9 t I> ) ;    ; S( t K\)( t K 9 t K\) (4 . 1 . 12) If there are no censored observations, (4.1.10) reduces to the sample mean t : tG/n, and (4.1.11) reduces to ( t Var() : Var( t ) : G 9 t ) n (4 . 1 . 13) which is not an unbiased estimate. Kaplan and Meier suggest that (4.1.11) and (4.1.13) be multiplied by m/( m 9 1) and n/( n 9 1), respectively, to correct the bias.

Consider the survival times in Example 4.1: The sample mean is t : : 8 . 2 months and the estimated variance of , by (4.1.13), is 0.616. If the factor n/( n 9 1) : 10 / 9 is multiplied, the estimated variance of becomes 0.684.

To compute the variance of in Example 4.2, we first compute the five APs: A, A, A, A, and A. The first AP is A: S( t)( t 9 t) ; S( t)( t 9 t) ;  ; S( t)( t 9 t) : 3 . 150 ; 2 . 251 ; 0 . 964 ; 0 . 723 : 7 . 088 The second AP is A: S( t)( t 9 t) ;  ; S( t)( t 9 t) : 2 . 251 ; 0 . 964 ; 0 . 723 : 3 . 938 The third, fourth, and fifth APs are, respectively, A :2 . 251;0 . 964;0 . 723: 3 . 938 A :0 . 964;0 . 723:1 . 687 A :0 . 723 Thus, (7.088) (3.938) (3.928) (1.687) (0.723) Var () : ; ; ; ; : 1.942 9 ; 10 6 ; 7 5 ; 6 3 ; 4 1 ; 2 The estimated standard error of is 1.394. If the factor m/( m 9 1) : 6 / 5 is included, these results become 2.330 and 1.526, respectively.

The Kaplan  Meier method provides very useful estimates of survival probabilities and graphical presentation of survival distribution. It is the most 76       widely used method in survival data analysis. Breslow and Crowley (1974) and Meier (1975b) have shown that under certain conditions, the estimate is consistent and asymptomatically normal. However, a few critical features should be mentioned.

1. The Kaplan  Meier estimates are limited to the time interval in which the observations fall. If the largest observation is uncensored, the PL estimate at that time equals zero. Although the estimate may not be welcomed by physicians, it is correct since no one in the sample lives longer. If the largest observation is censored, the PL estimate can never equal zero and is undefined beyond the largest observation.

2. The most commonly used summary statistic in survival analysis is the median survival time. A simple estimate of the median can be read from survival curves estimated by the PL method as the time t at which S( t) : 0 . 5. However, the solution may not be unique. Consider Figure 4.3 a, where the survival curve is horizontal at S( t) : 0 . 5; any t value in the interval t to t is a reasonable estimate of the median. A practical solution is to take the midpoint of the interval as the PL estimate of the median. Figure 4.3 b presents a different case in which the straightforward estimate ( t) tends to overestimate the median. A practical way to handle this problem is to connect the points and locate the median.

3. If less than 50% of the observations are uncensored and the largest observation is censored, the median survival time cannot be estimated. A practical way to handle the situation is to use probabilities of surviving a given length of time, say 1, 3, or 5 years, or the mean survival time limited to a given time t.

4. The PL method assumes that the censoring times are independent of the survival times. In other words, the reason an observation is censored is unrelated to the cause of death. This assumption is true if the patient is Figure 4.3 Kaplan  Meier estimate of median survival time.

-  77 still alive at the end of the study period. However, the assumption is violated if the patient develops severe adverse effects from the treatment and is forced to leave the study before death or if the patient died of a cause other than the one under study (e.g., death due to automobile accidents in a cancer survival study). When there is inap- propriate censoring, the PL method is not appropriate. In practice, one way to alleviate the problem is to avoid it or to reduce it to a minimum.

5. Similar to other estimators, the standard error (S.E.) of the Kaplan  Meier estimator of S( t) gives an indication of the potential error of S( t).

The confidence interval deserves more attention than just the point estimate S( t). A 95% confidence interval for S( t) is S( t) ; 1 . 96 S.E. [ S( t)] .

4.2 LIFE-TABLE ANALYSIS The life-table method is one of the oldest techniques for measuring mortality and describing the survival experience of a population. It has been used by actuaries, demographers, governmental agencies, and medical researchers in studies of survival, population growth, fertility, migration, length of married life, length of working life, and so on. There has been a decennial series of life tables on the entire U.S. population since 1900. States and local governments also publish life tables. These life tables, summarizing the mortality experience of a specific population for a specific period of time, are called population life tables. As clinical and epidemiologic research become more common, the life-table method has been applied to patients with a given disease who have been followed for a period of time. Life tables constructed for patients are called clinical life tables. Although population and clinical life tables are similar in calculation, the sources of required data are different.

4.2.1 Population Life Tables There are two kinds of population life tables: the cohort life table and current life table. The cohort life table describes the survival or mortality experience from birth to death of a specific cohort of persons who were born at about the same time, for example, all persons born in 1950. The cohort has to be followed from 1950 until all of them die. The proportion of death (survivor) is then used to construct life tables for successive calendar years. This type of table, useful in population projection and prospective studies, is not often constructed since it requires a long follow-up period.

The current life table is constructed by applying the age-specific mortality rates of a population in a given period of time to a hypothetical cohort of 100,000 or 1,000,000 persons. The starting point is birth at year 0. Two sources of data are required for constructing a population life table: (1) census data on 78       the number of living persons at each age for a given year at midyear and (2) vital statistics on the number of deaths in the given year for each age. For example, a current U.S. life table assumes a hypothetical cohort of 100,000 persons that is subject to the age-specific death rates based on the observed data for the United States in the 1990 census. The current life table, based on the life experience of an actual population over a short period of time, gives a good summary of current mortality. This type of life table is regularly published by government agencies of different levels. One of the most often reported statistics from current life tables is the life expectancy. The term population life table is often used to refer to the current life table.

In the United States, the National Center for Health Statistics publishes detailed decennial life tables after each decennial census. These complete life tables use one-year age groups. Between censuses, annual life tables are also published. The annual life tables are often seen in five-year age intervals and are called abridged life tables. Tables 4.4 and 4.5 are, respectively, a complete decennial life table for the total U.S. population for 1989  1991 and an abridged life table for the same population for 1998. The abridged table in Table 4.5 was constructed based on a complete life table.

Current life tables usually have the following columns: 1. Age interval [ x to x ; t). This is the time interval between two exact ages x and x ; t; t is the length of the interval. For example, the interval 20  21 includes the time interval from the 20th birthday up to the 21st birthday (but not including the 21st birthday).

2. Proportion of persons alive at beginning of age interval but dying during the interval ( RqV). The information is obtained from census data. For example, ( RqV) for age interval 20  21 is the proportion of persons who died on or after their 20th birthday and before their 21st birthday. It is an estimate of the conditional probability of dying in the interval given the person is alive at age x. This column is usually calculated from data of the decennial census of population and deaths occurring in the given time interval. For example, the mortality rates in Table 4.4 are calculated from the data of the 1990 Census of Population and deaths occurring in the United States in the three years 1989  1991. This column is the foundation of the life table from which all of the other columns are derived.

3. Number living at beginning of age interval ( lV). The initial value of lV, the size of the hypothetical population, is usually 100,000 or 1,000,000. The successive values are computed using the formula lV: lV\(1 9 RqV\ R) (4.2.1) where 1 9 RqV\ R is the proportion of persons who survived the previous age interval. For example, in Table 4.4, t : 1, l: l(1 9 q) : -  79 98,314(1 9 0 . 00101) : 98,215, which is the number of persons living at the beginning of age 20.

4. Number dying during age interval ( RdV) RdV : lV( RqV) : lV 9 lV> (4 . 2 . 2) For example, the number of persons dying during age interval 20  21, Rd : 98,215(0 . 00104) : 102 (or d : 98,215 9 98,113 : 102) .

5 . Stationary population ( RL V and TV). Here RL V is the total number of years lived in the i th age interval or the number of person-years that lV persons, aged x exactly, live through the interval. For those who survive the interval, their contribution to RL V is the length of the interval, t. For those who die during the interval, we may not know exactly the time of death and the survival time must be estimated. The conventional assumption is that they live one-half of the interval and contribute t/ 2 to the calculation of RL V. Thus, RL V : t( lV> ; RdV) (4.2.3) For example, in Table 4.4, L :98,113;102 / 2:98,164. If we do know the exact survival time of those who die in the interval, RL V should be computed accordingly.

The symbol TV is the total number of person-years lived beyond age t by persons alive at that age, that is, TV: RL H (4 . 2 . 4) j x and TV: RL V; TV>R (4 . 2 . 5) For example, in Table 4.4, T:7,536,614, which is the sum of all RL V values in column 5, and T:7,437,356, which is T 9 L :7,536,614999,258 .

6. Average remaining lifetime or average number of years of life remaining at beginning of age interval ( e G). This is also known as the life expectancy at a given age, which is defined as the number of years remaining to be lived by persons at age x: T e V V : (4 . 2 . 6) lV The expected age at death of a person aged x is x ; e V. The e V at x :0 is the life expectancy at birth. For example, according to the U.S. life em t eti f a of al if o ifeL g age L er f in ng 7 3 1 4 7 8 3 7 9 2 3 5 7 8 g age b o terv in e .3 .6 .7 .7 .3 .0 .1 .1 .1 .2 .2 .2 .2 .2 in m 5 5 5 5 5 5 4 3 2 1 0 9 8 7 rs a nni In 7 7 7 7 7 7 7 7 7 7 7 6 6 6 Aver n Aver u a m N egi ge Ye Re B A emaiR s ll ent s hi A u ,614 ,340 ,703 ,981 ,614 ,356 ,328 ,360 ,434 ,542 ,679 ,840 ,026 ,232 T V eq rval Age T In and bs Inte ,536 ,536 ,534 ,528 ,536 ,437 ,338 ,239 ,140 ,041 ,942 ,843 ,745 ,646 n 7 7 7 7 7 7 7 7 7 7 6 6 6 6 Su ry o nao latiu ati op St P e 4 7 2 5 8 8 8 6 2 3 9 4 4 4 th ge V 7 3 2 2 5 2 6 2 9 6 3 1 9 7 2 6 7 6 2 0 9 9 8 8 8 8 7 7 A erval L In 1, 5, Int 91, 99, 99, 98, 98, 98, 98, 98, 98, 98, 98, er g la b in VR 1 4 4 7 6 2 8 7 0 7 4 3 0 7 5 3 0 4 3 7 4 3 3 2 2 2 2 1 ying d 3 1 1 3 9 --1991 um ur Age D N D Interv 9891 000 ive Al tes, 00, a 1f rn St O Bo d r t g a l 0 9 5 1 0 4 2 4 7 7 0 6 3 3 be inn geA l VR 00 64 51 41 00 06 99 94 90 87 85 82 80 78 Unite um iving gin fo 00, 99, 99, 99, 00, 99, 98, 98, 98, 98, 98, 98, 98, 98, n, N L Interva 1 1 o Be ati pul f Po of e o g on liv in l ti g on A ing rval ur 1 5 4 9 6 3 8 7 0 7 5 3 0 8 Total in ti D Vq por or R ons ginn Inte g terva .0035 .0013 .0010 .0034 .0093 .0007 .0004 .0003 .0003 .0002 .0002 .0002 .0002 .0001 the o Dy op in In 0 0 0 0 0 0 0 0 0 0 0 0 0 0 r Pr ers Be y Age fo Pr P at D e Tabl ges fe A e Li o Lif wT t .4 of 4 n ; 1 7 28 365 1 2 3 4 5 6 7 8 9 10               od x 0 1 7 s 0 1 2 3 4 5 6 7 8 9 ble e erval ys 28 g ri to ar Ta A Int Pe Betwee x Da Ye 80 ) f rleave 9 0 1 3 5 8 1 6 1 7 3 9 5 1 7 3 9 5 1 7 3 0 7 4 1 8 6 3 1 0 o .2 .3 .3 .3 .3 .3 .4 .4 .5 .5 .6 .6 .7 .8 .8 .9 .9 .0 .1 .1 .2 .3 .3 .4 .5 .5 .6 .7 .8 .9 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 0 9 8 7 6 5 4 3 2 1 0 9 8 ed 6 6 6 6 6 6 6 5 5 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 3 3 uinnt ( Co ,458 ,700 ,958 ,235 ,538 ,880 ,276 ,742 ,289 ,927 ,662 ,498 ,438 ,487 ,647 ,920 ,306 ,807 ,426 ,165 ,030 ,028 ,166 ,449 ,886 ,482 ,246 ,186 ,312 ,631 ,547 ,448 ,349 ,251 ,152 ,053 ,955 ,856 ,758 ,659 ,561 ,463 ,365 ,267 ,169 ,071 ,974 ,876 ,779 ,682 ,585 ,488 ,391 ,294 ,197 ,101 ,005 ,909 ,813 ,717 6 6 6 6 6 6 5 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 4 3 3 3 8 2 3 7 8 4 4 3 2 5 4 0 1 0 7 4 9 1 1 5 2 2 7 3 4 6 0 4 1 7 5 4 2 9 5 0 3 5 6 6 6 6 5 4 2 1 9 8 6 3 0 6 1 6 0 3 6 7 8 7 7 7 7 6 6 6 5 4 3 2 1 0 9 8 7 6 4 3 2 1 0 8 7 5 4 2 0 8 6 4 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 97, 97, 97, 97, 97, 97, 97, 97, 97, 96, 96, 96, 96, 96, 96, 95, 95, 95, 6 6 1 2 6 2 6 8 5 9 2 7 0 2 3 5 5 9 3 9 6 3 9 7 3 2 1 9 9 8 1 1 2 3 4 6 7 8 9 9 0 0 1 1 1 1 1 1 2 2 3 4 4 5 6 7 8 8 9 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 6 0 4 3 1 5 3 7 9 4 5 3 6 6 4 1 6 1 2 9 0 4 1 2 5 2 0 9 0 1 76 75 73 71 68 63 57 49 40 31 21 11 00 89 78 67 55 44 32 19 07 93 79 64 48 32 15 96 78 58 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 97, 97, 97, 97, 97, 97, 97, 97, 96, 96, 96, 96, 96, 96, 95, 95, 95, 6 6 2 2 7 3 7 9 6 1 4 9 2 4 6 7 9 1 6 3 0 7 4 2 0 8 8 8 7 7 .0001 .0001 .0002 .0003 .0004 .0006 .0007 .0008 .0009 .0010 .0010 .0010 .0011 .0011 .0011 .0011 .0011 .0012 .0012 .0013 .0014 .0014 .0015 .0016 .0017 .0017 .0018 .0019 .0020 .0021 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40                               10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 81 em t eti f a of al if o ifeL g age L er f in ng 8 6 5 4 4 4 4 5 7 0 3 7 2 8 5 3 g age b o terv in e .9 .0 .1 .2 .3 .4 .5 .6 .7 .9 .0 .1 .3 .4 .6 .8 in m 7 7 6 5 4 3 2 1 0 9 9 8 7 6 5 4 rs a nni In 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 Aver n Aver u a m N egi ge Ye Re B A emaiR s ll ent s hi A u ,154 ,889 ,847 ,039 ,480 ,188 ,183 ,491 ,141 ,161 ,582 ,438 ,767 ,612 ,021 ,043 T V eq rval Age T In and bs Inte ,622 ,526 ,431 ,337 ,242 ,148 ,054 ,960 ,867 ,774 ,681 ,589 ,497 ,406 ,316 ,226 n 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 Su ry o nao latiu ati op St P e 5 2 8 9 2 5 2 0 0 9 4 1 5 1 8 1 th ge V 6 4 0 5 9 0 9 5 8 7 4 7 5 9 7 1 2 0 8 5 2 0 6 3 9 5 1 6 1 5 9 3 A erval L In Int 95, 95, 94, 94, 94, 94, 93, 93, 92, 92, 92, 91, 91, 90, 89.

89, er g la b in VR 7 8 1 7 7 9 7 5 6 7 2 4 9 8 9 3 1 2 4 5 7 9 2 5 8 1 5 9 3 8 3 9 ying d 2 2 2 2 2 2 3 3 3 4 4 4 5 5 6 6 um ur Age D N D Interv 000 ive Al 00,1f rn O Bo r t g a l be in 3 6 8 7 1 4 5 8 3 7 0 8 4 5 7 8 n geA l VR 37 15 92 68 43 15 85 52 17 78 37 91 42 88 29 65 um iving gin f N o 95, 95, 94, 94, 94, 94, 93, 93, 93, 92, 92, 91, 91, 90, 90.

89, L Interva Be f of e o g on liv in l ti g on A ing rval ur 8 0 4 1 2 8 8 0 4 9 0 7 0 7 8 3 in ti D Vq por or Inte g terva R o Dy ons ginn .0022 .0024 .0025 .0027 .0029 .0031 .0034 .0038 .0041 .0044 .0049 .0053 .0059 .0064 .0070 .0077 op in In 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Pr ers Be y Pr P Age at D nued ges nti A e Co o Lif wT t .4 of 4 n ; 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56                 od x ble e erval 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 g ri to Ta A Int Pe Betwee x 82 ) f rleave 2 2 3 6 0 5 1 9 8 8 9 1 5 9 6 3 3 4 6 0 6 o .0 .2 .4 .6 .9 .1 .4 .6 .9 .2 .5 .9 .2 .5 .9 .3 .7 .1 .5 .0 .4 92 40 89 40 93 48 04 63 23 4 3 2 1 0 0 9 8 7 7 6 5 5 4 3 3 2 2 1 1 0 9.

9.

8.

8.

7.

7.

7.

6.

6.

ed 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 uinnt ( Co ,732 ,143 ,337 ,386 ,365 ,352 ,422 ,654 ,127 ,924 ,131 ,833 ,114 ,067 ,795 ,411 ,034 ,785 ,782 ,131 ,930 ,266 ,227 ,904 ,390 ,783 ,174 ,631 ,196 ,872 5 5 7 0 6 5 5 9 5 3 5 9 7 7 1 7 9 2 5 9 2 6 0 4 9 4 9 4 0 6 3 9 ,136 ,048 ,960 ,873 ,787 ,702 ,618 ,535 ,454 ,373 ,295 ,217 ,142 ,068 9 9 8 7 7 6 6 5 4 4 3 3 3 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 9 6 1 1 3 0 8 7 3 3 8 9 7 2 4 7 9 3 1 1 4 9 3 4 7 9 3 5 4 8 8 0 5 2 1 3 6 2 0 9 9 1 4 7 8 7 4 0 5 0 6 3 2 1 0 0 4 3 2 2 5 8 9 0 0 9 7 5 2 7 2 7 0 2 3 3 2 0 6 2 6 0 3 5 6 6 5 4 3 2 88, 87, 86, 86, 85, 83, 82, 81, 80, 78, 77, 75, 74, 72, 70, 68, 66, 64, 61, 59, 56, 54, 51, 48, 45, 42, 39, 36, 33, 30, 1 7 1 9 7 2 9 2 8 3 5 4 1 9 6 7 0 2 3 4 2 9 1 9 5 8 7 8 6 3 5 1 9 7 4 2 9 8 6 5 3 2 2 2 4 6 9 0 0 9 8 6 6 5 5 3 9 1 0 8 7 8 8 6 ,0 ,1 ,1 ,2 ,3 .4 ,5 ,6 ,7 ,8 ,9 ,0 ,1 ,3 ,4 ,4 ,5 ,6 ,7 .8 ,9 ,0 ,0 ,1 ,1 ,0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 5 4 7 6 7 0 8 9 7 9 6 1 7 6 7 1 4 4 2 9 5 3 4 3 4 9 1 4 6 0 96 21 39 50 53 49 36 16 88 51 06 53 90 18 35 41 34 15 85 44 95 37 70 94 08 12 09 99 87 77 88, 88, 87, 86, 85, 84, 83, 82, 80, 79, 78, 76, 74, 73, 71, 69, 67, 65, 62, 60, 57, 55, 52, 49, 47, 44, 41, 37, 34, 31, 4 6 9 0 3 8 9 0 1 7 7 1 7 9 7 9 1 4 4 6 5 9 9 3 7 5 5 7 7 5 .0084 .0092 .0101 .0112 .0122 .0132 .0143 .0156 .0169 .0182 .0196 .0212 .0229 .0249 .0272 .0297 .0325 .0353 .0382 .0412 .0445 .0481 .0523 .0572 .0627 .0688 .0753 .0820 .0890 .0970 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86                               56 57 58 59 60 61 62 63 64 65 66 67 69 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 83 em t eti f a of al if o ifeL g age L er f in ng g age b o terv in e 84 48 13 81 50 21 in m rs a nni In 5.

5.

5.

4.

4.

4.

Aver n Aver u a m N egi ge Ye Re B A emaiR s ll ent s hi A u T V eq rval ,644 ,481 ,333 ,113 ,698 ,941 Age T 5 6 0 9 7 6 In and bs Inte 167 140 116 n Su ry o nao latiu ati op St P e 3 8 0 5 7 6 th ge V 6 4 2 1 5 6 1 1 2 4 7 2 A erval L In Int 27, 24, 21, 18, 15, 13, er g la b in VR 9 0 5 7 0 0 4 8 7 3 8 0 ying d um ur Age ,0 ,9 ,8 ,7 ,5 ,4 D 3 2 2 2 2 2 N D Interv 000 ive Al 00,1f rn O Bo r t g a l be in 7 8 8 3 6 6 n geA l VR 68 63 65 78 04 46 um iving gin f N o 28, 25, 22, 19, 17, 14, L Interva Be f of e o g on liv in l ti g on A ing rval ur 7 5 8 4 5 1 in ti D Vq por or Inte g terva R o Dy ons ginn .1062 .1162 .1268 .1383 .1513 .1659 op in In 0 0 0 0 0 0 Pr ers Be y Pr P Age at D nued ges nti A e Co o Lif wT t .4 of 4 n ; 87 88 89 90 91 92       od x ble e erval 86 87 88 89 90 91 g ri to Ta A Int Pe Betwee x 84 stics, tati 9 9 9 S 95 71 49 29 10 93 77 61 46 32 19 05 93 81 70 .5 .4 .3 3.

3.

3.

3.

3.

2.

2.

2.

2.

2.

2.

2.

1.

1.

1.

1 1 1 th ealHrfo ter enC 5 9 4 9 4 2 nal ,675 ,700 ,782 ,666 ,091 ,810 ,591 ,219 ,508 ,300 ,468 911 547 318 178 o 7 7 5 3 2 1 4 36 27 20 15 10 atiN -1, 150 8-1-9S 5 0 6 5 3 H 7 18 16 75 81 19 72 11 08 32 57 64 29 4 83 4 2 1 P 9 ,9 ,1 ,5 ,2 ,2 ,3 ,7 ,2 8 5 3 2 1 n 8 7 5 4 3 2 1 1 10, tio lica PubSHHD 2 3 9 4 4 9 6 5 3 9 9 9 9 0 5 7 6 8 , 8 7 4 2 1 ,1 93 66 41 17 94 74 57 43 31 22 15 10 2 1, 1, 1, 1, ablesT ifeL .S.U,1.o 6 4 1 2 8 4 5 9 4 1 2 3 4 5 5 0 3 7 8 5 8 6 9 4 9 2 9 7 4 8 7 0 6 3 1 06 ,N ,8 ,9 ,2 ,8 ,6 ,7 ,9 ,4 9 6 4 2 1 1 9 7 6 4 3 2 1 1 12, l.1o ,V 99119 198 8 2 0 2 6 9 5 1 8 2 9 4 3 4 3 7 5 5 for .1808 .1955 .2100 .2250 .2412 .2568 .2717 .2875 .3041 .3218 .3404 .3602 .3811 .4032 .4266 .4513 .4775 .5052 les 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 baTeifL .

ial 997 nn 1 ece C, D D .

, .S 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 on                   U: ingt 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 rce Sou Wash 85 y nc gn ta rval, ni ec in Inte .7 .3 .4 .4 .5 .7 .0 .2 .5 .8 .3 .8 .5 .5 .8 .3 .3 .6 .3 .7 .5 .6 xp e V 6 6 2 7 2 7 3 8 3 8 4 9 5 1 7 4 8 6 4 3 2 eg 7 7 7 6 6 5 5 4 4 3 3 2 2 2 1 1 11 E B 01.

t Age 0 ife a 2 L of ,CD, s t n hi en to T u s, g in 0 0 4 1 4 8 8 8 8 0 0 9 0 4 4 0 3 3 seq 0 3 4 7 1 8 6 1 7 5 8 6 3 6 8 2 60 76 50 5 3 83 hin nary n erval V 4 0 2 7 7 7 9 5 6 2 5 7 9 9 6 3 ,6 ,1 ,6 ,7 ,7 ,5 as o Sub T 6 4 4 W Int 8 2 , 718 432 218 lati ll e ,671, ,572, ,175, ,679, ,184, ,690, ,198, ,709, ,222, ,739, ,260, ,788, ,326, ,879, ,455, ,064, Statio u A g 7 7 7 6 6 5 5 4 4 3 3 2 2 1 1 1 stics po A P tati and Sh alt the l, He y in r ar 0 6 3 7 6 0 0 0 8 0 1 9 6 0 4 0 4 6 7 0 0 3 fo n terva V 7 8 7 5 2 2 5 4 2 7 1 3 6 8 6 6 8 2 9 2 5 8 3 7 4 0 9 8 4 8 4 6 8 8 9 2 3 6 4 5 8 0 1 5 ter tion L 4, atio In 99, 62, 20, ta 396, 495, 495, 493, 491, 489, 486, 483, 478, 471, 461, 446, 424, 391, 345, 286, 213, 131, en S ge Cl opul A a P n tio 998 a 1 N,8 es, gn 1 , .o Stat Dyi Age 8 5 1 6 3 8 21 38 8 09 49 69 78 86 95 32 44 97 52 11 32 6 1 8 2 4 05 61 N d g VR , er n erval d 7 1 1 3 4 4 5 7 ,1 ,6 ,3 ,6 ,5 ,7 5 1 9 9 4 ,4 ,7 48 ite ri 1 1 2 3 5 7 5 1 10, 13, 15, 15, 11, l.

mb u Int o Un D V n, Nu rts,op Re pulatio gn of l, cs Po ti ng 0 9 1 3 4 5 6 8 2 7 5 1 4 2 1 9 4 3 7 4 6 1 tis tal Livi terva 0 7 4 5 4 9 2 4 6 6 3 9 9 4 3 9 3 2 3 1 6 6 0 2 1 0 9 5 1 6 0 2 1 4 0 4 9 1 6 5 5 6 1 7 ta inni l VR S To er In 7, 1, eg 99, 99, 99, 98, 98, 98, 97, 97, 96, 95, 93, 91, 87, 81, 74, 63, 50, 34, 18, mb ge 100, ital the Bt A V r Nu a fo nal atio able g N T n . 8 e yi , if D Age L 199 n 21 39 89 10 53 76 87 00 19 76 28 64 09 02 37 39 04 41 04 02 26 00 g V d n erval q R es, rtio ri .007 .001 000 001 003 004 004 006 008 011 017 025 040 063 094 142 206 316 461 615 .754 000 o u Int 0 0 0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0 1.

Tabl ridge po D ife Ab Pr L .S.

.54 0 U 1 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 10 : ble                      ; 0 1 5 0 rce 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 Ta Age 10 Sou 86 -  87 table for 1989  1991 the life expectancy at birth is 75.37 years and that at age 40 is 37.98 years. This means that according to the mortality rates of 1989  1991 newborns are expected to live 75.37 years and those at age 40 are expected to live another 37.98 years. The life expectancy of a population is a general indication of the capability of prolonging life. It is used to identify trends and to compare longevity. Table 4.5 shows that according to the mortality rates of 1998, the newborns and those at age 40 are expected to live 76.7 and 38.8 years, respectively. The overall life expectancy indicates an improvement in longevity in the United States over the time period.

Population life tables can be constructed for various subgroups. For example, there are published life tables by gender, race, cause of death, as well as those which eliminate certain causes of death.

4.2.2 Clinical Life Tables The actuarial life table method has been applied to clinical data for many decades. Berkson and Gage (1950) and Cutler and Ederer (1958) give a life-table method for estimating the survivorship function; Gehan (1969) provides methods for estimating all three functions (survivorship, density, and hazard).

The life-table method requires a fairly large number of observations, so that survival times can be grouped into intervals. Similar to the PL estimate, the life-table method incorporates all survival information accumulated up to the termination of the study. For example, in computing a five-year survival rate of breast cancer patients, one need not restrict oneself only to those patients who have entered on study for five or more years. Patients who have entered for four, three, two, and even one year contribute useful information to the evaluation of five-year survival. In this way, the life-table technique uses incomplete data such as losses to follow-up and persons withdrawn alive as well as complete death data.

Table 4.6 shows the format of the clinical life table. The columns are described below.

1. Interval [ tG ; tG> ). The first column gives the intervals into which the survival times and times to loss or withdrawal are distributed. The interval is from tG up to but not including tG> , i: 1, .. . , s. The last interval has an infinite length. These intervals are assumed to be fixed.

2. Midpoint ( tKG). The midpoint of each interval, designated tKG, i: 1, ... , s 9 1, is included for convenience in plotting the hazard and probability density functions. Both functions are plotted as tKG.

3. W idth ( bG). The width of each interval, bG : tG> 9 tG, i :1, . . . , , s 91, is needed for calculation of the hazard and density functions. The width ) rd ) ) ) ) za a  H h( t KG h( t KG h( t K h( t KG h( t K Q\ ylit y ) ) ) ) ) abi sit b en f( t KG f( t K f( t K f( t KG ro D f( t K Q\ P e tiv . 00 tion ing 1 ) ) la ) ) or iv : mu p rv ) S( t s( t G S( t Q ro u S( t Q\ Cu P S S( t aln tion itio ving or d p p p p G n rvi p Q\ o ro uS C P lan tion g itio or in 10 d p y q q q G n D q Q\ o ro C P er ed isk Q mb os p R n n n Q\ n x n Nu E to er g G Q mb rval terin n n n Q\ n n n Nu E Inte erb g G Q m iny d d d Q\ d u D d N er wna G Q mb dr live w w w Q\ w A w Nu ith W er to e w-up mb st l l l G l Q abl llo l Q\ T Nu Lo oF ifeL th G a b b b Q\ f Wid b int rmato op t K t K t KG  Fo t K Q\ Mid .64 l a t Q t t G> 9 - ble rv t te 9 9 : 9 Ta In t t t G t Q\ t Q 88 -  89 of the last interval, bQ, is theoretically infinite; no estimate of the hazard or density function can be obtained for this interval.

4. Number lost to follow-up ( lG). This is the number of people who are lost to observation and whose survival status is thus unknown in the i th interval ( i : 1, . . . , s) .

5 . Number withdrawn alive ( wG). People withdrawn alive in the i th interval are those known to be alive at the closing date of the study. The survival time recorded for such persons is the length of time from entrance to the closing date of the study.

6. Number dying ( dG). This is the number of people who die in the i th interval. The survival time of these people is the time from entrance to death.

7. Number entering the i th interval ( n G). The number of people entering the first interval n is the total sample size. Other entries are determined from n G: n G\9 lG\9 wG\9 dG\. That is, the number of persons entering the i th interval is equal to the number studied at the beginning of the preceding interval minus those who are lost to follow-up, withdrawn alive, or have died in the preceding interval.

8. Number exposed to risk ( nG). This is the number of people who are exposed to risk in the i th interval and is defined as nG : n G 9( lG; wG).

It is assumed that the times to loss or withdrawal are approximately uniformly distributed in the interval. Therefore, people lost or with- drawn in the interval are exposed to risk of death for one-half the interval. If there are no losses or withdrawals, nG: n G.

9. Conditional proportion dying ( q G). This is defined as qG : dG/nG for i : 1, . . . , s 9 1, and q Q :1. It is an estimate of the conditional probability of death in the i th interval given exposure to the risk of death in the i th interval.

10. Conditional proportion surviving ( q G). This is given by p G: 19 q G, which is an estimate of the conditional probability of surviving in the i th interval.

11. Cumulative proportion surviving [ S( tG)]. This is an estimate of the survivorship function at time tG; it is often referred to as the cumulative survival rate. For i : 1, S( t G) :1 and for i:2, . .. , s, S( tG) : p G\ S( tG\). It is the usual life-table estimate and is based on the fact that surviving to the start of the i th interval means surviving to the start of and then through the ( i 9 1)th interval.

12. Estimated probability density function [ f ( tK)]. This is defined as the probability of dying in the i th interval per unit width. Thus, a natural estimate at the midpoint of the interval is S( t S( t f ( t G) 9 S( tG\) G) q G K) : : i : 1, . . . , s 9 1 (4 . 2 . 7) bG bG 90       13 . Hazard function [ h( tKG)]. The hazard function for the i th interval, estimated at the midpoint, is d h( t G KG) : : 2 q G i : 1, . . . , s 9 1 (4 . 2 . 8) bG( nG 9 dG) bG(1 ; p G) It is the number of deaths per unit time in the interval divided by the average number of survivors at the midpoint of the interval.

That is, h( tKG) is derived from f ( tKG) /S( tKG) and S( tKG) :[ S( tG> ) ; S( tG)] since S( tG) is defined as the probability of surviving at the beginning, not the midpoint, of the i th interval: h( tKG) : f ( tKG) : S( tG) q G/bG (4 . 2 . 9) S( t KG) S( tG)( p G ; 1) which reduces to (4.2.8).

Sacher (1956) derives an estimate of the hazard function by assuming that hazard is constant within an interval but varies among intervals.

His estimate is 9log p h( t G KG) : (4.2.10) bG In a Monte Carlo study, Gehan and Siddiqui (1973) showthat (4.2.9) is less biased than (4.2.10).

The large-sample approximate variances of the estimated survival functions, S( tG), f ( tKG), and h( tKG) in the i th interval are G\ q Var[ S( t H G)]< [ S( tG)] (4 . 2 . 11) H nHp H q Var[ f ( t H KG)]< [ S( tG) q G] G\ ; p G (4 . 2 . 12) bG H nHp H nHq H and Var[ h( tKG)]<[ h( tKG)] 191 h( t n KG) bG (4 . 2 . 13) Gq G 2 Equation (4.2.11) is given by Greenwood (1926); Gehan (1969) derived (4.2.12) and (4.2.13). These may be used to obtain approximate confidence intervals for the various survival functions.

The graph of S( tG) can be used to find an estimate of the median. Or let ( tH, tH> ) be the interval such that S( tH) 0 . 5 and S( tH> ) 0 . 5. Then the -  91 median survival time tK can be estimated by linear interpolation: S( t t H) 9 0 . 5 K : tH ; [ S( tH) 9 0 . 5] bH : t (4 . 2 . 14) S( t H ; H) 9 S( tH> ) f ( tKH) where f ( tKH) is defined in (4.2.7).

Another interesting measure that can be obtained from the life table is the median remaining lifetime at time tH, denoted by tKP( i), i:1, . . . , s 91. If at tG the proportion of individual survival is S( tG), the proportion of individual survival at tKP( i) is S( tG). That is, one-half of the people who are alive at time tG are expected to be alive at time tKP( i) . Let ( tH, tH> ) be the interval in which S( tG) falls; that is, S( tH) S( tG) and S( tH> ) S( tG). Then an estimate of tKP( i) is b t H[ S( tH) 9 S( tG)] KP( i) : ( tH 9 tG) ; (4.2.15) S( tH) 9 S( tH> ) Here S( tH) is the estimated proportion surviving beyond the lower limit of the interval containing the median.

The variance of tKP( i) is approximately Var[ t KP( i)] : [ S( tG)] (4.2.16) 4 nG[ f ( tKH)] Example 4.4 The following survival data for 2418 males with angina pectoris, originally reported by Parker et al. (1946), were also included in Gehans (1969) paper. Survival time is computed from time of diagnosis in years. The life table uses 16 intervals of one year. Table 4.7 gives estimates of the various survival functions, the median remaining lifetime, and their standard errors. The survivorship function, S( t), is plotted at t and the hazard and density functions, h( t) and f ( t), are plotted at the midpoint of the interval (Figure 4.4).

The graph of the estimated hazard function shows that the death rate is highest in the first year after diagnosis. From the end of the first year to the beginning of the tenth year, the death rate remains relatively constant, fluctuating between 0.09 and 0.12. The hazard rate is generally higher after the tenth year. Hence, the prognosis for a patient who has survived one year is better than that for a newly diagnosed patient if factors such as age, gender, and race are not considered. A similar interpretation is reached by examining the estimated median remaining lifetimes. Initially, the estimated median remaining lifetime is 5.33 years. It reaches a peak of 6.34 years at the beginning of the second year after diagnosis and then decreases. The median survival time, either read from the survival curve or using (4.2.14), is 5.33 years and the five-year survival rate is 0.5193 with a standard error of 0.0103.

( i)] t KP r[ . 17 . 20 . 24 . 24 . 19 . 18 . 19 . 27 . 28 . 41 . 42 0 0 0 0 0 0 0 0 0 0 0      Va( ( i) ; ; ; ;  t KP . 33 . 35 . 34 . 23 . 22 . 91 . 60 . 17 . 94 . 83 . 69 . 00 . 00 . 00 . 00 5 6 6 6 6 5 5 5 4 4 4 4 3 2 1 )] r[ h( t KG . 0097 . 0082 . 0076 . 0092 . 0093 . 0106 . 0110 . 0135 . 0147 . 0173 . 0236 . 0306 . 0351 . 0389 . 0549  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Va( )] f( t KG r[ . 0080 . 0060 . 0051 . 0054 . 0049 . 0050 . 0047 . 0052 . 0050 . 0053 . 0063 . 0068 . 0067 . 0065 . 0080  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Va( )] 0 2 7 1 3 4 5 6 7 9 1 4 8 3 3 S( t G r[  . 008 . 009 . 009 . 010 . 010 . 010 . 010 . 010 . 010 . 010 . 011 . 011 . 011 . 012 . 013 Va 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ( )  h( t KG . 2082 . 1235 . 0944 . 1199 . 1080 . 1186 . 1000 . 1167 . 1048 . 1123 . 1552 . 1794 . 1494 . 1169 . 1348 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 )  f( t KG . 1886 . 0944 . 0646 . 0738 . 0593 . 0581 . 0439 . 0460 . 0370 . 0355 . 0430 . 0421 . 0297 . 0203 . 0207 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ) S( t G . 0000 . 8114 . 7170 . 6524 . 5786 . 5193 . 4611 . 4172 . 3712 . 3342 . 2987 . 2557 . 2136 . 1839 . 1636 . 1429 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 lan onti ng itio or vi d . 8114 . 8837 . 9098 . 8869 . 8975 . 8880 . 9048 . 8897 . 9904 . 8937 . 8559 . 8354 . 8610 . 8896 . 8737 . 0000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 on rop urviS C P lan onti g itio in d por y n . 1131 . 1025 . 1120 . 0952 . 1103 . 0996 . 1063 . 1441 . 1646 . 1390 . 1104 . 1263 . 0000 D . 1886 . 1163 . 0902 o ro is C P erb ed isk . 00 . 50 . 00 . 50 . 00 . 50 . 50 . 00 . 00 . 00 . 50 . 50 . 50 . 50 . 50 . 01 ector 1 7 0 m osp R 8 4 3 P x 871 671 512 395 298 206 129 Nu E to 2418 1942 1686 1511 1317 1116 ina er g ng b rin 5 9 0 9 5 3 A m erval 938 722 546 427 321 233 146 u nte 2418 1962 1697 1523 1329 1170 N E Int th wi r g s be 3 4 9 6 0 m iny 8 7 51 42 43 34 18 u 456 226 152 171 135 125 ale D N M8 er wn b ra 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 241 m live u A f N ithd o W s er lysi b to w-up 0 9 2 3 4 8 4 5 3 3 7 3 0 m t 3 2 2 2 6 6 4 5 3 na u os lo 107 133 102 L ol A N F e abl dth . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 02 . 02  Wi e-T t ).

n Lif poid (1969 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 . 51 na .7 Mi 10 11 12 13 14  h 4 er is Ge aft os : 92 iagn Table ear 00 11 22 33 44 55 66 77 88 99 ource Y D 10 11 12 13 14 15 S -  93 Figure 4.4 Survival functions of male patients with angina pectoris.

94       Assume that survival time t (year) from each of 2418 males with angina pectoris in Example 4.4 has the same format as the data file C:D4d2.DAT defined in Example 4.2 and is saved in C:D4d4.DAT. Then the following SAS code can be used to produce a clinical life table such as Table 4.7.

data w1; infile c:d4d4.dat missover; input t cens; run; proc lifetest data : w1 outsurv : wa method : life intervals : 0 to 15 by 1; time t*cens(0); run; title Life table of the survival times; proc print data : wa; run; If BMDP 1L is used, the respective code is /input file : c:d4d4.dat .

variables : 2.

format : free.

/variable names : t, cens.

/form unit : year.

time : t.

status : cens.

response : 1.

/estimate method : life.

Print.

/end If the SPSS SURVIVAL procedure is used, the respective code is data list file : c:d4d4.dat free / t cens.

survival tables : t /status : cens (1) for t /intervals : thru 15 by 1 /print.

4.3 RELATIVE, FIVE-YEAR, AND CORRECTED SURVIVAL RATES Another approach to large-scale survival data is the calculation of the relative survival rate or annual survival ratio. The relative survival rate evaluates the survival experience of patients in terms of the general population. Greenwood (1926) first suggested this approach for evaluating the efficacy of cancer treatment: If the average survival time of the patients treated equals that of a , -,     95 random sample of persons of the same age, gender, occupation, and so on, the patients could be considered cured. Cutler et al. (1957, 1959, 1960 a, b, 1967) adopted Greenwoods idea of comparing the survival experience of cancer patients with that of the general population to ascertain (1) the ratio of observed to expected survival rates and (2) whether, in time, the mortality rate declines to a normal level.

The relative survival rate is defined as the ratio of the survival rate (probability of surviving one year) for a patient under study ( observed rate) to someone in the general population of the same age, gender, and race ( expected rate) over a specified period of time. To provide a more precise measure of the relationship of the observed and expected survival rates, Cutler et al. suggest computing the ratio for each individual follow-up year. A relative rate of 100% means that during a specific follow-up year the mortality rates in the patient and in the general population are equal. A relative rate of less than 100% means that the mortality rate in the patients is higher than that in the general population. Cutler et al. use the survival rates in the Connecticut and U.S. life tables for the general population.

Using the notations in Table 4.6, the survival rate observed at time tG is p G, the expected survival rate can be computed as follows: Suppose that at time tG there are n G individuals alive for whom age, gender, race, and time of observation are known. Let p* GH be the survival rate of the j th individual from general population life tables (with corresponding age, gender, and race). The expected survival rate is L Y p* G G : 1 p* n GH (4.3.1) G H Then the relative survival rate at time tG is defined by p r G G : (4 . 3 . 2) p* G Example 4 . 5 taken from Cutler et al. (1957) illustrates the interpretation of relative survival rates.

Example 4.5 A total of 9121 breast cancer cases were diagnosed in Connecticut hospitals from 1935 to 1953. The Connecticut life table for white females, 1939  1941, is used in calculation of the expected survival rate. Table 4.8 gives the observed and expected survival rates as well as the relative survival rates. Figure 4.5 a graphically shows these data: the survival curves for the breast cancer patients and the general population. The relative survival rates are plotted in Figure 4.5 b. For this group of patients, the relative survival rates, although increasing during 13 successive years, are less than 100% throughout the 15 years of follow-up. During each of the 15 years, the 96       Table 4.8 Relative Survival Rates of Breast Cancer Patients in Connecticut, 1935--1953 Survival Rates (%) Relative Years after Survival Rate Diagnosis Observed Expected (%) 0  1 82.9 97.2 85 1  2 83.3 97.1 86 2  3 85.9 96.9 89 3  4 86.8 96.7 90 4  5 89.2 96.6 92 5  6 90.0 96.4 93 6  7 89.9 96.4 93 7  8 91.6 96.2 95 8  9 92.0 96.1 96 9  10 92.7 96.1 96 10  11 92.9 95.9 97 11  12 94.0 95.8 98 12  13 94.1 95.3 99 13  14 91.5 95.3 96 14  15 90.6 94.9 95 Source: Cutler et al. (1957).

breast cancer patient mortality rate is greater than that of the general population.

Other measures of describing survival experience of cancer patients are the five-year survival rate and the corrected rate. The five-year survival rate is simply the cumulative proportion surviving at the end of the fifth year. For example, the five-year survival rate for the males with angina pectoris in Example 4.4 is 0.5193. The five-year survival rate is no longer a measure of treatment success for patients with many types of cancer since the survival of cancer patients has improved considerably in the last fewdecades.

Berkson (1942) suggests using a corrected survival rate. This is the survival rate if the disease under study alone is the cause of death. In most survival studies, the proportion of patients surviving is usually determined without considering the cause of death, which might be unrelated to the specific illness.

If pA denotes the survival rate when cancer alone is the cause of death, Berkson proposes that p pA : (4.3.3) p where p is the observed total survival rate in a group of cancer patients and p is the survival rate for a group of the same age and gender in the general     97 Figure 4.5 Survival rates of breast cancer patients in Connecticut, 1935  1953.

population. Rate pA may be computed at any time after the initiation of follow-up; it provides a measure of the proportion of patients that escaped a death from cancer up to that point. If a five-year survival rate is 0.5 and it is corrected for noncancer deaths and if we find that five-year survival rate of the general population is 0.9, the corrected survival rate is 0.5/0.9, or 0.56.

4.4 STANDARDIZED RATES AND RATIOS Rates and ratios are often used in demography and epidemiology to describe the occurrence of a health-related event. For example, the standardized mortality (or morbidity) ratio (SMR) is frequently used in occupational epidemiology as a measure of risk, and the standardized death rate is commonly used in comparing mortality experiences of different populations or the same population at different times.

The concept of the SMR is very similar to that of the relative survival rate described above. It is defined as the ratio of the observed and the expected number of death and can be expressed as SMR : observed number of deaths in study population ; 100 (4.4.1) expected number of deaths in study population where the expected number of deaths is the sum of the expected deaths from the same age, gender, and race groups in the general population. The standardized morbidity ratio can similarly be calculated simply by replacing the word deaths by disease cases in (4.4.1). If only newcases are of interest, we call the ratio the standardized incidence ratio (SIR).

98       Table 4.9 Population and Deaths of Sunny City and Happy City by Age Sunny City Happy City Age-Specific Age-Specific Rates Rates Age Population Deaths (per 1000) Population Deaths (per 1000) 25 25,000 25 1.00 55,000 110 2.0 25  44 40,000 50 1.25 20,000 50 2.5 45  64 20,000 200 10.00 21,000 315 15.0 65 15,000 1,200 80.00 4,000 650 162.5 Total 100,000 1,475 100,000 1,125 The standardized death rate is only one of the many rates used to describe the health status of a population or to compare the health status of different populations. If the populations are similar with respect to demographic variables such as age, gender, or race, the crude rate, or ratio of the number of persons to whom the event under study occurred to the total number of persons in the population, can safely be used for comparison.

The level of the crude rate is affected by demographic characteristics of the population for which the rate is computed. If populations have different demographic compositions, a comparison of the crude rates may be misleading. As an example consider the two hypothetical populations, Sunny City and Happy City, in Table 4.9. The crude death rate of Sunny City is 1000(1475/ 100,000) or 14.7 per 1000. The crude death rate of Happy City is 1000(1125/ 100,000), or 11.25 per 1000, which is lower than that of Sunny City even though all age-specific rates in Happy City are higher. This is mainly because there is a large proportion of older people in Sunny City. A crude death rate of a population may be relatively high merely because the population has a high proportion of older people; it may be relatively lowbecause the population has a high proportion of younger people. Thus, one should adjust the rate to eliminate the effects of age, gender, or other differences. The procedure of adjustment is called standardization and the rate obtained after standardization is called the standardized rate.

The most frequently used methods for standardization are the direct method and the indirect method.

Direct Method In this method a standard population is selected. The distribution across the groups with different values of the demographic characteristic (e.g., different age groups) must be known. Let r, . . . , rI, where k is the number of groups, be the specific rates of the different groups for the population under study. Let p, . . . , pI be the proportions of people in the k groups for the standard population. The direct standardized rate is obtained by multiplying the specific     99 rates rG by pG in each group. The formula for the direct standardized rate is I R : rGpG (4 . 3 . 2) G As an example, consider the data in Table 4.9. If we choose a standard population whose distribution is shown in the second column of Table 4.10, the direct standardized death rate for Sunny City and Happy City is, respectively, 9.37 and 17.84 per 1000. These standardized rates are more reliable than the crude rates for comparison purposes.

Indirect Method If the specific rates rG of the population being studied are unknown, the direct method cannot be applied. In this case, it is possible to standardize the rate by an indirect method if the following are available: 1. The number of persons to whom the event being studied occurred ( D) in the population. For example, if the death rate is being standardized, D is the number of deaths.

2. The distribution across the various groups for the population being studied, denoted by n, . . . , nI.

3. The specific rates of the selected standard population, denoted by s, . . . , sI.

4. The crude rate of the standard population, denoted by r.

The formula for indirect standardization is D R : I r (4 . 3 . 3) G nGsG The summation in (4.3.3) is the expected number of persons to whom the event occurred on the basis of the specific rates of the standard population. Thus, the indirect method adjusts the crude rate of the standard population by the ratio of the observed to expected number of persons to whom the event occurred in the population under study.

Table 4.11 represents an example for the death rate in the states of Oklahoma and Arizona in 1960 (data are from Grove and Hetzel, 1963). The U.S. population in 1960 is used as the standard population. The crude death rate of Oklahoma (9.7 per thousand) is higher than that of Arizona (7.8 per thousand). However, the indirect standardized rates show a reverse relationship (8.6 for Oklahoma and 9.6 for Arizona). This, again, is because of the differences in age distribution. There is a higher proportion of people belowthe age of 25 in Arizona and a higher proportion of people above the age of 54 in Oklahoma.

ediz ,tesa ) R 0 0 4 r GG . 84 .7 .3 .00 .8 h p 0 3 3 tandard 1 17 R ty eat Ci ge-S D y A appH cifi es, ec . 00 5 0 5 p Rat r G 2 2.

15.

ity -S th 162.

C ea y Age D p Hap ediz , and tesa )( ity R r GG 5 0 0 7 C h p . 42 .3 .2 .4 .3 tandard 0 0 2 6 9 eat ( R nny ityC ge-S D Su y A fordo Sunn cifi es, ec Rat 25 00 00 Meth p r G . 00 -S th 1 1.

10.

80.

ect ea Age D Dir by on, ates G 8 2 8 R orti p . 42 .2 .2 .0 p 0 0 0 0 h roP Deat ed rd rdiz a 000 000 000 d ation ,000 ,000 n 0, 0, 0, 0 pul 8 42 28 22 ,000 tanda Sta o 1 S P 0.14 lta 44 64 ble eg 25   65 To Ta A 25 45 100 d , 0 2 7 1 9 5 6 2 6 7 . 17 .6 .9 .4 .8 .0 9 9 8 6 .6 s GG eaths n 934 145 142 205 254 519 ,037.

,615.

,430.

,968.

812 068 1 1 2 1 0, Expecte D 1 an 69.

rizoA 9 : on, 9 7 0 3 9 3 1 4 9 2 1 5 G 59 36 83 ,78 87 02 57 87 63 49 09 16 9.

4, .8 157 068 ulati n 34, 92, 63, 22, 02, 7 132, 285, 186 169, 173, 136, 10, 10, op ,31 P 157 068 10, 10, 1960 na, 1 9 5 9 8 2 3 1 0 6 o d , .0 .4 .1 .9 .9 5 0 1 2 3 s G . 78 G Ariz eaths n 25 074 ,3 213 227 362 418 863 ,045.

,759.

,012.

,549.

,296.

2 3 6 6 3 5, Expecte D 1 2 and ma ma o o 68.

lah lah k : on, 3 4 2 0 7 4 7 6 5 8 8 4 O Ok 5 10 64 97 23 32 99 14 03 38 84 59 28 lati G 9.

n .7 584 074 for u 49, 74, 16, 28, 9 193, 454, 329, 279, 287, 269, 216, 157, 22, 25, d ,32 Pop 584 074 tho 22, 25, Me ct , ire ) n tesa Ind oti 1960 R by la th ).

es pu on, ea 63 at Po lati D s G R 0005 0011 0015 0030 0076 0174 0382 0875 1986 (19 d c . 0270 .0011 .5 0 0.

0.

0.

0.

0.

0.

0.

0.

0.

9 dar tzel Popu ecifi .

He Death .S d Stan e-Sp n ed (U g a A ev rdiz o ) ) Gr d s ?

te d tanda ths ra m S an a tha an fro de 1 tes ous de ized ous ta .1 d 4 l ra th ed th Da ta e ct : .

4 14 24 34 44 54 64 74 84 d er erved er s GG ble 10          ; To u (p pe (p rce n 1 5 x tandar Ta Age 15 25 35 45 55 65 75 85 Cr Obs E S Sou ?

101 102       Results for the adjusted rates depend on the standard population selected.

Hence, this selection should be done carefully. When discussing death rate by age, Shryock et al. (1971) suggest that a population with similar age distribution to the various populations under study be selected as a standard. If the death rate of two populations is being compared, it is best to use the average of the two distributions as a standard.

It should be remembered that specific rates are still the most accurate and essential indicators of the variations among populations. No matter which method is used, standardized rates are meaningful only when compared with similarly computed rates. Kitagawa (1964) also criticizes the standardized rate because if the specific rates vary in different ways between the two populations being compared, standardization will not indicate the differences and sometimes will even mask the differences. Nevertheless, if the specific rates are not available, if a single rate for a population is desired, or if the demographic composition of the population being compared is different, the standardized rate is useful.

Bibliographical Remarks Kaplan and Meiers (1958) PL method is the most commonly used technique for estimating the survivorship function for samples of small and moderate size.

However, with the aid of a computer, it is not difficult to use the method for large sample sizes.

Berkson (1942), Berkson and Gage (1950), Cutler and Ederer (1958), and Gehan (1969) have written classic reports on life-table analysis. Peto et al.

(1976) published an excellent reviewof some statistical methods related to clinical trials. The term life-table analysis that they use includes the PL method.

Other references on life tables are, for example, Armitage (1971), Shryock et al.

(1971), Kuzma (1967), Chiang (1968), Gross and Clark (1975), and Elandt- Johnson and Johnson (1980).

Relative survival rates and corrected survival rates have been used by Cutler and co-workers in a series of survival studies on cancer patients in Connecticut in the 1950s and 1960s (Cutler et al., 1957, 1959, 1960 a, b, 1967; Ederer et al., 1961). Discussions of SMR, standardized rates, and related topics can be found in many standard epidemiology textbooks: for example, Mausner and Kramer (1985), Kahn (1983), Kelsey et al. (1986), Shryock et al. (1971), Chiang (1961), and Mantel and Stark (1968).

EXERCISES 4.1 Consider the survival time of the 30 melanoma patients in Table 3.1.

(a) Compute and plot the PL estimates of the survivorship functions S( t) of the two treatment groups and check your results with Table 3.2 and Figure 3.1.

103 (b) Compute the variance of S( t) for every uncensored observation.

(c) Estimate the median survival times of the two groups.

4.2 Do the same as in Exercise 4.1 for the remission durations of the two treatment groups in Table 3.1.

4.3 Compute and plot the PL estimates of the tumor-free time distributions for the saturated fat and unsaturated fat diet groups in Table 3.4.

Compare your results with Figure 3.4.

4.4 Consider the remission data of 42 patients with acute leukemia in Example 3.3.

(a) Compute and plot the PL estimates of S( t) at every time to relapse for the 6-MP and placebo groups.

(b) Compute the variances of S(10) in the 6-MP group and of S(3) in the placebo group.

(c) Estimate the median remission times of the two treatment groups.

4.5 (a) Compute the survival time for each patient in Exercise Table 3.1.

(b) Estimate and plot the overall survivorship function using the PL method. What is the median survival time?

(c) Divide the patients into two groups by gender. Compute and plot the PL estimates of the survivorship functions for each group. What is the median survival time for each?

4.6 Consider the skin test results in Exercise Table 3.1. For each of the five skin tests: (a) Divide patients into two groups according to whether they had a positive reaction. Measurements less than 10;10 (5;5 for mumps) are considered negative.

(b) Estimate and plot the survivorship functions of the two groups.

(c) Can you tell from the plots if any skin tests might predict survival time?

4.7 Consider the data of patients with cancer of the ovary diagnosed in Connecticut from 1935 to 1944 (Cutler et al. 1960b). Exercise Table 4.1 Exercise Table 4.1 Number Time from Number Lost Withdrawn Number Number Diagnosis to Follow-up, Alive, Dying, Entering, (yr) lG wG dG n G 0  5 18 0 731 949 5  10 16 0 52 200 10  15 8 67 14 132 15  20 0 33 10 43 104       reproduces the data in life-table format. Provide a life-table like Table 4.5. What do you find out?

4.8 Do a complete life-table analysis for the two sets of data given in Table 3.5. Plot the three survival functions.

4.9 Do a complete life-table analysis of the data given in Exercise Table 4.2.

Plot the three survival functions.

Exercise Table 4.2 Survival Data of Female Patients with Angina Pectoris Year After Number Entering Number Lost to Diagnosis Interval Follow-up Number Dying 0  1 555 0 82 1  2 473 8 30 2  3 435 8 27 3  4 400 7 22 4  5 371 7 26 5  6 338 28 25 6  7 285 31 20 7  8 234 32 11 8  9 191 24 14 9  10 153 27 13 10  11 113 22 5 11  12 86 23 5 12  13 58 18 5 13  14 35 9 2 14  15 24 7 3 15; 14 11 3 Source: R. L. Parker et al., JAMA, 131(2), 95  100 (1946). Copyright 1946. American Medical Association.

4.10 Consider the survival times of the melanoma patients in Exercise Table 3.4. Do a complete life-table analysis of the survival time. Plot the three survival functions.

4.11 Consider the data given in Exercise Table 4.3. Compute the direct standardized death rate for the states of Oklahoma and Montana using the U.S. population of 1960 as the standard.

4.12 Given the population of Japan and Chile (Exercise Table 4.4), compute the indirect standardized death rate for the two countries using the U.S.

death rate of 1960 in Table 4.11 as the standard.

105 Exercise Table 4.3 Oklahoma Average Montana Average Death Rate Death Rate U.S. Population, Proportion, (per 1000) (per 1000) Age 1960 (thousands) pG rG rG 1 4,112 0 . 023 25 . 5 25 . 8 1  4 16,209 0.091 1.2 1.2 5  14 35,465 0.198 0.5 0.5 15  24 24,020 0.134 1.2 1.6 25  34 22,818 0.127 1.6 1.8 35  44 24,081 0.134 2.9 3.1 45  54 20,486 0.114 6.9 7.5 55  64 15,572 0.087 14.8 16.3 65  74 10,997 0.061 32.4 37.3 75  84 4,634 0.026 79.0 87.3 85; 929 0.005 190.4 202.8 Total 179,323 1.000 Source: Grove and Hetzel (1963).

Exercise Table 4.4 Population (thousands) Age Japan Chile 1 1,577 228 1  4 6,268 876 5  14 20,223 1,817 15  24 17,627 1,323 25  34 15,727 1,034 35  44 11,057 779 45  54 9,018 603 55  64 6,573 395 65  74 3,724 212 75  84 1,438 83 85 188 22    Total 93,419 7,374 Observed deaths 706,599 95,486 Source: Shryock et al. (1971).

C H A P T E R 5 Nonparametric Methods for Comparing Survival Distributions The problem of comparing survival distributions arises often in biomedical research.A laboratory researcher may want to compare the tumor-free times of two or more groups of rats exposed to carcinogens.A diabetologist may wish to compare the retinopathy-free times of two groups of diabetic patients.

A clinical oncologist may be interested in comparing the ability of two or more treatments to prolong life or maintain health.Almost invariably, the disease-free or survival times of the different groups vary.These differences can be illustrated by drawing graphs of the estimated survivorship functions, but that gives only a rough idea of the difference between the distributions.It does not reveal whether the differences are significant or merely chance variations.A statistical test is necessary.

In Section 5.1 we introduce five nonparametric tests that can be used for data with and without censored observations.Section 5.2 is devoted to the Mantel  Haenszel test, which is particularly useful in stratified analysis, a method commonly used to take account of possible confounding variables.In Section 5.3 we discuss the problem of comparing three or more survival distributions with or without censoring.

5.1 COMPARISON OF TWO SURVIVAL DISTRIBUTIONS Suppose that there are n and n patients who receive treatments 1 and 2, respectively.Let x, . . . , xP be the r the n failure observations and x> P > , . . . , x>L 9 r censored observations in group 1.In group 2, let y, . . . , yP be the r the n failure observations and y> P > , . . . , y>L 9 r censored observations.That is, at the end of the study n 9 r patients who received treatment 1 and n 9 r patients who received treatment 2 are still alive.Suppose that the observations in group 1 are samples from a distribution with survivorship function S( t) and the observations in group 2 are samples from a distribution 106      107 with survivorship function S( t).Then null hypothesis to consider is H: S( t) : S( t) (treatments 1 and 2 are equally effective) against the alternative H: S( t) S( t) (treatment 1 more effective than 2) or H: S( t) S( t) (treatment 2 more effective than 1) or H: S( t) " S( t) (treatments 1 and 2 not equally effective) When there are no censored observations, standard nonparametric tests can be used to compare two survival distributions.For example, the Wilcoxon (1945) test or the Mann  Whitney (1947) U-test can test the equality of two independent populations, and the sign test can be used for paired (or dependent) samples (Marascuilo and McSweeney, 1977).In the following we introduce five nonparametric tests: Gehans generalized Wilcoxon test (Gehan, 1965 a, b), the Cox  Mantel test (Cox 1959, 1972; Mantel, 1966), the logrank test (Peto and Peto, 1972), Peto and Petos generalized Wilcoxon test (1972), and Coxs F-test (1964).All the tests are designed to handle censored data; data without censored observations can be considered a special case.

5.1.1 Gehans Generalized Wilcoxon Test In Gehans generalized Wilcoxon test every observation xG or x>G in group 1 is compared with every observation yH or y>H in group 2 and a score UGH is given to the result of every comparison.For the purpose of illustration, let us assume that the alternative hypothesis is H: S( t) S( t), that is, treatment 1 is more effective than treatment 2.

Define UGH: ;1 if xG yH or x>G yH 0 if xG: yH or x>G yH or y>H xG or ( x>G, y>H) 91 if xG yH or xG y>H and calculate the test statistic L L W : UGH (5.1.1) G H where the sum is over all n n comparisons.Hence, there is a contribution to 108       the test statistic W for every comparison where both observations are failures (except for ties) and for every comparison where a censored observation is equal to or larger than a failure.The calculation of W is laborious when n and n are large.Mantel (1967) shows that it can be calculated in an alternative way by assigning a score to each observation based on its relative ranking.In Gehans computation each observation in sample 1 is compared with each in sample 2.If the two samples are combined into a single pooled sample of n; n observations, it is the same as comparing each observation with the remaining n; n 9 1.Let UG, i :1, . . . , n; n, be the number of remaining n; n 91 observations that the i th is definitely greater than minus the number that it is definitely less than.The n; n UGs define a finite population with mean 0 and it is true that Gehans L W : UG (5.1.2) G where summation is over the UG of sample 1 only.From either (5.1.1) or (5.1.2), it is clear that W would be a large positive number if H is true.Mantel also suggests that the permutational variance of W be used instead of the more complicated variance formula derived by Gehan.The permutational distribution of W can be obtained by considering all n; n:( n; n)!

n n! n!

ways of selecting n of the UG at random.The test statistic W under H can be considered approximately normally distributed with mean 0 and variance L >L n n U G Var( W ) : G (5.1.3) ( n; n)( n ; n 91) Since W is discrete, an appropriate continuity correction of 1 is ordinarily used when there are neither ties nor censored observations.Otherwise, a continuity correction of 0.5 would probably be appropriate.

Since W has an asymptotically normal distribution with mean zero and variance in (5.1.3), Z : W /(Var( W ) has standard normal distribution.The rejection regions are Z Z? for H, and Z 9 Z? for H, and Z Z? for H where P( Z Z? H) :.

n! is read n factorial: n! : n( n 9 1)( n 9 2) % 3 . 2 . 1 .

This is called the permutational variance because it is obtained by considering the per mutational distribution of all ( n ; n)! /n! n! W s      109 The number UG can be computed in two stages.For each observation, the first stage yields, unity plus the number of remaining observations that it is definitely larger than, that is, R G.The second stage yields R G, which is unity plus the number of remaining observations that the particular observation is definitely less than.Then UG : R G 9 R G.The computations of R G and R G can be accomplished systematically in steps, as illustrated in the following hypothetical example.

Example 5.1 Ten female patients with breast cancer are randomized to receive either CMF (cyclic administration of cyclophosphamide, methatrexate, and fluorouracil) or no treatment after a radical mastectomy.At the end of two years, the following times to relapse (or remission times) in months are recorded: CMF (group 1): 23, 16;, 18;, 20;, 24; Control (group 2): 15, 18, 19, 19, 20 The null hypothesis and the alternatives are H: S: S (the two treatments are equally effective) H: S S (CMF more efficient than no treatment) The computations of R G, R G, and UG are given in Table 5.1. Thus, W : 1 ; 2 ; 5 ; 4 ; 6 : 18, Var( W ) : (5)(5)(208) /[(10)(9)] : 57 . 78, and Z : 18 /(57 . 78 : 2 . 368.Suppose that the significance level used is : 0.05, Z:1 . 64; then the Z value computed is in the rejection region.Therefore, we reject H at 0.05 level and conclude that the data show that CMF is more effective than no treatment.In fact, the approximate p value corresponding to Z : 2 . 368 is 0.009.

Note that the sum of all n ; n UGs equals zero.This fact can be used to check the computation.

5.1.2 Cox--Mantel Test Let t   t I be the distinct failure times in the two groups together and m G be the number of failure times equal to tG, or the multiplicity of tG, so that I m G: r; r (5 . 1 . 4) G Further, let R( t) be the set of people still exposed to risk of failure at time t, whose failure or censoring times are at least t.Here R( t) is called the riskset at time t.Let n R and n R be the number of patients in R( t) that belong to 110       Table 5.1 Mantels Procedure of Calculating U for Gehans Generalized Wilcoxon Test i Observations of Two Samples in Ascending Order 15 16 > 18 18 > 19 19 20 20 > 23 24 > Computation of R G Step 1.Rank from left to right, omitting censored observations 1 2 3 4 5 6 Step 2.Assign next-higher rank to censored observations 2 3 6 7 Step 3.Reduce the rank of tied observations to the lower rank for the value 3 Step 4. R G 1 2 2 3 3 3 5 6 6 7 Computation of R G Step 5.Rank from right to left 10 9 8 7 6 5 4 3 2 1 Step 6.Reduce the rank of tied observations to the lowest rank for the value 5 Step 7.Reduce the rank of censored observations to 1 1 1 1 1 Step 8. R G 10 1 8 1 5 5 4 1 2 1 UG: R G 9 R G 99 1 ?

96 2 ?

92 92 1 5 ?

4 ?

6 ?

? From group 1.

treatment groups 1 and 2, respectively.The total number of observations, failure or censored in R( t G), is r G: n R; n R.Define I U : r 9 m G A G (5 . 1 . 5) G I m I : G( r G 9 m G) A G(1 9 A G) (5.1.6) G r G 91 where r G is the number of observations, failure or censored, in R( t G) and A G      111 is the proportion of r G that belong to group 2.An asymptotic two-sample test is thus obtained by treating the statistic C : U/( I as a standard normal variate under the null hypothesis (Cox, 1972).The following example illustrates the procedure.

Example 5.2 Consider the remission data and the hypotheses in Example 5.1. There are k : 5 distinct failure times in the two groups, r:1 and r :5 .

To perform the Cox  Mantel test, Table 5.2 is prepared for convenience: U : 5 9 (0 . 5 ; 0 . 5 ; 2 ; 0 . 5 ; 0 . 25) : 5 9 2 . 25 : 2 . 75 I : 1;9 (0 . 5;0 . 5) ; 1;7 (0 . 5;0 . 5) ; 2;4 (0 . 5;0 . 5) ; 1;3 (0.25;0.75) 9 7 5 3 : 0.25 ; 0.25 ; 0.4 ; 0.1875 : 1.0875 Therefore, C : 2 . 75 /(1 . 0875 : 2 . 637 Z:1 . 64 and we reject H at 0.05 level and reach the same conclusion as in Example 5.1. The p value corresponding to Z : 2 . 637 is approximately 0.004.

5.1.3 Logrank Test Mantels (1966) generalization of the Savage (1956) test, often referred to as the logranktest (Peto and Peto, 1972), is based on a set of scores wG assigned to the observations.The scores are functions of the logarithm of the survival Table 5.2 Computations of Cox--Mantel Test Number in Risk Set of: Distinct Sample 1 Sample 2 Failure Time, tG m G n R n R r G A G 15 1 5 5 10 0 . 5 18 1 4 4 8 0 . 5 19 2 3 3 6 0 . 5 20 1 3 1 4 0 . 25 23 1 2 0 2 0 112       function.Altshuler (1970) estimates the log survival function at t G using m 9 e( t H G) : 9 (5 . 1 . 7) r j t G H where m H and r H are as defined in Section 5.1.2. The scores suggested by Peto and Peto are wG :19 e( t G) for an uncensored observation t G and 9 e( T ) for an observation censored at T.In practice, for a censored observation t> G , wG:9 e( t H), where t H is the largest uncensored observation that t H t>G.

Thus, the larger the uncensored observation, the smaller its score.Censored observations receive negative scores.The w scores sum identically to zero for the two groups together.The logrank test is based on the sum S of the w scores of the two groups.The permutational variance of S is given by n Var( S) : n L >L G w G (5 . 1 . 8) ( n; n)( n; n 91) which can be rewritten as m V : I H( r H 9 m H) n n (5 . 1 . 9) H r H ( n ; n)( n ; n 91) The test statistic L : S/(Var( S ) has an asymptotically standard normal distribution under the null hypothesis.If S is obtained from group 1, the critical region is L 9 Z?, and if S is obtained from group 2, the critical region is L Z?, where is the significance level for testing H: S: S against H: S S.The following example illustrates the computational procedures.

Example 5.3 Consider the data and hypotheses in Example 5.1. The test statistic of the logrank test can be computed by tabulating m G, r G, m G /r G, and e( t G) as in Table 5.3. Since every observation in the two samples, censored or not, is assigned a score, it is convenient to list them in column 1.Columns 2 to 5 pertain only to the failure times; e( t G) is the cumulative value of m G /r G, Altshulers (1970) estimate of the logarithm of the survivorship function multipled by 91.For example, at t G:18, e( t G) :0.100;0.125:0.225; at t G:19, e( t G) :0 . 225; 0 . 333:0 . 558.The last column, wG, gives the score for every observation.For an uncensored observation wG:19 e( t G), for example, at tG :18, wG:190 . 225: 0 . 775.Since e( t G) is an estimate of a function of the survivorship function, which we assume to be constant between two consecutive failures, e( t> G ) is equal to e( t H) for t H t> G .Thus wG for censored observations t> G equals 9 e( t H), where t H t> G .For example, wG for 16 > is 9 e(15), or 90.100, and that for 18 > is 9 e(18), or 90.225. Tied observations like the two 19s receive the same score: 0.442. The 10 scores wG sum to zero, which can be used to check the computation.

113 Table 5.3 Computations of Logrank Test Remission Times in Both Samples, tG m G r G m G /r G e( t G) wG 15 1 10 0 . 100 0 . 100 0 . 900 ?

16;     90 . 100 18 1 8 0 . 125 0 . 225 0 . 775 ?

18;     90 . 225 19 2 6 0 . 333 0 . 558 0 . 442 ?

20 1 4 0 . 250 0 . 808 0 . 192 ?

20;     90 . 808 23 1 2 0 . 500 1 . 308 90 . 308 24;     91 . 308 ? From sample 2.

The statistic S : 0 . 900 ; 0 . 775 ; 0 . 442 ; 0 . 442 ; 0 . 192 : 2 . 751.The variance of S, computed by (5.8) is 1.210. Hence, the test statistic L : 2 . 751 / (1 . 210 : 2 . 5 and the p value is approximately 0.0064, data showing that CMF treatment is superior.The logrank statistic S can be shown to equal the sum of the failures observed minus the conditional failures expected computed at each failure time, or simply the difference between the observed and expected failures in one of the groups.A similar version of the logrank test is a chi-square test which compares the observed number of failures to the expected number of failures under the hypothesis.Let O and O be the observed numbers and E and E the expected numbers of death in the two treatment groups.The test statistic X : ( O 9 E) ; ( O 9 E) (5 . 1 . 10) E E has approximately the chi-square distribution with 1 degree of freedom.A large X value (e.g., X) would lead to the rejection of the null hypothesis in favor of the alternative that the two treatments are not equally effective ( : 0.05).

To compute E and E, we arrange all the uncensored observations in ascending order and compute the deaths expected at each uncensored time and sum them.The number of deaths expected at an uncensored time is obtained by multiplying the deaths observed at that time by the proportion of patients exposed to risk in the treatment group.Let d be the number of deaths at time t and n R and n R be the numbers of patients still exposed to risk of dying at time up to t in the two treatment groups.The deaths expected for groups 1 114       and 2 at time t are n n e R R R : ; d ; d n R e R: R (5.1.11) R ; n R n R; n R Then the total numbers of deaths expected in the two groups are E: e R E: e R R R In practice, we only need to compute the total number of deaths expected in one of the two groups, for example, E, since E is the total observed number of deaths minus E.The following example illustrates the calculation procedure.

Example 5.4 Let us use the hypothetical data in Example 5.1 again. The remission times in months are: CMF (group 1): 23, 16;, 18;, 20;, 24; Control (group 2): 15, 18, 19, 19, 20.

Consider the following null and alternative hypotheses: H: S: S (the two treatments are equally effective) H: S" S (the two treatments are not equally effective) Table 5.4 gives the calculation of E.For example, at t:18, four patients in group 1 and four in group 2 are still exposed to the risk of relapse, and there is one relapse.Thus, dR :1, n R: n R: 4, and e R:0 . 5 .

The total number of relapses expected is E: 3 . 75.Since there are a total of six deaths ( O:1, O: 5) in the two groups, E: 693 . 75:2 . 25.Using Table 5.4 Computation of E of Logrank Test 1 Relapse time, t dR n R n R e R e R 15 1 5 5 0.5 0.5 18 1 4 4 0.5 0.5 19 2 3 3 1.0 1.0 20 1 3 1 0.75 0.25 23 1 2 0 1.0 0 Total 3.75 2.25      115 (5.1.10), we have X : (1 9 3 . 75) ; (5 9 2 . 25) : 5 . 378 3 . 75 2 . 25 Using Table C-2, the p value corresponding to this X value is less 0.05 ( p < 0 . 02).Therefore, we reach the same conclusion: that there is a significant difference in remission duration between the CMF and control groups.

Computer software is available to perform a number of two-sample tests with censored observations.For example, SAS, SPSS, and BMDP provide procedures for the logrank and Cox  Mantel tests.We use the remission time of the 10 breast cancer patients in Example 5.1 to illustrate the use of these software packages.To compare the two groups, we create the following three variables: t, remission time; CENS : 0 if t is censored and 1 otherwise; and TREAT : 1 if receiving CMF and :2 if no treatment.Assume that the data have been saved in C:D5d1.DAT as a text file, which contains three columns, separated by a space ( t is in the first column, CENS the second column, and TREAT the third column), and the data in each row are for the same patient.The following SAS code can be used to perform the logrank test.

data w1; infile c:d5d1.dat missover; input t cens treat; run; proc lifetest data : w1; time t*cens(0); strata treat; run; If BMDP procedure 1L is used, the following code can be used to perform the Cox  Mantel test.

/input file : c:d5d1.dat .

variables : 3.

format : free.

/variable names : t, cens, treat.

/form time : t.

status : cens.

response : 1.

/group codes(treat) : 1, 2.

Names(treat) : treated, control.

/estimate method : product.

Group : treat.

Stat : mantel.

/end 116       If procedure KM in SPSS is used, the following code can be used to perform the Cox  Mantel test.

data list file : c:d5d1.dat free / t cens treat.

km t by treat /status : cens event (1) /test : logrank.

These codes can be modified to perform tests comparing more than two groups simply by replacing TREAT in the codes with the group variable defined.

5.1.4 Peto and Petos Generalized Wilcoxon Test Another generalization of Wilcoxons two-sample rank sum test is described by Peto and Peto (1972).Similar to the logrank test, this test assigns a score to every observation.For an uncensored observation t, the score is uG : S ( t;) ; S ( t 9) 9 1, and for an observation censored at T, the score is uG: S ( T ) 9 1, where S is the Kaplan  Meier estimate of the survival function.

If we use the notation of Section 5.1.2, the score for an uncensored observation t G is uG : S ( t G) ; S ( t G\) 91 and S ( t) :0 and that for a censored observation is t> H is uH : S ( t G) 9 1, where t G t> H .These generalized Wilcoxon scores sum to zero.The test procedure after the scores are assigned is the same as for the logrank test.The following example illustrates the computational procedures.

Example 5.5 Using the same data and hypotheses as in Example 5.1, the calculations of the scores uG for Peto and Petos generalized Wilcoxon test are given in Table 5.5. Using the scores of group 1, we obtain S : 90 . 100 9 0 . 212 9 0 . 605 9 0 . 408 9 0 . 803 : 92 . 128 (0 . 9) ; % ; (90 . 803) Var( S) : (5)(5) : 0 . 765 10 ; 9 Thus, Z : 92 . 128 /(0 . 765 : 92 . 433 9 Z:91 . 64.We reject H at the 0.05 level and reach the same conclusion as in the last three examples: that the data show that CMB is more effective than no treatment.

5.1.5 Coxs F-test Coxs F-test (Cox, 1964) is based on ordered scores from the exponential distribution.It is for singly censored or complete samples; it is not applicable to progressively censored data.The procedure is as follows:      117 Table 5.5 Computations of Peto and Petos Generalized Wilcoxon Test t G S ( t) uG 15 0.900 1 ; 0.900 9 1 : 0.900 16;  0.900 9 1 : 90.100 ?

18 0.788 0.900 ; 0.788 9 1 : 0.688 18;  0.788 9 1 : 90.212 ?

19 0.657 0.788 ; 0.657 9 1 : 0.445 19 0.526 0.526 ; 0.657 9 1 : 0.183 20 0.395 0.395 ; 0.526 9 1 : 90.079 20;  0.395 9 1 : 90.605 ?

23 0.197 0.197 ; 0.395 9 1 : 904.08 ?

24;  0.197 9 1 : 90.803 ?

? Group 1.

1.Rank the observations in the combined sample.

2.Replace the ranks by the corresponding expected order statistics in sampling the unit exponential distribution [ f ( t) : e\ R].Denote by tPL the expected value of the r th observation in increasing order of magnitude, tPL:1 ;%; 1 r : 1, . . . , n (5 . 1 . 12) n n 9 r ; 1 where n is the total number of observations in the two samples.In particular, t L:1 n t L:1; 1 n n 9 1 (5 . 1 . 13) tLL: 1; 1 ; %;1 n n 9 1 For n not too large, they can easily be computed by using tables of reciprocals.When two or more observations are tied, the average of the scores is used.

3.For data without censored observations, the entire set of n observations is replaced by the set of scores tPL so obtained.The sample mean scores denoted by t and t of the two samples with n, n observations are then computed.The ratio t/ t has been shown to follow an F distribution with (2 n, 2 n) degrees of freedom.Critical regions for testing H: S: S 118       against H( S S), H( S S), and H( S" S) are, respectively, t /t F L L?, t /t F L L\?, and t /t F L L? or t / t F L L\?.

4.The calculation of F is slightly different for singly censored data.Let r and r be the number of failures and n 9 r and n 9 r the number of censored observations in the two samples.Then there are p : r; r failures in the combined sample and n 9 p censored observations.Cox (1964) suggests using the scores t L, . . . , tNL as before for the failures and t N> L for all censored observations.The mean score, for example, for the first group is r t t ; ( n 9 r) t N> L : (5.1.14) r where t is the mean score of the failures.The mean score for the second group is calculated in a similar way.The F-statistic t /t, has an approximate F-distribution with (2 r,2 r) degrees of freedom.

This test is for the hypothesis that the two samples are from populations with equal means.It can also determine if the second population mean is k times the first population mean, for a given k, by dividing the observations in the second sample by k before ranking and applying the test.The set of all values k not rejected in such a significance test forms a confidence interval.The following example illustrates the computation.

Example 5.6 In an experiment comparing two treatments (A and B) for solid tumor, suppose that the question is whether treatment B is better than treatment A.Six mice are assigned to treatment A and six to treatment B.The experiment is terminated after 30 days.The following survival times in days are recorded.Our null and alternative hypotheses are H: S: S and H: S S .

Treatment A: 8, 8, 10, 12, 12, 13 Treatment B: 9, 12, 15, 20, 30;, 30; That is, all the mice receiving treatment A die within 13 days and two mice receiving treatment B are still alive at the end of the study.Do the data provide sufficient evidence that treatment B is more effective than treatment A?

To compute the test statistic, it is convenient to set up a table like Table 5.6.

The first column lists all the observations in the two samples.The second column contains the ordered exponential scores tPL.In this case, n:6, n :6, n : 12, r:6, and r :4.The scores are computed following (5.1.12) and (5.1.13).For example, tPL for tG:10 is equal to 1/12;1/11; 1/10;1/9 or simply the previous tPL plus 1/9, that is, 0.274;1/9:0.385. The tied observations receive an average score: for example, for tG :12,      119 Table 5.6 Computations of Coxs F-Test for Data in Example 5.6 tPL of tPL of tG tPL Sample A Sample B 8 :0.0831 0.129  0.129 8 ; :0.174 0.129  9 ; ; :0.174;0.100:0.274  0.274 10 0.274 ; :0.385 0.385  12 0.385 ; :0.510 0.661  12 0.510 ; :0.6610.661 0.661  12 0.653 ; :0.820  0.661 13 0.820 ; :1.020 1.020  15 1.020 ; :1.270  1.270 20 1.270 ; :1.603  1.603 30; 1.603 ; :2.103  2.103 30; 2.103  2.103     2.985 8.014 tPL:(0 . 510 ;0 . 653;0 . 820) :0 . 661.The last two columns of Table 5.6 give the scores for the two samples and the sums are entered at the bottom.Thus t :2 . 985 / 6:0 . 498 and t :8 . 014 / 4:2 . 004 according to (5.1.14) and t F : : 0 . 498 : 0 . 249 t 2 . 004 with (12, 8) degrees of freedom.The critical region is F F: 1 /F: 1 / 2 . 8486: 0 . 351 for :0.05. Hence, the data provide strong evidence that treatment B is superior to treatment A.

5.1.6 Comments on the Tests The tests presented in Sections 5.1.1 to 5.1.5 are based on rank statistics obtained from scores assigned to each observation.The first four tests are applicable to data with progressive censoring.They can be further grouped into two categories: generalization of the Wilcoxon test (Gehans and Peto and Petos) and the non-Wilcoxon test (Cox  Mantel and logrank test).In the logrank test, if the statistic S is the sum of w scores in group 2, it is the same as U of the Cox  Mantel test.This can be seen in Examples 5.2 ( U : 2 . 75) and 5.3 ( S : 2 . 751); the small discrepancy is due to rounding-off errors.

FP P?:1 /FP P\?.

120       The only reason to choose one test over another in a given circumstance is if it will be more powerful, that is, more likely to reject a false hypothesis.When sample sizes are small ( n, n 50), Gehan and Thomas (1969) show that Coxs F-test is more powerful than Gehans generalized Wilcoxon test if samples are from exponential or Weibull distributions and if there are no censored observations or the observations are singly censored.Comparisons of Gehans Wilcoxon test to several other tests are reported by Lee et al. (1975).They show that when samples are from exponential distributions, with or without censoring, the Cox  Mantel and logrank tests are more powerful and more efficient than the generalized Wilcoxon tests of Gehan and Peto and Peto.

There is little difference between the Cox  Mantel and logrank tests and between the two generalized Wilcoxon tests.When the samples are taken from Weibull distributions with a constant hazard ratio (i.e., the ratio of the two hazard functions does not vary with time), the results are essentially the same as in the exponential case.However, when the hazard ratio is nonconstant, the two generalizations of the Wilcoxon test have more power than the other tests.Thus, the logrank test is more powerful than the Wilcoxon tests in detecting departures when the two hazard functions are parallel (proportional hazards) or when there is random but equal censoring and when there is no censoring in the samples (Crowley and Thomas, 1975).The generalized Wilcoxon tests appear to be more powerful than the logrank test for detecting many other types of differences, for example, when the hazard functions are not parallel and when there is no censoring and the logarithm of the survival times follow the normal distribution with equal variance but possibly different means.

The generalized Wilcoxon tests give more weight to early failures than later failures, whereas the logrank test gives equal weight to all failures.Therefore, the generalized Wilcoxon tests are more likely to detect early differences in the two survival distributions, whereas the logrank test is more sensitive to differences in the right tails.Prentice and Marek (1979) show that Gehans Wilcoxon statistic is subject to a serious criticism when censoring rates are high.If heavy censoring exists, the test statistic is dominated by a small number of early failures and has very low power.

There are situations in which neither the logrank nor Wilcoxon test is very effective.When the two distributions differ but their hazard functions or survivorship functions cross, neither the Wilcoxon nor logrank test is very powerful, and it will be sensible to consider other tests.For example, Tarone and Ware (1977) discuss general statistics of similar form (using scores) and Fleming and Harrington (1979) and Fleming et al. (1980) present a two-sample test based on the maximum of a Smirnov-type statistic designed to measure the maximum distance between estimates of two distributions.The latter approach is shown to be more effective than the logrank or Wilcoxon tests when two survival distributions differ substantially for some range of t values, but not necessarily elsewhere.These statistics have not been widely applied.Interested readers are referred to the original papers.

121 5.2 MANTEL--HAENSZEL TEST The Mantel  Haenszel (1959) test is particularly useful in comparing survival experience between two groups when adjustments for other prognostic factors are needed.The test has been used in many clinical and epidemiological studies as a method of controlling the effects of confounding variables.For example, in comparing two treatments for malignant melanoma, it would be important to adjust the comparison for a possible confounding variable such as stage of the disease.In studying the association of smoking and heart disease, it would be important to control the effects of age.To use the Mantel  Haenszel test, the data are stratified by the confounding variable and cast into a sequence of 2;2 tables, one for each stratum.

Let s be the number of strata, nHG be the number of individuals in group j, j : 1, 2, and stratum i, i : 1, . . . , s, and dHG be the number of deaths (or failures) in group j and stratum i.For each of the s strata, the data can be represented by a 2;2 contingency table: Number of Number of Group Deaths Survivors Total 1 d G n G 9 d G n G 2 d G n G 9 d G n G Total DG SG TG The null hypothesis to be tested can be stated as H: p: p p: p pQ: pQ where pGH : P (deathgroup j, stratum i).Thus, the test permits simultaneous comparison over all the s contingency tables of the difference in survival or death probabilities for the two groups.

The chi-square test statistic without continuity correction is given by X : [ QG d G 9 QG ( d G)] Q (5 . 2 . 1) G Var( d G) According to Grizzle (1967), the distribution of X without continuity correction is closer to the chi-square distribution than the X with continuity correction.His simulations show that the probability of Type I error (rejecting a true hypothesis) is better controlled without the continuity correction at : 0 . 01, 0 . 05 .

122       where n E( d GDG G) : (5.2.2) TG n Var( d Gn GDGSG G) : (5.2.3) T G( TG 91) are the mean and variance, respectively, of the number of deaths in group i computed conditionally on the contingency table marginal totals.This statistic follows the chi-square distribution with 1 degree of freedom.Thus, a computed chi-square value larger than the table chi-square value for the significance level chosen indicates a significant difference in survival between the two groups.

The following two examples illustrate the use of the test.

Example 5.7 Five hundred and ninety-five persons participate in a case control study of the association of cholesterol and coronary heart disease (CHD).Among them, 300 persons are known to have CHD and 295 are free of CHD.To find out if elevated cholesterol is significantly associated with CHD, the investigator decides to control the effects of smoking.The study subjects are then divided into two strata: smokers and nonsmokers.

The following tables give the data for smokers: Elevated Cholesterol?

With CHD Without CHD Total Yes 120 20 140 No 80 60 140 Total 200 80 280 and for nonsmokers: Elevated Cholesterol?

With CHD Without CHD Total Yes 30 60 90 No 70 155 255 Total 100 215 315    123 Using (5.2.2) and (5.2.3), we obtain E( d) :140 ;200:100 E( d : 28 . 571 280 ) : 90 ; 100 315 Var( d) :140 ;140;200;80 :14 . 337 (280)(280 9 1) Var( d) :90 ;225; 100;215 :13 . 974 (315)(315 9 1) Using (5.2.1) and d:120, d:30, we have X : (150 9 128 . 571) : 16 . 220 14 . 337 ; 13 . 974 which is significant at the 0.001 level. Thus, elevated cholesterol is significantly associated with CHD after adjusting for the effects of smoking.

Example 5.8 Table 5.7 gives survival data in life-table format of male cases with localized cancer of the rectum in Connecticut for 1935  1944 and 1945  1954.We use Mantel and Haenszels chi-square test to see if the survival distribution of patients diagnosed in 1935  1944 is the same as for patients diagnosed in 1945  1954.The null hypothesis is that the two survival distributions are the same.It is not necessary to set up 10 contingency tables for the 10 intervals.The chi-square value is easily calculated by constructing columns 7 to 12 directly from the life table.Using the sums in columns 1, 10, and 12, we obtain X : (330 . 0 9 246 . 50) : 52 . 624 132 . 491 which is significant at the 0.001 level. Thus, the data show a significant difference between the survival distributions of patients diagnosed in 1935  1944 and 1945  1954.

It should be noted that this chi-square test statistic, when applied to life tables, gives more weight to those deaths that occur in an early time interval rather than later.That is, if the two groups are subject to the same probability of surviving through the entire study period, (5.2.1) (5.2.3) will give high mortality for the group in which early deaths occur.Mantel (1966) gives the following illustration.

Consider two groups of 100 persons each.Both have 50 deaths.In group 1 all deaths occur in the first interval, and in group 2 all deaths occur in the ) ) 1 G . 0  (1 1 cticut ) ( d 9 . 624 . 418 . 832 . 174 . 090 . 036 . 221 . 546 . 641 . 909 . 491 8 7 5 2 2 2 2 (12 );  0 ) 54 22 16 10 3 (9  1 onne Var (1 C in G ) ) /T G (8 ) . 45 . 86 . 67 . 35 . 05 . 66 . 22 . 06 . 04 . 64 S 2 3 8 9 4 4 0 1 0 ctum (11 G ); (9 1 5 7 3 9 3 7 3 0 69 n (6 5 4 3 3 2 2 1 1 1 Re of er ) ) anc ) G (7 ) . 45 . 86 . 67 . 35 . 05 . 66 . 22 . 06 . 54 . 64  . 50 C ( d (9 0 7 7 5 2 0 6 d (10 E ); 2 (3  24 zelia Loc l, ) . 01 . 53 . 52 . 01 . 01 . 51 . 08 . 04 . 04 . 05 ta G 1 7 3 3 9 6 9 0 3 6 (9 o T 3 6 2 1 3 5 6 1 7 3 ith T 1 w ds ed o rs, Cases ) in eri ov G . 01 . 57 . 56 . 05 . 04 . 53 . 02 . 02 . 01 . 01 (8 P S mb e rvi 779 634 523 451 390 314 241 198 161 123 u Male Co im S T s: , hs tion ) G 2 9 2 8 2 2 3 (7 52 33 00 6 4 4 2 1 1 1 eat D 3 1 1 buri D istD l, . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 5 . 0 l ) ta G 7 a (6 n 744 549 451 386 331 266 190 139 107 iv To Surv 4 rs, G ) 195 o d . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 0 . 5 . 07  v 1 Two (5 5 9 7 4 rvi G 559 461 396 343 299 235 170 132 101 9 u n ing 1 S s, ) th G 8 5 3 2 1 0 7 6 (4 d 85 8 5 4 3 3 2 Compar ea 1 D for l, ) . 0 . 5 . 5 . 0 . 0 . 5 . 0 . 0 . 5 . 06 ta G 0 9 1 5 9 (3 o n edure T 387 218 172 127 108 oc Pr 4 rs, G ) 194 o d . 0 . 5 . 5 . 0 . 0 . 59 . 07 . 07 . 56 . 05  v 9 1 9 1 6 9 2 ional (2 9 7 7 6 5 5 35 rvi 220 173 127 108 u G tat n 19 S , ) hs 5 5 9 7 1 7  0 Compu G (1 67 4 4 1 eat d 1  33 D .75 al ble rnte Ta 1 2 3 4 51 61 78 85 96 In 10 124 COMPARISON OF K ( K 2) SAMPLES 125 second interval.The contingency table for the first interval is: Group Deaths Survivors Total 1 50 50 100 2 0 100 100 Total 50 150 200 and for the second interval is: Group Deaths Survivors Total 1 0 50 50 2 50 50 100 Total 50 100 150 From these two tables we have E( d) : 100;50 / 200:25 and E( d) : 100;50 / 150 : 16 . 67.The total deaths expected is 25 ; 16.67 : 41.67, so the 50 deaths in group 1 is 20% larger than expected.Thus, a significant chi-square value may be obtained if early survival patterns differ significantly in the two groups.

5.3 COMPARISON OF K (K 2) SAMPLES In this section the two-sample problem is generalized to a situation in which the data consist of K ( K 2) samples, one sample from each of the K treatment populations.The problem is to decide whether the K independent samples can be regarded as coming from the same population, or in practical terms, to see if the survival data from patients receiving the K treatments provide enough evidence to conclude that the K treatments are not equally effective.This problem has been considered by many statisticians: for example, Kruskal and Wallis (1952), Mantel and Haenszel (1959), Breslow (1970), and Peto and Peto (1972).In this section two nonparametric tests for the problem are presented.The first is Kruskal and Walliss (1952) H-test for uncensored data.The second is a generalization of the H-test for censored data (Peto and Peto, 1972).Both use ranks instead of the original observations and are simple to apply.

5.3.1 Kruskal--Wallis Test The Kruskal  Wallis H-test (Kruskal and Wallis, 1952; Hollander and Wolfe, 1973; Marascuilo and McSweeney, 1977), analogous to the F-test in the usual analysis of variance, uses ranks rather than original observations; it is also called the Kruskal  Wallis one-way analysis of variance by ranks.It assumes 126       that the variable (survival time) under study has an underlying continuous distribution.

Let N be the total number of independent observations in the K samples, nH the number of observations in the j th sample, j: 1, . . . , K, and tGH the i th observation in the j th sample.The null hypothesis H states that the K samples come from the same population (or clinically, the K treatments are equally effective).

In computation of the Kruskal  Wallis H-test, we first rank all N observations from smallest to largest.Let rGH be the rank of tGH.Compute, for j: 1, .. . , K, LH R R H H : rGH R H : R : 1 ( N ; 1) (5.3.1) G nH 2 where RH and R H are, respectively, the sum of the ranks and the average rank of the j th treatment, and R is the overall average rank.Then the Kruskal  Wallis H-statistic is ) H : 12 n N( N ; 1) H( R H 9 R) (5 . 3 . 2) H ) : 12 R H 9 3( N ; 1) (5.3.3) N( N ; 1) H nH Under the null hypothesis, H has an asymptotic ( nHs approaching infinity or nHs are large) chi-square distribution with K 9 1 degrees of freedom.Thus, for large nHs, the approximate test procedure at the level is to reject H if H I\?.When K:3 and the number of observations in each of the three samples is 5 or fewer, the chi-square approximation is not sufficiently close.For such cases, exact permutational distributions of H are available and percentage points I are given in Table B-4 of Appendix B.The test procedure is to reject H if H I?, where I? satisfies the equation P( H I? H):.

When there are tied observations, each is assigned the average of the ranks.

To correct for the effects of ties, H is computed by (5.3.3) and then divided by E 1 9 1 T N 9 N H (5.3.4) H where g is the number of tied groups, and TH: t H 9 tH, with tH being the number of tied observations in a tied group.In counting g, an untied observation is considered as a tied group of size 1.Thus, a general expression of H corrected for ties is H : [12 /N( N ; 1)] IH ( R H/nH) 9 3( N ; 1) (5 . 3 . 5) 1 9 EH TH/( N 9 N) COMPARISON OF K ( K 2) SAMPLES 127 Table 5.8 Cholesterol Values of 12 Subjects on Three Different Diets Diet 1 Diet 2 Diet 3 229 145 231 176 181 208 187 147 217 208 187 199 Note that when there are no ties, g : N, tH :1 for all j, and TH:0, and (5.3.5) reduces to (5.3.3).The following example illustrates the use of the test.

Example 5.9 In a study of the relationship between cholesterol level and diet, three diets are given randomly to 12 men whose initial cholesterol levels are almost the same.Table 5.8 shows the cholesterol levels of the 12 people after having their assigned diet for a given period of time.The purpose of the study is to decide if the three diets are equally effective in controlling cholesterol level.

The null hypothesis H states that there is no difference in cholesterol level of men having the three diets, and the alternative H says that the cholesterol levels of men having the three different diets are different.To compute the H-statistic, we first rank the observations as in Table 5.9 and compute RH.In this case N : 12, n: n: n :4, g :10, and TH: 0 except for j :5, 7 .

Table 5.9 Computation of H for Data in Example 5.9 Ordered Ranks of Ranks of Ranks of Observations Ranks Diet 1 Diet 2 Diet 3 145 1  1 147 2  2 176 3 3 181 4  4 187 5.5  5.5 187 5.5 5.5 199 7   7 208 8.5 8.5 208 8.5   8.5 217 10   10 229 11 11 231 12   12 RH 28 12.5 37.5 128       Hence, EH TH :2(8 92) : 12, and by (5.3.5), H : [12 /(12;13)](784 / 4 ; 156 . 25 / 4 ; 1406 . 25 / 4) 9 3(13) : 6 . 168 1 9 12 /(1728 9 12) From Table B-4 we find that P( H 6 . 038 H):0 . 037 and P( H 6 . 269 H) :0 . 033; we reject H at the 0.035 level. There is evidence of significant differences among the diets.

5.3.2 Multiple Comparisons Based on the Kruskal--Wallis Test If the null hypothesis that the K samples are from the same distribution is rejected, we might ask which particular samples are from different distributions.In Example 5.9 we reject the null hypothesis that the three diets are similar.The investigator may also be interested in knowing which particular diets differ from one another.In this section we introduce some nonparametric methods for multiple comparison based on Kruskal  Wallis rank sums.An excellent treatment of multiple comparisons is given by Miller (1966).

To decide which treatments differ from one another, there are K( K 91) decisions to make, one for each pair of treatments.The null hypothesis can be written as H: samples i and j are from the same population for i : 1, . . . , K 9 1, j : i ; 1, . . . , K, i j Let the probability of at least one wrong decision when H is true be controlled by and the probability of making all correct decisions when H is true be 1 9 .To make the K( K 91) decisions, we introduce the following comparison procedures.

1.When sample sizes are equal, that is, n: n :%: n): n, and n is small, we reject the hypothesis that the i th and j th samples, i j, are from the same distribution if RG 9 RH y(, K, n) (5.3.6) where y(, K, n) satisfies the equation P( RG 9 RH y(, K, n) H, i j) :1 9 (5 . 3 . 7) and R, R, . . . , R) are given in (5.3.1).Some approximate values of y are given in Table B-5.

2.When sample sizes are equal to n and n is large, we introduce Millers (1966) procedure, that is, to reject the hypothesis that the i th and j th COMPARISON OF K ( K 2) SAMPLES 129 Table 5.10 Multiple Comparisons for Data in Example 5.9 i j RG 9 RH Decision 1 2 28 9 12.5 : 15.5 Not significant 1 3 28 9 37.5 : 9.5 Not significant 2 3 12.5 9 37.5 : 25.0 Significant samples, i j, are from the same distribution if R G 9 R H q( a, K)[ K( Kn ;1)] (5 . 3 . 8) where R, . . . , R ) are given in (5.3.1) and q(, K) is the upper percentile point of the range of K independent standard normal variables.Table B-6 gives the q(, K) values for some K and .

3.For cases of small unequal sample sizes n, . . . , n), a conservative procedure is to reject the hypothesis that the i th and j th samples, i j, are from the same distribution if R G 9 R H( x? )) 1 N( N;1)1 ; 1 (5 . 3 . 9) 12 nG nH where N is the total number of observations.Values of x? ) are given in Table B-4.

4.When n, . . . , n) are large, Dunn (1964) suggests the following procedure.

Reject the hypothesis that the i th and j th samples, i j, are from the same distribution if R G 9 R H Z? ) )\ 1 N( N;1) 1 ; 1 (5 . 3 . 10) 12 nG nH where Z? ) )\ is the upper 100/[ K( K 91)] percentage point of the standard normal distribution (see Table B-1).

Example 5.10 Let us use the data in Example 5.9. To examine which particular diets differ from one another, we apply (5.3.6).Since K : 3, there are three possible comparisons.The calculation is shown in Table 5.10.For K : 3, n : 4, and from Table B-5, y(0 . 045, 3, 4) : 24; hence for ( i, j ) : (2, 3), (5.3.6) is satisfied.Thus, at < 0.045, we conclude that diets 2 and 3 are significantly different.

130       5.3.3 Test for Censored Data In Section 5.1 we introduced three nonparametric tests based on scores for comparing two samples with censored observations; Gehans generalized Wilcoxon test (if Mantels procedure is used), Peto and Petos generalized Wilcoxon test, and the logrank test.The K-sample test discussed in this section can be considered an extension of these tests and the Kruskal  Wallis test.

Suppose that we have a set of N scores w, w, . . . , w, obtained according to the manner of scoring in one of the three tests mentioned above.The sum of the N scores is zero.Let SH be the sum of the scores in the j th sample.The null hypothesis H states that the K samples are from the same distribution.

To test H we calculate ) X : H ( S H/nH) s (5 . 3 . 11) where , s : G w G (5 . 3 . 12) N 9 1 Under the null hypothesis X has approximately chi-square distribution with K 9 1 degrees of freedom (Peto and Peto, 1972).Thus, we reject H if X exceeds the upper 100 percentage point of the chi-square distribution with K 9 1 degrees of freedom, that is, if X I\?.

Example 5.11, using the scoring method of Mantel (1967) for Gehans generalized Wilcoxon test, illustrates the K-sample test for censored data.

Example 5.11 Consider the initial remission times of leukemia patients (in days) induced by three treatments as given in Table 5.11. In this case, K : 3, N : 66, n:25, n: 19, and n: 22.A table similar to Table 5.1 may be set up to compute the score for every observation.The computation is left to the reader as an exercise.The sums of scores in the three samples are S:9273, S:170, and S:103.The sum of squares of the scores w G: 89,702.

Hence, from (5.3.11) and (5.3.12), X : 3 . 612.From Table B-2, : 5.991; Table 5.11 Initial Remission Times of Leukemia Patients 1 2 3 4, 5, 9, 10, 12, 13, 10, 8, 10, 10, 12, 14, 8, 10, 11, 23, 25, 25, 23, 28, 28, 28, 29 20, 48, 70, 75, 99, 103, 28, 28, 31, 31, 40, 31, 32, 37, 41, 41, 162, 169, 195, 220, 48, 89, 124, 143, 57, 62, 74, 100, 139, 161;, 199;, 217;, 12;, 159;, 190;, 196;, 20;, 258;, 269; 245; 197;, 205;, 219;  131 thus we do not reject H.The data do not show significant differences among the three initial treatments.

Bibliographical Remarks Gehans test was first proposed in 1965.The Cox  Mantel test was first discussed by Cox in 1959, then by Mantel in 1966, and finally, by Cox again in 1972.The scores for the logrank test was proposed by Peto and Peto in 1972 along with another generalization of the Wilcoxon test.In the same paper, they also discuss the K-sample test for censored data.The logrank test is also discussed in Peto et al. (1977).Coxs F-test was developed in 1964 and the Mantel  Haenszel chi-square test can be found in Mantel and Haenszel (1959) and Mantel (1966).The Kruskal  Wallis one-way analysis of variance can be found in most standard textbooks under nonparametric methods.Readers who are interested in the theoretical development or more properties of these tests should read the original papers cited above.Applications of these tests are given in the original papers or can easily be found in medical and epidemiological journals.

EXERCISES The first five exercises are continuations of Exercises 4.1 to 4.4 and 4.6.

5.1 For the survival times given in Table 3.1, compare the survival distributions of the two treatment groups using: (a) Gehans generalized Wilcoxon test (b) The Cox  Mantel test 5.2 For the remission data given in Table 3.1, compare the remission time distributions of the two treatment groups using: (a) The logrank test (b) Peto and Petos generalized Wilcoxon test 5.3 For the data given in Table 3.4, compare the tumor-free time distribu- tions of the three diet groups.

5.4 For the remission data of 42 leukemia patients given in Example 3.3, use the two generalized Wilcoxon tests to see if 6-MP is more effective than placebo in prolonging remission time.

5.5 For the first four skin tests given in Exercise Table 3.1, use the Cox  Mantel and logrank tests to see if there is a significant difference in survival between patients with positive (5 mm for mumps,10 mm for others) and negative (5 mm for mumps, 10 mm for others) reactions.

132       5.6 Compute the test statistic W of Gehans generalized Wilcoxon test by using (5.1.1) for the data in Example 5.1. Do you get the same result as in Example 5.1?

5.7 Consider the data in Example 5.11. Use Mantels procedure for Gehans generalized Wilcoxon test to compute a score for each observation and the sum of scores for each of the three treatment groups.

5.8 Using the data in Table 3.1, compare the age distributions of the two treatment groups using Coxs F-test.

5.9 Consider the data in Exercise Table 5.1. Is elevated percent standard BMI associated with renal cell carcinoma after controlling the effects of gender?

Exercise Table 5.1 Percentage of Male Female Standard BMI ?

Case Control Case Control 140 130 160 60 65 140 85 55 55 50 ? Standard BMI: male, 22.1; female, 20.6. Percentage of standard BMI : (observed BMI/standard BMI);100.

5.10 Consider the survival data of men with angina pectoris in Table 4.6 and women with the same disease in Exercise Table 4.2. Is there a significant difference between the survival distributions of men and women?

5.11 In a study of noise level and efficiency, 18 students were given a very simple test under three different noise levels.It is known that under Exercise Table 5.2 1 2 3 10.5 10.0 12.0 9.0 12.0 13.0 9.5 12.5 15.5 9.0 11.0 14.0 8.5 12.0 12.5 10.0 10.5 15.0  133 normal conditions, they should be able to finish the test in 10 minutes.

The students were randomly assigned to the three levels.Exercise Table 5.2 gives the time required to finish the test. Are the three noise levels significantly different? If they are, determine which levels differ from one another.

5.12 Exercise Table 5.3 gives the survival time in weeks of 30 brain tumor patients receiving four different treatments.Are the four treatments equally effective?

Exercise Table 5.3 1 2 2 3 4 1 3 5 5 4 7 15 9 9 14 20 12 12 20 31 20; 15 27 39 25 23 30 47 30; 30 32; 55; 50; 67; C H A P T E R 6 Some Well-Known Parametric Survival Distributions and Their Applications Usually, there are many physical causes that lead to the failure or death of a person at a particular time. It is very difficult, if not impossible, to isolate these physical causes and account mathematically for all of them. Therefore, choosing a theoretical distribution to approximate survival data is as much an art as a scientific task. In this chapter, several theoretical distributions that have been used widely to describe survival time are discussed, their characteristics summarized, and their applications illustrated.

6.1 EXPONENTIAL DISTRIBUTION The simplest and most important distribution in survival studies is the exponential distribution. In the late 1940s, researchers began to choose the exponential distribution to describe the life pattern of electronic systems. Davis (1952) gives a number of examples, including bank statement and ledger error, payroll check errors, automatic calculating machine failure, and radar set component failure, in which the failure data are well described by the exponential distribution. Epstein and Sobel (1953) report why they select the exponential distribution over the popular normal distribution and show how to estimate the parameter when data are singly censored. Epstein (1958) also discusses in some detail the justification for the assumption of an exponential distribution. The exponential distribution has since continued to play a role in lifetime studies analogous to that of the normal distribution in other areas of statistics.

The exponential distribution is often referred to as a purely random failure pattern. It is famous for its unique lack of memory, which requires that the age of the animal or person does not affect future survival. Although many 134   135 Figure 6.1 Exponential distribution: ( a) survivorship function; ( b) probability density function; ( c) hazard function.

survival data cannot be described adequately by the exponential distribution, an understanding of it facilitates the treatment of more general situations.

The exponential distribution is characterized by a constant hazard rate , its only parameter. A high value indicates high risk and short survival; a low value indicates low risk and long survival. Figure 6.1 depicts the survivorship function, the density function, and the hazard function of the exponential distribution with parameter . When : 1, the distribution is often referred to as the unit exponential distribution.

When the survival time T follows the exponential distribution with a parameter , the probability density function is defined as t 0, 0 f ( t) : e\H R (6.1.1) 0 t 0 The cumulative distribution function is F( t) : 1 9 e\H R t 0 (6.1.2) and the survivorship function is then S( t) : e\H R t 0 (6.1.3) So that, by (2.2.1), the hazard function is h( t) : t 0 (6 . 1 . 4) a constant, independent of t. Figure 6.1 gives the graphical presentation of the three functions.

Because the exponential distribution is characterized by a constant hazard rate, independent of the age of the person, there is no aging or wearing out, 136 -    and failure or death is a random event independent of time. When natural logarithms of the survivorship function are taken, log S( t) : 9 t, which is a linear function of t. Thus, it is easy to determine whether data come from an exponential distribution by plotting log S( t) against t, where S( t) is an estimate of S( t). A linear configuration indicates that the data follow an exponential distribution and the slope of the straight line is an estimate of the hazard rate .

The mean and variance of the exponential distribution with parameter are, respectively, 1/ and 1/. The median is (1/) log 2. The coefficient of variation is 1.

A more general form of the exponential distribution is the two-parameter exponential distribution with probability density function t G f ( t) : e\H R\ % (6.1.5) 0 t G Then t G F( t) : 19 e\H R\ % (6.1.6) 0 t G t G S( t) : e\H R\ % (6 . 1 . 7) 0 t G and 0 t G h( t) : 0 (6 . 1 . 8) t G The term G is a guarantee time within which no deaths or failures can occur, or a minimum survival time. If G : 0, (6 . 1 . 5) (6.1.8) reduce to (6.1.1)  (6.1.4) for the one-parameter exponential. The mean and the median of the two-parameter exponential distribution are, respectively, G ; 1 / and (log 2 ; G) / .

Example 6.1 In a study of new anticancer drugs in the L1210 animal leukemia system, Zelen (1966) used the exponential distribution successfully as the model for survival time. The system consists of injecting a tumor inoculum into inbred mice. These tumor cells then proliferate and eventually kill the animal, but survival time may be prolonged by an active drug. Figure 6.2 shows the survival curve in a semilogarithmic scale of the untreated mice inoculated at different cell dilutions. Twenty-five mice were inoculated at each dilution. The reasonably linear configurations suggest that the survival distributions follow the exponential distribution quite well. The four straight lines fitted to the points are almost parallel, indicating that the hazard rate was independent of the inoculum size. Table 6.1 gives the estimated values of the   137 Figure 6.2 Survival curves of untreated mice inoculated with serial 10-fold dilutions of leukemia L1210: (*) 10 cells; () 10 cells; ()) 10 cells; () 10 cells. (From Zelen, 1966.) guarantee times G, hazard rates , and the mean survival times (in days) for the various dilutions. (Estimation procedures are discussed in Chapter 7.) Note that the estimated hazard rates, , are very close.

The probability that a mouse receiving 10 cells of inoculum will survive more than 20 days is, from (6.1.7), S(20) : e\\ < 0 . 0001 and the median survival time is 8.9 days.

Table 6.1 Estimates of G, , and Mean Survival Time for Untreated Mice with Serial Leukemia Dilutions Dilution G Mean Survival Time 10 8.0 0.78 9.3 10 10.0 0.78 11.3 10 11.9 0.76 13.2 10 13.9 0.67 15.4 Source: Zelen (1966).

138 -    Figure 6.3 Survival curves of mice treated with cyclophosphamide on day 3 after inoculation of 10 tumor cells: (*) control; () 80 mg/kg; () 160 mg/kg. (From Zelen, 1966.) Figure 6.3 gives the survival curves of mice treated with different doses of cyclophosphamide on day 3 after receiving a 10 tumor inoculum. Table 6.2 gives the estimates of G, , and the mean survival time. Mice receiving 160 mg/kg of the drug show a remarkably improved surivival pattern over the control group.

The probability that a mouse receiving 80 mg/kg of cyclophosphamide will survive more than 20 days is, from (6.1.7), S(20) : e\\ : 0 . 279 The median survival time is approximately 18 days.

6.2 WEIBULL DISTRIBUTION The Weibull distribution is a generalization of the exponential distribution.

However, unlike the exponential distribution, it does not assume a constant hazard rate and therefore has broader application. The distribution was proposed by Weibull (1939) and its applicability to various failure situations discussed again by Weibull (1951). It has then been used in many studies of reliability and human disease mortality.

The Weibull distribution is characterized by two parameters, and . The value of determines the shape of the distribution curve and the value of   139 Table 6.2 Estimates of G, , and Mean Survival Time for Treated Mice on Day 3 Dose (mg/kg) G Mean Survival Time Control 8.7 1.12 9.6 80 15.6 0.29 19.0 160 21.5 0.10 31.5 Source: Zelen (1966).

determines its scaling. Consequently, and are called the shape and scale parameters, respectively. The relationship between the value of and survival time can be seen from Figure 6.4, which shows the hazard rate of the Weibull distribution with : 0.5, 1, 2, 4. When : 1, the hazard rate remains constant as time increases; this is the exponential case. The hazard rate increases when 1 and decreases when 1 as t increases. Thus, the Weibull distribution may be used to model the survival distribution of a population with increasing, decreasing, or constant risk. Examples of increasing and decreasing hazard rates are, respectively, patients with lung cancer and patients who undergo successful major surgery.

The probability density function and cumulative distribution functions are, respectively, f ( t) : ( t)A\ e\H R A t 0, , 0 (6.2.1) Figure 6.4 Hazard functions of Weibull distribution with : 1.

140 -    and F( t) : 1 9 e\H R A (6 . 2 . 2) The survivorship function is, therefore, S( t) : e\H R A (6 . 2 . 3) and the hazard function, the ratio of (6.2.1) to (6.2.3), is h( t) : ( t)A\ (6 . 2 . 4) Figure 6.5 gives the Weibull density function with scale parameter : 1 and several different values of the shape parameter .

For the survival curve, it is simple to plot the logarithm of S( t), log S( t) : 9( t)A (6 . 2 . 5) Figure 6.6 gives log S( t) for : 1 and : 1, 1, 1. When : 1 is a straight line with negative slope. When 1, negative aging, log S( t) decreases very slowly from 0 and then approaches a constant value. When 1, positive aging, log S( t) decreases sharply from 0 as t increases. Equation (6.2.5) can also Figure 6.5 Density curves of Weibull distribution with : 1.

141 Figure 6.6 Curves of log CS( t) of Weibull distribution with :1.

be written as log[9log S( t)] : log C ; log Ct (6.2.6) The mean of the Weibull distribution is : (1 ; 1 /) ( 6.2.7) and the variance is : 1 1;29 1;1 (6.2.8) where () is the well-known gamma function defined as () : x A\ e\ V d x : ( 9 1)!

when is a positive integer (6.2.9) Values of () can be found in Abramowitz and Stegun (1964). The coefficient of variation is then CV : (1;2 /) 9 1 (6.2.10) (1 ; 1 /) The Weibull distribution can also be generalized to take into account a guarantee time G during which no deaths or failures can occur. The three- 142 -    parameter Weibull probability density function is f ( t) : A( t 9 G)A\ exp[9A( t 9 G)A] (6.2.11) Consequently, S( t) : exp[9A( t 9 G)A] (6 . 2 . 12) and h( t) : A( t 9 G)A\ (6 . 2 . 13) Example 6.2 Pike (1966) applied the Weibull distribution to a two-group experiment on vaginal cancer in rats exposed to the carcinogen DMBA. The two groups were distinguished by pretreatment regime. The times in days, after the start of the experiment, at which the carcinoma was diagnosed for the two groups of rats were as follows: Group 1: 143, 164, 188, 188, 190, 192, 206, 209, 213, 216, 220, 227, 230, 234, 246, 265, 304, 216;, 244; Group 2: 142, 156, 173, 198, 205, 232, 232, 233, 233, 233, 233, 239, 240, 261, 280, 280, 296, 296, 323 204;, 344; Assuming that G : 100 and : 3, Pike obtained :(4.51;10\) for group 1 and :(2.38;10\) for group 2. Analytical estimation procedure is discussed in Chapter 7. Figure 6.7 plots the survival curves of the two groups.

The step functions are nonparametric estimates similar to the Kaplan  Meier Figure 6.7 Survival curves of rats exposed to carcinogen DMBA. (From Pike, 1966.

Reproduced with permission of the Biometrics Society.)   143 Table 6.3 Calculation of Survivorship Functions for Group 2 of Rats Exposed to DMBA Kaplan  Modified Meier Kaplan  Meier S( t) Obtained n 9 r Estimates, Estimates ? , from Weibull Time r n 9 r ; 1 n 9 r ; 1 S( t) S( t) Plotted Fit 142 1 21 0.9524 0.9524 0.9546 0.9825 156 2 20 0.9500 0.9048 0.9091 0.9590 163 3 19 0.9474 0.8572 0.8637 0.9421 198 4 18 0.9444 0.8095 0.8182 0.7990 204;  17 1.0000 0.8095 0.8182 0.7647 205 6 16 0.9375 0.7589 0.7700 0.7588 232 7 15 0.9333 0.7083 0.7218 0.5778 232 8 14 0.9286 0.6577 0.6737 0.5778 232 9 13 0.9231 0.6071 0.6255 0.5706 233 10 12 0.9167 0.5565 0.5773 0.5706 233 11 11 0.9091 0.5059 0.5292 0.5706 233 12 10 0.9000 0.4553 0.4810 0.5706 239 13 9 0.8888 0.4047 0.4320 0.5271 240 14 8 0.8750 0.3541 0.3847 0.5198 261 15 7 0.8571 0.3035 0.3365 0.3697 280 16 6 0.8333 0.2529 0.2883 0.2489 280 17 5 0.8000 0.2023 0.2402 0.2489 296 18 4 0.7500 0.1517 0.1920 0.1660 296 19 3 0.6667 0.1011 0.1439 0.1660 323 20 2 0.5000 0.0506 0.0958 0.0710 344;  1 1.0000 0.0506 0.0958 0.0313 ? Instead of ( n 9 r) /( n 9 r ; 1), Pike uses ( n 9 r ; 1) /( n 9 r ; 2) in the Kaplan  Meier product-limit estimate to avoid ( n 9 r) /( n 9 r ; 1) : 0 .

Source: Pike (1966). Reproduced with permission of the Biometric Society.

estimate. The smooth curves are obtained from the Weibull fits. Table 6.3 shows the calculation of the plotting points for group 2.

It is obvious that the Weibull distributions with G : 100, : 3, :(4 . 51;10\), and :(2.38;10\) fit the carcinoma-free time of the two groups of rats very well.

6.3 LOGNORMAL DISTRIBUTION In its simplest form the lognormal distribution can be defined as the distribution of a variable whose logarithm follows the normal distribution. Its origin may be traced as far back as 1879, when McAlister (1879) described explicitly a theory of the distribution. Most of its aspects have since been under study.

Gaddum (1945 a, b) gave a review of its application in biology, followed by 144 -    Boags (1949) applications in cancer research. Its history, properties, estimation problems, and uses in economics have been discussed in detail by Aitchison and Brown (1957). Later, other investigators also observed that the age at onset of Alzheimers disease and the distribution of survival time of several diseases such as Hodgkins disease and chronic leukemia could be rather closely approximated by a lognormal distribution since they are markedly skewed to the right and the logarithms of survival times are approximately normally distributed.

Consider the survival time T such that log T is normally distributed with mean and variance . We then say that T is lognormally distributed and write T as (, ). It should be noted that and are not the mean and variance of the lognormal distribution. Figure 6.8 gives the hazard function of the lognormal distribution with different values for the parameters. The hazard function increases initially to a maximum and then decreases (almost as soon as the median is passed) to zero as time approaches infinity (Watson and Wells 1961). Therefore, the lognormal distribution is suitable for survival patterns with an initially increasing and then decreasing hazard rate. By a central limit theorem, it can be shown that the distribution of the product of n independent positive variates approaches a lognormal distribution under very general conditions: for example, the distribution of the size of an organism whose growth is subject to many small impulses, the effect of each of which is proportional to the momentary size of the organism.

The popularity of the lognormal distribution is due in part to the fact that the cumulative values of y : log t can be obtained from the tables of the standard normal distribution and the corresponding values of t are then found by taking antilogs. Thus, the percentiles of the lognormal distribution are easy to find.

Figure 6.8 Hazard of the lognormal distribution with different parameters.

145 The probability density function and survivorship function are, respectively, f ( t) : 1 exp 9 1 (log t 9) t 0, 2 (6.3.1) t(2 2 and 1 S( t) : 1 exp9 1 (log x 9) dx (6.3.2) (2 R x 2 Let a : exp(9). Then 9 : log a, (6.3.1) and (6.3.2) can be written as f ( t) : 1 exp 9 1 t(2 2 (log at) (6 . 3 . 3) and 1 S( t) : 1 exp9 1 (log ax) dx (6 . 3 . 4) (2 R x 2 at : 1 9 G log (6 . 3 . 5) where G( y) is the cumulative distribution function of a standard normal variable G( y) : 1 We\ S du (6 . 3 . 6) (2 The lognormal distribution is specified completely by the two parameters and . Time T cannot assume zero values since log T is not defined for T : 0 .

Figure 6.9 gives the lognormal frequency curves for : 0, : 0.1, 0.5, 2, from which an idea of the flexibility of the distribution may be obtained. It is obvious that the distribution is positively skewed and that the greater the value of , the greater the skewness. Figure 6.10 shows the frequency curves for : 0.5, : 0, 0.5, 1. It is obvious that and are, respectively, scale parameters and not location and scale parameters as in the normal distribution. The hazard function, from (6.3.3) and (6.3.5), has the form h( t) : (1 /t(2) exp[9 (log at) / 2] (6.3.7) 1 9 G(log at/) and is plotted in Figure 6.8.

146 -    Figure 6.9 Lognormal density curves with : 0.

The mean and variance of the two-parameter lognormal distribution are, respectively, exp( ; ) and [exp()91]exp(2;). The coefficient of variation of the distribution is then [exp() 9 1]. The median is e I and the mode is exp( ; ).

The two-parameter lognormal distribution can also be generalized to a three-parameter distribution by replacing t with t 9 G in (6.3.1). In other words, the survival time log( T 9 G) follows the normal distribution with mean and variance . In certain situations the value of G may be determined a priori and should not be regarded as an unknown parameter that requires estimation. If this is so, the variable T 9 G may be considered in place of T and the distribution of T 9 G has all the properties of the two-parameter lognormal distribution. However, the estimation procedures developed for the two-parameter case are not directly applicable to the distribution of T 9 G.

Figure 6.10 Lognormal density curves with : 0.5.

147 Figure 6.11 Lognormal probability plot of the survival time of 234 male patients with chronic lymphocytic leukemia. (From Feinleib and MacMahon, 1960. Reproduced by permission of the publisher.) Example 6.3 In a study of chronic lymphocytic and myelocytic leukemia, Feinleib and MacMahon (1960) applied the lognormal distribution to analyze survival data of 649 white residents of Brooklyn diagnosed from 1943 to 1952.

The analysis of several subgroups of patients follows. The survival time of each patient is computed from the date of diagnosis in months. Analytical method is used to fit the lognormal distribution to the data. The method is discussed in Chapters 7 and 8.

Figure 6.11 gives the probability plot of the survival time of 234 male patients with chronic lymphocytic leukemia, in which the horizontal axis for the survival time is in logarithmic scale and the vertical axis is in normal probability scale. When plotting 1 9 S( t) on this graph paper, a straight line is obtained when the data follow a two-parameter lognormal distribution. An inspection of the graph shows that the distribution is concave. Gaddum (1945 a, b) has pointed out that such a deviation can be corrected by subtracting an appropriate constant from the survival times. In other words, the three-parameter lognormal distribution can be used. Figure 6.12 gives a similar plot in which the survival time of every patient plus 4 is plotted. The configuration is linear and hence empirically it seems valid to assume that the lognormal distribution is appropriate.

Similar graphs for male patients with chronic myelocytic leukemia and for female patients with chronic lymphocytic or myelocytic leukemia are given in Figures 6.13 and 6.14. Parameters of the lognormal distribution are estimated.

Feinleib and MacMahon report that the agreement between the observed and calculated distributions is striking for each group except for women with chronic lymphocytic leukemia. The corresponding p values for the chi-square 148 -    Figure 6.12 Lognormal probability plot of the survival time in months plus 4 of 234 male patients with chronic lymphocytic leukemia. (From Feinleib and MacMahon, 1960. Reproduced by permission of the publisher.) goodness-of-fit test are as follows: Chronic Myelocytic Chronic Lymphocytic Male 0.86 0.73 Female 0.57 0.016 Since a large p value indicates close agreement, it is concluded that the three-parameter lognormal distribution adequately describes the distribution of survival times for each subgroup except women with chronic lymphocytic leukemia. The shape of the observed distribution for the latter group suggests that it might actually be composed of two dissimilar groups, each of whose survival times might fit a lognormal distribution.

6.4 GAMMA AND GENERALIZED GAMMA DISTRIBUTIONS The gamma distribution, which includes the exponential and chi-square distribution, was used a long time ago by Brown and Flood (1947) to describe the life of glass tumblers circulating in a cafeteria and by Birnbaum and Saunders (1958) as a statistical model for life length of materials. Since then, this distribution has been used frequently as a model for industrial reliability problems and human survival.

149 Figure 6.13 Lognormal probability plot of the survival time in months plus 4 of 162 male patients with chronic myelocytic leukemia. (From Feinleib and MacMahon, 1960.

Reproduced by permission of the publisher.) Suppose that failure or death takes place in n stages or as soon as n subfailures have happened. At the end of the first stage, after time T, the first subfailure occurs; after that the second stage begins and the second subfailure occurs after time T; and so on. Total failure or death occurs at the end of the n th stage, when the n th subfailure happens. The survival time, T, is then T; T;%; TL. The times T, T, . . . , TL spent in each stage are assumed to Figure 6.14 Lognormal probability plot of the survival time in months plus 4 of female patients with two types of leukemia. (From Feinleib and MacMahon, 1960. Reproduced by permission of the publisher.) 150 -    be independently exponentially distributed with probability density function exp(9 tG), i:1, . . . , n. That is, the subfailures occur independently at a constant rate . The distribution of T is then called the Erlangian distribution.

There is no need for the stages to have physical significance since we can always assume that death occurs in the n-stage process just described. This idea, introduced by A. K. Erlang in his study of congestion in telephone systems, has been used widely in queuing theory and life processes.

A natural generalization of the Erlangian distribution is to replace the parameter n restricted to the integers 1, 2, . . . by a parameter taking any real positive value. We then obtain the gamma distribution.

The gamma distribution is characterized by two parameters, and . When 0 1, there is negative aging and the hazard rate decreases monotonically from infinity to as time increases from 0 to infinity. When 1, there is positive aging and the hazard rate increases monotonically from 0 to as time increases from 0 to infinity. When : 1, the hazard rate equals , a constant, as in the exponential case. Figure 6.15 illustrates the gamma hazard function for : 1 and 1, : 1, 2, 4. Thus, the gamma distribution describes a different type of survival pattern where the hazard rate is decreasing or increasing to a constant value as time approaches infinity.

The probability density function of a gamma distribution is f ( t) : ( t)A\ e\H R t 0, 0, 0 (6.4.1) () where () is defined as in (6.2.9). Figures 6.16 and 6.17 show the gamma density function with various values of and . It is seen that varying changes the shape of the distribution while varying changes only the scaling.

Consequently, and are shape and scale parameters, respectively. When 1, there is a single peak at t : ( 9 1) / .

Figure 6.15 Gamma hazard functions with : 1.

151 Figure 6.16 Gamma density functions with : 1.

The cumulative distribution function F( t) has a more complex form: F( t) : R ( x)A\ e\H V dx (6 . 4 . 2) () : 1 u A\ e\ S du H R () : I( t, ) (6 . 4 . 3) where I( s, ) : 1 u A\ e\ S du Q (6 . 4 . 4) () known as the incomplete gamma function, is tabulated in Pearson (1922, 1957).

Figure 6.17 Gamma density functions with : 3.

152 -    For the Erlangian distribution, it can be shown that L\ e\H R( t) I F( t) : 1 9 (6.4.5) I k!

Thus, the survivorship function 1 9 F( t) is S( t) : ( x)A\ e\H V dx (6 . 4 . 6) R () for the gamma distribution or L\ ( t) I S( t) : e\ R (6.4.7) I k!

for the Erlangian distribution.

Since the hazard function is the ratio of f ( t) to S( t), it can be calculated from (6.4.1) and (6.4.7). When is an integer n, ( t) L\ h( t) : ( n 91)! L\ I (1 /k!)( t) I (6 . 4 . 8) When : 1, the distribution is exponential. When : and :, where is an integer, the distribution is chi-square with degrees of freedom. The mean and variance of the standard gamma distribution are, respectively, / and /, so that the coefficient of variation is 1/(.

Many survival distributions can be represented, at least roughly, by suitable choice of the parameters and . In many cases, there is an advantage in using the Erlangian distribution, that is, in taking integer.

The exponential, Weibull, lognormal, and gamma distributions are special cases of a generalized gamma distribution with three parameters, , , and , whose density function is defined as ?A f ( t) : t?A\ exp [9( t)?] t 0, 0, 0, 0 (6 . 4 . 9) () It is easily seen that this generalized gamma distribution is the exponential distribution if : : 1, the Weibull distribution if : 1; the lognormal distribution if ; -, and the gamma distribution if : 1.

In later chapters (e.g., Chapters 7 and 9), we discuss several parametric procedures for estimation and hypothesis testing. To use available computer software such as SAS to carry out the computation, we use the distributions adopted by the software. One of the very few software packages that include the gamma or generalized gamma distribution is SAS. In SAS, the generalized      153 Table 6.4 Lifetimes of 101 Strips of Aluminum Coupon 370 1085 1293 1522 1792 706 1102 1300 1522 1820 716 1102 1310 1530 1868 746 1108 1313 1540 1881 785 1115 1315 1560 1890 797 1120 1330 1567 1893 844 1134 1355 1578 1895 855 1140 1390 1594 1910 858 1199 1416 1602 1923 886 1200 1419 1604 1940 886 1200 1420 1608 1945 930 1203 1420 1630 2023 960 1222 1450 1642 2100 988 1235 1452 1674 2130 990 1238 1475 1730 2215 1000 1252 1478 1750 2268 1010 1258 1481 1750 2440 1016 1262 1485 1763 1018 1269 1502 1768 1020 1270 1505 1781 1055 1290 1513 1782 Source: Birnbaum and Saunders (1958).

gamma distribution is defined as having the following density function: A?A f ( t) : t?A\ exp [9( t)?], t 0, 0, 0 (6 . 4 . 10) () To differentiate this form of the generalized gamma distribution from the generalized gamma in (6.4.9), we refer to this distribution as the extended generalized gamma distribution. It can be shown that the extended generalized gamma distribution reduces to the Weibull distribution when 0 and : 1, the lognormal distribution when ; -, the gamma distribution when : 1, and the exponential distribution when : : 1.

Example 6.4 Birnbaum and Saunders (1958) report an application of the gamma distribution to the lifetime of aluminum coupon. In their study, 17 sets of six strips were placed in a specially designed machine. Periodic loading was applied to the strips with a frequency of 18 hertz and a maximum stress of 21,000 pounds per square inch. The 102 strips were run until all of them failed.

One of the 102 strips tested had to be discarded for an extraneous reason, yielding 101 observations. The lifetime data are given in Table 6.4 in ascending order. From the data the two parameters of the gamma distribution were 154 -    Figure 6.18 Graphical comparison of observed and fitted cumulative distribution functions of data in Example 6.4. (From Birnbaum and Saunders, 1958.) estimated (estimation methods are discussed in Chapter 7). They obtained : 11.8 and : 1/(118.76;10).

A graphical comparison of the observed and fitted cumulative distribution function is given in Figure 6.18, which shows very good agreement. A chi-square goodness-of-fit test (discussed in Chapter 9) yielded a value of 4.49 for 6 degrees of freedom, corresponding to a significance level between 0.5 and 0.6. Thus, it was concluded that the gamma distribution was an adequate model for the life length of some materials.

6.5 LOG-LOGISTIC DISTRIBUTION The survival time T has a log-logistic distribution if log( T ) has a logistic distribution. The density, survivorship, hazard, and cumulative hazard functions of the log-logistic distribution are, respectively, t A\ f ( t) : (6 . 5 . 1) (1 ; t A) S( t) : 1 1 ; t A (6 . 5 . 2)    155 t A\ h( t) : 1; t A (6 . 5 . 3) H( t) : log(1 ; t A) (6 . 5 . 4) t 0, 0, 0 The log-logistic distribution is characterized by two parameters , and . The median of the log-logistic distribution is \A. Figure 6.19( a) to ( c) show the log-logistic hazard, density, and survivorship functions with : 1 and various values of : 2.0, 1, and 0.67.

When 1, the log-logistic hazard has the value 0 at time 0, increases to a peak at t : ( 9 1)A / A, and then declines, which is similar to the lognormal hazard. When : 1, the hazard starts at A and then declines monotonically.

When 1, the hazard starts at infinity and then declines, which is similar to the Weibull distribution. The hazard function declines toward 0 as t approaches infinity. Thus, the log-logistic distribution may be used to describe a first increasing and then decreasing hazard or a monotonically decreasing hazard.

Example 6.5 Byers et al. (1988) used the log-logistic distribution to describe the rate of spread of HIV between 1978 and 1986. Between 1978 and 1980, over 6700 homosexual and bisexual men in San Francisco were enrolled in studies of the prevalence and incidence of sexually transmitted hepatitis B virus (HBV) infections. Blood specimens were collected from the participants.

Four hundred and eighty-eight men who were HBV-seronegative were ran- domly selected to participate in a study of HIV infection later. These men agreed to allow the investigators to test the specimens collected previously together with a current specimen. For those who convert to positive, the infection time is only known to have occurred between the previous negative test and the time of the first positive one. The exact time is unknown. The time to infection is therefore interval censored. The investigators tried to fit several distributions to the interval-censored data, including the Weibull and loglogistic by maximum likelihood methods (discussed in Chapter 7). Based on the Akaike information criterion (discussed in Chapter 9), the log-logistic distribution was found to provide the best fit to the data. The maximum likelihood estimates of the two parameters are : 0.003757 and : 1.424328.

Based on the log-logistic model, the median infection time is estimated to be 50.4 months, and the hazard function approaches its peak at 27.6 months.

6.6 OTHER SURVIVAL DISTRIBUTIONS Many other distributions can be used as models of survival time, three of which we discuss briefly in this section: the linear exponential, the Gompertz (1825), (a) (b) (c) Figure 6.19 ( a) Hazard function of the log-logistic distribution; ( b) density function of the log-logistic distribution; ( c) Survivorship function of the log-logistic distribution.

156    157 and a distribution whose hazard rate is a step function. The linear-exponential model and the Gompertz distribution are extensions of the exponential distribution. Both describe survival patterns that have a constant initial hazard rate. The hazard rate varies as a linear function of time or age in the linear-exponential model and as an exponential function of time or age in the Gompertz distribution.

In demonstrating the use of the linear-exponential model, Broadbent (1958), uses as an example the service of milk bottles that are filled in a dairy, circulated to customers, and returned empty to the dairy. The model was also used by Carbone et al. (1967) to describe the survival pattern of patients with plasmacytic myeloma. The hazard function of the linear-exponential distribution is h( t) : ; t (6 . 6 . 1) where and can be values such that h( t) is nonnegative. The hazard rate increases from with time if 0, decreases if 0, and remains constant (an exponential case) if : 0, as depicted in Figure 6.20.

The probability density function and the survivorship function are, respectively, f ( t) : ( ; t) exp[9( t ; t)] (6 . 6 . 2) and S( t) : exp[9( t ; t)] (6 . 6 . 3) The mean of the linear-exponential distribution is 9(/) ; (/2)\ L ( / 2), where L ( x) : eV y e\ Wdy V Figure 6.20 Hazard function of linear-exponential model.

158 -    Table 6.5 Values of L( x) and G( x) x L ( x) G( x) 0 0 . 886 - 0 . 1 0 . 951 2 . 015 0 . 2 1 . 012 1 . 493 0 . 3 1 . 067 1 . 223 0 . 4 1 . 119 1 . 048 0 . 5 1 . 168 0 . 923 0 . 6 1 . 214 0 . 828 0 . 7 1 . 258 0 . 753 0 . 8 1 . 300 0 . 691 0 . 9 1 . 341 0 . 640 1 1 . 381 0 . 596 2 1 . 712 0 . 361 3 1 . 987 0 . 262 Source: Broadbent (1958).

is tabulated in Table 6.5. A special case of the linear-exponential distribution, the Rayleigh distribution, is obtained by replacing by (Kodlin, 1967). That is, the hazard function of the Rayleigh distribution is h( t) : ; t.

The Gompertz distribution is also characterized by two parameters, and . The hazard function, h( t) : exp( ; t) (6 . 6 . 4) is plotted in Figure 6.21. When 0, there is positive aging starting from e H; when 0, there is negative aging; and when : 0, h( t) reduces to a constant, e H. The survivorship function of the Gompertz distribution is e H S( t) : exp 9 ( e A R 91) (6 . 6 . 5) Figure 6.21 Gompertz hazard function.

159 and the probability density function, from (6.6.4) and (2.2.5), is then f ( t) : exp (; t)91 ( e H > A R 9 e H) (6 . 6 . 6) The mean of the Gompertz distribution is G( e H /) /e H, where G( x) : eV y\ e\ Wdy V is tabulated in Table 6.5.

Finally, we consider a distribution where the hazard rate is a step function: 0 t t t t t h( t) : a a (6 . 6 . 7) aI\ tI\ t tI\ aI t tI\ where t, t, . . . , tI are different time points. Figure 6.22 shows a typical hazard function of this nature for k : 5. Using (2.2.4), the survivorship function can be derived: S( t) : exp(9 a t) 0 t t exp[9 a t 9 a( t 9 t)] t t t (6 . 6 . 8) exp[9 a t 9 a( t 9 t) 9 %9 aI( t 9 tI\) t tI\ Figure 6.22 Step hazard function.

160 -    The probability density function f ( t) can then be obtained from (6.6.7) and (6.6.8) using (2.2.5): f ( t) : a exp(9 a t) 0 t t a exp[9 a t 9 a( t 9 t)] t t t (6 . 6 . 9) aI exp[9 a t 9 a( t 9 t) 9%9 aI( t 9 tI\) t tI\ One application of this distribution is the life-table analysis discussed in Chapter 4. In a life-table analysis, time is divided into intervals and the hazard rate is assumed to be constant in each interval. However, the overall hazard rate is not necessarily constant.

The nine distributions described above are, among others, reasonable models for survival time distribution. All have been designed by considering a biological failure, a death process, or an aging property. They may or may not be appropriate for many practical situations, but the objective here is to illustrate the various possible techniques, assumptions, and arguments that can be used to choose the most appropriate model. If none of these distributions fits the data, investigators might have to derive an original model to suit the particular data, perhaps by using some of the ideas presented here.

Bibliographical Remarks In addition to the papers on the distributions cited in this chapter, Mann et al.

(1974), Hahn and Shapiro (1967), Johnson and Kotz (1970 a, b), Elandt-Johnson and Johnson (1980), Lawless (1982), Nelson (1982), Cox and Oakes (1984), Gertsbakh (1989), and Klein and Moeschberger (1997) also discuss statistical failure models, including the exponential, Weibull, gamma, lognormal, generalized gamma, and log-logistic distributions. Applications of survival distributions can be found easily in medical and epidemiological journals. The following are a few examples: Dharmalingam et al. (2000), Riffenburgh and Johnstone (2001), and Mafart et al. (2002).

EXERCISES 6.1 Summarize the distributions discussed in this chapter, answering the following questions.

(a) What distributions describe constant hazard rates? Give the range of parameter values.

(b) What distributions describe increasing hazard rates? If there are more than one, discuss the differences between them.

(c) What distributions describe decreasing hazard rates? If there are more than one, discuss the differences between them.

161 6.2 Suppose that the survival distribution of a group of patients follows the exponential distribution with G : 0 (year), : 0.65. Plot the survivorship function and find: (a) The mean survival time (b) The median survival time (c) The probability of surviving 1.5 years or more 6.3 Suppose that the survival distribution of a group of patients follows the exponential distribution with G : 5 (years) and : 0.25. Plot the survivorship function and find: (a) The mean survival time (b) The median survival time (c) The probability of surviving 6 years or more 6.4 Consider the following two Weibull distributions as survival models: (i) G : 0, : 1, : 0 . 5 (ii) G : 0, : 0 . 5, : 2 For each distribution, plot the survivorship function and the hazard function and find: (a) The mean (b) The variance (c) The coefficient of variation Which distribution gives the larger probability of surviving at least 3 units of time?

6.5 Suppose that the survival time follows the lognormal distribution with : 1 and : 0.5. Find: (a) The mean survival time (b) The variance (c) The coefficient of variation (d) The median (e) The mode 6.6 Suppose that pain relief time follows the gamma distribution with : 1, : 0.5. Find: (a) The mean (b) The variance (c) The coefficient of variation 6.7 Suppose that the survival distribution is (1) Gompertz and (2) linear- exponential, and : 1, : 2.0. Plot the hazard function and find: (a) The mean (b) The probability of surviving longer than 1 unit of time 6.8 Consider the survival times of hypernephroma patients given in Exercise Table 3.1. From the plot you obtained in Exercise 4.5, suggest a distribution that might fit the data.

C H A P T E R 7 Estimation Procedures for Parametric Survival Distributions without Covariates In this chapter we discuss some analytical procedures for estimatingthe most commonly used survival distributions discussed in Chapter 6. We introduce the maximum likelihood estimates (MLEs) of the parameters of these distributions.

The general asymptotic likelihood inference results that are most widely used for these distributions are given in Section 7.1. We begin to used the general symbol b : ( b, b, . . . , bN) to denote a set of parameters. For example, in discussingthe Weibull distribution, b could be and b could be , and p :2 .

b is called a vector in linear algebra. Readers who are not familiar with linear algebra or are not interested in the mathematical details may skip this section and proceed to Section 7.2 without loss of continuity. In Sections 7.2 to 7.7 we introduce the MLEs for the parameters of the exponential, Weibull, lognormal, gamma, log-logistic, and Gompertz distributions for data with and without censored observations. The related BMDP or SAS programming codes that may be used to obtain the MLE are given in the respective sections.

7.1 GENERAL MAXIMUM LIKELIHOOD ESTIMATION PROCEDURE 7.1.1 Estimation Procedures for Data with Right-Censored Observations Suppose that persons were followed to death or censored in a study. Let t, t, . . . , tP, t>P> , . . . , t>L be the survival times observed from the n individuals, with r exact times and ( n 9 r) right-censored times. Assume that the survival times follow a distribution with the density function f ( t, b) and survivorship function S( t, b), where b : ( b, . . . , bN) denotes unknown p parameters b, . . . , bN in the distribution. As shown in Chapter 6, an exponential distribution has one ( p : 1) parameter , the Weibull distribution has two ( p : 2) 162      163 parameters and , and so on. If the survival time is discrete (i.e., it is observed at discrete time only), f ( t, b) represents the probability of observing t and S( t, b) represents the probability that the survival or event time is greater than t. In other words, f ( t, b) and S( t, b) represent the information that can be obtained from an observed uncensored survival time and an observed right-censored survival time, respectively. Therefore, the product LG f ( tG,b) represents the joint probability of observingthe uncensored survival times, and LG P> S( t>G,b) represents the joint probability of those right-censored survival times. The product of these two probabilities, denoted by L (b), P L L (b) : f ( tG, b) S( t>G, b) G G P> represents the joint probability of observing t, t, . . . , tP, t>P> , . . . , t>L. A similar interpretation applies to continuous survival. L (b) is called the likelihood function of b, which can also be interpreted as a measure of the likelihood of observinga specific set of survival times t, t, . . . , tP, t>P> , . . . , t>L, given a specific set of parameters b. The method of the MLE is to find an estimator of b that maximizes L (b), or in other words, which is most likely to have produced the observed data t, t, . . . , tP, t>P> , . . . , t>L. Take the logarithm of L (b) and denote it by l(b), P L l(b) : log L (b) : log[ f ( tG, b)] ; log[ S( t>G, b)] (7.1.1) G G P> Then the MLE b of b is the set of b, . . . , b N that maximizes l(b): l(b) : max ( l(b)).

b It is clear that b is a solution of the followingsimultaneous equations, which are obtained by takingthe derivative of l(b) with respect to each bH: l(b) : 0 j : 1, 2, . . . , p (7 . 1 . 2) bH The exact forms of (7.1.2) for the parametric survival distributions discussed in Chapter 6 are given in Sections 7.2 to 7.7. Often, there is no closed solution for the MLE b from (7.1.2). To obtain the MLE b, one can use a numerical method. A commonly used numerical method is the Newton  Raphson iterative procedure, which can be summarized as follows.

1. Let the initial values of b, . . . , bN be zero; that is, let b : 0 164       2. The changes for b at each subsequent step, denoted by H, is obtained by takingthe second derivative of the log-likelihood function: l H : 9 (b H\) ( 7.1.3) b b \ l(b H\) b 3. Using H, the value of b H at j th step is b H : b H\ ; H j : 1, 2, . . .

The iteration terminates at, say, the m th step if K , where is a given precision, usually a very small value, 10\ or 10\. Then the MLE b is defined as b : b K\ (7.1.4) The estimated covariance matrix of the MLE b is given by l(b) V (b) : Cov(b) : 9bb \ (7.1.5) One of the good properties of a MLE is that if b is the MLE of b, then g(b) is the MLE of g(b) if g(b) is a finite function and need not be one-to-one. The concept of the Newton  Raphson method for p : 1 is illustrated in detail in Appendix A.

The estimated 100(1 9 )% confidence interval for any parameter bG is ( b G 9 Z?( vGG, b G; Z?( vGG) (7.1.6) where vGG is the i th diagonal element of V (b) and Z? is the 100(19/2) percentile point of the standard normal distribution [ P( Z Z?) : / 2]. For a finite function g( bG) of bG, the estimated 100(19)% confidence interval for g( bG) is its respective range R on the confidence interval (7.1.6), that is, R : g( bG) : bG + ( b G 9 Z?( vGG, b G ; Z?( vGG) (7.1.7) In case g( bG) is monotone in bG, the estimated 100(19)% confidence interval for g( bG) is [ g( b G 9 Z?( vGG), g( b G; Z?( vGG)] (7.1.8)      165 7.1.2 Estimation Procedures for Data with Right-, Left-, and Interval-Censored Observations If the survival times t, t, . . . , tL observed for the n persons consist of uncensored, left-, right-, and interval-censored observations, the estimation procedures are similar. Assume that the survival times follow a distribution with the density function f ( t, b) and the survivorship function S( t, b), where b denotes all unknown parameters of the distribution. Then the log-likelihood function is l(b) : log L (b) : log[ f ( tG, b)]; log[ S( tG, b)] ; log[1 9 S( tG, b)]; log[ S( vG, b)9 S( tG, b)] (7.1.9) where the first sum is over the uncensored observations, the second sum over the right-censored observations, the third sum over the left-censored observations, and the last sum over the interval-censored observations, with vG as the lower end of a censoringinterval. The other steps for obtainingthe MLE b of b are similar to the steps shown in Section 7.1.1 by substitutingthe log - likelihood function defined in (7.1.1) with the log-likelihood function in (7.1.9).

The computation of the MLE b and its estimated covariance matrix is tedious. The following example gives the general procedure for using SAS to carry out the computation.

Example 7.1 If the survival time observed contains uncensored, right-, left-, and interval-censored observations, one needs to create a new data set from the observed data to use SAS to obtain the estimates of the parameters in the distribution. For an observed survival time t (uncensored, right-, or left-censored), we define two variables LB and UB as follows: If t is uncensored, take LB : UB : t; if t is left-censored, LB : . and UB : t; and if t is right-censored, then LB : t and UB:., where . means missing in SAS. If a survival time is interval-censored, [i.e., one observed two numbers t and t, t t and the survival time is in the interval ( t, t)], let LB: t and UB: t.

Assume that the new data set (in terms of LB and UB) has been saved in C:EXAMPLEA.DAT as a text file, which contains two columns (LB in the first column and UB the second column) separated by a space.

As an example, the followingSAS code can be used to obtain the estimated covariance matrix defined in (7.1.5) and the MLE of the parameters of the Weibull distribution for the survival data observed in the text file C:EXAMPLEA.DAT. One can replace d : weibull in the followingcode with the respective distribution in Sections 7.2 to 7.6 (see the SAS code in these sections for details) to obtain the estimate.

data w1; infile c:examplea.dat missover; input lb ub; run; proc lifereg; model (lb,ub):/covb d : weibull; run; 166       7.2 EXPONENTIAL DISTRIBUTION 7.2.1 One-Parameter Exponential Distribution The one-parameter exponential distribution has the followingdensity function; f ( t) : e\H R (7 . 2 . 1) survivorship function; S( t) : e\H R (7 . 2 . 2) and hazard function; h( t) : (7 . 2 . 3) where t 0, 0. Obviously, the exponential distribution is characterized by one parameter, . The estimation of by maximum likelihood methods for data without censored observations will be given first followed by the case with censored observations.

Estimation of for Data without Censored Observations Suppose that there are n persons in the study and everyone is followed to death or failure. Let t, t, . . . , tL be the exact survival times of the n people. The likelihood function, using (7.2.1) and (7.1.1), is L L : e\H RG G and the log-likelihood function is L l() : n log 9 tG (7 . 2 . 4) G From (7.1.2), the MLE of is n : L (7 . 2 . 5) G tG Since the mean of the exponential distribution is 1/ and a MLE is invariant under an one-to-one transformation, the MLE of is L : 1 : G tG : t ( 7.2.6) n   167 It can be shown 2 n / has an exact chi-square distribution with 2 n degrees of freedom (Epstein and Sobel, 1953). Since : 1/ and : 1/, an exact 100(1 9 )% confidence interval for is L\?

L?

(7 . 2 . 7) 2 n 2 n where L? is the 100 percentage point of the chi-square distribution with 2 n degrees of freedom, that is, P( L L?) : (Table B-2). When n is large ( n 25, say), is approximately normally distributed with mean and variance / n. Thus, an approximate 100(1 9 )% confidence interval for is Z Z 9 ? ; ?

(7 . 2 . 8) ( n ( n where Z? is the 100/2 percentage point, P( Z Z?) : / 2, of the standard normal distribution (Table B-1).

Since 2 n / has an exact chi-square distribution with 2 n degrees of freedom, an exact 100(1 9 a)% confidence interval for the mean survival time is 2 n 2 n (7 . 2 . 9) L?

L\?

The followingexample illustrates the procedures.

Example 7.2 Consider the followingremission times in weeks for 21 patients with acute leukemia: 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 8, 8, 9, 10, 10, 12, 14, 16, 20, 24, and 34. Assume that remission duration follows the exponential distribution. Let us estimate the parameter by usingthe formulas given above.

Accordingto (7.2.5), the MLE of the relapse rate, , is : 21 : 0.106 per week 198 The mean remission time is then 198/21 : 9.429 weeks. Usingthe analytical procedures given above, confidence intervals for and can also be obtained.

A 95% confidence interval for the relapse rate , following (7.2.7), is approximately (0.106)(24.433) ( 0.106)(59.342) 42 42 or (0.062, 0.150). A 95% confidence interval for the mean remission time, 168       following (7.2.9), is (42)(9.429) ( 42)(9.429) 59.342 24.433 or (6.673, 16.208).

Once the parameter is estimated, other estimates can be obtained. For example, the probability of stayingin remission for at least 20 weeks, estimated from (7.2.2), is S(20) : exp[90.106(20)] : 0.120. Any percentile of survival time tN may be estimated by equating S( t) to p and solvingfor tN, that is, tN: 9log p/. For example, the median (50th percentile) survival time can be estimated by t: 9log0.5/:6.539 weeks.

Estimation of for Data with Censored Observations We first consider singly censored and then progressively censored data.

Suppose that without loss of generality, the study or experiment begins at time 0 with a total of n subjects. Survival times are recorded and the data become available when the subjects die one after the other in such a way that the shortest survival time comes first, the second shortest second, and so on.

Suppose that the investigator has decided to terminate the study after r out of the n subjects have died and to sacrifice the remaining n 9 r subjects at that time. Then the survival times for the n subjects are t t% t P: t> P> :%: t> L where a superscript plus indicates a sacrificed subject, and thus t> G is a censored observation. In this case, n and r are fixed values and all of the n 9 r censored observations are equal.

The likelihood function, using (7.1.1), (7.2.1), and (7.2.2), is P L : n!

e\H R G( e\H R P) L\ P ( n 9 r)! G and from (7.1.2), the MLE of is r : P (7 . 2 . 10) G t G ; LG P> t> G The mean survival time : 1/ can then be estimated by P : 1 : G t G ; LG P> t> G (7.2.11) r It is shown by Halperin (1952) that 2 r / has a chi-square distribution with 2 r   169 degrees of freedom. The mean and variance of are r /( r 9 1) and /( r 9 1), respectively. The 100(1 9 )% confidence interval for is P\?

P?

(7 . 2 . 12) 2 r 2 r When n is large, the distribution of is approximately normal with mean and variance /( r 9 1). An approximate 100/(1 9 )% confidence interval for is then Z Z 9 ? ; ?

(7 . 2 . 13) ( r 9 1 ( r 9 1 Epstein and Sobel (1953) show that 2 r / has a chi-square distribution with 2 r degrees of freedom. Thus a 100/(1 9 )% confidence interval for (see also Epstein, 1960b) is 2 r 2 r (7 . 2 . 14) P?

P\?

They also develop test procedures for the hypothesis H: : against the alternative H: . One of their rules of action is to accept H if c and reject H if c, where c:( P?) / 2 r and is the significance level. Or if the estimated mean survival time calculated from (7.2.11) is greater then c, the hypothesis H is rejected at the level. The followingexample illustrates the procedure.

Example 7.3 Suppose that in a laboratory experiment 10 mice are exposed to carcinogens. The experimenter decides to terminate the study after half of the mice are dead and to sacrifice the other half at that time. The survival times of the five dead mice are 4, 5, 8, 9, and 10 weeks. The survival data of the 10 mice are 4, 5, 8, 9, 10, 10;, 10;, 10;, 10;, and 10;. Assumingthat the failure of these mice follows an exponential distribution, the survival rate and mean survival time are estimated, respectively, accordingto (7.2.10) and (7.2.11) by : 5 : 0.058 per week 36 ; 50 and : 1/0.058 : 17.241 weeks. A 95% confidence interval for by (7.2.12) is (0.058)(3.247) ( 0.058)(20.483) (2)(5) (2)(5) 170       or (0.019, 0.119). A 95% confidence interval for following (7.2.13) is 2(5)(17.241) 2(5)(17.241) 20.483 3.247 or (8.417, 53.098).

The probability of survivinga given time for the mice can be estimated from (7.2.2). For example, the probability that a mouse exposed to the same carcinogen will survive longer than 8 weeks is S(8) : exp[90.058(8)] : 0.629 The probability of dyingin 8 weeks is then 1 9 0.629 : 0.371.

A slightly different situation may arise in laboratory experiments. Instead of terminatingthe study after the r th death, the experimenter may stop after a period of time T, which may be six months or a year. If we denote the number of deaths between 0 and T as r, the survival data may look as follows: t t% t P t> P> :% : t> L: T Mathematical derivations of the MLE of and are exactly the same and (7.2.10) can still be used. The samplingdistribution of for singly censored data is also discussed by Bartholomew (1963).

Progressively censored data come more frequently from clinical studies where patients are entered at different times and the study lasts a predetermined period of time. Suppose that the study begins at time 0 and terminates at time T and there are a total of n people entered. Let r be the number of patients who die before or at time T and n 9 r the number of patients who are lost to follow-up duringthe study period or remain alive at time T. The data look as follows: t, t, . . . , tP, t>P> , t>P> , . . . , t>L. Orderingthe r uncensored observations accordingto their magnitude, we have t t % tP, t>P> , t>P> , . . . , t>L The likelihood function, using (7.1.1), (7.2.1), and (7.2.2), is P L L : e\H R G e\H RG> G G P> and the log-likelihood function is P L l() : n 9 tG 9 t>G (7 . 2 . 15) G G P>   171 and from (7.1.2), the MLE of the parameter is r : P (7 . 2 . 16) G t G ; LG P> t> G Consequently, P : 1 : G t G ; LG P> t> G (7 . 2 . 17) r is the MLE of the mean survival time. The sum of all of the observations, censored and uncensored, divided by the number of uncensored observations, gives the MLE of the mean survival time. To overcome the mathematical difficulties arisingwhen all of the observations are censored ( r : 0), Bartholomew (1957) defines L : t> G (7 . 2 . 18) G In practice, this estimate has little value.

Distributions of the estimators are discussed by Bartholomew (1957). The distribution of for large n is approximately normal with mean and variance: Var() : L (7 . 2 . 19) (1 9 e\H 2G) G where TG is the time that the i th person is under observation. In other words, TG is computed from the time the i th person enters the study to the end of the study. If the observation times TG are not known, the followingquick estimate of Var() can be used: Var () : (7.2.20) r Thus an approximate 100(1 9 )% confidence interval for is, by (7.1.6), 9 Z?(Var(); Z?(Var() (7.2.21) The distribution of is approximately normal with mean and variance: Var() : L (7 . 2 . 22) G (1 9 e\H 2G) 172       Again, a quick estimate is Var () : (7 . 2 . 23) r An approximate 100(1 9 )% confidence interval for is then, by (7.1.6), 9 Z?(Var(); Z?(Var() (7.2.24) The exact distribution of derived by Bartholomew (1963) is too cumbersome for general use and thus is not included here.

Example 7.4 Consider the remission duration of the 21 leukemia patients receiving6-MP in Example 3.3. The remission times in weeks were 6, 6, 6, 7, 10, 13, 16, 22, 23, 6;, 9;, 10;, 11;, 17;, 19;, 20;, 25;, 32;, 32;, 34;, and 35;. The hazard plot given in Figure 3.6 shows that the exponential distribution fits the data very well. Maximum likelihood estimates of the relapse rate and the mean remission time can be obtained, respectively, from (7.2.16) and (7.2.17): : 9 : 0.025 per week : 1 : 40 weeks 109 ; 250 0.025 The graphical estimate of obtained in Example 3.3 is 0.027, which is very close to the MLE. Thus, the remission duration of leukemia patients receiving 6-MP can be described by an exponential distribution with a constant weekly relapse rate of 2.5% and a mean remission time of 40 weeks. The probability of stayingin remission for one year (or 52 weeks) or more is estimated by S(52) : exp[90.025(52)] : 0.273 Using (7.2.20) and (7.2.23) for the variance of and , the 95% confidence intervals for and are, respectively, (0.009, 0.041) and (13.867, 66.133).

Example 7.5 The results in Examples 7.2 to 7.4 can also be obtained by usingavailable statistical software. Let t denote the observed survival time (exact or censored) and CENS be an index (or dummy) variable with CENS : 0 if t is censored and 1 otherwise. Assume that the data have been saved in C:EXAMPLE.DAT as a text file, which contains two columns ( t in the first column and CENS in second column for the same study subject), separated by a space.

The followingSAS code for procedure LIFEREG can be used to obtain the estimated covariance matrix defined in (7.1.5) and the MLE of the parameter of the exponential distribution for the observed survival data in C:EXAMPLE.DAT.

173 data w1; infile c:example.dat missover; input t cens; run; proc lifereg; model t*cens(0) : /covb d : exponential; run; The respective BMDP code for program 2L is /input file : c:example.dat .

variables : 2.

format : free.

/print level : brief.

cova. survival.

/variable names : t, cens.

/form time : t.

status : cens.

response : 1.

/regress accel : exponential.

/end If SAS is used, the estimated parameter of the exponential distribution can be obtained by : exp(9INTERCEPT), where INTERCEPT is the name of output estimated parameter in SAS procedure LIFEREG. In BMDP 2L, : exp(9CONSTANT) where CONSTANT is given by the program.

7.2.2 Two-Parameter Exponential Distribution In the case where a two-parameter exponential distribution is more appropriate for the data (Zelen, 1966), the density and survivorship functions are defined, respectively, as t G 0, 0 f ( t) : e\H R\ % (7.2.25) 0 t G and t G 0, 0 S( t) : e\H R\ % (7 . 2 . 26) 1 t G where G is called the guarantee time, the minimum survival time before which no deaths occur.

174       Estimation of and G for Data without Censored Observations If t, t, . . . , tL are the survival times of the n patients, using (7.1.1), (7.1.2), (7.2.25), and (7.2.26), the MLE of is n : L (7 . 2 . 27) ( tG 9 G) G where G is an estimate of G that is the smallest observation in the data, G : min( t, t, . . . , tL) (7 . 2 . 28) and the mean survival time is estimated by : G ; 1 / .

Example 7.6 Consider the survival times in months of 11 patients following initial pulmonary metastasis from ostenogenic sarcoma considered by Burdette and Gehan (1970). The data were 11, 13, 13, 13, 13, 13, 14, 14, 15, 15, and 17.

Suppose that the two-parameter exponential distribution is selected. The guarantee time G is estimated by the smallest observation (i.e., G : 11), and the hazard rate estimated by (7.2.27) is : 11 : 0.367 (11 9 11) ; (13 9 11) ; % ; (17 9 11) Thus, the exponential model tells us that the minimum survival time is 11 months, and after that the chance of death per month is 0.367. Similarly, the probability of survivinga given amount of time can then be estimated from (7.2.26). For example, the estimated probability of surviving18 months or longer is S(18) : exp[90.367(18 9 11)] : 0.077 Estimation of and G for Data with Censored Observations We first consider singly censored data. Suppose that an experiment begins with n animals and terminates as soon as the first r deaths occur. For this case, we introduce the estimation procedures derived by Epstein (1960a).

Let the first r survival times be t t% t P and let T * be the total survival observed between the first and the r th death: T * : ( n 9 1)( t 9 t) ; ( n 92)( t 9 t) ; %;( n 9 r ;1)( t P 9 t P\) : 9( n 9 1) t; t; t;%; t P\;( n 9 r;1) t P P : t G 9 nt;( n 9 r) t P (7.2.29) G   175 The best estimates for G and in the sense that they are unbiased and have minimum variance are given by G : t 9 (7 . 2 . 30) n and : T * (7 . 2 . 31) r 9 1 Then can then be estimated by : 1/.

Confidence intervals for the mean survival time are easy to obtain from the fact that 2( r 9 1) / : 2 T */ has a chi-square distribution with 2( r 9 1) degrees of freedom. Thus, for r 1, the 100(1 9 )% confidence interval for is 2( r 9 1) 2( r 91) (7 . 2 . 32) P\?

P\\?

or 2 T * 2 T * (7 . 2 . 33) P\?

P\\?

To find confidence intervals for G, we use the fact that x: 2 n( t 9 G) / and x: 2( r 9 1) / are independent and have a chi-square distribution with 2 and 2( r 9 1) degrees of freedom, respectively. Thus the ratio x n( t n( r 9 1)( t Y : / 2 : 9 G) : 9 G) (7 . 2 . 34) x / 2( r 91) T * follows the F-distribution with 2 and 2( r 9 1) degrees of freedom. Let F P\? be the 100 percentage point of the F P\ distribution [i.e., P( Y F P\?) :] (Table B-3 in Appendix B), and then a 100(19)% confidence interval for G is t 9 F n P\? G t (7.2.35) or t 9 T * F n( r 9 1) P\? G t (7 . 2 . 36) Epstein and Sobel (1953) show that this interval is the shortest in the class of intervals beingused. If for some particular values of r and the value F P\?

is not tabulated in the F-table, Epstein (1960a) suggests using the following 176       confidence intervals for G: ( r 9 1) t 9 g n \? G t (7 . 2 . 37) or t 9 T * g n \? G t (7 . 2 . 38) where g\?: 1 P\91 (7 . 2 . 39) is computable for any and r. Example 7.7 illustrates the procedures.

Example 7.7 In a laboratory experiment 20 mice are injected with a tumor inoculum. These tumor cells multiply and eventually kill the animal. Suppose that the investigator decides to terminate the experiment after 10 deaths. The first occurs 30 days after the experiment starts. The total survival observed between the time when the first and tenth deaths occur is 600 animal days.

Assumingthat the survival distribution of these mice is exponential, the shortest 95% confidence interval for G can be obtained by (7.2.36). Since F:3 . 555, the interval is 30 9 600 (3.555) G 30 (20)(9) or (18.150, 30).

The mean survival time estimated by (7.2.31) is : 66.667 days, and the 95% confidence interval for computed from (7.2.33) is 2(600) 2(600) 31 . 526 8 . 231 or (38.064, 145.790).

When data are progressively censored, Gehan (1970) derives an estimate for G and a modified MLE for the hazard rate . Suppose that r out of the n individuals in the study die before the end of the study and n 9 r individuals are alive at the time of the last follow-up or termination. The n survival times are denoted by t t % t P, t> P> , . . . , t> L An estimate of G obtained by G : max t 9 1 n, 0 (7 . 2 . 40)   177 and the variance of G is Var( G) : 1 (7 . 2 . 41) ( n) 1; 1 r 9 1 When n is large, G and Var( G) can be estimated by G < t (7 . 2 . 42) and Var ( G) < 1 ( n) (7 . 2 . 43) A modified MLE for is r 9 : 1 ( P 7.2.44) G t G ; LG P> t> G 9 nt with variance Var() : (7 . 2 . 45) r 9 1 Any percentile of survival time tN may be estimated by equating S( t) to p and solvingfor t N; that is, t N:9(log Cp) / ; G .

The followingexample illustrates the procedures.

Example 7.8 Suppose that 19 patients with brain tumor are followed in a clinical trial for a year. Their survival times in weeks are 3, 4, 6, 8, 8, 10, 12, 16, 17, 30, 33, 3;, 8;, 13;, 21;, 26;, 35;, 44;, and 45;. In this case n : 19, r : 11, t:3, G t G : 147, and G t> G : 195. The hazard rate per week and its variance may be estimated by (7.2.44) and (7.2.45) as : 10 : 0.035 147 ; 195 9 19(3) and (0.035) Var () : : 0.0001 10 The guarantee time G and its variance may then be estimated by (7.2.40) and (7.2.41): 178       G : max 39 1 , 0:1.496 19;0.035 and Var ( G) : 1 :2 . 487 (19;0 . 035) 1 ; 110 Thus, after a guarantee time of approximately 1.5 weeks, the chance of death per week is 0.035. The estimated median survival time is t:9log0.5;1.496:21.3 weeks 0.035 The probability of survivingat least six months (or 26 weeks) is estimated by S(26) : exp[90.35(26 9 1.496)] : 0.424 7.3 WEIBULL DISTRIBUTION The Weibull distribution has the density and survivorship functions f ( t) : A t A\ exp[9( t)A] S( t) : e\H R A t 0, 0, 0 (7.3.1) The MLE of the parameters and involves equations to be solved simulta- neously. Numerical methods such as the Newton  Raphson iterative procedure (7.1.13) can be applied. We begin with the case where no censored observations are presented.

Let t, t, . . . , tL be the exact survival times of n individuals under investigation. If their survival times follow the Weibull distribution, the log-likelihood function is L l(, ) : n log ; n log ; [( 9 1) log tG 9 A t A G] (7 . 3 . 2) G The MLE of and in (7.3.1) can be obtained by solvingthe followingtwo equations simultaneously: L n 9 t G:0 (7.3.3) G n L L ; n t( log ; log tG 9 G log ; log tG) : 0 (7 . 3 . 4) G G   179 Next, let us consider a typical laboratory experiment in which subjects are entered at the same time and the experiment is terminated after r of the n subjects have failed (or after a fixed period of time T ). In both of these cases the data collected are singly censored. The ordered survival data are t t% t P: t> P> :%: t> L If the time to failure follows the Weibull distribution with the density function given in (7.3.1), the MLE of and may be obtained by solvingthe following two equations simultaneously: r 9 P t G;( n 9 r) t P:0 (7.3.5) G r P ; r log ; log tG G ; P t G(log;log tG);( n 9 r) t P(log;log t P):0 (7.3.6) G When data are progressively censored, we have t t% t P, t> P> , . . . , t> L If the survival distribution is Weibull defined by (7.3.1), the log-likelihood function is P L l(, ) : r log ; r log ; [( 9 1)log t G 9A t A G]9 A t> A G G G P> (7 . 3 . 7) The MLE of and may be obtained by solvingthe followingtwo equations simultaneously: L r 9 A P t G ; t>G :0 (7 . 3 . 8) G G P> r P P ; r t ( log ; log tG 9 G log ; log tG) G G L 9 t; G (log ; log t> G ) : 0 (7 . 3 . 9) G P> The followingexample illustrates the use of available computer software to obtain the MLE of and .

180       Example 7.9 Referringto Example 7.5, for the observed survival data in the file EXAMPLE.DAT, we can use either SAS or BMDP to obtain the estimated parameters of the Weibull distribution. The codes given in Example 7.5 can be used except that d : exponential in the SAS code must be changed to d : weibull and accel : exponential in BMDP code be changed to accel : weibull. If SAS is used, the estimated parameters of the Weibull distribution are : exp(9INTERCEPT) and : 1 SCALE where INTERCEPT and SCALE are produced by SAS procedure LIFEREG.

If BMDP is used, : exp(9INTERCEPT) and : 1 SCALE where CONSTANT and SCALE are given by procedure 2L.

7.4 LOGNORMAL DISTRIBUTION If the survival time T follows the lognormal distribution with density function f ( t) : 1 exp 9 1 (log t 9) (7 . 4 . 1) t(2 2 the mean and the variance are exp( ; ) and [exp()91] exp(2;), respectively. Estimation of the two parameters and has been investigated either by using (7.4.1) directly or by usingthe fact that Y : log T follows the normal distribution with mean and variance . In the following, we discuss the estimation of and for samples with and without censored observations.

7.4.1 Estimation of and 2 for Data without Censored Observations Estimations of and for complete samples by maximum likelihood methods have been studied by many authors: for example, Cohen (1951) and Harter and Moore (1966). But the simplest way to obtain estimates of and with optimum properties is by consideringthe distribution of Y : log T. Let t, t, . . . , tL be the survival times of n subjects. The MLE of is the sample mean of Y given by L : 1 log t n G (7 . 4 . 2) G The MLE of is : 1 L (log t (7 . 4 . 3) n G) 9 ( LG log tG) G n   181 The estimate is also unbiased but is not. The best unbiased estimates of and are and the sample variance s : [ n/( n 9 1)]. If n is moderately large, the difference between s and is negligible.

One of the properties of the MLE is that if is the MLE of , g() is the MLE of g() if g() is a finite function. Therefore, the MLEs of the mean and variance of T are, respectively, exp( ; ) and exp[(91)] exp(2; ).

It is known that : y is normally distributed with mean and variance / n. Hence, if is known, a 100(1 9 )% confidence interval for is < Z? /( n. If is unknown, we can use Students t-distribution. A 100(1 9 )% confidence interval for is < t? L\ s/( n 91, where t? L\ is the 100/2 percentage point of Students t-distribution with n 9 1 degrees of freedom (Table B-7).

Confidence intervals for can be obtained by usingthe fact that n / has a chi-square distribution with n 9 1 degrees of freedom. A 100(1 9 )% confidence interval for is n n (7 . 4 . 4) L\?

L\\?

The followinghypothetical example illustrates the procedures.

Example 7.10 Five melanoma (resected) patients receivingimmunotherapy BCG are followed. The remission duration in weeks are, in order of magnitude, 8, 16, 23, 27, and 28. Suppose that the remission times follow a lognormal distribution. In this case, parameters are estimated by (7.4.2) and (7.4.3) as follows: t log t (log t) 8 2 . 079 4 . 322 16 2 . 773 7 . 690 23 3 . 135 9 . 828 27 3 . 296 10 . 864 28 3 . 332 11 . 102   14 . 615 43 . 806 : 14.615 : 2.923 5 : 1 43.80691 (14.615):0.217 5 5 s : 5 : 0 . 271 5 9 1 182       The mean remission time is exp(2.923 ; 0.217/2), or 20.728, weeks and the standard deviation of the remission time is [exp(0.217) 9 1] exp(5.846 ; 0.217), or 10.204, weeks. A 95% confidence interval for is 2.923 9 2.776 0.5212.923;2.776 0.521 (4 (4 or (2.200,3.646). A 95% confidence interval for , following (7.4.4), is 5(0.217) 5(0.217) 11.1433 0.4844 or (0.097, 2.240).

7.4.2 Estimation of and 2 for Data with Censored Observations We first consider samples with singly censored observations. The data consist of r exact survival times t t% t P and n 9 r right-censored survival times that are at least t P, denoted by t> P. Again, we use the fact that Y :log T has normal distribution with mean and variance . Estimates of and can be obtained from the transformed data yG :log tG. Many authors have investigated the estimation of and : for example, Gupta (1952), Sarhan and Greenberg (1956, 1957, 1958, 1962), Saw (1959), and Cohen (1959, 1961). We shall discuss the methods of Sarhan and Greenbergand Cohen because of the available table that reduces computation time and efforts.

The best linear estimates of and proposed by Sarhan and Greenbergare linear combinations of the logarithms of the r exact survival times: P : aG log t G (7 . 4 . 5) G and P : bG log t G (7 . 4 . 6) G where the coefficients aG and bG are calculated and tabulated by Saharan and Greenbergfor n 20 and are partially reproduced in Table B-8. The variance and covariance of and are tabulated in Table B-9.

The followingexample illustrates the procedure.

Example 7.11 Suppose that in a study of the efficacy of a new drug, 12 mice with tumors are given the drug. The experimenter decides to terminate the study after 9 mice have died. The survival times are, in weeks, 5, 8, 9, 10, 12, 15, 20, 21, 25, 25;, 25;, and 25;. Assume that the times to death of these   183 mice follow the lognormal distribution. In this case n : 12, r : 9, and n 9 r : 3. Using (7.4.5), (7.4.6), and Table B-8, and can be calculated as : 0.036 log5 ; 0.0581 log8 ; 0.0682 log9 ; 0.0759 log10 ; 0.0827 log12 ;0.0888 log15 ; 0.0948 log20 ; 0.1006 log21 ; 0.3950 log25 : 2.811 : 90.2545 log5 9 0.1487 log8 9 0.1007 log9 9 0.0633 log10 9 0.0308 log12 9 0.0007 log15 ; 0.0286 log20 ; 0.0582 log21 ; 0.5119 log25 : 0.747 The variance of and given in Table B-9 are, respectively, 0.0926 and 0.0723 and the covariance of and is 0.0152.

Cohens (1959, 1961) MLEs for the normal distribution can be used for n 20. Let P y : 1 log t r G (7 . 4 . 7) G and s : 1 (log t (7 . 4 . 8) r G) 9 ( log t G) r Then the MLEs of and are : y 9 ( y 9 log t P) (7 . 4 . 9) and : s ; ( y 9 log t P) (7 . 4 . 10) where the value of has been tabulated by Cohen (1961) as a function of a and b. The proportion of censored observations, b, is calculated as b : n 9 r n and a : 1 9 Y ( Y 9 c) ( Y 9 c) where Y : [ b/(1 9 b)] f ( c) /F( c), f ( c) and F( c) beingthe density and distribu- 184       tion functions, respectively, of the standard normal distribution, evaluated at c : (log t P 9) /. Table 7.1 gives values of for b:0 . 01 to 0.90 and a :0 . 00 to 1.00. For a censored sample, after computing a : s /( y 9 log t P), and b : ( n 9 r) /n, enter Table 7.1 with these values of a and b to obtain . For values not tabulated, two-way linear interpolation can be used.

The asymptotic variances and covariance are the following: Var() : m n Var() : m n (7.4.11) Cov(, ) : m n where m, m, and m are also tabulated by Cohen (1961). The table is reproduced in Table 7.2. For any censored sample, compute c : (log t P 9) / and then enter the appropriate columns of Table 7.2 with y : 9 c, and interpolate to obtain the required values of mG, i :1, 2, 3, if the experiment was terminated after a predetermined time. If the experiment was terminated after a given proportion of animals have died, enter Table 7.2 through the percent censored column with percentage censored : 100 b and interpolate to obtain the required value of mG.

To illustrate the use of Tables 7.1 and 7.2 for the computation of , , Var(), Var(), and Cov(, ), consider Example 7.12, adapted from Cohen (1961).

Example 7.12 Suppose that in a laboratory experiment 300 insects were followed until 119 died within seconds, y : 1,304 . 832 seconds, s : 12,128 . 250, and log t:1,450.000 seconds. In this case n :300 and r: 119. Accordingly, a : 12,128 . 25 : 0 . 575 b : 300 9 119 : 0 . 603 (1,304 . 832 9 1,450) 300 From Table 7.1, is approximately 1.36. Using (7.4.9) and (7.4.10), we obtain : 1,304.832 9 1.36(1,304.832 9 1,450) : 1,502.26 seconds : 12,128.250 ; 1.36(1,304.8329 1,450) : 40,788.55 and : 201.96 seconds.

For the variance and covariance of and , we enter Table 7.2 with percentage censored 100 b : 60 . 3 and interpolate linearly to obtain m: 2 . 002, .90 282 314 345 376 405 435 464 492 520 547 575 601 628 654 679 705 730 754 779 803 827 3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

3.

0.8 176 203 229 255 280 305 329 353 376 399 421 443 465 486 507 528 548 568 588 607 626 2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

2.

.70 561 585 608 630 651 672 693 713 732 751 770 788 .806 824 841 858 875 892 908 .924 .940 1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1 1.

1.

1.

1.

1.

1.

1 1 1 8 2 5 39 57 76 94 11 28 45 .6 .336 .358 379 400 419 4 4 4 4 5 5 5 56 577 593 608 624 639 653 66 68 1 1 1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

.60 145 166 185 204 222 240 257 274 290 306 321 337 351 366 380 394 408 422 435 448 461 1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

5.5 9808 9994 017 035 051 067 083 098 113 127 141 155 169 182 195 207 220 232 244 255 267 0.

0.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

1.

.50 8368 8540 8703 8860 9012 9158 9300 9437 9570 9700 9826 9950 007 019 030 042 053 064 074 085 095 0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

0.

1.

1.

1.

1.

1.

1.

1.

1.

1.

5.4 .7096 .7252 .7400 .7542 .7678 .7810 .7937 .8060 .8179 .8295 .8408 .8517 .8625 .8729 .8832 .8932 .9031 .9127 .9222 .9314 .9406 .40 713 .5961 .6101 .6234 .6361 .6483 .6600 6.

.6821 .6927 .7029 .7129 .7225 .7320 .7412 .7502 .7590 .7676 .7761 .7844 .7925 .8005 5.3 .4941 .5066 .5184 .5296 .5403 .5506 .5604 .5699 .5791 .5880 .5967 .6051 .6133 .6213 .6291 .6367 .6441 .6515 .6586 .6656 .6724 .30 .4021 .4130 .4233 .4330 .4422 .4510 .4595 .4676 .4755 .4831 .4904 .4976 .5045 .5114 .5180 .5245 .5308 .5370 .5430 .5490 .5548 5.2 .31862 .32793 .33662 .34480 .35255 .35993 .36700 .37379 .38033 .38665 .39276 .39870 .40447 .41008 .41555 .42090 .42612 .43122 .43622 .44112 .44592 0.2 .24268 .25033 .25741 .26405 .27031 .27626 .28193 .28737 .29260 .29765 .30253 .30725 .31184 .31630 .32065 .32489 .32903 .33307 .33703 .34091 .34471 b 5.1 .17342 .17935 .18479 .18985 .19460 .19910 .20338 .20747 .21139 .21517 .21882 .22235 .22578 .22910 .23234 .23550 .23858 .24158 .24452 .24740 .25022 0.1 .11020 .11431 .11804 .12148 .12469 .12772 .13059 .13333 .13595 .13847 .14090 .14325 .14552 .14773 .14987 .15196 .15400 .15599 .15793 .15983 .16170 9.0 .09824 .10197 .10534 .10845 .11135 .11408 .11667 .11914 .12150 .12377 .12595 .12806 .13011 .13209 .13402 .13590 .13773 .13952 .14126 .14297 .14465 .08 .086488 .089834 .092852 .095629 .098216 .10065 .10295 .10515 .10725 .10926 .11121 .11308 .11490 .11666 .11837 .12004 .12167 .12325 .12480 .12632 .12780 7.0 .074953 .077909 .080568 .038009 .085280 .087413 .089433 .091355 .093193 .094958 .096657 .098298 .099887 .10143 .10292 .10438 .10580 .10719 .10854 .10987 .11116 2 .06 .063627 .066189 .068483 .070586 .072539 .074372 .076106 .077756 .079332 .080845 .082301 .083708 .085068 .086388 .087670 .088917 .090133 .901319 .092477 .0093611 .094720 5 and .0 .052507 .054670 .056596 .058356 .059990 .061522 .062969 .064345 .065660 .066921 .068135 .069306 .070439 .071538 .072605 .073643 .074655 .075642 .076606 .077549 .078471 for .

es 0 .04 .041583 .043350 .044902 .046318 .047629 .048858 .050018 .051120 .052173 .053182 .054153 .055089 .055995 .056874 .057726 .058556 .059364 .060153 .060923 .061676 .062413 : alu V 1, d 3.0 ).

ate .030902 .032225 .033398 .034466 .035453 .036377 .037249 .038077 .038866 .039624 .040352 .041054 .041733 .042391 .043030 .043652 .044258 .044848 .045425 .045989 .046540 1 a stim (196 0 .02 E s .020400 .021294 .022082 .022798 .023459 .024076 .024658 .025211 .025738 .026243 .026728 .027196 .027649 .028087 .028513 .028927 .029330 .029723 .030107 .030483 .030850 n he lue 1 va 1 Co .0 lla .010100 .010551 .010950 .011310 .011642 .011952 .012243 .012520 .012784 .013036 .013279 .013513 .013739 .013958 .014171 .014378 .014579 .014755 .014967 .015154 .015338 ce: r Table7.

0 5 0 5 0 5 0 5 0 5 0 5 0 5 0 5 0 5 0 5 00 a .0 .0 .1 .1 .2 .2 .3 .3 .4 .4 .5 .5 .6 .6 .7 .7 .8 .8 .9 .9 1.

Sour ? Fo 185 186       Table 7.2 Estimated Values of m , m . and m for Var(), Var(), 1 2 3 and Cov(, ) Percentage y m m m Censored 94.0 1.00000 0.500030 0.000006 0.00 93.5 1.00001 0.500208 0.000052 0.02 93.0 1.00010 0.501180 0.000335 0.13 92.5 1.00056 0.505280 0.001712 0.62 92.4 1.00078 0.506935 0.002312 0.82 92.3 1.00107 0.509030 0.003099 1.07 92.2 1.00147 0.511658 0.004121 1.39 92.1 1.00200 0.514926 0.005438 1.79 92.0 1.00270 0.518960 0.007123 2.28 91.9 1.00363 0.523899 0.009266 2.87 91.8 1.00485 0.529899 0.011971 3.59 91.7 1.00645 0.537141 0.015368 4.46 91.6 1.00852 0.545827 0.019610 5.48 91.5 1.01120 0.556186 0.024884 6.68 91.4 1.01467 0.568417 0.031410 8.08 91.3 1.01914 0.582981 0.039460 9.68 91.2 1.02488 0.600046 0.049355 11.51 91.1 1.03224 0.620049 0.061491 13.57 91.0 1.04168 0.643438 0.076345 15.87 90.9 1.05376 0.670724 0.094501 18.41 90.8 1.06923 0.702513 0.116674 21.19 90.7 1.08904 0.739515 0.143744 24.20 90.6 1.11442 0.782574 0.176698 27.43 90.5 1.14696 0.832691 0.217183 30.85 90.4 1.18876 0.891077 0.266577 34.46 90.3 1.24252 0.959181 0.327080 38.21 90.2 1.31180 1.03877 0.401326 42.07 90.1 1.40127 1.13198 0.492641 46.02 0.0 1.51709 1.24145 0.605233 50.00 0.1 1.66743 1.37042 0.744459 53.98 0.2 1.86310 1.52288 0.917165 57.93 0.3 2.11857 1.70381 1.13214 61.79 0.4 2.45318 1.91942 1.40071 65.54 0.5 2.89293 2.17751 1.73757 69.15 0.6 3.47293 2.48793 2.16185 72.57 0.7 4.24075 2.86318 2.69858 75.80 0.8 5.2612 3.3192 3.3807 78.81 0.9 6.6229 3.8765 4.2517 81.59 1.0 8.4477 4.5614 5.3696 84.13 1.1 10.903 5.4082 6.8116 86.43 1.2 14.224 6.4616 8.6818 88.49 1.3 18.735 7.7804 11.121 90.32 1.4 24.892 9.4423 14.319 91.92   187 Table7.2 Continued Percentage y m m m Censored 1.5 33.339 11.550 18.539 93.32 1.6 44.986 14.243 24.139 94.52 1.7 61.132 17.706 31.616 95.54 1.8 83.638 22.193 41.664 96.41 1.9 115.19 28.046 55.252 97.13 2.0 159.66 35.740 63.750 97.72 2.1 222.74 45.930 99.100 98.21 2.2 312.73 59.526 134.08 98.61 2.3 441.92 77.810 182.68 98.93 2.4 628.58 102.59 250.68 99.18 2.5 899.99 136.44 346.53 99.38 Source: Cohen (1961).

m:1 . 635, and m :1 . 051 . Substitutingthese values and :40,788.55 into (7.4.11), we obtain Var() < 40,788.55(2.022) : 274.91 300 var() < 40,788.55(1.635) : 222.30 300 Cov(, ) < 40,788.55(1.051) : 142.90 300 When the data are progressively censored, let t, t, . . . , tP be the uncensored and t> P> , t> P> , . . . , t> L be the censored observations, the likelihood function, using (7.4.1) and (7.1.1), is P l(, ) : 9 r log(2) 9 log t 2 G ; (log tG 9 ) G 2 L ; 1 log exp 9 1 (log x 9) dx G P> R> 2 G x(2 and the MLE of and can be obtained by solvingthe followingtwo 188       equations: log x 9 exp9 1 (log x 9) dx P L 2 log tG 9 ; R>G x(2 : 0 G G P> 1 exp9 1 (log x 9) dx R> 2 G x(2 n P ( 9 ; log tG 9 ) 2 G 2 (log x 9)exp9 1 (log x 9) dx L x 2 ; R>G 2(2 : 0 G P> 1 exp9 1 (log x 9) dx R> 2 G x(2 Again, this can be done by applying the Newton  Raphson iterative procedure.

The followingexample illustrate the use of SAS and BMDP to obtain estimates of the lognormal parameters.

Example 7.13 Referringto Example 7.5, for the observed survival data in the file EXAMPLE.DAT, by changing d : exponential in SAS code to d : lnormal and accel : exponential in BMDP code to accel : lnormal we can obtain the estimated parameters of the lognormal distribution. If SAS is used, the estimated parameters of the lognormal distribution are : INTERCEPT and : SCALE where INTERCEPT and SCALE are the names of output estimated par- ameters in SAS procedure LIFEREG. If BMDP is used, : CONSTANT and : SCALE where CONSTANT and SCALE are given by procedure 2L.

7.5 STANDARD AND GENERALIZED GAMMA DISTRIBUTIONS The density function of the standard gamma distribution is f ( t) : ( t)A\ exp(9 t) t 0, , 0 (7.5.1) ()      189 where () : x A\ e\ Vdx (7.5.2) ( 9 1)!

if is an integer In this section we discuss the MLE of and for data with and without censored observations.

7.5.1 Estimation of and for Data without Censored Observations Suppose that the n patients under study are followed to death and their exact survival times t, t, . . . , tL are known. The MLE of and can be obtained by solvingsimultaneously the two equations n L 9 tG :0 (7 . 5 . 3) G and n () L n log 9 ; log t () G : 0 (7 . 5 . 4) G where () is the derivative of (), () : x A\log( x) e\ V dx (7 . 5 . 5) From (7.5.3), we have n : L (7 . 5 . 6) G tG On eliminating , we substitute (7.5.6) into (7.5.4) and obtain () ( L 9 G tG) L : log 9 log 0 (7 . 5 . 7) () LG tG/n to solve for . This can be done by usingthe Newton  Raphson iterative procedure. Tables for the solution of (7.5.7) for as a function of R are given by Greenwood and Durand (1960), where R is the ratio of the geometric mean to the arithmetic mean of the n observations: R : ( LG tG) L L (7 . 5 . 8) G tG/n 190       Wilk et al. (1962a) show that the relationship between and 1/(1 9 R) is linear.

A table of values of as a function of 1/(1 9 R) given in their paper is reproduced in Table B-10. Thus if R and 1/(1 9 R) are computed from the sample, a MLE of can be found from Table B-10. For values not tabulated, linear interpolation can be used. Having so determined, can be obtained from (7.5.6).

In the method of moments (Fisher, 1922), the estimators are obtained simply by equatingthe population mean and variance to the sample mean and variance. The moment estimators of and are L * : G tG LG( tG 9 t) (7 . 5 . 9) and * : ( LG tG) n LG ( tG 9 t) (7 . 5 . 10) Both types of estimators give biased estimates. The moment estimators are easy to calculate but are inefficient in the sense that their variances are larger than the variance of the MLE. To reduce the bias, Lilliefors (1971) suggests correction factors for these two types of estimators. The corrected MLE of and are, respectively, A: (7 . 5 . 11) 1 ; 3 /n and A A : (7 . 5 . 12) t 19 1 n A The corrected moments estimators of and are * * A : 9 3 (7 . 5 . 13) 1 ; 2 /n n and * * A A : 19 1 (7 . 5 . 14) t n *A Lilliefors shows by the Monte Carlo method that the corrected MLE and the method-of-moment estimates are approximately unbiased. In addition, as longas 2, the corrected moments estimators have no more bias than the corrected MLE and for n : 10 have considerably less bias. For n : 10, 20 and 2, the variance is close to that of the MLE.

191 Example 7.14 Ten patients with melanoma achieve remission after surgery and therapy. They are followed to relapse. The durations of remission in months are recorded as follows: 5, 8, 10, 11, 15, 20, 21, 23, 30, and 40. Assuming that the distribution of remission duration is standard gamma, we first calculate the MLE of and accordingto Wilk et al. (1962a). To compute R, we obtain LG tG:183 and ( LG tG) :15 . 43. Therefore R: 0.84 and 1/(1 9 R) : 6 . 25. From Table B-10, : 2.89830 for 1/(1 9 R) : 6.0 and : 3.14984 for 1/(1 9 R) : 6.5. By linear interpolation, for 1/(1 9 R) : 6.25, : 3.02407. From (7.5.6), : 0.16525. The corrected MLEs obtained from (7.5.11) and (7.5.12) are A: 2.326 and A:0.122. The moment estimates of and following (7.5.9) and (7.5.10) are * : 0.173 and * : 3.171. With the correction factors, * A: 0.1225 and * A:2.3425, which are very close to the corrected MLE.

7.5.2 Estimation of and for Data with Censored Observations When data are singly censored, the survival times can be ordered as t t% t P t> P> :%: t> L where r persons in the study have exact survival times recorded and n 9 r others have their lives terminated after the r th death occurs. In this case, the maximum likelihood procedure becomes much more complicated.

Let : t P, P :[ PG t G] P/t P, and S: PG t G /rt P. The MLE of and and can be obtained by solvingsimultaneously n () n log P : 9 log 9 n 91 J (, ) (7 . 5 . 15) r() r r J(, ) and S : 9 1 9 n 1 e\E (7 . 5 . 16) r J(, ) where J(, ) : t A\ e\E Rdt (7 . 5 . 17) and J (, ) : J t A\ (, ) : log te\E R dt (7 . 5 . 18) Wilk et al. (1962a) generate, for a grid of values of P and S and n/r, tables of values of and : / based on the solutions of (7.5.15) and (7.5.16). The tables are reproduced in Table B-11. Thus, to find and , one needs to 192       compute P and S first. For specific values of P, S, and n/r, and may be looked up from Table B-11. Then can be obtained from : /[ t P].

Interpolations may be needed when any of the values of P, S, and n/r are not tabulated.

Example 7.15, adapted from Wilk et al. (1962a), illustrates the procedure of calculating , , and when Table B-11 is used. This method can also be used in the case of a complete sample (no censored observations); that is, r : n. If it is obvious that some of the observations may be outliers (too large or too small), it is reasonable not to use them in estimation. In this case, r is the number of observations used in the estimation procedure.

Example 7.15 Consider an experiment with n : 34 animals. The following data are the lifetimes tG in weeks of 34 animals: 3, 4, 5, 6, 6, 7, 8, 8, 9, 9, 9, 10, 10, 11, 11, 11, 13, 13, 13, 13, 13, 17, 17, 19, 19, 25, 29, 33, 42, 42, 52, 52;, 52;, and 52;. The study is terminated when 31 animals have died and the other 3 are sacrificed. In our notation, n : 34 and r : 31 .

1. Compute n/r, P, and S: n :34:1 . 10 r 31 t S : G : 487 : 0 . 30 rt P (31)(52) To compute P, it is easier first to compute log P: log P : 1 log t ;33 . 90207 9 1 . 716 : 90 . 622385 r G 9 log t P : 1 31 Hence P : 0 . 24 .

2. Consider the entries for n/r : 1 . 10 and P : 0 . 24 in Table B-11: S : 0 . 28: : 1.986 : 0.365 S : 0 . 32: : 1.449 : 0.410 Usinglinear interpolation, approximate estimates of and are : 1.72 and : 0.39.

3. Finally, : 1.72/(0.39;52) : 0.085.

For a more accurate two-way interpolation, the reader is referred to Wilk et al. (1962a).

193 When the data are progressively censored, let t, t, . . . , tP be the uncensored and t> P> , t> P> , . . . , t> L be the censored observations; the likelihood function is l(, ) : log L (, ) : n log 9 n log () P L ; [( 9 1) log tG 9 tG]; log x A\ e\H Vdx G G P> R>G and the MLE of and can be obtained by solvingthe two equations x A e\H Vdx n P L 9 t R : G 9 G> 0 G G P> x A\ e\H Vdx RG> x A\ e\H V P L log( x) dx n log 9 n () ; R : log t G> 0 () G ; G G P> x A\ e\H Vdx RG> usingthe Newton  Raphson iterative procedure.

7.5.3 Estimation of , , and in the Extended Generalized Gamma Distribution for Data with or without Censored Observations The extended generalized gamma distribution has density function defined in (6.4.10), f ( t) : A?A t?A\ exp[9( t)?] t 0, 0, 0 (7 . 5 . 19) () Let us consider the case 0. Let t, t, . . . , tP be the uncensored and t> P> , . . . , t> L the censored observations from n persons and the survival times follow the generalized gamma distribution. Then the likelihood function is l(, , ) : n log ; n log ; n log 9 n log () P ; [( 9 1)log tG 9( tG)?] G L ; log x?A\exp[9( x)?] dx G P> RG> 194       and the MLE of , , and can be obtained by solvingthe three equations x?A\ > ?exp(9( x)?) dx n P L 9 ?\ R : t? G 9?\ G> 0 (7 . 5 . 20) G G P> x?A\exp(9( x)?) dx RG> n () P n log ; n log ; n 9 ; [ log t () G 9 ( tG)?] G L x?A\exp[9( x)?][ log( x) 9( x)?] dx ; RG> : 0 (7.5.21) G P> x?A\exp(9( x)?) dx RG> n P n log ; ; [ log tG 9( tG)? log( tG)] G L x?A\ exp[9( x)?][ log ; C( x) 9 ( x)? log( x)] dx RG> : 0 (7 . 5 . 22) G P> x?A\exp[9( x]?) dx RG> usingthe Newton  Raphson iterative procedure.

If all the observed survival times are uncensored, the respective equations for the MLE of , , and can be obtained simply by replacing r with n in (7.5.20) (7.5.22). The SAS procedure LIFEREG can be used to obtain the MLE of , , and in the extended generalized gamma distribution.

Example 7.16 Referringto Example 7.5, for the observed survival data in the file EXAMPLE.DAT, by changing d : exponential in the SAS code to d : gamma, one can obtain the MLE of the parameters of the extended generalized gamma distribution: : exp(9INTERCEPT) : SHAPE1 : 1 SCALE SHAPE1 where INTERCEPT, SHAPE1, and SCALE are given by the SAS LIFEREG procedure.

-  195 7.6 LOG-LOGISTIC DISTRIBUTION The log-logistic distribution has the density function t A\ f ( t) : (1 ; t A) (7 . 6 . 1) and survivorship function S( t) : 1 1 ; t A (7 . 6 . 2) where t 0, 0, 0 . Let t, t, . . . , tP be the uncensored and t>P> , t> P> , . . . , t> L the censored observations from n persons and the survival times follow the log-logistic distribution. Then the MLE of and can be obtained from solvingthe followingtwo simultaneous equations: P t A L t> A r 9 2 G ; G :0 (7.6.3) G 1 ; t A G G P> 1 ; t> A G r P P t A L t> A ; G log( tG) ; G log( t> G ) log( tG) 9 2 :0 (7.6.4) G G 1 ; t A G G P> 1 ; t> A G usingthe Newton  Raphson iterative procedure. If all the survival times observed are uncensored, the respective equations for the MLE of and can be obtained simply by replacing r with n in (7.6.3) and (7.6.4).

Example 7.17 Referringto Example 7.5, for the observed survival data in file EXAMPLE.DAT, replacingd : exponential in the SAS code by d : llogistic and accel : exponential in the BMDP code by accel : llogistic, we can obtain the estimated parameters of the log-logistic distribution. If SAS is used, the estimated parameters of the log-logistic distribution are : exp 9INTERCEPT and : 1 SCALE SCALE where INTERCEPT and SCALE are given by the SAS LIFEREG procedure.

If BMDP is used, : exp 9CONSTANT and : 1 SCALE SCALE where CONSTANT and SCALE are produced by the BMDP procedure 2L.

196       Example 7.18 Assume that the tumor-free time of the 30 rats in the low-fat diet group in Table 3.4 follows the log-logistic distribution. The estimates of the two parameters from either SAS or BMDP are : 0.000025484 and : 2.01866. Therefore, from Section 6.5, the median survival time for this group is 188.64 days, and the hazard function approach the peak at 190.37 days.

7.7 OTHER PARAMETRIC SURVIVAL DISTRIBUTIONS The Gompertz distribution (Section 6.6) has the followingsurvivorship and probability density functions: e H S( t) : exp 9 ( e A R 91) (7 . 7 . 1) f ( t) : exp (; t)91 ( e H > A R 9 e H) (7 . 7 . 2) 7.7.1 Estimation of and for Data with or without Censored Observations Assume that t, t, . . . , tL are the observed survival times from n individuals and the survival times follow the Gompertz distribution, without loss of generality, and assume that t, t, . . . , tP are uncensored and t>P, t>P> , . . . , t>L right-censored.

The MLE of and can be obtained by solvingthe equations e H L r ; P [19exp( tG)] ; [1 ; exp( t> G )]:0 (7 . 7 . 3) G G P> P e H L tG 9 [1 ; ( tG 91) exp( tG)] ; [1 ;( t>G 91) exp( t>G)]:0 G P G G P> (7.7.4) usingthe Newton  Raphson iterative procedure.

If all t, t, . . . , tL are uncensored, the MLE of and can be obtained similarly by replacing r with n in (7.7.3) and (7.7.4). The MLE of the parameters of the other models in Section 6.6 can be obtained in a similar manner.

Bibliographical Remarks In addition to the papers cited in this chapter, Gross and Clark (1975) have chapters on estimation and inference in the exponential distribution and on the estimation of parameters of three distributions, includingthe Weibull and  197 gamma. Mann et al. (1974), Lawless (1982), and Nelson (1982) also provide a chapter on the estimation procedures for survival distributions, includingthe exponential, Weibull, gamma, and lognormal. A more recent book is by Klein and Moeschberger (1997). Readers with a background in mathematical statistics and an interest in mathematical treatment of estimation procedures are referred to these books.

EXERCISES 7.1 Consider the survival times given in Exercise 8.2. Assuming that they follow the one-parameter exponential distribution, obtain: (a) The MLE of (b) The MLE of (c) The 95% confidence intervals for and 7.2 Assumingthat the correct entries between errors in Exercise 8.3 follow the two-parameter exponential distribution, obtain: (a) An estimate of G (b) The MLE of (c) The MLE of (d) The probability of 100 correct entries between two errors 7.3 Consider the survival data in Exercise 8.5. Obtain the MLE of the parameter(s) and mean survival times, assuming: (a) A one-parameter exponential distribution (b) A Weibull distribution 7.4 In a study of deep venous thrombosis, the followingblood clot lysis times in hours were recorded from 20 patients: 2, 3, 4, 5.5, 9, 13, 16.5, 17.5, 12.5, 7, 6, 17.5, 11.5, 6, 14, 25, 49, 37.5, 49, and 28. Assume that the blood clot lysis times follow the lognormal distribution.

(a) Obtain MLEs of the parameters and .

(b) Obtain 95% confidence intervals for and .

7.5 Consider the followingtumor-free times in days of 10 animals: 2, 3.5, 5, 7, 9, 10, 15, 20, 30, and 40. Assume that the tumor-free times follow the log-logistic distribution. Estimate the parameters and .

C H A P T E R 8 Graphical Methods for Survival Distribution Fitting The use of probabilitymodels for survival experience has played an increasing-lyimportant role in biomedical sciences. Survival models summarize the survival pattern, suggest further studies, and generate hypotheses. In this chapter we introduce three graphical methods for survival distribution fitting.

In Section 8.1 we discuss the advantages of the graphical techniques. In Section 8.2 we discuss probabilityplotting, including how to make probability plots and how to estimate parameters from them. In Section 8.3 we discuss the theoryand applications of hazard plotting for censored data. In Section 8.4 we introduce the Cox  Snell residual method.

8.1 INTRODUCTION Graphical methods have long been used for displayand interpretation of data because theyare simple and effective. Often used in place of or in conjunction with numerical analysis, a plot of data serves a number of purposes simulta-neouslythat no numerical method can. The basic idea of the three graphical methods is to see if the survival time itself, or a function of it, has a linear relationship with the distribution function and the cumulative hazard function of a given parametric distribution, or a function of the distribution function and the cumulative hazard function. If such a linear relationship exists, it can be demonstrated graphicallyas a straight line. Thus, if one chooses the appropriate distribution and makes a probability, or hazard, plot, the result will be a straight line fit to the data. Parameters of the distribution chosen can be estimated from the probabilityor hazard plots without tedious numerical calculations. Such estimates maybe adequate and useful for preliminary purposes. However, prior information is often not sufficient to choose a suitable distribution, and the plot maynot be a straight line. If the plot is not a straight line, there is no need to estimate the parameters and an alternative 198  199 Figure 8.1 Two curved normal probabilityplots.

distribution maybe selected. If the Cox  Snell residual plotting method is used, estimates of the parameters must be obtained first.

A nonlinear plot can provide insight into the data. There are several possible interpretations. First, the wrong theoretical distribution might have been used. Second, the sample might be from a mixture of populations. In the latter case, it is necessaryto separate the data accordinglyand make a separate plot for each population. If one or two points are wayout of line, theymight be the results of errors in collecting and recording the data or theymight not be from the same population. Other reasons for peculiar looking plots and interpretations of them are discussed byKing (1971) and Hahn and Shapiro (1967).

Consider the normal probabilityplots in Figures 8.1 a and b. The plot in Figure 8.1 a is convex, indicating that the data have a long tail to the left and could be from a distribution with a negativelyskewed densityfunction such as in Figure 8.2 a. On the contrary, the concave plot in Figure 8.1 b indicates that Figure 8.2 Two skewed densityfunctions.

200       the data have a long tail to the right and could be from a distribution with a positivelyskewed densityfunction such as in Figure 8.2 b. From the discussion in Chapter 6, we maytryto fit a lognormal or gamma distribution.

The advantages of graphical methods can be summarized as follows: 1. Theyare fast and simple to use, in contrast with numerical methods, which maybe computationallytedious and require considerable analyti- cal sophistication. The additional accuracyof numerical methods is usuallynot great enough in practice to warrant the effort involved.

2. Probabilityand hazard plots provide approximate estimates of the parameters of the distribution bysimple graphical means.

3. Theyallow one to assess whether a particular theoretical distribution provides an adequate fit to the data.

4. Peculiar appearance of a plot or points in a plot can provide insight into the data when the reasons for the peculiarities are determined.

5. A graph provides a visual representation of the data that is easyto grasp.

This is useful not onlyfor oneself but also in presenting data to others, since a plot allows one to assess conclusions drawn from the data by graphical or numerical means.

8.2 PROBABILITY PLOTTING The basic ideas in probabilityplotting are illustrated bythe following example.

Example 8.1 Consider the white blood cell counts (WBCs) of 23 pediatric leukemia patients given in Table 8.1, ranging from 8000 to 120,000. A sample cumulative distribution is constructed byordering the data from smallest to largest, as shown in Table 8.1. A sample cumulative distribution curve can then be made byplotting each WBC value versus the percentage of the sample equal to or less than that value. That is, the i th ordered data value in a sample of n values is plotted against the percentage 100 i/n. Note that for tied observations, we compute and plot the sample distribution onlyfor the one with the largest i value. This gives a conservative estimate of the survivorship function. For example, the third value of WBC, 10, is plotted against a percentage of 100;3/23 : 13%.

A plot of the cumulative distribution function for most large populations contains manycloselyspaced values and can be well approximated bya smooth curve drawn though the points. In contrast, a sample cumulative distribution function has a relativelysmall number of points and thus somewhat ragged appearance. To approximate the population cumulative distribution function, one draws a smooth curve through the data points, obtaining a best fit byeye. Such a curve from the WBC data is given in Figure 8.3. It is an   201 Table 8.1 Ordered WBCsData and Sample Cumulative Distribution for Example 8.1 Sample Distribution WBC Order, (10) i i/ 23 ( i 9 0 . 5) / 23 \( F ) ?

8 1 8 2 0 . 087 0 . 065 91 . 512 10 3 0 . 130 0 . 109 91 . 233 15 4 0 . 174 0 . 152 91 . 027 20 5 0 . 217 0 . 196 90 . 857 30 6 0 . 261 0 . 239 90 . 709 50 7 50 8 50 9 50 10 50 11 0 . 478 0 . 457 90 . 109 60 12 60 13 0 . 565 0 . 543 0 . 109 75 14 75 15 0 . 652 0 . 630 0 . 333 80 16 80 17 0 . 739 0 . 717 0 . 575 90 18 90 19 90 20 0 . 870 0 . 848 1 . 027 100 21 0 . 913 0 . 891 1 . 233 110 22 0 . 957 0 . 935 1 . 512 120 23 1 . 000 0 . 978 2 . 019 ? \(  ) denotes the inverse of the standard normal distribution function.

estimate of the cumulative distribution function of the population and is used to obtain estimates and other information about the population.

An estimate of the population median (50th percentile) is obtained by entering the plot on the percentage scale at 50% going horizontallyto the fitted line and then verticallydown to the data scale to read the estimate of the median. For the WBC data, an estimate of the population median is 65,000.

The median is a representative of nominal value for the population since half of the population values are above it and half below. An estimate of anyother percentile can be obtained similarlybyentering the plot at the appropriate point on the percentage scale going horizontallyto the fitted line and then verticallydown to the data scale where the estimate is read. For example, an estimate for the 25th percentile is 40,000.

202       Figure 8.3 Sample cumulative distribution curve of the WBC data.

One can obtain an estimate of the proportion of the population that has a WBC below a specific value in a similar way. For example, to find the proportion of the population with a WBC of 10,000 or less, you enter the plot on the horizontal axis at the given value, 10, go verticallyup to the line fitted to the data, and then horizontallyto the probabilityscale, where the estimate of the population proportion is read, 8%. An estimate of the proportion of a population between two given values is obtained byfirst getting an estimate of the proportion below each value and then taking the difference. For example, the estimate of the population proportion with WBC between 10,000 and 65,000 is 50 9 8 : 42%.

As mentioned above, a smooth curve can be fitted byey e to a sample cumulative distribution function to obtain an estimate of the population distribution function. Also, one can fit data with a theoretical cumulative distribution function byusing a probabilityplot and then use this plot to estimate the parameters in the theoretical cumulative distribution function. The distribution maybe the normal, lognormal, exponential, Weibull, gamma, or log-logistic. To make a probabilityplot, one generallyuses ( i 9 0 . 5) /n or i/( n ; 1) to estimate the sample cumulative distribution function at the i th ordered value of the n observations in the sample. The ( i 9 0 . 5) /n for the WBC data are given in Table 8.1.

The probabilityplot is so constructed that if the theoretical distribution is adequate for the data, the graph of a function of t (used as the y-axis) versus a function of the sample cumulative distribution function (used as the x-axis) will be close to a straight line. The parameters of the theoretical distribution can then be estimated from a fitted line. This is carried out as follows.

Step 1. A theoretical distribution for the survival time t has to be selected.

Step 2. The sample cumulative distribution function is estimated byusing ( i 9 0 . 5) /n or i/( n ; 1), i : 1, 2, . . . , n, for the i th ordered t value. For tied   203 observations have the same value, the sample cumulative distribution function is plotted against onlythe t with the largest i value.

Step 3. Plot t or a function of it versus the estimated sample cumulative distribution or a function of it.

Step 4. Fit a straight line through the points byey e. The position of the straight line should be chosen to provide a fit to the bulk of the data and may ignore outliers or data points of doubtful validity.

Figure 8.4 gives a normal probabilityplot of the WBC versus \( F), where \(  ) is the inverse of the standard normal distribution function. The values of \( F(WBC G)) are shown in Table 8.1. The plot is reasonablylinear. The straight line fitted byey e in a probabilityplot can be used to estimate percentiles and proportions within given limits in the same manner as for the sample cumulative distribution curve. In addition, a probabilityplot provides estimates of the parameters of the theoretical distribution chosen. The mean (or median) WBC estimated from the normal probabilityplot in Figure 8.4 is 56,000 [at \( F) : 0, F : 0 . 5 and WBC : 56,000]. At \( F) : 1, WBC : 91,000, which corresponds to the mean plus 1 standard deviation.

Thus, the standard deviation is estimated as 35,000.

We now discuss probabilityplots of the exponential, Weibull, lognormal, and log-logistic distributions.

Figure 8.4 Normal probabilityplot of the WBC data in Example 8.1.

204       Exponential Distribution The exponential cumulative distribution function is F( t) : 1 9 exp[9( t)] t 0 (8 . 2 . 1) The probabilityplot for the exponential distribution is based on the relationship between t and F( t), from (8.2.1), 1 t : 1log (8 . 2 . 2) 1 9 F( t) This relationship is linear between t and the function log[1/(1 9 F( t))]. Thus, an exponential probabilityplot is made byplotting the i th ordered observed survival time t G versus log[1/(19 F( t G))], where F( t G) is an estimate of F( t G), for example, ( i 9 0 . 5) /n, for i : 1, . . . , n.

From (8.2.2), at log1/[1 9 F( t)] : 1, t : 1 /. This fact can be used to estimate 1/ and thus from the fitted straight line. That is, the value t Table 8.2 Probability Plotting for Example 8.2 Order, F, t i ( i 9 0 . 5) / 21 log[1/(1 9 F)] 1 1 1 2 0.071 0.074 2 3 2 4 0.167 0.182 3 5 0.214 0.241 4 6 4 7 0.310 0.370 5 8 5 9 0.405 0.519 6 10 0.452 0.602 8 11 8 12 0.548 0.793 9 13 0.595 0.904 10 14 10 15 0.690 1.173 12 16 0.738 1.340 14 17 0.786 1.540 16 18 0.833 1.792 20 19 0.881 2.128 24 20 0.929 2.639 34 21 0.976 3.738   205 corresponding to log1/[1 9 F( t)] : 1 is an estimate of the mean 1/ and its reciprocal is an estimate of the hazard rate .

Example 8.2 Suppose that 21 patients with acute leukemia have the following remission times in months: 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 8, 8, 9, 10, 10, 12, 14, 16, 20, 24, and 34. We would like to know if the remission time follows the exponential distribution. The ordered remission times t G and the log1/ [1 9 F( t)] are given in Table 8.2. The exponential probabilityplot is shown in Figure 8.5. A straight line is fitted to the points byeye, and the plot indicates that the exponential distribution fits the data verywell. At the point log[1/ (1 9 F( t))] : 1 . 0, the corresponding t, approximately9.0 months, is an estimate of the mean 1/ and thus an estimate of the hazard rate is : 1/9 : 0.111 per month. An alternative is to use (7.2.5) to estimate , : 21/198 : 0.107, which is veryclose to the graphical estimate.

Weibull Distribution The Weibull cumulative distribution function is F( t) : 1 9 exp[9( t)A] t 0, 0, 0 (8 . 2 . 3) The probabilityplot for the Weibull distribution is based on the relationship 1 1 log t : log ; 1 log log (8 . 2 . 4) 1 9 F( t) Figure 8.5 Exponential probabilityplot of the data in Example 8.2.

206       between t and the cumulative distribution function F of t obtained from (8.2.3).

This relationship is linear between log t and the function log(log1/[19 F( t)]).

Thus, a Weibull probabilityplot is a graph of log( t G) and log(log1/ [1 9 F( t G)]), where F( t G) is an estimate of F( t G), for example, ( i 90 . 5) /n, for i : 1, . . . , n.

The shape parameter is estimated graphicallyas the reciprocal of the slope of the straight line fitted to the graph. If the fitted line is appropriate, then at log(log1/[1 9 F( t)]) : 0, the corresponding log( t) is an estimate of log(1/) from (8.2.4). This fact can be used to estimate 1/ and thus graphicallyfrom a Weibull probabilityplot. At log(log1/[1 9 F( t)]) : 0.5, (8.2.4) reduces to log t : log(1/) ; 0.5/. This equation can be used to estimate .

Estimates of the parameters can also be obtained from the method described in Chapter 7 if the Weibull distribution appears to be a good fit graphically.

The following hypothetical example illustrates the use of the Weibull probabilityplot. The small number of observations used in the example is onlyfor illustrative purposes. In practice, manymore observations are needed to identifyan appropriate theoretical model for the data.

Example 8.3 Six mice with brain tumors have survival times, in months of 3, 4, 5, 6, 8, and 10. Log( t G) plotted against log(log1/[19( i 90 . 5) / 6]) for i : 1, . . . , 6 is shown in Figure 8.6. A straight line is fitted to the data point by eye. From the fitted line, at log(log1/[1 9 F( t)]) : 0, the corresponding log( t) : 1 . 9, and thus an estimate of 1/ is approximately6.69 [:exp(1.9)] months and an estimate of is 0.150. At log(log1/[1 9 F( t)]) : 0.5, the corresponding log( t) : 2.09, and thus an estimate of : 0.5/(2.09  1.9) : 2.63.

The maximum likelihood estimates of and obtained from the SAS procedure LIFEREG are 2.75 and 0.148, respectively. The graphical estimates of and are close to the MLE.

Lognormal Distribution If the survival time t follows a lognormal distribution with parameters and , log t follows the normal distribution with mean and variance .

Consequently, (log t 9 ) / has the standard normal distribution. Thus, the lognormal distribution function can be written as F( t) : log t 9 t 0 (8 . 2 . 5) where (  ) is the standard normal distribution function and and are, respectively, the mean and standard deviation of log t.

A probabilityplot for the lognormal distribution is based on the following relationship obtained from (8.2.5): log t : ; \( F( t)) (8 . 2 . 6)   207 Figure 8.6 Weibull probabilityplot of the data in Example 8.3.

The function \(  ) is the inverse of the standard normal distribution function or its 100 F percentile. This relationship is linear between the value log t and the function \( F( t)). Thus, a log-normal probabilityplot is a graph of log( t G) versus \( F( t G)), where F( t G) is an estimate of F( t G).

From (8.2.6), at \( F( t)) : 0, log t : ; and at, \( F( t)) : 1, : log t 9 .

These facts can be used to estimate and from a straight line fitted to the graph.

Example 8.4 In a studyof a new insecticide, 20 insects are exposed.

Survival times in seconds are 3, 5, 6, 7, 8, 9, 10, 10, 12, 15, 15, 18, 19, 20, 22, 25, 28, 30, 40, and 60. Suppose that prior experience indicates that the survival time follows a lognormal distribution; that is, some insects might react to the insecticide veryslowlyand not die for a long time. The log( t G) versus \[( i 9 0 . 5) / 20], i : 1, . . . , 20, are plotted in Figure 8.7. The plot shows a reasonablystraight line. From the fitted line, at \( F( t)) : 0, log t is an estimate of , which is equal to 2.64, and at \( F( t)) : 1, log t : 3 . 4 and thus : 3.4 9 2.64 : 0.76. \( F( t)) can be obtained byapplying Microsoft Excel function NORMSINV.

208       Figure 8.7 Lognormal probabilityplot of the data in Example 8.4.

Log-Logistic Distribution The log-logistic distribution function is t A F( t) : t 0, 0, 0 (8 . 2 . 7) 1 ; t A A probabilityplot for the log-logistic distribution is based on the following relationship obtained from (8.2.7): log t : 1 9 log 1 191 1 9 F( t) log (8.2.8) Thus, a log-logistic probabilityplot is a graph of log( t G) versus log(1/ [1 9 F( t G)] 9 1), where F( t G) is an estimate of F( t G), for example, ( i 90 . 5) /n, for i : 1, . . . , n. From (8.2.8), at log[1/(1 9 F)] 9 1 : 0, log t : 9(1 /) log ; and at log[1/(1 9 F)] 9 1 : 1, log t : (1 /)(1 9 log ). These facts can be used to estimate and . The following example illustrates the log-logistic probabilityplot.

Example 8.5 Consider the following survival times of 10 experimental rats in days: 8, 15, 25, 30, 50, 90, 95, 100, 150, and 300. Figure 8.8 plots log( t G)   209 Figure 8.8 Log-logistic probabilityplot of the data in Example 8.5.

against log(1/[1 9 ( i 9 0 . 5) / 10] 9 1) for i : 1, . . . , 10. To estimate and , from the fitted line, at log(1/[1 9 F( t)] 9 1) : 0, log t : 4 . 0; and at log(1/ [1 9 F( t)] 9 1) : 1, log t : 4 . 6. Thus, we have two equations: 4.0 : 91 ( log and 4.6 : 1 1 9 log ) From these two equations, : 1.667 and : 0.0013.

8.3 HAZARD PLOTTING Hazard plotting (Nelson 1972, 1982) is analogous to probabilityplotting, the principal difference being that the survival time (or a function of it) is plotted against the cumulative hazard function (or a function of it) rather than the distribution function. Hazard plotting is designed to handle censored data.

Similar to probabilityplotting, estimates of parameters in the distribution can be determined from the hazard plot with little computational effort.

To determine if a set of survival time with censored observation is from a given theoretical distribution, we construct a hazard plot byplotting the survival time (or a function of it) versus an estimation cumulative hazard (or 210       a function of it). The cumulative hazard function can be estimated byfollowing the steps below.

Step 1. Order the n observations in the sample from smallest to largest without regard to whether theyare censored. If some uncensored and censored observations have the same value, theyshould be listed in random order. In the list of ordered values, the censored data are each marked with a plus.

Step 2. Number the ordered observations in reverse order, with n assigned to the smallest data value, n 9 1 to the second smallest, and so on. The numbers so obtained are called K values or reverse-order numbers. For the uncensored observation, K is the number of subjects still at risk at that time.

Step 3. Obtain the corresponding hazard value for each uncensored observation. Censored observations do not have a hazard value. The hazard value for an uncensored observation is 1 /K. This is the fraction of the K individuals who survived that length of time and then failed. It is an observed conditional failure probabilityfor an uncensored observation.

Step 4. For each uncensored observation, calculate the cumulative hazard value. This is the sum of the hazard values of the uncensored observation and of all preceding uncensored observations. For tied uncensored observations, the cumulative hazard is evaluated onlyat the smallest K among the uncensored observations.

The table in the following example illustrates the procedure.

Example 8.6 Consider the remission data of the 21 leukemia patients receiving 6-MP in Example 3.3. Table 8.3 illustrates the procedure for estimating the cumulative hazard function.

We now discuss the basic idea underlying hazard plotting for the exponential, Weibull, lognormal, and log-logistic distributions.

Exponential Distribution The exponential distribution has constant hazard function h( t) : . Thus, the cumulative hazard function is H( t) : t (8.3.1) From (8.3.1), the time can be written as a linear function of the cumulative hazard H, t : 1 H( t) (8 . 3 . 2) Thus, t plots as a straight-line function of H. The slope of the fitted line is the   211 Table 8.3 Estimation of Cumulative Hazard Reversed Cumulative Order, Hazard, Hazard, t K 1 /K H( t) 6 21 0 . 048 6; 20 6 19 0 . 053 6 18 0 . 056 0 . 156 7 17 0 . 059 0 . 215 9; 16 10 15 0 . 067 0 . 281 10; 14 11; 13 13 12 0 . 083 0 . 365 16 11 0 . 091 0 . 456 17; 10 19; 9 20; 8 22 7 0 . 143 0 . 598 23 6 0 . 167 0 . 765 25; 5 32; 4 32; 3 34; 2 35; 1 mean survival time 1/ of the distribution. More simply, 1/ is the value of t when H( t) : 1. This fact is used to estimate 1/ from an exponential hazard plot.

Example 8.7 Using the estimated cumulative hazard values H( t) in Table 8.3, we construct the exponential hazard plot in Figure 3.5 byplotting each exact time t against its corresponding H( t). The configuration appears to be reasonablylinear, suggesting that the exponential distribution provides a reasonable fit. In Chapter 3 we see that the Weibull distribution gives a better fit than the exponential. We use the data here just to demonstrate how the parameter can be estimated.

To find an estimate for the mean remission time of the leukemia patients, we can use H( t) : 0 . 5 since the time for which H : 1 is out of the range of the horizontal axis. At H( t) : 0 . 5, t : 16 . 9, from (8.3.2), an estimate of is 0.5/16.9 : 0.0296. Thus, an estimate of the mean remission time is 34 weeks.

212       Weibull Distribution The Weibull distribution has the hazard function h( t) : ( t)A\ t 0 The cumulative hazard function is H( t) : ( t)A t 0 (8 . 3 . 3) and is plotted in Figure 8.9 for four different values of : 0.5, 1, 2, and 4. From (8.3.3), the time t can be written as a function of the cumulative hazard function, that is, t : 1 [ H( t)]A (8 . 3 . 4) Taking the logarithm of (8.3.4), we obtain 1 log t : log ; 1 log H( t) (8 . 3 . 5) Since log t is a linear function of log H( t), a plot of log t against log H( t) is a straight line. For log H( t) : 0 or H( t) : 1, (8.3.5) reduces to log t : log(1/), and thus the corresponding time t equals 1/. This fact is used to estimate 1/ and consequently, . The slope of the fitted straight line is 1/, or at log H( t) : 1, (8.3.5) can be written as : 1/(log t ; log ). This equation can be used to estimate .

Figure 8.9 Cumulative hazard functions of the Weibull distribution with :0.5, 1, 2, 4.

213 Figure 8.10 Weibull hazard plot of the data in Example 8.8.

Example 8.8 Consider the following survival times in months of 14 patients: 15, 25, 38, 40;, 50, 55, 65, 80;, 90, 140, 150;, 155, 250;, 252.

Figure 8.10 is the hazard plot with log t versus log H( t) of the data. From the fitted line, at log H( t) : 0, log t : 4 . 8 . Thus, t : 121 . 5 and the estimate of is : 1/ t : 0 . 0082. Similarly, at, log H( t) : 1, log t : 5 . 6, and thus : 1/ (5.6 9 4.8) : 1.25.

Lognormal Distribution The densityfunction of a lognormal distribution is f ( t) : 1 exp 9 1 (log t 9) t (2 2 : 1 g log t 9 t t 0 (8.3.6) where g( x) is the standard normal densityfunction. The lognormal cumulative distribution function is F( t) : log t 9 t 0 (8 . 3 . 7) 214       where (  ) is the standard normal distribution function. Thus, by (2.10), the hazard function can be written as 1 g log t 9 t h( t) : 1 9 log t 9 (8 . 3 . 8) The cumulative hazard function, plotted in Figure 8.11 for three values of , is H( t) : 9log 19log t 9 (8 . 3 . 9) From (8.3.9), the logarithm of the survival time t as a function of the cumulative hazard H is log t : ; \[1 9 e\ & R] (8 . 3 . 10) where \(  ) is the inverse of the standard normal distribution function.

Thus, log t is a linear function of \[1 9 e\ & R]. The log-normal hazard plot is a graph of log t versus \[1 9 e\ & R]. From (8.3.10), at \[1 9 e\ & R] : 0, log t : ; and at \[1 9 e\ & R] : 1, log t : ; .

These facts can be used to estimate and .

Example 8.9 Consider the following remission times in months of 18 cancer patients: 4, 5, 6, 7, 8, 9;, 12, 12;, 13, 15, 18, 20, 25, 26;, 28;, 35, 35;, 56. Figure 8.12 gives the log-normal hazard plot. From the fitted line by eye, at \[1 9 e\ & R] : 0, log t : 2 . 8; and at \[1 9 e\ & R] : 1, Figure 8.11 Cumulative hazard functions of the lognormal distribution with : 0.1, 0.5, 1.0.

215 log t : 3 . 76. Thus, the estimate of is 2.8 and the estimate of is 3.76 9 2.8 : 0.96.

Log-Logistic Distribution The cumulative hazard function of the log-logistic distribution is H( t) : log(1 ; t A) This equation can be written as log t : 1logexp[ H( t)] 9191log (8.3.11) Thus, log t is a linear function of logexp[ H( t)] 9 1. A log-logistic hazard plot is a graph of log t versus logexp[ H( t)] 9 1. From (8.3.11), at logexp[ H( t)] 9 1 : 0, log t : 9(1 /) log ; and at logexp[ H( t)] 9 1 : 1, log t : (1 /) 9 (1 /) log . These facts can be used to estimate and .

8.4 COX-- SNELL RESIDUAL METHOD The Cox  Snell (1968) residual method can be applied to anyparametric model. The Cox  Snell residual rG for the i th individual with observed survival time tG, uncensored or censored, is defined as rG :9log S( tG) i : 1, 2, . . . , n (8 . 4 . 1) Figure 8.12 Lognormal hazard plot of the data in Example 8.9.

216       where S( t) is the estimated survival function based on the MLE of the parameters. If the observed tG is censored, the corresponding rG is also censored.

Since the cumulative hazard function H( t) :9log S( t), the Cox  Snell residual rG is an estimated cumulated hazard value at tG. The important propertyof the Cox  Snell residual is that if the model selected fits the data, rGs follow the unit exponential distribution with densityfunction f 0( r) : e\ P.

Let S0( r) denote the survival function of the Cox  Snell residual rG. Then S0: P f0( x) dx: P e\ Vdx: e\ P, and 9log S0( r) :9log( e\ P) : r (8.4.2) Let S 0( r) denote the Kaplan  Meier estimate of S0( r) . It is clear from (8.4.2) that the plot of rG versus 9log S 0( rG) should be a straight line with unit slope and zero intercept if the fitted survival distribution is appropriate, regardless of the form of the distribution.

The procedure for using Cox  Snell residuals can be summarized as follows.

1. Use the methods shown in Sections 7.1 to 7.7 to find the MLE of the parameters of the selected theoretical distribution.

2. Calculate Cox  Snell residuals rG :9log S( tG), i: 1, 2, . . . , n, where S( tG) is the estimated survival function with the MLE of the parameters.

3. Applythe Kaplan  Meier method to estimate the survival function S0( r) of the Cox  Snell residuals rGs obtained in step 2, then using the estimate S 0( r), calculate 9log S 0( rG), i:1, 2, . . . , n.

4 . Plot rG versus 9log S 0( rG), i:1, 2, . . . , n. If the plot is closed to a straight line with unit slope and zero intercept, the fitted distribution is appropriate.

From (8.4.1), if an individual survival time is right-censored, say, t> G and the fitted model is correct, the corresponding Cox  Snell residual 9log S( t> G ) : H( t> G ) is smaller than the residual evaluated at an uncensored observation with the same value tG since H( t) is a monotone-increasing function of t. To take this into account, two modified Cox  Snell residuals have been proposed for censored observations (Crowleyand Hu, 1977). One is based on the mean, and the other is based on the median (:log 2 : 0.693) of the unit exponential distribution byassuming that difference between H( tG) and H( t>G) also follows the unit exponential distribution. For a censored observation t> G , the modified residual r> G is defined as r> G : rG ; 1 (8 . 4 . 3) or r> G : rG ; 0 . 693 where rG:9log S( tG) (8 . 4 . 4) Example 8.10 Consider the tumor-free time data observed from rats fed with saturated diets in Table 3.4. We select the lognormal distribution for this     217 set of data for illustrative purposes. Using methods discussed in Chapter 7, the MLE of the parameters obtained are : 4.76458 and : 0.56053. We then calculate the Cox  Snell residuals rG:9log S( tG) :9log[19 F( tG)], where F( t) is the distribution function of the lognormal distribution. An easywayto compute rG for the lognormal distribution is to use the relationship between the normal and lognormal distributions, i.e., the distribution function of the lognormal distribution, F( t), is equivalent to [(log t 9 ) / ], where ( ) is the distribution function of the standard normal distribution. We can use Microsoft Excel function NORMSDIST to calculate ( t). Thus, for the lognormal distribution, S( tG) :19([log( tG) 94 . 76458] / 0 . 56053) Using the specific notation of NORMSDIST, ln for log, rG: 9ln(19normsdist[ln( tG) 94 . 76458] / 0 . 56053) The rGs so obtained are given in Table 8.4. The next step is to obtain the Kaplan  Meier estimate of the survival function S( rG), and compute 9log S( rG).

These values are also given in Table 8.4.

Figure 8.13 gives the graph of rG versus 9log S 0( rG), i : 1, . . . , 22. The graph is close to a straight line with unit slope and zero intercept. Therefore, a Figure 8.13 Cox  Snell residual plot for the fitted lognormal model on the tumor-free time data for rats fed with saturated diets.

218       Table 8.4 Kaplan--Meier Estimate of Survivorship Function for the Cox--Snell Residuals from the Fitted Lognormal Model on Tumor-Free Time Data for Rats Fed with Saturated Diets t r?

S 0( r) @ 9log S 0( r) 0 . 000 1 . 000 0 . 000 43 0 . 037 0 . 967 0 . 034 46 0 . 049 0 . 933 0 . 069 56 0 . 098 0 . 900 0 . 105 58 0 . 110 0 . 867 0 . 143 68 0 . 181 0 . 833 0 . 182 75 0 . 239 0 . 800 0 . 223 79 0 . 275 0 . 767 0 . 266 81 0 . 294 0 . 733 0 . 310 86 0 . 342 0 . 667 0 . 405 86 0 . 342 0 . 667 0 . 405 89 0 . 373 0 . 633 0 . 457 96 0 . 447 0 . 600 0 . 511 98 0 . 469 0 . 567 0 . 568 105 0 . 548 0 . 533 0 . 629 107 0 . 571 0 . 500 0 . 693 110 0 . 606 0 . 467 0 . 762 117 0 . 690 0 . 433 0 . 836 124 0 . 776 0 . 400 0 . 916 126 0 . 800 0 . 367 1 . 003 133 0 . 889 0 . 333 1 . 099 142 1 . 004 0 . 267 1 . 322 142 1 . 004 0 . 267 1 . 322 165 1 . 305 0 . 233 1 . 455 170; 1.371; 200; 1.769; 200; 1.769; 200; 1.769; 200; 1.769; 200; 1.769; 200; 1.769; ? r, ordered Cox  Snell residuals from the fitted lognormal model.

@S0( r), Kaplan  Meier estimate of survivorship function for the Cox  Snell residuals.

lognormal model maybe appropriate for the tumor-free times observed. In Chapter 9 (Example 9.2) we will see that the lognormal model was not rejected based on a goodness-of-fit test. Thus the result is consistent with those obtained byusing the analytical method. A weakness of the Cox  Snell residual method is that the plot does not indicate the kind of departure the data have from the model selected if the configuration is not linear.

219 Bibliographical Remarks Probabilityplotting has been widelyused since Daniels (1959) classical work on the use of half-normal plot. A quite complete and excellent treatment of probabilityplotting is given byKing (1971). Although examples given are applications to industrial reliability, its interpretation of probability plots of manydistributions, such as the uniform, lognormal, Weibull, and gamma, are applicable to biomedical research. Recent applications of probabilityplotting include Leitner et al. (1986), Horner (1987), Waters et al. (1991), and Tsumagari et al. (2000).

Hazard plotting was developed byNelson (1972, 1982). Applications in- cluded Gore (1983) and Wurpel et al. (1986).

EXERCISES 8.1 Show that the Cox  Snell residuals defined in (8.4.1) follow the unit exponential distribution with densityfunction f ( r) : exp(9 r).

8.2 Consider the following survival times of 16 patients in weeks: 4, 20, 22, 25, 38, 38, 40, 44, 56, 83, 89, 98, 110, 138, 145, and 27.

(a) Does the exponential distribution provide a reasonable fit to the survival data? Use the probabilityplotting technique.

(b) Estimate graphicallythe parameter of the exponential distribution and consequently, the mean survival time.

8.3 To computerize patients records, a data clerk is hired to transcribe medical data from the patients charts to computer coding forms. The number of correct entries between errors is listed in chronological order of occurrence over a period of five days as follows: 73, 12, 40, 65, 100, 15, 70, 40, 110, 64, 200, 6, 90, 102, 20, 102, 90, 34. The assumption is that the data clerk, during the five days, would not change her error rate appreciably. Use the technique of probability plotting to evaluate the assumption above. What is your conclusion?

8.4 Twenty-five rats were injected with a give tumor inoculum. Their times, in days, to the development of a tumor of a certain size are given below.

30 53 77 91 118 38 54 78 95 120 45 58 81 101 125 46 66 84 108 134 50 69 85 115 135 Which of the distributions discussed in this chapter provide a reasonable fit to the data? Estimate graphicallythe parameters of the distribution chosen.

220       8.5 In a clinical study, 28 patients with cancer of the head and neck did not respond to chemotherapy. Their survival times in weeks are given below.

1.7 8.3 14.0 22.7 6.0; 13.1; 5.1 9.6 15.9 33.0 7.4; 13.4; 5.3 11.3 16.7 3.7; 8.0; 16.1; 6.0 12.1 17.0 5.0; 8.3; 8.3 12.3 21.0 5.9; 9.1; (a) Make a hazard plot for each of the following distributions: exponen- tial, Weibull, lognormal, and log-logistic.

(b) Which distribution provides a reasonable fit to the data? Estimate graphicallythe parameters of the distribution chosen.

8.6 Thirty-one patients with advanced melanoma treated with combined chemotherapy, immunotherapy, and hormonal therapy have survival times as given below.

26.3; 16.1 24.0 4.3 31.3; 94.0 49.6 77.9 97.6; 17.6; 9.1 27.3 16.6; 7.3 16.3 34.6; 61.9; 3.4 75.6; 9.4 46.6; 10.9 14.3 25.7 22.4; 13.0 56.4 88.7 7.1 64.4; 9.1 (a) Make a hazard plot for each of the following distributions: exponen- tial, Weibull, lognormal, and log-logistic.

(b) Which distribution provides a reasonable fit to the data? Estimate the parameters of the distribution chosen.

8.7 Consider the survival times of the hypernephroma patients in Exercise Table 3.1 (see Exercise 4.5). Make a hazard plot for the distribution you chose in Exercise 6.8. Did you make a good selection? If not, try two other distributions.

8.8 Consider the following survival times in weeks of 10 mice with injection of tumor cells: 5, 16, 18;, 20, 22;, 24;, 25, 30;, 35, 40;. Make an exponential hazard plot. Does the exponential distribution provide a reasonable fit? If not, is the lognormal distribution better?

8.9 Consider the following survival times in months of 25 patients with cancer of the prostate. Use a graphical method to see if the survival time of prostate cancer patients follows the exponential distribution with : 0.01: 2, 19, 19, 25, 30, 35, 40, 45, 45, 48, 60, 62, 69, 89, 90, 110, 145, 160, 9;, 10;, 20;, 40;, 50;, 110;, 130;.

8.10 Make a log-logistic hazard plot of the following data and estimate the two parameters: 20, 30, 32;, 40, 60, 100, 150, 200;, 300.

C H A P T E R 9 Tests of Goodness of Fit and Distribution Selection In Chapter 8 we discuss three graphical methods for checking if a parametric distribution fits the observed data. Parametric distributions can be grouped into families. First, any given distribution with different parameter values forms a family. Second, if a distribution includes other distributions as its special cases, this distribution is a nesting (larger) family of these distributions. For example, the distributions introduced in Chapter 6 belongto more than one nested family. First, the Weibull distribution reduces to the exponential when : 1. Therefore, the exponential distribution is a special case of the Weibull and the two distributions are said to belongto one family, the Weibull family.

Second, consider the standard gamma distribution; when : 1, it reduces to the exponential, and when : and :, it becomes the chi-square distribution with degrees of freedom. Thus, the gamma distribution includes the exponential and chi-square as a family. Now let us consider the generalized gamma distribution. It reduces to the exponential if : : 1, the Weibull if : 1, the lognormal if ; -, and the gamma if : 1. Thus, the generalized gamma distribution includes these four distributions and represents a large family of distributions. The relationship of the generalized gamma distribution to the exponential, Weibull, lognormal, and gamma distributions allows us to evaluate the appropriateness of these distributions relative to each other and to a more general distribution. It is known that the generalized gamma distribution is a special case of the generalized F-distribution and therefore belongs to the generalized F family (Kalbfleisch and Prentice, 1980) Because of its complexity, we do not cover the generalized F family.

In this chapter we discuss several analytical procedures for comparing parametric distributions and assessingg oodness of fit. In Section 9.1 we introduce several widely used statistics for testingthe appropriateness of a distribution. Readers who are not familiar with linear algebra or are not interested in the mathematical details may skip this section without loss of continuity. In Section 9.2 we discuss statistics for testingwhether a distribution 221 222         is appropriate by comparingit with other distributions in the same family or a more general family. Section 9.3 covers the selection of a distribution based on Baysian information criteria. Section 9.4 covers the statistics for testing whether a given distribution with known parameters is appropriate. All the test statistics discussed in Sections 9.1 to 9.4 are based on asymptotic likelihood inferences. In Section 9.5 we introduce the test statistic of Hollander and Proschan (1979) for testingwhether a distribution with given parameters is appropriate. Computer codes for BMDP or SAS that can be used to carry out the test procedures are provided.

9.1 GOODNESS-OF-FIT TEST STATISTICS BASED ON ASYMPTOTIC LIKELIHOOD INFERENCES We take the exponential distribution as an example to see how to construct statistics to test whether it is appropriate for the observed survival times. As noted in Chapter 6, the Weibull family with : 1, the gamma family with : 1, and the generalized gamma family with : : 1 reduce to the exponential distribution. Therefore, to test if the exponential distribution is appropriate for the observed survival time, we can first fit a Weibull distribution and test if : 1, or fit a gamma distribution, then test if : 1, or fit a generalized gamma distribution, then test if : : 1. Similarly, to test whether the family of Weibull distributions, or the gamma distributions, or the lognormal distributions is appropriate for the survival data observed, we can fit a generalized gamma distribution (their nestingdistribution) and then test if : 1, or : 1, or with ; -, respectively. Thus, testingthe appropriateness of a family of distributions is equivalent to testingwhether a subset of the parameters in its nestingdistribution equal to some specific values. If the data can be assumed to follow a certain distribution but the values of its parameters are uncertain, we need to test only that the parameters are equal to certain values. In the following, we separately introduce test statistics for testing whether some of the parameters in a distribution are equal to certain values and whether all parameters in a distribution are equal to certain values.

Readers who are interested in a detailed discussion of these statistics are referred to Kalbfleisch and Prentice (1980).

9.1.1 Testing a Subset of Parameters in a Distribution Let b : (b,b) denote all the parameters in a parametric distribution, where b and b are subsets of parameters, and let the hypothesis be H: b: b (9.1.1) where b is a vector of specific numbers. Let b be the MLE of b, b(b) the MLE of b given b:b, and V(b) the submatrix of the covariance matrix in --   223 (7.1.5), V (b), correspondingto b. Under H and some mild assumptions, both of the followingtwo statistics have an asymptotic chi-square distribution with degrees of freedom equal to the dimension of (or the number of parameters in) b.

Log-likelihood ratio statistic: X*: 2[ l(b)9 l(b(b), b)] (9.1.2) Wald statistic: X5 :(b9b) V \ (b)(b 9 b) (9.1.3) If the number of parameters in b is equal to q, for a given significant level , H is rejected if X* O ? when the likelihood ratio statistic is used; or if X5 O? or X5 O\?, (two-sided test) or X5 O? (one-sided test) when the Walds statistic is used, where O?, O? and O\? are the 100(1 9 ), 100(1 9 /2), and 100/2 percentile points of the chi-square distribution with q degrees of freedom; that is, P( O O?) : and P( O O?) : P( O O\?) :2 Example 9.1 Suppose that we wish to test whether the observed data are from an exponential distribution. We can use a Weibull distribution and test whether its shape parameter, , is equal to 1. The Weibull distribution has two parameters, and ; thus b : (, ) and the null and alternative hypotheses are: H: :1 (the underlyingdistribution is an exponential distribution)(9.1.4) H: "1 (the underlyingdistribution is a Weibull distribution) Let b : (, ) be the MLE of b, l5(b): l5(, ) and l#() be the log-likelihood of the Weibull and exponential distributions, respectively, l#() Yl5((1),1), where (1) is the MLE of in the Weibull distribution given : 1. The log-likelihood ratio and Wald statistics defined in (9.1.2) and (9.1.3) in this case become X*:2[ l5(, )9 l5((1), 1)] (9.1.5) and X5 :( 91) V \ (, )( 9 1) (9 . 1 . 6) 224         respectively, where V(, ) is the second diagonal element of the covariance matrix l5(, ) V (, ) :9 and l5(,) l \ (9 . 1 . 7) 5(, ) l5(, ) V \ (, ) :9[ l5(, ) /][ l5(, ) /] 9 ( l5(, ) / ) l5(, ) / (9 . 1 . 8) For a given significant-level , H is rejected if X*?, when the likelihood ratio statistic is used; or if X5? or X5 \?, when the Wald statistic is used.

It must be pointed out that failure to reject H in (9.1.4) does not imply that an exponential distribution provides the best fit to the data. On the other hand, rejection of H does not indicate that a Weibull distribution is the choice either. Further testingof other distributions is needed. The details and examples are given in Section 9.2.

Since the gamma and generalized gamma distribution also include the exponential as a special case, similar test statistics can be constructed to test the null hypothesis that the data are from the exponential distribution by using the gamma, the generalized gamma, or the extended generalized gamma distribution.

9.1.2 Testing All Parameters in a Distribution To test whether all of the parameters in b equal a given set of known values b, the null hypothesis is H:b:b (9.1.9) and the followingthree test statistics can be used.

Log-likelihood ratio statistic: X*:2[ l(b) 9 l(b)] (9.1.10) Wald statistic: l(b l(b) X ) 5 : 9(b 9 b) ( ( b 9 b b 9 b b b ) or:9(b9b)bb ) (9.1.11)         225 Score statistic: l(b l(b X ) ) 1 : l(b) 9 or: l(b) V(b) b b b \ l(b) b b b (9.1.12) where V (b) is the estimated covariance matrix in (7.1.5). Under H and the assumption that b has approximately multinormal distribution, each of the three statistics has an asymptotic chi-square distribution with p (the dimension of b or the number of parameters in b) degrees of freedom.

For a given significant-level , H is rejected if X* N?, when the likelihood ratio statistic is used; or if X5 N? or X5 N\?, when the Wald statistic is used; or if X1 N? or X1 N\?, when the score statistic is used.

It must be pointed out that rejection of H in (9.1.9) means only that the given distribution with the known parameters b, not the family of distributions to which the given distribution belongs, is not appropriate for the observed data. It is possible that a distribution with different b in the family may be appropriate.

9.2 TESTS FOR APPROPRIATENESS OF A FAMILY OF DISTRIBUTIONS The usual method for testingwhether a distribution is appropriate for the observed data is to compare the distribution with a larger or more general family that includes the distribution of interest as a special case (Hagar and Bain, 1970).

Let l#(), l5(, ), l%(, ), l*, (, ), and l%%(, , ) denote, respectively, the log-likelihood function defined in (7.1.1) based on the exponential, Weibull, gamma, lognormal, and extended generalized gamma distribution, and l#(), l5(, ), l%(, ), l*, (, ), and l%%(, , ) denote the respective log-likelihood values where , (, ), (, ), (, ), and (, , ) are the MLE. For example, the log-likelihood of the exponential distribution can be obtained from P L P L l#(): log( e 9 tG) ; log( e 9 t>G) : r log9 tG 9 t>G G G P> G G P> for a set of observed survival times t, . . . , tP, t>P> , . . . , t>L. The log-likelihood value and the estimated covariance matrix in (7.1.5) and parameters for each of the distributions discussed in Sections 7.2 to 7.6 can be obtained from SAS or BMDP. The results can be used to construct the log-likelihood ratio statistic and the Wald statistic defined in (9.1.2) and (9.1.3). In the following, we 226         introduce several tests for the appropriateness of a family of distributions based on the log-likelihoods. Construction of the respective Wald statistics is left to the reader as exercises.

1. Testing the hypothesis that the underlying distribution is exponential. The null hypothesis is H:The underlyingdistribution is an exponential distribution If the Weibull distribution is used, testingthe null hypothesis above is equivalent to testingthe followingnull and alternative hypotheses: H: :1 (the underlyingdistribution is an exponential distribution) H: "1 (the underlyingdistribution is a Weibull distribution) Let (1) be the MLE of in the Weibull distribution given : 1, the log-likelihood ratio statistic is X*:2[ l5(, ) 9 l5((1), 1)] (9.2.1) which has an asymptotic chi-square distribution with 1 degree of freedom. For a given level of significance , H is rejected if X*?. Note that l5((1), 1) Yl#().

Similarly, a log-likelihood ratio statistic can be constructed by using the gamma or the extended generalized gamma distribution. These will be left to the reader as exercises.

2. Testing the hypothesis that the underlying distribution is Weibull. The null hypothesis is H: The underlyingdistribution is a Weibull distribution We can use the extended generalized gamma distribution and test whether its parameter equals 1. Thus the null and alternative hypotheses can be stated as H: :1 (the underlyingdistribution is a Weibull distribution) H: "1 (the underlyingdistribution is an extended generalized gamma distribution) Let (1) and (1) be the MLE of and in the extended generalized gamma distribution given : 1. Accordingto Section 6.4, an extended generalized         227 gamma distribution with : 1 is a Weibull distribution. The likelihood ratio statistic is X*:2[ l%%(, , ) 9 l%%((1), (1), 1)] (9 . 2 . 2) which follows asymptotically the chi-square distribution with 1 degree of freedom. H is rejected at a significance level of if X*?. Note that l%%((1), (1), 1) Yl5(, ).

3. Testing the hypothesis that the underlying distribution is standard gamma.

The null hypothesis is H: The underlyingdistribution is a gamma distribution Followingthe same logic in Section 6.4, the null hypothesis above is equivalent to the following if the extended generalized gamma distribution is used.

H::1 (the underlyingdistribution is a standard gamma distribution) H:"1 (the underlying distribution is a generalized gamma distribution).

The likelihood test statistic is X*:2[ l%%(, , ) 9 l%%(1, (1), (1))] (9 . 2 . 3) where (1) and (1) are the MLE of and given : 1, which has an asymptotic chi-square distribution with 1 degree of freedom under H. The rejection rule is the same as that for the exponential or Weibull distribution.

Note that l%%(1, (1), (1)) Yl%(, ) .

4 . Testing the hypothesis that the underlying distribution is lognormal. The null hypothesis is H: the underlyingdistribution is a lognormal distribution The log-likelihood test statistic is X*:2[ l%%(, , ) 9 l*, (, )] which has an asymptotic chi-square distribution with 1 degree of freedom under H. The rejection rule is the same as that for the exponential or Weibull distribution.

For the log-logistic and extended generalized gamma distributions, it can be shown that a generalized F- distribution (Kalbfleisch and Prentice, 1980) includes the exponential, Weibull, lognormal, gamma, generalized gamma, 228         Table 9.1 Summary of Goodness-of-Fit Tests for Testing Whether a Family of Models Is Appropriate for the Observed Data ?

Hypothesized Model LL X* df Generalized gamma l%% Lognormal l*, 2( l%% 9 l*, ) 1 Gamma l% 2( l%% 9 l%) 1 Weibull l5 2( l%% 9 l5) 1 Exponential l# 2( l%% 9 l#) 2 Exponential l# 2( l% 9 l#) 1 Exponential l# 2( l5 9 l#) 1 ? LL, log-likelihood; X*, likelihood ratio chi-square statistic; df, degrees of freedom.

extended generalized gamma, and log-logistic distributions as special cases.

Therefore, one can follow the same logic to construct either the log-likelihood ratio or the Wald statistic to test the appropriateness of a family of generalized gamma or log-logistic distributions. However, methods for testing the appropriateness of a generalized F- distribution remain unknown. Unless we can find a more general distribution that includes the generalized F- distribution as a special case, there is no formal way to check whether the generalized F-distribution is appropriate. However, the generalized gamma distribution is a rich family and includes a considerable number of distributions. It should be sufficient for most applications. All the tests introduced in this section are summarized in Table 9.1.

As pointed out in Section 9.1, when usingany of the testingprocedures above, failure to reject H does not imply that the hypothesized distribution provides a perfect fit to the data. On the other hand, rejection of H does not mean that the distribution under the alternative hypothesis is the best choice either. In practice, with the help of available computer software, it is easy to fit several distributions simultaneously and then select the most appropriate one, usually the simplest one, as the final choice for the data. The following examples illustrate the procedure.

Example 9.2 Consider the tumor-free times of the 30 rats that are fed with a saturated diet in Table 3.4. UsingSAS, we obtain the MLE of the parameters and the log-likelihoods for the exponential, Weibull, lognormal, and generalized gamma distributions. The results are given in Table 9.2. For example, the MLE of in the exponential distribution is 5.054 and the corresponding log-likelihood is 935.359, and the MLE of the two parameters in the Weibull distribution are : 5.002 and : 0.500 and the correspondinglog-likelihood s dn .359 .398 .641 .478 .867 a .

Rat IC 7 3 0 1 0 , n A  3 3 3 3 3 al m 9 9 9 9 9 tio rm u froa 0 0 2 0 8 gno istrib 6 0 4 8 6 lo d 0 8 0 5 2 e Dat IC a B  37.

32.

30.

30.

30.

th m r m me 9 9 9 9 9 fo ag Ti e : ed e liz ll, -Fre u 001 001 005 127 u era Val 0.

0.

0.

0.

eib gen umor p W T e edd e th th C D D D r ten * fo ex for e X 922 762 .840 .326   g e 1.

9.

7 2 th 1 1 lo r ) fo) ferenc (1/ In 9 9 8 1 8 7 5 5 9 4 7 6 3 3 3 6 4 8 :9 ( , 1/ LL hood 35.

35.

29.

26.

25.

26.

) . * ma : li 9 9 9 9 9 9 X d am n g a Like al, ( X tic ized B rm 088 P .n pto C     1.

e, eraln gno m lo tio eters 9 valu ge e Asy p th ribu ded r aram n ist .

on fo d P A 0 1 7 2 a 6 2 tistic; n.

a m ed B   50 33 ?

.5 .5 exte ed 0.

0 0 0.

m sta tio : as e m gam B .43 tio th ibu ga timat a istic, ed sts le nd istr g b zed liz Es @ 2 5 5 9 dr a d lo a Te a 54 54 0 3 o l ali T A .0 .0 .0 76 49 .7 o g- er it tia stic lo n 5 5 5 4.

4.

4 elih en d gen f-F gener ik n logi n ieti a ed ,l g- * l ed .ll d expo lo ul d n ess-o ed X u te ; e ten tedD d the eib ex a o th r Weib ex oodn eraliz o r W fo e e the G tur n ih fo a l l th the a a ge ic el g th r to for .2 nti nti lik lo fo to 9 l log ithS rmal gist ) e el ne ne o 1/ v o o mma lo log- tivew (1/ 1/ ti gn g- , :9 : : edw ga ela ela Table F Mod Exp Exp Weibul Lo Extended Lo ? LL @ A :9 A B B C C R D R 229 230         is 929.398. To test the null hypothesis that the underlyingdistribution is an exponential distribution versus the alternative hypothesis that the underlyingdistribution is Weibull (or extended generalized gamma), the likelihood ratio test statistic X* :2(35.359929.398):11.922 [or 2(35.359925.478): 19.762]. The probability of observingsuch a chi-square value is 0.001; therefore, the exponential distribution is rejected and the Weibull or the generalized gamma is preferred.

However, the Weibull distribution is also rejected at the 0.001 level relative to the extended generalized gamma distribution ( X* :7 . 840, p 0 . 001). This implies that the extended generalized gamma distribution may be better.

However, the extended generalized gamma distribution is not significantly better than the lognormal distribution ( X* :2 . 326, p:0.127). Thus, among these distributions, the lognormal and extended generalized gamma distributions are our choices. Because of its simplicity, we may select the lognormal distribution as the choice for this set of data.

Example 9.3 Table 9.3 contains a set of remission times from 137 cancer patients. These remission times are a subset of the data from a bladder cancer study and are used here only for illustrative purposes. The results of goodness of fit tests based on asymptotic likelihood inferences are shown in Table 9.4.

From this table, we see that the exponential distribution is not rejected relative to the Weibull distribution based on the statistic defined in (9.2.1) ( X*: 0 . 638, p : 0.425). The hypothesis that the underlyingdistribution is exponential versus the alternative hypothesis that the distribution is the extended generalized gamma is rejected ( X*: 6 . 772, p:0.034). Furthermore, the Weibull and lognormal distributions are also rejected in favor of the extended generalized gamma ( X* :6 . 135, 8 . 120, p:0.013 and 0.004, respectively). This implies that the exponential distribution may not be an appropriate distribution since the Weibull distribution (its nestingdistribution) is rejected. Therefore, we may accept the extended generalized gamma as our final choice of distribution for the data.

9.3 SELECTION OF A DISTRIBUTION USING BIC OR AIC PROCEDURES The test procedures discussed in Section 9.2 require knowledge of the distribution family to which the distribution of interest belongs. In this section we introduce a simpler selection procedure called the Baysian information criterion (BIC; Schwarz, 1978). This criterion is based on the log-likelihood l(b), the number of parameters in the distribution ( p), and the total number of observations ( n). For each candidate distribution, compute p r : l(b) 9 log n (9 . 3 . 1) 2       231 Table 9.3 Remission Times (Months) of 137 Cancer Patients t t t t 4.50 32.15 3.88 13.80 19.13 4.87 3.02; 5.85 14.24 5.71 19.36; 7.09 7.87 7.59 20.28 5.32 5.49 3.02 46.12 4.33; 2.02 4.51 5.17 2.83 9.22 1.05 0.20 8.37 3.82 9.47 36.66 14.77 26.31 79.05 10.06 8.53 4.65; 2.02 4.98 11.98 2.62 4.26 5.06 1.76 0.90 11.25 16.62 4.40 21.73 10.34 12.07 34.26 0.87; 10.66 6.97 2.07 0.51 12.03 0.08 17.12 3.36 2.64 1.40 12.63 43.01 14.76 2.75 7.66 0.81 1.19 7.32 4.18 3.36 8.66 1.26 13.29 1.46 14.83 6.76 23.63 24.80; 5.62 8.60; 3.25 10.86; 18.10 7.62 7.63 17.14 25.74 3.52 2.87 15.96 17.36 9.74 3.31 7.28 1.35 0.40 2.26 4.33 9.02 5.41 2.69 22.69 6.94 2.54 11.79 2.46 7.26 2.69 5.34 3.48 4.70; 8.26 6.93 4.23 3.70 0.50 10.75 6.54 3.64 5.32 13.11 8.65 3.57 5.09 7.39 5.41 11.64 2.09 2.23 6.25 7.93 4.34 25.82 12.02 where b denotes the MLE of all the parameters in the distribution.

The candidate distribution with the largest r value is the distribution that fits the data the best. It has been shown that for some distribution families and under mild assumptions, for sufficiently large n, the distribution selected by the BIC procedure approaches the true underlyingdistribution, if it exists.

4 5 8 8 4 23 91 90 84 34 ICA  00.

01.

02.

00.

99.

2 2 2 2 1 9 9 9 9 9 .694 .835 .828 .228 .264 ICB  200 202 203 202 200 ?

9 9 9 9 9 .39 le eu Tab Val .425 .034 .013 .004   0 0 0 0 in p ta Da C D D D * for X 638 772 134 120   e 0.

6.

6.

8.

ferencIn .234 .234 .915 .908 .848 .344 LL hood 198 198 197 198 194 195 ) . * li 9 9 9 9 9 9 X Like tic ( X B P pto C     .520  e, 0 m eters valu Asy p aram on P A 9 0 9 1 9 9 .

tistic; ed B   94 .0 .9 59 ed 0.

1 0 0.

ma sta asB am tio g timat a d sts Es @ 2 1 7 6 dr .

ize Te 03 03 2 6 o 2 A .3 .3 .3 82 08 .8 o 9.

it 2 2 2 1.

2.

1 eral elih le n b f-F ik a ge ,l T .

* ll ed u ess-o ed X in ;d tes eib o o W extend oodn eraliz o tn e e G l l n ih o th a a ge ic el th fo to to .4 nti nti lik 9 l rmal gist the ve el ne ne o o o mma lo log- ti tive gn , ga g- la ela Table Mod Exp Exp Weibul Lo Extended Lo ? LL @ A B See C Re D R 232         233 In general, the larger the number of parameters p in a distribution, the larger the log-likelihood l(b) in (9.3.1). Thus the first term represents the gain by using a distribution with more parameters. But the larger the p, the larger the second term in (9.3.1) is, which represents a penalty by havingmore parameters in the distribution. Therefore, the BIC provides a balance between the gain and the penalty.

Another widely used criterion is called an information criterion (AIC; Akaike, 1969), in which r is defined as r : l(b) 9 2 p (9 . 3 . 2) Example 9.4 The values of the BIC and AIC for the various distributions considered in Examples 9.2 and 9.3 are listed in the last two columns in Tables 9.2 and 9.4. Based on Table 9.2, the lognormal distribution would be selected by either the BIC or AIC procedure, which is consistent with the results obtained in Example 9.2. The results in Table 9.4 show that the log-logistic distribution, rather than the extended generalized gamma distribution, should be selected based on either the BIC or AIC procedure.

9.4 TESTS FOR A SPECIFIC DISTRIBUTION WITH KNOWN PARAMETERS In this section we introduce the likelihood ratio statistic for testingif the survival data observed follow a given distribution with known parameters. We use the same notations as in Section 9.2. In addition to the exponential, Weibull, lognormal, gamma, generalized gamma distributions, we also consider the log-logistic distribution. Let l**(, ) and l**(, ) denote its log-likelihood function and the log-likelihood with (, ), the MLE of (, ).

1. Testing the hypothesis that the underlying distribution is exponential with known parameter . The null hypothesis is H: the underlyingdistribution is the exponential distribution with : The likelihood ratio test statistic based on (9.1.10) is X*:2[ l#() 9 l#()] (9 . 4 . 1) X* has an asymptotic chi-square distribution with 1 degree of freedom under H . H is rejected if X* X?, where is the significance level. Similarly, the Wald test statistic and the score statistic can be derived by following (9.1.11) and (9.1.12). This is left to the reader as exercises.

Example 9.5 Consider the followingsurvival times in weeks of 10 mice with a given tumor: 1, 3, 5, 8, 10;, 15, 18, 19, 22, 25;. We test the following 234         null hypothesis: H: the underlyingdistribution of the observed data is exponential with : 0.06 In this case, n : 10, r : 8, PG tG :91, and LG P> t>G: 35. The MLE of based on (7.2.16) is : 8 : 0.0635 91 ; 35 and l#() :8(log0.0635)90.0635(91)90.0635(35): 930.055. Under H, l#() :8(log0.06)9 0.06(91)90.06(35):930.067. Thus, following (9.4.1), X* :2[930 . 0559(930 . 067)] : 0 . 024 . X:3 . 84; therefore, we cannot reject the null hypothesis that the data are from the exponential distribution with : 0.06.

2. Testing the hypothesis that the underlying distribution is Weibull with known parameters and . The null hypothesis is H: the underlyingdistribution is Weibull with known parameters : and : Based on (9.1.10), the likelihood ratio test statistic is X*: 2[ l5(, ) 9 l5(, )] (9 . 4 . 2) Under H, X* has an asymptotic chi-square distribution with 2 degrees of freedom. H is rejected if X* X? where is the significance level.

3. Testing the hypothesis that the underlying distribution is lognormal with known parameters and . Similar to the procedures above, the likelihood ratio test statistic is X*:2[ l*, (, ) 9 l*, (, )] (9 . 4 . 3) Under H, X* has an asymptotic chi-square distribution with 2 degrees of freedom.

4. Testing the hypothesis that the underlying distribution is standard gamma with known parameters and . The likelihood ratio test statistic is X*:2[ l%(, ) 9 l%(, )] (9 . 4 . 4) Under H, X* is asymptotically chi-square distributed with 2 degrees of freedom.

235 5. Testing the hypothesis that the underlying distribution is generalized gamma with known parameters , , and . The likelihood ratio test statistic is X*:2[ l%%(, , ) 9 l%%(, , )] (9 . 4 . 5) Under H, X* is asymptotically chi-square distributed with 3 degrees of freedom.

6. Testing the hypothesis that the underlying distribution is log-logisticwith known parameters and . The likelihood ratio test statistic is X*:2[ l**(, ) 9 l**(, )] (9 . 4 . 6) Under H, X* has an asymptotic chi-square distribution with 2 degrees of freedom.

Note that the respective Wald and score statistics can be constructed for these tests by following (9.1.11) and (9.1.12). These are left to the reader as exercises. As noted in Section 9.3, the log-likelihood and estimated covariance matrix and parameters in (9.1.10) (9.1.12) for each of the distributions discussed in Sections 7.2 to 7.6 can be obtained from SAS or BMDP. The other terms in these test statistics can also be obtained by usingSAS or BMDP. The followingexample illustrates the use of SAS and BMDP.

Example 9.6 To use the likelihood ratio statistic (9.4.1) to test the null hypothesis in Example 9.5, H: ::0.06, we need to calculate the log-likelihood l#() and l#(). l#() can be obtained by applyingeither the SAS or BMDP codes in Example 7.5. We now show how to use SAS or BMDP to calculate l#(). Suppose that the survival data of the 10 mice in Example 9.5 are saved in the file C:EXAMPLE.DAT. If SAS is used, we specify that the distribution is exponential by using D : EXPONENTIAL in the model statement and lettingINTERCEPT : 2.813 [: 9 log : 9log(0.06)]. If BMDP is used, we specify the distribution by lettingAC- CEL : EXPONENTIAL and CONSTANT : 2.813. The followingSAS or BMDP codes can be used to obtain the l#() and the terms needed for the Wald and score statistics in (9.1.11) and (9.1.12).

SAS code: data w1; infile c:example.dat missover; input t cens; run; proc lifereg; model t*cens(0):/maxit:0 covb itprint d:exponential intercept:2.813; run; 236         BMDP code: /input file : c:example.dat .

variables : 2.

format : free.

/print level : brief.

cova. iterations.

/variable names : t, cens.

/form time : t.

status : cens.

response : 1.

/regress iteration : 0.

accel : exponential.

constant : 2.813.

/end Similarly, to obtain the log-likelihood ratio statistic, the Wald and the score statistics in (9.1.10) (9.1.12) for testingnull hypotheses about the parameters of other distributions, we can follow the same procedure but change the D: and ACCEL: statements to reflect the distribution under the null hypothesis.

We also need to provide values for the input variables INTERCEPT and SCALE, for Weibull, lognormal, and log-logistic distributions, if SAS is used.

For the extended generalized gamma distribution, we need to provide a value for SHAPE1. BMDP does not have a procedure for the gamma distribution.

For the Weibull, lognormal, and log-logistic distributions, we need to provide values for CONSTANT and SCALE. All of these input variables are based on the distribution and their relationship to the parameters under the null hypothesis (see notes at the end of each of the SAS or BMDP codes in Section 7.2 to 7.6).

9.5 HOLLANDER AND PROSCHANS TEST FOR APPROPRIATENESS OF A GIVEN DISTRIBUTION WITH KNOWN PARAMETERS Another test for the appropriateness of a parametric distribution with known parameters was proposed by Hollander and Proschan (1979).

Let 0 : t t t % t L be a set of distinct ordered survival times and some of the t Gs may be censored. If censored observations are tied with uncensored observations, treat the censored observations of tie as beinggreater than the uncensored of the tie. Let S( t) be the underlyingsurvivorship function and S( t) the survivorship function of the specific distribution. The null hypothesis is H: S( t) : S( t)     237 Usingthe Kaplan  Meier product-limit method, S( t) is estimated as n 9 j B H t S( t) : I\ I\ t t I, k : 1, . . . , n H n 9 j ; 1 (9 . 5 . 1) 0 t t L where H:1 if t H is uncensored and H: 0 if t H is censored. Hollander and Proschans test statistic for the null hypothesis that the data are from a distribution with survivorship function S( t) is C : S( t G) f ( t G) (9 . 5 . 2) where f ( t G) is the jump of the Kaplan  Meier estimates at consecutive uncensored observation and at the largest observation, uncensored or not, G\ f ( t G) :1 n 9 j;1\B H.

(9.5.3) n H n 9 j Under the null hypothesis, ( n( C 9 0 . 5) C* : (9 . 5 . 4) follows approximately the standard normal distribution, where is an estimate of the standard deviation of C and L n : 1 [ S 16 ( t G\) 9 S( t G)] (9 . 5 . 5) G n 9 i ; 1 To test H: S: S versus H: S S, we reject H if C* 9 Z?; to test H versus H: S S, we reject H if C* Z?; and to test H versus H: S " S, we reject H if C* 9 Z? or C* Z?, where Z? is the upper percentile point of the standard normal distribution.

The procedure for the calculation of C* can be summarized as follows.

1. Compute the Kaplan  Meier estimate S( t) for each uncensored observation.

2. Compute the jump of the Kaplan  Meier distribution at each t G uncensored, that is, f ( t G), which is the difference of F( t) : 19 S( t) at two consecutive uncensored observations.

3. Compute S( t G) for each observation.

238         4. Multiply S( t G) by f ( t G) and sum over all uncensored t Gs to obtain C.

5. Compute accordingto (9.5.5) and consequently, C* accordingto (9.5.4).

Example 9.7 Consider the survival times in weeks of 10 mice in Example 9.5: 8, 5, 10;, 1, 3, 18, 22, 15, 25;, and 19. We wish to test that the survival time follows an exponential distribution with : 0.06. The null and alternative hypotheses are H: S( t) : S( t) H: S( t) " S( t) where S( t) : exp(90.06 t).

Followingthe procedure outlined above, we first arrange the observations in ascendingorder and compute the Kaplan  Meier estimates as shown in column (d) of Table 9.5. The jumps are given in column (e). For example, the first jump is between S(0) and S(1) or 1 9 0.9 : 0.1. Column (f) gives the survival function under the null hypothesis, for example, S(3) :exp(90.06;3): 0.835. Following (9.5.2), column (g) gives the value of C : 0 . 4808. The last three columns are for calculation of the estimated variance of C. Thus, : 1 (1.3166) : 0.0823 16 and (10(0 . 4808 9 0 . 5) C* : : 90 . 2116 (0 . 0823 For : 0.05, Z?:1 . 96, C* does not fall in the rejection region. From Table B-1 we obtain that the p value correspondingto C* : 90 . 2116 is approximately 0.84. Therefore, we conclude that there is insufficient evidence to say that the data are not from an exponential distribution with : 0.06. Figure 9.1, which plots the Kaplan  Meier estimates and the hypothesized theoretical distribution S( t) :exp(90.06 t), demonstrates a close agreement between the two. The result is consistent with that obtained in Example 9.5, where the likelihood ratio test is used.

Bibliographical Remarks Readers with a background in mathematical statistics and an interest in mathematical details about asymptotic likelihood theory, likelihood ratio, Walds, and score statistics are referred to Cox (1961, 1962 a), Atkinson (1970), Hagar and Bain (1970), Cox and Hinkley (1974), and Kalbfleisch and Prentice (i); 1 9 1 8 0 3 8 0 7 0 0 6 j) ; 215  316 n i .331 .230 .221 .093 .126 .035 .009 .027 .026 0.

0 0 0 0 0 0 0 0 0  1.

9 n ) ( t G S ? 9 0 6 7 0 4 0 9 4 6 i)( 9) .215 .298 .184 .154 .056 .063 .014 .002 .005 .002 0 0 0 0 0 0 0 0 0 0 ( t G\ S ) 1 1 5 8 8 4 4 5 1 5 )(h ( t G 784 486 301 146 090 027 013 010 005 .002 S 0.

0.

0.

0.

0.

0.

0.

0.

0.

0 0 0 )( (f)  941 835 741 619 560 408 384 320 808 7 g ; 0 0 0 0 .0 .0 .0 .0 4 9.

(e) 0.

0.

0.

0.

0 0 0 0  0.

lep ) xam 1 5 1 9 9 7 0 0 7 3 4 3 4 1 2 E f)( ( t G .9 .8 .7 .6 54 40 34 32 26 .2 in S 0 0 0 0 0.

0.

0.

0.

0.

0 taaD ) 0 0 0 0 0 0 0 0 0 0 r e)( 2 2 2 2 10 10 10 10 fo f( t G .1 .1 .1 .1 0.

0.

0.

0.

0 0 0 0 C* c sti )( 0 0 0 0 0 0 0 0 d 0 0 0 0 ati S( t) .9 .8 .7 .6  48 36 24 12  0 0 0 0 0.

0.

0.

0.

St st Te 1 of i ; 0 9 5 7 0 0 7 0 c)( 9 i 0 5 6 0 90 88 87 85   n .8 .7 .6 .5 tion 9 0.

0.

0.

0.

0 0 0 0 a n . 1 cul :) Cal )(b i 1 2 3 4 5 6 7 8 9 (0 10 S .59 :) )( ( t 1 3 5 8 ; ; Table (a t G 10 15 18 19 22 25 ?S 239 240         Figure 9.1 Kaplan  Meier estimator S( t) and the hypothesized survival function S( t) :exp(90.06 t) .

(1980). There have been many papers about the AIC and BIC criteria in the literature since the introduction of AIC by Akaike (1969). The asymptotic properties of the two criteria and their relationships with other criteria were discussed by Akaike (1974), Parzen (1974), Schwarz (1978), Hannan (1979), Shibata (1980), Wang (1984, 1989), Rissanen (1986), and Wei (1992). Interested readers are referred to these papers for details.

When there are no censored observations, the chi-square goodness of fit test introduced by Karl Pearson in 1900 can be used to test any distributional assumption. In addition, tests for the exponential and lognormal (Shapiro and Wilk, 1965a, b) are available.

EXERCISES 9.1 Derive the likelihood ratio and Wald test statistics following (9.1.2) and (9.1.3) for the followingnull hypothesis: H: The underlyingdistribution is exponential versus the alternatives (a) H: The underlyingdistribution is gamma (b) H: The underlying distribution is generalized gamma  241 9.2 Derive the Wald test statistics following (9.1.3) for the followingnull and alternative hypotheses H: The underlyingdistribution is Weibull H: The underlying distribution is generalized gamma 9.3 Derive the respective Wald test statistics by following (9.1.3) for the null hypothesis that the distribution is the standard gamma versus the alternative hypothesis that the distribution is the generalized gamma.

9.4 Derive the Wald and score statistics for testingthe null hypotheses in Section 9.4 by following (9.1.11) and (9.1.12).

9.5 Consider the survival time of 28 cancer patients in Exercise 8.5.

(a) Obtain the log-likelihoods for the exponential, Weibull, lognormal, and generalized gamma distributions. Perform the likelihood ratio test and select the best distribution amongthese four distributions.

(b) Use the BIC and AIC procedures to select the best distribution amongthe four distributions in part (a) plus the log-logistic distribu- tion.

(c) Compare the results obtained in parts (a) and (b) and those obtained in Exercise 8.5.

9.6 Consider the survival time of 31 patients with advanced melanoma in Exercise 8.6.

(a) Select the best distribution usingthe likelihood ratio, Wald, and score statistics among the exponential, Weibull, gamma, lognormal, and generalized gamma distributions.

(b) Use the BIC and AIC procedures to do the same as in part (a) with the addition of the log-logistic distribution.

(c) Compare the results obtained in parts (a) and (b) and those obtained in Exercise 8.6.

(d) Compare the MLE of the parameters with those estimates obtained by usingthe graphical methods in Exercise 8.6.

9.7 Do the same as in Exercise 9.5 for the data in Exercise Table 3.1.

9.8 Consider the followingsurvival time in weeks of 10 mice with injection of tumor cells: 5, 16, 18;, 20, 22;, 24;, 25, 30;, 35, 40;. Do the data follow the exponential distribution with : 0.02?

(a) Use the likelihood ratio test.

(b) Use Hollander and Proschans test statistic.

(c) Plot the Kaplan  Meier estimator of S( t) and the hypothesized distribution.

242         9.9 Consider the followingsurvival time in months of 25 patients with cancer of the prostate. Test the hypothesis that the survival time of prostate cancer patients follows the exponential distribution with : 0.01: 2, 19, 19, 25, 30, 35, 40, 45, 45, 48, 60, 62, 69, 89, 90, 110, 145, 160, 9;, 10;, 20;, 40;, 50;, 110;, 130;.

9.10 The Gompertz distribution belongs to the Gompertz  Makeham dis- tribution family and the Gompertz  Makeham distribution (Makeham, 1860) has the followinghazard function: h( t) : ; exp( ; t) 0 Construct a likelihood ratio statistic and Walds statistic to test the appropriateness of a Gompertz distribution.

C H A P T E R 10 Parametric Methods for Comparing Two Survival Distributions In Chapter 5 we discussed several nonparametric tests for comparing two survival distributions. If the distributions follow a known model, parametric tests are more powerful than nonparametric tests, but their computation is more tedious. In this chapter we first discuss the likelihood ratio test in general for comparing two survival distributions in Section 10.1. Readers who are not familiar with linear algebra may skip this section without loss of continuity. In Sections 10.2 to 10.4 we present either the likelihood ratio test or other tests for the comparison of two survival patterns that follow the exponential, Weibull, and gamma distributions.

10.1 LIKELIHOOD RATIO TEST FOR COMPARING TWO SURVIVAL DISTRIBUTIONS Let x, . . . , xL , and y be the observed exact or censored survival times of n , . . . , yL and n subjects from two groups. Assume that the survival times from the two groups follow the same distribution with different parameters. We use the general notation b : ( b, b, . . . , bN) to denote the set of parameters of the distribution, p 1. Let lG(b G), i: 1, 2, denote the log-likelihood function for the observed survival times from each group, where b G:( bG, . . . , bGI, bGI> , . . . , bGN) :(b G, b G), and b G: ( bG, . . . , bGI) and b G :( bGI> , . . . , bGN) are two subsets of the p parameters, i : 1, 2 . Then the joint log-likelihood function for the two groups is l(b, b) : l(b) ; l(b). Let b G denote the MLE of b G, and b G(b) denote the MLE of b G given b G:b, where b is known.

For example, if the survival time of the two groups follows the Weibull distribution with a scale parameter and a shape parameter . Then p : 2, b:(, ), and b:(, ), where , and , are the respective parameters in the two Weibull distributions. Let l(,) and l(, ) denote the log-likelihood functions of the observed survival times from two groups; 243 244        then the joint log-likelihood function for the two groups is l(, , , ) : l(, ) ; l(, ) In this case, b G may be a singleton G, and similarly, b G may be G.

The following tests are widely used in comparing two survival distributions.

Case 1. All parameters are unknown. When b G, i:1, 2, are unknown, we test the hypothesis H: b:b :b (10.1.1) that is, that the two groups have the same survival distribution with equal but unknown parameters b. The log-likelihood ratio test statistic X*:92[ l(b, b) 9 l(b, b)] : 2[ l(b); l(b)9 l(b, b)] (10.1.2) has an asymptotic chi-square distribution with p degrees of freedom. For a given significance level , H is rejected if X* N?

(10 . 1 . 3) or equivalently, if P( N X*) (10.1.4) where N denotes the chi-square random variable with p degrees of freedom, and N? is its 100(19) percentile points, P( N N?) :.

In the case of comparing two Weibull distributions, it reduces to H: : : and : : where and are unknown, X*:2[ l(, ) ; l(, ) 9 l(, , , )] and H is rejected if X*?, or equivalently, if P( X*) .

Case 2. A subset of the parameters of the two survival distributions are known and equal, say, b: b:b, where the values of b are known. The null hypothesis is the equality of the remaining parameters, or H:b:b:b (10.1.5)         245 where b is unknown. The log-likelihood ratio statistic is X*:2[ l(b, b(b)); l(b, b(b)) 9 l((b, b(b)), (b, b(b))] (10.1.6) where b(b) is the MLE of b given b:b, and so are the others. X* has an asymptotic chi-square distribution with degrees of freedom equal to the number of parameters in b (or b).

In the case of comparing two Weibull distributions, we may assume that :: (or ::), where the value of (or ) is known, and test the null hypothesis H: : : (or : :) Then X* :2[ l(, ()) ; l(, ()) 9 l(, (), , ())] (or X* :2[ l((), ) ; l((), ) 9 l((), , (), )] and H is rejected if X*?, equivalently, if P( X*) .

Case 3. A subset of the parameters of the two survival distributions are equal but unknown, say, if b :b: b and the values of b are unknown.

The null hypothesis is the equality of the remaining parameters, or H:b:b:b (10.1.7) where b is unknown and needs to be estimated. In addition, b also needs to be estimated. The log-likelihood ratio statistic, X*:2[ l((b, b), (b, b)) 9 l(b, b)] (10.1.8) has an asymptotic chi-square distribution with degrees of freedom equal to the number of parameters in b (or b).

For the case of comparing two Weibull distributions, the derivation of X* in (10.1.8) is left to the reader as an exercise.

Case 4. A subset of the parameters of the two survival distributions are known but not equal, say, if b:b, b:b, and b and b are known 246        but b" b. The null hypothesis is the equality of the remaining parameters, or H:b:b:b (10.1.9) The log-likelihood ratio statistic X* :2[ l(b, b(b)) ; l(b, b(b)) 9 l((b, b(b, b)), (b, b(b, b)))] (10.1.10) has an asymptotic chi-square distribution with degrees of freedom equal to the number of parameters in b or b.

For the case of comparing two Weibull distributions, the derivation of X* in (10.1.10) is left to the reader as an exercise.

10.2 COMPARISON OF TWO EXPONENTIAL DISTRIBUTIONS Suppose that two survival distributions follow the exponential model with parameters and , respectively. Two tests can compare the distributions: the likelihood ratio test and an F- test suggested by Cox (1953). These two tests can test the hypothesis that the two exponential distributions are equal whether or not the samples include censored observations.

10.2.1 Likelihood Ratio Test Suppose that there are n and n individuals in groups 1 and 2, respectively, x, . . . , xP uncensored and x> censored in group 1, and y P > , . . . , x>L , . . . , yP uncensored and y> censored in group 2. Thus, in group 1, there P are r > , . . . , y> L uncensored and n 9 r censored observations. In group 2, there are r uncensored and n 9 r censored observations. If it is known that the survival times of the two groups follow the exponential distribution with density function fG( t) : Ge\H GR, i:1,2, testing the equality of two exponential distributions is equivalent to testing the hypothesis H: :. This is because the two exponential distributions are characterized by the two parameters and .

Thus, the null hypothesis is H: :: and the alternative hypothesis is H: ". According to (10.1.2), the test statistic for the likelihood ratio test is L (, ) X* :92log (10 . 2 . 1) L (, )      247 where the denominator is the likelihood function for the two groups combined, L L (, ) : P P exp9 P xG; x>G G G P > L 9 P yG; y>G (10 . 2 . 2) G G P > and and are the MLE of and , respectively, from groups 1 and 2.

From Section 7.2, r r : P (10 . 2 . 3) : G xG ; L G P P > x> G G yG ; L G P > y> G The numerator in (10.2.1) is the likelihood function for the combined sample under the null hypothesis, that is, : :, L P L L (, ) : P >P exp 9 P xG; x>G; yG; G G P > G G P > (10 . 2 . 4) where is the MLE of obtained from the combined sample, r : ; r P (10 . 2 . 5) G xG ; L G P > x> G ; P G yG ; L G P > y> G From Section 10.1, X* has an approximate chi-square distribution with 1 degree of freedom for samples of at least 25 ( n ; n 25) under the null hypothesis. For a given significance level , H is rejected if X* ?, or equivalently, if P( X*).

The test procedure can be summarized as follows: 1. Compute and following (10.2.3).

2. Compute L (, ) in (10.2.2) using the given data and and obtained in step 1.

3. Compute following (10.2.5).

4. Compute L (, ) in (10.2.4).

5. Compute X* in (10.2.1). If X* ? (Table B-2), reject H and conclude that the two exponential survival distributions are not equal. Otherwise, the data do not provide enough evidence to reject the null hypothesis.

If there are no censored observations in the data, (10.2.1) (10.2.5) are also applicable simply be letting n: r, n: r and omitting the terms involving 248        x> G and y> G . The likelihood ratio test is primarily for two-sided tests and is difficult to apply to a one-sided test. It is approximate and should be used with caution when the sample size is small. The power of the test, similar to that of other likelihood tests, is not high. That is, if the likelihood ratio test is used regularly, one is more likely not to reject the null hypothesis when the two survival distributions are not equal.

Example 10.1 Consider the remission data of the two treatment groups given in Example 5.1. The remission times in months are as follows: CMF: 23, 16;, 18;, 20;, 24; Control: 15, 18, 19, 19, 20 Assume that the two distributions are exponential with parameters and , respectively. Using the likelihood ratio test, we test the following null hypothesis H: :: (the two treatments are equally effective) against H: " (the two treatments are not equally effective) Following the above, we proceed as follows: 1. Compute and in (10.2.3): In this case, n: n :5, r:1, r :5, P G xG:23, L G P > x>G:78, P G yG:91, L G P > y>G:0, : 1 : 1 :0 . 0099 23 ; 78 101 : 5 :0 . 0549 91 2. Compute L (,) in (10.2.2): L (, ) :(0 . 0099)(0 . 0549) exp[90.0099(101)90.0549(91)] : 1.2290(10)\ 3. Compute in (10.2.5): : 1 ; 5 : 6 : 0.0313 23 ; 78 ; 91 192      249 4. Compute L (,) in (10.2.4): L (,) :(0 . 0313) exp[90.0313(192)]:2.3085(10)\ 5. Compute X* in (10.2.1): 2.3085(10)\ X*:92log : 92 log(0.1878) : 3.344 1.2290(10)\ From Table B-2 we obtain :3.84. Thus we cannot reject H at the 0.05 level. Recall that in Chapter 5 the null hypothesis was rejected at the 0.05 level by using the four nonparametric tests.

10.2.2 Coxs F-Test for Exponential Distributions If the times to failure can be assumed to follow the exponential distribution in both treatment groups, an F- test suggested by Cox (1953) can be used to test for treatment differences whether or not censored observations are present.

Suppose that we wish to test the hypothesis H:: against either the one-sided alternative H: (or H:) or the two-sided alternative H: ". An efficient test is to take t /t as having an F- distribution with (2 r, 2 r) degrees of freedom, where P t G xG ; L G P > x> G : (10 . 2 . 6) r P t G yG ; L G P : > y> G (10 . 2 . 7) r The test procedures are (1) for H, reject H if t /t F P P?; (2) for H, reject H if t /t F P P\?; and (3) for H, reject H if t /t F P P? or t /t F P P\?, where is the significance level and F P P? is the upper 100 percentage point of the F- distribution with (2 r,2 r) degrees of freedom.

Similarly, the hypothesis that / : k can be tested by referring kt /t to the table of the F- distribution.

When there are no censored observations, that is, n: r, n: r, the second terms of the numerators in (10.2.6) and (10.2.7) are zero. Then the test statistic t /t has an F- distribution with (2 n,2 n) degrees of freedom.

Confidence intervals for the ratio / can be obtained from the fact that t / t has the F- distribution with (2 n,2 n) degrees of freedom. It follows that a 100(1 9 )% confidence interval for the ratio of two hazard rates / is t t F F t P P P\? t P?

(10 . 2 . 8) 250        Example 10.2 Thirty-six patients with glioblastoma multiforme were divided into two groups; the experimental group contained 21 patients who had surgery and chemotherapy, and the control group contained 15 patients who had surgery only. The survival times in weeks are available about one year after the start of the study (Burdette and Gerhan, 1970): Experimental: 1, 2, 2, 2, 6, 8, 8, 9, 13, 16, 17, 29, 34, 2;,9;, 13;, 22;, 25;, 36;, 43;, 45; Control: 0, 2, 5, 7, 12, 42, 46, 54, 7;, 11;, 19;, 22;, 30;, 35;, 39; The hypotheses are H: : (no difference in survival between experimental and control groups) H: (difference in survival favoring experimental group) In this case, n :21, n: 15, r :13, r:8, xG :147, x>G:195, yG:168, and y>G:163. Hence t:147;195 :26 . 308 t : 41 . 375 13 : 168 ; 163 8 and t /t: 0.636 with (26,16) degrees of freedom. For :0.05, F is approximately 2.23; hence the hypothesis H is not rejected and the data do not provide enough evidence that the survival time is longer in the experimental group. A 95% confidence interval for the ratio / is 41.375 (0.419) 41.375 (2.625) 26.308 26.308 or (0.659, 4.128). The estimate of / according to (10.2.3) is 1.58. Hence the data show that the death rate per week of the experimental group is close to that of the control group.

In Example 10.2, the guarantee time in both groups is zero. In the case where a group has a nonzero guarantee time, it can be subtracted from every observation in the group and the test then applied. Monte Carlo studies (Gehan and Thomas, 1969; Lee et al., 1975) show that when samples are from exponential distributions, with or without censoring, the F- test is the most powerful test among the parametric or nonparametric tests discussed in this chapter and Chapter 5.

251 10.3 COMPARISON OF TWO WEIBULL DISTRIBUTIONS It is well known that if the survival time T has a Weibull distribution with shape parameter , then T A has an exponential distribution. Thus, if and for the two groups are known, the most powerful Coxs F- test described in Section 10.2 can be applied to the transformed observations. However, in practice, and are probably unknown, and so are the scale parameters, and . In this case, the likelihood ratio tests described in Section 10.1 can be applied to test whether the observed survival times from the two groups have the same Weibull distribution. To test the equality of two Weibull distributions, it suffices to test : and : . If the hypothesis : is rejected, we need not test the hypothesis :. If the hypothesis : is not rejected, we do need to test :. In the following, we introduce an additional two-sample test proposed by Thoman and Bain (1969) for uncen- sored samples.

Assume that independent random samples of equal size ( n: n : n) are obtained from Weibull distributions f( t) and f( t), where fG( t) : G G( Gt)A G\ exp[9( Gt)A G] i : 1, 2 (10 . 3 . 1) To test :, we use the property of the maximum likelihood estimator (Thoman et al., 1969; Thoman and Bain, 1969). To test the null hypothesis H: : against H: , we use the fact that ( /)/( /): / under H. The percentage points of / are given in Table B-12. We compute the MLE of and , that is, and , and compare / with the percentage points for a given in Table B-12. Reject H at level if / l?. For example, if n : n: n:10, a computed / 1.897 would lead to rejection of H at a significance level of 0.05. For 0.50, percentage points l? can be calculated by using the relationship l?:1 /l\?.

The procedure described above can be generalized to test H: : k against H: : k. For the case when k k, the rejection region becomes / kl?, where is the significance level.

If the hypothesis H:: is rejected, the two Weibull distributions are not the same. However, if the hypothesis is not rejected, we need to test the equality of the two scale parameters and . A test of H: : against H: suggested by Thoman and Bain (1969) rejects H if G : ( ; )(log 9log) z?

(10 . 3 . 2) where z? is such that P( G z? H) :1 9 and , , , and are the MLEs of , , , and respectively. The percentage points z? are given in Table B-13. For example, if the common sample size is 10, the hypothesis H: : is rejected if G 0 . 918 at significance level 0.05. A test of H:: against H: can be constructed in a similar fashion. The critical points z? can be obtained from Table B-13 by using the fact that z?:9 z\?.

252        Table 10.1 Survival Times of Patients in Two Treatment Groups Treatment 1 Treatment 2 5, 10, 17, 32, 32, 33, 34, 36, 43, 44, 44, 48, 20.9, 32.2, 33.2, 39.4, 40.0, 46.8, 57.3, 48, 61, 64, 65, 65, 66, 67, 68, 82, 85, 58.0, 59.7, 61.1, 61.4, 54.3, 66.0, 66.3, 67.4, 90, 92, 92, 102, 103, 106, 107, 114, 114, 68.5, 69.9, 72.4, 73.0, 73.2, 88.7, 89.3, 116, 117, 124, 139, 142, 143, 151, 158, 195 91.6, 93.1 94.2, 97.7, 101.6, 101.9, 107.6, 108.0, 109.7, 110.8, 114.1, 117.5, 119.2, 120.3, 133.0, 133.8, 163.3, 165.1 Example 10.3 illustrates the test procedures. The data are adapted and modified from Harter and Moore (1965). Forty observations are generated from a Weibull distribution with :0.01 and : 2 and another 40 from a Weibull distribution with :0.01 and :3. The resulting data are shown in Table 10.1. For illustrative purposes, we consider the two samples as two treatment groups.

Example 10.3 Consider the survival times of the patients in the two treatment groups in Table 10.1. The null hypothesis is that the two populations have the same shape parameter; that is, H: : against H: .

The MLEs are :1.945, :2.715, and hence / :1.396, which is significant at the 0.05 level ( l:1 . 342 for n:40) but not significant at the 0.02 level ( l:1 . 453 for n :40). If we choose :0.05 and reject H, the decision is correct. An error of not rejecting H would be committed if an of 0.02 or 0.01 is chosen. This is because the two shape parameters are very close ( :2, :3).

To illustrate the procedure of testing the equality of the scale parameters, let us assume that the hypothesis H: : is not rejected. To test H: : against H:, we need the MLEs of and . Harter and Moore obtain :0.010776 and :0.010471. From (10.3.2) we obtain G : (1.945; 2.715)(4.5599 4.530):0.068 From Table B-13, the critical region for n : 40 is G 0.404. Hence we do not reject H. This decision is correct since : :0.01. Note that the MLEs of , , , and are very close to their real values.

10.4 COMPARISON OF TWO GAMMA DISTRIBUTIONS Suppose that x, . . . , xL, and y, . . . , yL are the survival times of patients receiving two different treatments and that they follow the gamma distribution with the density function given in (6.4.1). Let and be the parameters of      253 the x population and and be those of the y population. The likelihood ratio tests introduced in Section 10.1 can be used to test whether the survival times observed from the x population and the y population have different gamma distributions. The estimation of the parameters is quite complicated but can be obtained using commercially available computer programs. In the following we introduce an F- test for testing the null hypothesis H: : against H: ", under the assumptions that the xGs and yGs are exact (uncensored) survival times, and that and are known (usually assumed equal).

Let x and y be the sample mean survival times of the two groups. The test is based on the fact that x /y has the F- distribution with 2 n and 2 n degrees of freedom (Rao, 1952). Thus the test procedure is to reject H at the level if x /y exceeds F L A L A?, the 100(/2) percentage point of the F- distribution with (2 n, 2 n) degrees of freedom. Since the F-table gives percentage points for integer degrees of freedom only, interpolations (linear or bilinear) are necessary when either 2 n or 2 n is not an integer.

The following example illustrates the test procedure. The data are adapted and modified from Harter and Moore (1965). They simulated 40 survival times from the gamma distribution with parameters :: :2, :0.01. The 40 individuals are divided randomly into two groups for illustrative purposes.

Example 10.4 Consider the survival time of the two treatment groups in Table 10.2. The two populations follow the gamma distributions with a common shape parameter : 2. To test the hypothesis H:: against H: ", we compute x:181 . 80, y: 173 . 55, and x /y: 1 . 048. Under the null hypothesis, x /y has the F- distribution with (80,80) degrees of freedom. Use : 0.05, F<1.45. Hence, we do not reject H at the 0.05 level of significance. The result is what we would expect since the two samples are simulated from the same overall sample of 40 with : 0.01.

To test the equality of two lognormal distributions, we use the fact that the logarithmic transformation of the observed survival times follows the normal distributions, and thus we can use the standard tests based on the normal distribution. In general, for other distributions, such as log-logistic and the generalized gamma, the log-likelihood ratio statistics defined in Section 10.1 Table 10.2 Survival Times of 40 Patients Receiving Two Different Treatments Treatment 1( x) Treatment 2( y) 17, 28, 49, 98, 119 26, 34, 47, 59, 101, 133, 145, 146, 158, 160, 112, 114, 136, 154, 154, 174, 211, 220, 231, 252, 161, 186, 197, 226, 226, 256, 267, 322, 323, 327 243, 253, 269, 308, 465 254        can be applied to test whether the survival times observed from two groups have the same distribution. Readers can follow Example 10.2.1 in Section 10.2 and use the respective likelihood functions derived in Chapter 7 to construct the needed tests.

Bibliographical Remarks In addition to the papers cited in this chapter, readers are referred to Mann et al. (1974), Gross and Clark (1975), Lawless (1982), and Nelson (1982).

EXERCISES 10.1 Derive the likelihood ratio tests in (10.1.8) and (10.1.10) for testing the equality of two Weibull distributions.

10.2 Derive the likelihood ratio test in (10.1.2) for testing the equality of two log-logistic distributions with unknown parameters.

10.3 Consider the remission data of the leukemia patients in Example 3.3.

Assume that the remission times of the two treatment groups follow the exponential distribution. Test the hypothesis that the two treatments are equally effective using: (a) The likelihood ratio test (b) Coxs F- test Obtain a 95% confidence interval for the ratio of the two hazard rates.

10.4 For the same data in Exercise 10.3, test the hypothesis that :5.

10.5 Suppose that the survival time of two groups of lung cancer patients follows the Weibull distribution. A sample of 30 patients (15 from each group) was studied. Maximun likelihood estimates obtained from the two groups are, respectively, :3, :1.2 and :2, :0.5. Test the hypothesis that the two groups are from the same Weibull distribu- tion.

10.6 Divide the lifetimes of 100 strips (delete the last one) of aluminum coupon in Table 6.4 randomly into two equal groups. This can be done by assigning the observations alternately to the two groups. Assume that the two groups follow a gamma distribution with shape parameter : 12. Test the hypothesis that the two scale parameters are equal.

10.7 Twelve brain tumor patients are randomized to receive radiation ther- apy or radiation therapy plus chemotherapy (BCNU) in a one-year clinical trial. The following survival times in weeks are recorded:  255 1. Radiation ; BCNU: 24, 30, 42, 15;, 40;, 42; 2. Radiation: 10, 26, 28, 30, 41, 12; Assuming that the survival time follows the exponential distribution, use Coxs F- test for exponential distributions to test the null hypothesis H: : versus the alternative H: .

10.8 Use one of the nonparametric tests discussed in Chapter 5 to test the equality of survival distributions of the experimental and control groups in Example 10.2. Compare your result with that obtained in Example 10.2.

C H A P T E R 11 Parametric Methods for Regression Model Fitting and Identification of Prognostic Factors Prognosis, the prediction of the future of an individual patient with respect to duration, course, and outcome of a disease plays an important role in medical practice. Before a physician can make a prognosis and decide on the treatment, a medical history as well as pathologic, clinical, and laboratory data are often needed. Therefore, many medical charts contain a large number of patient (or individual) characteristics (also called concomitant variables, independent variables, covariates, prognostic factors, or risk factors), and it is often difficult to sort out which ones are most closely related to prognosis. The physician can usually decide which characteristics are irrelevant, but a statistical analysis is usually needed to prepare a compact summary of the data that can reveal their relationship. One way to achieve this purpose is to search for a theoretical model (or distribution), that fits the observed data and identify the most important factors. These models, usually regression models, extend the methods discussed in previous chapters to include covariates. In this chapter we focus on parametric regression models (i.e., we assume that the survival time follows a theoretical distribution). If an appropriate model can be assumed, the probability of surviving a given time when covariates are incorporated can be estimated.

In Section 11.1 we discuss briefly possible types of response and prognostic variables and things that can be done in a preliminary screening before a formal regression analysis. This section applies to methods discussed in the next four chapters. In Section 11.2 we introduce the general structure of a commonly used parametric regression model, the accelerated failure time (AFT) model. Sections 11.3 to 11.7 cover several special cases of AFT models.

Fitting these models often involves complicated and tedious computations and requires computer software. Fortunately, most of the procedures are available in software packages such as SAS and BMDP. The SAS and BMDP code that 256     257 can be used to fit the models are given at the end of the examples. Readers may find these codes helpful. Section 11.8 introduces two other models. In Section 11.9 we discuss the model selection methods and goodness of fit tests.

11.1 PRELIMINARY EXAMINATION OF DATA Information concerning possible prognostic factors can be obtained either from clinical studies designed mainly to identify them, sometimes called prognostic studies, or from ongoing clinical trials that compare treatments as a subsidiary aspect. The dependent variable (also called the response variable), or the outcome of prediction, may be dichotomous, polychotomous, or continuous.

Examples of dichotomous dependent variables are response or nonresponse, life or death, and presence or absence of a given disease. Polychotomous dependent variables include different grades of symptoms (e.g., no evidence of disease, minor symptom, major symptom) and scores of psychiatric reactions (e.g., feeling well, tolerable, depressed, or very depressed). Continuous dependent variables may be length of survival from start of treatment or length of remission, both measured on a numerical scale by a continuous range of values.

Of these dependent variables, response to a given treatment (yes or no), development of a specific disease (yes or no), length of remission, and length of survival are particularly common in practice. In this chapter we focus our attention on continuous dependent variables such as survival time and remission duration. Dichotomous and multiple-response dependent variables are discussed in Chapter 14.

A prognostic variable (or independent variable) or factor may be either numerical or nonnumerical. Numerical prognostic variables may be discrete, such as the number of previous strokes or number of lymph node metastases, or continuous, such as age or blood pressure. Continuous variables can be made discrete by grouping patients into subcategories (e.g., four age subgroups: 20, 20  39, 40  59, and 60). Nonnumerical prognostic variables may be unordered (e.g., race or diagnosis) or ordered (e.g., severity of disease may be primary, local, or metastatic). They can also be dichotomous (e.g., a liver either is or is not enlarged). Usually, the collection of prognostic variables includes some of each type.

Before a statistical calculation is done, the data have to be examined carefully. If some of the variables are significantly correlated, one of the correlated variables is likely to be a predictor as good as all of them.

Correlation coefficients between variables can be computed to detect significantly correlated variables. In deleting any highly correlated variables, information from other studies has to be incorporated. If other studies showthat a given variable has prognostic value, it should be retained.

In the next eight sections we discuss multivariate or regression techniques, which are useful in identifying prognostic factors. The regression techniques involve a function of the independent variables or possible prognostic factors.

258         The variables must be quantitative, with particular numerical values for each patient. This raises no problem when the prognostic variables are naturally quantitative (e.g., age) and can be used in the equation directly. However, if a particular prognostic variable is qualitative (e.g., a histological classification into one of three cell types A, B, or C), something needs to be done. This situation can be covered by the use of two dummy variables, e.g., x, taking the value 1 for cell type A and 0 otherwise, and x, taking the value 1 for cell type B and 0 otherwise. Clearly, if there are only two categories (e.g., sex), only one dummy variable is needed: x is 1 for a male, 0 for a female. Also, a better description of the data might be obtained by using transformed values of the prognostic variables (e.g., squares or logarithms) or by including products such as x x (representing an interaction between x and x). Transforming the dependent variable (e.g., taking the logarithm of a response time) can also improve the fit.

In practice, there are usually a larger number of possible prognostic factors associated with the outcomes. One way to reduce the number of factors before a multivariate analysis is attempted is to examine the relationship between each individual factor and the dependent variable (e.g., survival time). From the univariate analysis, factors that have little or no effect on the dependent variable can be excluded from the multivariate analysis. However, it would be desirable to include factors that have been reported to have prognostic values by other investigators and factors that are considered important from biomedical viewpoints. It is often useful to consider model selection methods to choose those significant factors among all possible factors and determine an adequate model with as few variables as possible. Very often, a variable of significant prognostic value in one study is unimportant in another. Therefore, confirma-tion in a later study is very important in identifying prognostic factors.

Another frequent problem in regression analysis is missing data. Three distinctions about missing data can be made: (1) dependent versus independent variables, (2) many versus fewmissing data, and (3) random versus nonrandom loss of data. If the value of the dependent variable (e.g., survival time) is unknown, there is little to do but drop that individual from analysis and reduce the sample size. The problem of missing data is of different magnitude depending on howlarge a proportion of data, either for the dependent variable or for the independent variables, is missing. This problem is obviously less critical if 1% of data for one independent variable is missing than if 40% of data for several independent variables is missing. When a substantial proportion of subjects has missing data for a variable, we may simply opt to drop them and perform the analysis on the remainder of the sample. It is difficult to specify howlarge and howsmall, but dropping 10 or 15 cases out of several hundred would raise no serious practical objection. However, if missing data occur in a large proportion of persons and the sample size is not comfortably large, a question of randomness may be raised. If people with missing data do not showsignificant differences in the dependent variable, the problem is not serious. If the data are not missing randomly, results obtained from dropping       259 subjects will be misleading. Thus, dropping cases is not always an adequate solution to the missing data problem.

If the independent variable is measured on a nominal or categorical scale, an alternative method is to treat individuals in a group with missing information as another group. For quantitatively measured variables (e.g., age), the mean of the values available can be used for a missing value. This principle can also be applied to nominal data. It does not mean that the mean is a good estimate for the missing value, but it does provide convenience for analysis.

A more detailed discussion on missing data can be found in Cohen and Cohen (1975, Chap. 7), Little and Rubin (1987), Efron (1994), Crawford et al.

(1995), Heitjan (1997), and Schafer (1999).

11.2 GENERAL STRUCTURE OF PARAMETRIC REGRESSION MODELS AND THEIR ASYMPTOTIC LIKELIHOOD INFERENCE When covariates are considered, we assume that the survival time, or a function of it, has an explicit relationship with the covariates. Furthermore, when a parametric model is considered, we assume that the survival time (or a function of it) follows a given theoretical distribution (or model) and has an explicit relationship with the covariates. As an example, let us consider the Weibull distribution in Section 6.2. Let x : ( x, . . . , xN) denote the p covariates considered. If the parameter in the Weibull distribution is related to x as follows: : e 9( a; NG aGxG) : exp[9( a; a x)] where a : ( a, . . . , aN) denote the coefficients for x, then the hazard function of the Weibull distribution in (6.2.4) can be extended to include the covariates as follows: h( t, x) : A t A\ : t A\ e 9( a; NG aGxG) : t A\ exp[9( a ; a x)] (11.2.1) The survivorship function in (6.2.3) becomes S( t, x) : ( e\ R A)exp(9( a; a x)) (11.2.2) or log[9log S( t, x)] : 9( a; a x); log t (11 . 2 . 3) which presents a linear relationship between log[9log S( t, x)] and log t and the covariates. In Sections 11.2 to 11.7 we introduce a special model called the accelerated failure time model.

Analogous to conventional regression methods, survival time can also be analyzed by using the accelerated failure time (AFT) model. The AFT model 260         for survival time assumes that the relationship of logarithm of survival time T and the covariates is linear and can be written as N log T : a; aHxH; (11.2.4) H where xH, j:1, . . . , p, are the covariates, aH, j:0, 1, . . . , p the coefficients, ( 0) is an unknown scale parameter, and , the error term, is a random variable with known forms of density function g( , d) and survivorship function G( , d) but unknown parameters d. This means that the survival is dependent on both the covariate and an underlying distribution g.

Consider a simple case where there is only one covariate x with values 0 and 1. Then (11.2.4) becomes log T : a; a x; Let T and T denote the survival times for two individuals with x:0 and x : 1, respectively. Then, T :exp( a; ), and T:exp( a; a; ) : T exp( a). Thus, T T if a 0 and T T if a 0. This means that the covariate x either accelerates or decelerates the survival time or time to failure  thus the name accelerated failure time models for this family of models.

In the following we discuss the general form of the likelihood function of AFT models, the estimation procedures of the regression parameters ( a, a, , and d) in (11.2.4) and tests of significance of the covariates on the survival time.

The calculations of these procedures can be carried out using available software packages such as SAS and BMDP. Readers who are not interested in the mathematical details may skip the remaining part of this section and move on to Section 11.3 without loss of continuity.

Let t, t, . . . , tL be the observed survival times from n individuals, including exact, left-, right-, and interval-censored observations. Assume that the log survival time can be modeled by (11.2.4) and let a : ( a, a, . . . , aN), and b : (a, d, a, ) . Similar to (7.1.1), the log-likelihood function in terms of the density function g( ) and survivorship function G( ) of is l(b) : log L (b) : log[ g( G)] ;log[ G( G)] log[1 9 G( G)] ;log[ G( G) 9 G( G)] (11.2.5) where G:log tG 9 a 9 NH aHxHG (11 . 2 . 6) G:log G 9 a 9 NH aHxHG (11 . 2 . 7)       261 The first term in the log-likelihood function sums over uncensored observations, the second term over right-censored observations, and the third term over left-censored observations, and the last term over interval-censored observations with G as the lower end of a censoring interval. Note that the last two summations in (11.2.5) do not exist if there are no left- and interval-censored data.

Alternatively, let N G: a; aHxHG i : 1, 2, . . . , n (11.2.8) H Then (11.2.4) becomes log T : ; (11 . 2 . 9) The respective alternative log-likelihood function in terms of the density function f ( t, b) and survivorship function S( t, b) of T is l(b) : log L (b) : log[ f ( tG, b)]; log[ S( tG, b)] ; log[1 9 S( tG, b)]; log[ S( G, b) 9 S( tG, b)] (11.2.10) where f ( t, b) can be derived from (11.2.4) through the density function g( ) by applying the density transformation rule g((log t 9 ) /) f ( t, b) : (11 . 2 . 11) t and S( t, b) is the corresponding survivorship function. The vector b in (11.2.10) and (11.2.11) includes the regression coefficients and other parameters of the underlying distribution.

Either (11.2.5) or (11.2.10) can be used to derive the maximum likelihood estimates (MLEs) of parameters in the model. For a given log-likelihood function l(b), the MLE b is a solution of the following simultaneous equations: ( l(b)) : 0 for all i (11 . 2 . 12) bG Usually, there is no closed solution for the MLE b from (11.2.12) and the Newton  Raphson iterative procedure in Section 7.1 must be applied to obtain b. By replacing the parameters b with its MLE b in S( tG, b), we have an estimated survivorship function S( t, b), which takes into consideration the covariates.

All of the hypothesis tests and the ways to construct confidence intervals shown in Section 7.1 can be applied here. In addition, we can use the following tests to test linear relationships among the regression coefficients a, a, . . . , aN.

262         To test a linear relationship among x, . . . , xN is equivalent to testing the null hypothesis that there is a linear relationship among a, a, . . . , aN. H can be written in general as H: La:c (11.2.13) where L is a matrix or vector of constants for the linear hypothesis and c is a known column vector of constants. The following Walds statistics can be used: X5:(La 9c)[L V ? (a)L]\(La9c) (11.2.14) where V?(a) is the submatrix of the covariance matrix V(b) corresponding to a.

Under the H and some mild assumptions, X5 has an asymptotic chi-square distribution with degrees of freedom, where is the rank of L. For a given significance level , H is rejected if X5 J? or X5 J .

,19/2 For example, if p : 3 and we wish to test if x and x have equal effects on the survival time, the null hypothesis is H: a : a (or a 9 a:0). It is easy to see that for this hypothesis, the corresponding L : (1, 91, 0) and c : 0 since La : (1, 91, 0)( a, a, a) : a 9 a Let the ( i, j ) element of V ? (a) be GH; then the X5 defined in (11.2.14) becomes X5:( a 9 a) (1, 91, 0) 191\( a 9 a) 0 : ( a 9 a) ;92 X5 has an asymptotic chi-square distribution with 1 degree of freedom (the rank of L is 1).

In general, to test if any two covariates have the same effects on T, the null hypothesis can be written as H: aG : aH (or aG 9 aH: 0) (11 . 2 . 15) The corresponding L : (0, . . . , 0, 1, 0, . . . , 0, 91, 0, . . . , 0) and c : 0, and the X5 in (11.2.14) becomes X5: ( a G 9 a H) (11 . 2 . 16) GG ; HH 9 2 GH    263 which has an asymptotic chi-square distribution with 1 degree of freedom. H is rejected if X5 ? or X5 \?.

To test that none of the covariates is related to the survival time, the null hypothesis is H: a: 0 (11.2.17) The respective test statistics for this overall null hypothesis are shown in Section 9.1. For example, the log-likelihood ratio statistics there becomes X* :92[ l(0, d(0), a(0), (0))9 l(b)] (11.2.18) which has an asymptotic chi-square distribution with p degrees of freedom under H, where p is the number of covariates; d(0), a(0), and (0) are the MLE of d, a, and given a:0.

11.3 EXPONENTIAL REGRESSION MODEL To incorporate covariates into the exponential distribution, we use (11.2.4) for the log survival time and let : 1: N log TG: a ; aHxHG ; G: G ; G, (11.3.1) H where G : a; NH aHxHG, Gs are independently identically distributed (i.i.d.) random variables with a double exponential or extreme value distribution which has the following density function g( ) and survivorship function G( ): g( ) : exp[ 9 exp( )] (11.3.2) G( ) : exp[9exp( )] (11.3.3) This model is the exponential regression model. T has the exponential distribution with the following hazard, density, and survivorship functions.

N h( t, G) : G :exp9 a; aHxHG:exp(9 G) (11.3.4) H f ( t, G) : G exp(9 Gt) (11.3.5) S( t, G) :exp(9 Gt) (11.3.6) where G is given in (11.3.4). Thus, the exponential regression model assumes a linear relationship between the covariates and the logarithm of hazard. Let 264         hG( t, G) and hH( t, H) be the hazards of individuals i and j; the hazard ratio of these two individuals is hG( t, G) N : G : exp[9( a h G 9 H)] : exp 9 I( xIG 9 xIH) (11 . 3 . 7) H( t, H) H I This ratio is dependent only on the differences of the covariates of the two individuals and the coefficients. It does not depend on the time t. In Chapter 12 we introduce a class of models called proportional hazard models in which the hazard ratio of any two individuals is assumed to be a time-independent constant. The exponential regression model is therefore a special case of the proportional hazard models.

The MLE of b : ( a, a, . . . , aN) is a solution of (11.2.12), using (11.2.10), where f ( t, ) and S( t, ) are given in (11.3.5) and (11.3.6). Computer programs in SAS or BMDP can be used to carry out the computation.

In the following we introduce a practical exponential regression model.

Suppose that there are n : n; n;% ; nI individuals in k treatment groups. Let tGH be the survival time and x GH, x GH, . . . , xNGH the covariates of the j th individual in the i th group, where p is the number of covariates considered, i : 1, . . . , k, and j : 1, . . . , nG. Define the survivorship function for the j th individual in the i th group as SGH( t) :exp(9 GHt) (11 . 3 . 8) where N GH:exp(9 GH) and GH:9 a G; aJxJGH (11 . 3 . 9) J This model was proposed by Glasser (1967) and was later investigated by Prentice (1973) and Breslow (1974). The term exp(9 a G) represents the underlying hazard of the i th group when covariates are ignored. It is clear that GH defined in (11.3.9) is a special case of (11.3.4) by adding a newindex for the treatment groups. To construct the likelihood function, we use the following indicator variables to distinguish censored observations from the uncensored: GH:1 if tGH uncensored 0 if tGH censored According to (11.2.10) and (11.3.8), the likelihood function for the data can then be written as I LG L ( GH) : ( GH)B GH exp(9 GHtGH) G H    265 Substituting (11.3.9) in the logarithm of the function above, we obtain the log-likelihood function of a:( a, a, . . . , a I) and a :( a, a, . . . , aN): I LG N N l(a, a): GH a G; aJxJGH 9 tGH exp a G; aJxJGH G H J J I N L : G a GrG ; aJsGJ 9exp( a G) tGH exp N aJxJGH (11 . 3 . 10) G J H J where LG sGJ: GHxJGH H is the sum of the l th covariate corresponding to the uncensored survival times in the i th group and rG is the number of uncensored times in that group.

Maximum likelihood estimates of a Gs and aJs can be obtained by solving the following k ; p equations simultaneously. These equations are obtained by taking the derivative of l( a, a) in (11.3.10) with respect to the k a Gs and p aJs: LG rG 9exp( a G) tGH exp N a JxJGH:0 i:1, ... , k (11 . 3 . 11) H J I L G sGJ 9exp( a G) tGHxJGH exp N a JxJGH:0 l:1, ... , p (11 . 3 . 12) G H J This can be done by using the Newton  Raphson iterative procedure in Section 7.1. The statistical inferences for the MLE and the model are the same as those stated in Section 7.1. Let a and a be the MLE of a and a in (11.3.10), and a(0) be the MLE of a given a:0. According to (11.2.18), the difference between l(a, a) and l(a(0),0) can be used to test the overall null hypothesis (11.2.17) that none of the covariates is related to the survival time by considering X*:92( l(a(0),0)9 l(a,a)) (11.3.13) as chi-square distributed with p degrees of freedom. A X* greater than the 100 percentage point of the chi-square distribution with p degrees of freedom indicates significant covariates. Thus, fitting the model with subsets of the covariates x, x, . . . , xN allows selection of significant covariates of prognostic variables. For example, if p : 2, to test the significance of x after adjusting for x, that is, H: a:0, we compute X*:92[ l(a(0), a(0), 0) 9 l(a, a, a)] 266         Table 11.1 Summary Statistics for the Five Regimens Additive Therapy Geometric Median 6-MP MTX Number of Number in Mean ? of Mean Remission Regimen Cycle Cycle Patients Remission WBC Age (yr) Duration 1 A-D NM 46 20 9,000 4.61 510 2 A-D A-D 52 18 12,308 5.25 409 3 NM NM 64 18 15,014 5.70 307 4 NM A-D 54 14 9,124 4.30 416 5 None None 52 17 13,421 5.02 420 1, 2, 4   152 52 10,067 4.74 435 3, 5   116 35 14,280 5.40 340 All   268 87 11.711 5.02 412 Source: Breslow (1974). Reproduced with permission of the Biometric Society.

? The geometric mean of x, x, . . . , xL is defined as ( LG xG) L. It gives a less biased measure of central tendency than the arithmetic mean when some observations are extremely large.

where a(0) and a(0) are, respectively, the MLE of a and a given a:0 . X* follows the chi-square distribution with 1 degree of freedom. A significant X* value indicates the importance of x. This can be done automatically by a stepwise procedure. In addition, if one or more of the covariates are treatments, the equality of survival in specified treatment groups can be tested by comparing the resulting maximum log-likelihood values. Having estimated the coefficients a G and aJ, a survivorship function adjusted for covariates can then be estimated from (11.3.9) and (11.3.8).

The following example, adapted from Breslow (1974), illustrates howthis model can identify important prognostic factors.

Example 11.1 Two hundred and sixty-eight children with newly diagnosed and previously untreated ALL were entered into a chemotherapy trial. After successful completion of an induction course of chemotherapy designed to induce remission, the patients were randomized onto five maintenance regimens designed to maintain the remission as long as possible. Maintenance chemotherapy consisted of alternating eight-week cycles of 6-MP and methot-rexate (MTX) to which actinomycin-D (A-D) or nitrogen mustard (NM) was added. The regimens are given in Table 11.1. Regimen 5 is the control. Many investigators had a prior feeling that actinomycin-D was the active additive drug; therefore, pooled regimens 1, 2, and 4 (with actinomycin-D) were compared to regimens 3 and 5 (without actinomycin-D). Covariates considered were initial WBC and age at diagnosis. Analysis of variance showed that differences between the regimens with respect to these variables were not significant. Table 11.1 shows that the regimen with lowest (highest) WBC geometric mean has the longest (shortest) estimated remission duration. Figure    267 Figure 11.1 Remission curves of all patients by WBC at diagnosis. (From Breslow, 1974. Reproduced with permission of the Biometric Society.) 11.1 gives three remission curves by WBC; differences in duration were significant. It is well known that the initial WBC is an important prognostic factor for patients followed from diagnosis; however, it is interesting to know if this variable will continue to be important after the patient has achieved remission.

To identify important prognostic variables, model (11.3.9) was used to analyze the effect of WBC and age at diagnosis. Previous studies (Pierce et al., 1969; George et al., 1973) showed that survival is longest for children in the middle age range (6  8 years), suggesting that both linear and quadratic terms in age be included. The WBC was transformed by taking the common logarithm. Thus, the number of covariates is p : 3. Let x, x, and x denote log(WBC), age, and age squared, and a, a, and a be the respective coefficients. Instead of using a stepwise fitting procedure, the model was fitted five times using different numbers of covariates. Table 11.2 gives the results.

The estimated regression coefficients were obtained by solving (11.3.11) and (11.3.12). Maximum log-likelihood values were calculated by substituting the regression coefficients with the estimates in (11.3.10). The X* values were computed following (11.3.13), which show the effect of the covariates included.

The first fit did not include any covariates. The log-likelihood so obtained is the unadjusted value l(a(0),0) in (11.3.13). The second fit included only x or log(WBC), which yields a larger log-likelihood value than the first fit.

Following (11.3.13), we obtain X*:92( l(a(0),0)9 l(a, a)):92(91332.925; 1316.399):33.05 268         Table 11.2 Regression Coefficients and Maximum Log-Likelihood Values for Five Fits Regression Coefficient Covariates Maximum Fit Included Log-Likelihood b b b df 1 None 91332.925 2 x (logWBC) 91316.399 0.72 33.05 1 3 x, x (age) 91316.111 0.73 0.02 33.63 2 4 x, x (age squared) 91327.920 90.24 0.018 10.01 2 5 x, x, x 91314 . 065 0 . 67 90 . 14 0 . 011 37 . 72 3 Source: Breslow (1974). Reproduced with permission of the Biometric Society.

with 1 degree of freedom. The highly significant ( p 0.001) X* value indicates the importance of WBC. When age and age squared are included (fit 4) in the model, the X* value, 10.01, is less than that of fit 2. This indicates that WBC is a better predictor than age as the only covariate. To test the significance of age effects after adjusting for WBC, we subtract the log-likelihood value of fit 2 from that of fit 5 and obtain X*: 92(91316 . 399 ; 1314 . 065) :4 . 668 with 3 9 1 : 2 degrees of freedom. The significance of this X* value is marginal ( p : 0.10). Comparing the maximum log-likelihood value of fit 2 to that of fit 5, we find that log WBC accounts for the major portion of the total covariate effect. Thus, log(WBC) was identified as the most important prognostic variable. In addition, subtracting the maximum log-likelihood value of fit 5 from that of fit 3 yields X*: 92(91316 . 111 ; 1314 . 065) :4 . 092 with 1 degree of freedom. This significant ( p 0.05) value indicates that the age relationship is indeed a quadratic one, with children 6 to 8 years old having the most favorable prognosis. For a complete analysis of the data, the interested reader is referred to Breslow (1974).

To use SAS to perform the analysis, let T be the remission duration, TG an indicator variable (TG : 1 if in regimen groups 1, 2, and 4; 0 otherwise), CENS a second indicator variable (CENS : 0 when t is censored; 1 otherwise), and x1, x2, and x3 be log(WBC), age, and age squared, respectively. Assume that the data are saved in C:RDT.DAT as a text file, which contains six columns, and that each row (consisting of six space-separated numbers) gives the observed T, CENS, TG, x1, x2, and x3 from a child. For instance, a first row    269 in RDT.DAT may be 500 1 0 4.079 5.2 27.04 which represents that a 5.2-year-old child with initial log(WBC):4.079 who received regimen 3 or 5 relapsed after 500 days [i.e., t : 500, CENS : 1, TG : 0, x1 : 4.079, x2 : 5.2, and x3 (age squared) : 27.04].

For this data set, the following SAS code can be used to perform fits 1 to 5 in Table 11.2 by using procedure LIFEREG.

data w1; infile c:rdt.dat missover; input t cens tg x1 x2 x3; run; proc lifereg; model 1: model t*cens(0) : tg / d : exponential; model 2: model t*cens(0) : tg x1/ d : exponential; model 3: model t*cens(0) : tg x1 x2/ d : exponential; model 4: model t*cens(0) : tg x2 x3/ d : exponential; model 5: model t*cens(0) : tg x1 x2 x3/ d : exponential; run; For BMDP procedure 2L the following code can be used for fit 5.

/input file : c:rdt.dat.

variables : 6.

format : free.

/print level : brief.

/variable names : t, cens, tg, x1, x2, x3.

/form time : t.

status : cens.

response : 1.

/regress covariates : tg, x1, x2, x3.

accel : exponential.

/end 11.4 WEIBULL REGRESSION MODEL To consider the effects of covariates, we use the model (11.2.4); that is, the log-survival-time of individual i is N log TG : a ; aIxIG ; G : G; G (11.4.1) I where G: a; NI aIxIG and has the distribution defined in (11.3.2) and 270         (11.3.3). This model is the Weibull regression model. T has the Weibull distribution with G G : exp 9 and : 1 (11 . 4 . 2) and the following hazard, density, and survivorship functions that are related with covariates via G in (11.4.2): h( t, G, ) : G t A\ (11 . 4 . 3) f ( t, G, ) : G t A\exp(9 Gt A) (11 . 4 . 4) S( t, G, ) :exp(9 Gt A) (11 . 4 . 5) The hazard ratio of any two individuals i and j, based on (11.4.3) and (11.4.2), is hG N : exp 9 G 9 H a h I( xIG 9 xIH) H :exp9 1 I which is not time-dependent. Therefore, similar to the exponential regression model, the Weibull regression model is also a special case of the proportional hazard models.

The following example illustrates the use of the Weibull regression model and of computer software packages.

Example 11.2 Consider the tumor-free time in Table 3.4. Suppose that we wish to know if three diets have the same effect on the tumor-free time. Let T be the tumor-free time; CENS be an index (or dummy) variable with CENS : 0 if T is censored and 1 otherwise; and LOW, SATU, and UNSA be index variables indicating that a rat was fed a low-fat, saturated fat, or unsaturated fat diet, respectively (e.g., LOW : 1 if fed a low-fat diet; 0 otherwise). The data from the 90 rats in Table 3.4 can be presented using these five variables. For example, the three observations in the first rowof Table 3.4 can be rearranged as T CENS LOW SATU UNSA 140 1 1 0 0 124 1 0 1 0 112 1 0 0 1 Assume that the rearranged data are saved in the text file C:RAT.DAT, which contains the data from the 90 rats in five columns as above and the five numbers in each roware space-separated. This data file is ready for almost all    271 of the statistical software packages for parametric survival analysis currently available, such as SAS and BMDP. Suppose that the tumor-free time follows the Weibull distribution and the following Weibull regression model is used: log TG : a; a SATU G ; a UNSA G ; G : G ; G (11.4.6) where G has a double exponential distribution as defined in (11.3.2) and (11.3.3). Note that from (11.4.3) and (11.4.2), log h( t, G, ) : log G;log( t A\) : 9 G ; log( t A\) 9 : a 9 a SATU G 9 a UNSA G ; log( t A\) (11 . 4 . 7) Denote the hazard function of a rat fed an unsaturated, saturated, and low-fat diet as hS, hQ, and hJ, respectively. From (11.4.7), log hS:(9 a 9 a) / ; log( t A\), log hQ :(9 a 9 a) / ;log( t A\), and log hJ:9 a / ; log( t A\). Thus, the logarithm of the hazard ratio of rats fed a low-fat diet and those fed a saturated fat diet is log( hJ/hQ) : a /, and the similar ratios of rats fed a low-fat diet and those an unsaturated fat diet, and of rats fed a saturated fat diet and those fed an unsaturated fat diet are, respectively, log( hJ/hS) : a / and log( hQ/hS) :( a 9 a) /. These ratios are constants and are independent of time. Therefore, to test the null hypothesis that the three diets have an equal effect on tumor-free time is equivalent to testing the following three hypotheses: H: hJ/hQ: 1 or a :0, H: hJ/hS:1, or a :0, and H: hQ/hS:1 or a: a. The statistic defined in Section 9.1.1 can be used to test the first two null hypotheses, and the statistic defined in (11.2.16) can be used for the third one. Failure to reject a null hypothesis implies that the corresponding log-hazard ratio is not statistically different from zero; that is, there are no statistically significant differences between the two corresponding diets. For example, failure to reject H: a :0 means that there are no significant differences between the hazards for rats fed a low-fat diet and rats fed a saturated fat diet. When all three hypotheses H: a:0, H: a:0, and H: a: a are rejected, we conclude that the three diets have significantly different effects on tumor-free time. Furthermore, a positive (negative) estimated implies that the hazard of a rat fed a low-fat diet is exp( a /) times higher (lower) than that of a rat fed a saturated fat diet. Similarly, a positive (negative) estimated a and ( a 9 a) imply, respectively, the hazard of a rat fed a low-fat diet is exp( a /) times higher (lower) than that of a rat fed an unsaturated fat diet, and the hazard of a rat fed a saturated fat diet is exp[( a 9 a) /] times higher (lower) than that of a rat fed an unsaturated fat diet.

272         To estimate the unknown coefficients, a, a, a, and , we construct the log-likelihood function by replacing in (11.4.2), (11.4.4), and (11.4.5) with (11.4.6). Next, place the resulting f ( tG, G,) and S( tG, G,) in the log-likelihood function (11.2.10). The log-likelihood function for the observed 90 exact or right-censored tumor-free times, t, t, . . . , t, in the three diet groups is l( a, a, a, ) : log[ f( tG, G, )] ; log[ S( tG, G, )] : [log ; ( 9 1) log tG 9 G 9 t A G exp(9 G)] ; [9 t A G exp(9 G)] : log ; ( 9 1) log tG 9( a; a SATU ; a UNSA ) 9 t A G exp[9( a; a SATU ; a UNSA )] ; 9 t A G exp[9( a; a SATU ; a UNSA )] The first term in the log-likelihood function sums over the uncensored observations, and the second term sums over the right-censored observations.

The MLE ( a, a, a, ) of ( a, a, a,) where :1/ is a solution of (11.2.12) with the above log-likelihood function by applying the Newton  Raphson iterative procedure. The results from SAS are shown in Table 11.3, where INTERCPT : a and SCALE: . The MLE :0.43, a:90 . 394, a:90 . 739, and a 9 a:90 . 345 . H: a:0 (or hJ/hQ :1), H: a: 0 (or hJ/hS: 1), and H: a 9 a:0 (or hQ/ hS:1) are rejected at significance level p : 0.0065, p : 0.0001, and p : 0.0038, respectively. The conclusion that the data indicate significant differences among the three diets is the same as that obtained in Chapter 3 using the k-sample test. Furthermore, both a and a are negative and h J/h Q :exp( a /) :exp(90.916):0.40, h J/h S:exp( a / ) : exp(91.719) : 0.18, and h Q/h S:exp(( a 9 a) /) :exp(90.802):0.45.

Thus, based on the data observed, the hazard of rats fed a low-fat diet is 40% and 18% of the hazard of rats a saturated fat diet and an unsaturated fat diet, respectively, and the hazard of rats fed a saturated fat diet is 45% of that of rats fed an unsaturated fat diet.

The survivorship function in (11.4.5) can be estimated by using (11.4.2) and the MLE of a, a, a, and : S( t, , ) : exp(9 t) : exp 9exp91 ( a; a SATU; a UNSA) t 1 / : exp[9exp(912.56 ; 0.92;SATU ; 1.72;UNSA) t] Based on S( t, G, ), we can estimate the probability of surviving a given time for rats fed with any of the diets. For example, for rats fed a low-fat diet,    273 Table 11.3 Analysis Results for Rat Data in Table 3.4 Using a Weibull Regression Model Regression Standard Variable Coefficient Error X* p exp( a G/) INTERCPT ( a) 5 . 400 0 . 113 2297 . 610 0 . 0001 TRTSA( a) 90.394 0.145 7.407 0.0065 0.40 TRTUS( a) 90.739 0.140 28.049 0.0001 0.18 SCALE() 0.430 0.043 a 9 a 90.345 0.119 8.355 0.0038 0.45 (SATU : 0 and UNSA : 0), the probability of being tumor-free for 200 days is S*-5(200): exp[9exp(912.56)(200)] : exp[90.00000353(200)]: 0.132 and for rats fed an unsaturated fat diet, (SATU : 0 and UNSA : 1), the probability is 0.011.

Following is the SAS code used to obtain Table 11.3, based on the Weibull regression model in (11.4.6).

data w1; infile c:rat.dat missover; input t cens lowsatu unsa; run; proc lifereg covout; model t*cens(0) : satu unsa / d : weibull; run; The respective BMDP procedure 2L code based on (11.4.6) is /input file : c:rat.dat.

variables : 5.

format : free.

/print level : brief.

/variable names : t, cens, low, satu, unsa.

/form time : t.

status : cens.

response : 1.

/regress covariates : satu, unsa .

accel : weibull.

/end 274         11.5 LOGNORMAL REGRESSION MODEL Let in (11.2.4) be the standard normal random variable with the density function g( ) and survivorship function G( ), g( ) : exp(9 /2) (11.5.1) (2 G( ) : 1 9 ( ) : 1 9 1 C e\ V dx (11.5.2) (2 \ where is the cumulative distribution function of the standard normal distribution. Then the model defined by (11.2.4) for the survival time T of individual i, N log TG : a ; aIxIG ; G : G; G I is the lognormal regression model. T has the lognormal distribution with the density function f ( t, G, ) :exp[9(log t 9 G) / 2] (11 . 5 . 3) (2 t and the survivorship function S( t, G, ) :19 log t 9 G (11.5.4) It can be shown that the hazard function h( t, , a, a, . . . , aN) of T with covariate x, x, . . . , xN and unknown parameters and coefficients , a, a, . . . , aN can be written as log h( t, , a, a, . . . , aN) :log h[ t exp(9)]9 (11.5.5) where h( ) is the hazard function of an individual with all covariates equal to zero. Equation (11.5.5) indicates that h( t, , a, a, . . . , aN) is a function of h evaluated at t exp(9), not independent of t. Thus, the lognormal regression model is not a proportional hazards model.

Example 11.3 Consider the survival time data from 30 patients with AML in Table 11.4. Two possible prognostic factors or covariates, age, and cellular-    275 Table 11.4 Survival Times and Data for Two Possible Prognostic Factors of 30 AML Patients Survival Time x x Survival Time x x 18 0 0 8 1 0 9 0 1 2 1 1 28; 0 0 26; 1 0 31 0 1 10 1 1 39; 0 1 4 1 0 19; 0 1 3 1 0 45; 0 1 4 1 0 6 0 1 18 1 1 8 0 1 8 1 1 15 0 1 3 1 1 23 0 0 14 1 1 28; 0 0 3 1 0 7 0 1 13 1 1 12 1 0 13 1 1 9 1 0 35; 1 0 ity status are considered: x :1 if patient is50 years old 0 otherwise x :1 if cellularity of marrowclot section is 100% 0 otherwise Let us use the lognormal regression model log TG : a; a x G; a x G; G (11.5.6) and G: a; a x G; a x G (11 . 5 . 7) The unknown coefficients and parameter a, a, a, need to be estimated.

We construct the log-likelihood function by replacing in (11.5.3) and (11.5.4) with (11.5.7), then replacing f ( tG, ,) and S( tG, ,) in the log-likelihood function (11.2.5) with their expression (11.5.3) and (11.5.4), respectively. The resulting log-likelihood function for the exact and right-censored survival times 276         observed from the 30 patients with AML is (log t l( a G 9 G) , a, a, ) : 9 9 log((2 t 2 G) ; log19 log tG 9 G : 9[log tG 9( a; a x G; a x G)]9log( t 2 G (2) ( ; log t log 19 G 9 ( a ; a x G ; a x G) The first term in the log-likelihood function sums over the uncensored observations, and the second sums over the right-censored observations. The MLE ( a, a, a, ) of ( a, a, a, ) can be obtained by applying the Newton  Raphson iterative procedure. The hypothesis-testing procedures discussed in Section 9.1.2 can be used to test whether the coefficients a and a are equal to zero. Table 11.5 shows that a is significantly ( p:0.0039) different from zero, while a is not ( p:0.4514). The signs of the regression coefficients indicate that age over 50 years has significantly negative effects on the survival time, while a 100% cellularity of marrow clot section also has a negative effect; however, the effect is not of significant importance to the survival time.

Let T be the survival time and CENS be an index (or dummy) variable with CENS : 0 if T is censored and 1 otherwise. Assume that the data are saved in a text file C:AML.DAT with four numbers in each row, space-separated, which contains successively T, CENS, x1, and x2.

Let T be the survival time and CENS be an index (or dummy) variable with CENS : 0 if T is censored and 1 otherwise. Assume that the data are saved in a text file C:AML.DAT with four numbers in each row, space-separated, which contains successively T, CENS, x1, and x2. The following SAS code is used to obtain the results in Table 11.5.

Table 11.5 Asymptotic Likelihood Inference for Data on 30 AML Patients Using a Lognormal Regression Model Regression Standard Variable ?

Coefficient Error X* p INTERCPT ( a) 3.3002 0.3750 77.4675 0.0001 x ( a) 91.0417 0.3605 8.3475 0.0039 x ( a) 90.2687 0.3568 0.5672 0.4514 SCALE () 0.9075 0.1409 ? x:1 if patient 50 years old, and 0 otherwise; x:1 if cellularity of marrowclot section is 100%, and 0 otherwise.

277 data w1; infile c:aml.dat missover; input t cens x1 x2; run; proc lifereg; model 1: model t*cens(0) : x1 x2 / d : lnormal; run; If BMDP is used, the following 2L code is suggested.

/input file : c:aml.dat.

variables : 4.

format : free.

/print level : brief.

/variable names : t, cens, x1, x2.

/form time : t.

status : cens.

response : 1.

/regress covariates : x1, x2.

accel : lnormal.

/end 11.6 EXTENDED GENERALIZED GAMMA REGRESSION MODEL In this section we introduce a regression model that is based on an extended form of the generalized gamma distribution defined in Section 6.4. Assume that the survival time T of individual i and covariates x, . . . , xN have the relationship given in (11.4.1), where has the log-gamma distribution with the density function g( ) and survivorship function G( ): [exp( )/]B exp[9exp( )/] g( ) : ( 11.6.1) (1/) 1 if 0 (11.6.2) G( ) : I exp( ), 1 1 9 I exp( ) ( , if 0 9- ;- 11.6.3) This model is the extended generalized gamma regression model. It can be shown that T has the extended generalized gamma distribution with the density function A?A f ( t, , , ) : G t?A\ exp[9( Gt)?] (11 . 6 . 4) () and survivorship function if 0 (11.6.5) S( t, , , ) : I(( Gt)?, ) 1 9 I(( Gt)?, ) if 0 (11.6.6) 278         where G:exp(9 G) : : 1 ( 11.6.7) ( x) is the complete gamma function defined in (6.2.9), I( a, x) is the incomplete gamma function defined in (6.4.4), and is a shape parameter. We used the extended generalized gamma distribution in (11.6.4) here because it is the distribution used in SAS. The derivation is left to the reader as an exercise (Exercise 11.12).

The estimation procedures for the parameters, regression coefficients, and the covariate adjusted survivorship function are similar to those discussed in Sections 11.3 and 11.4.

Example 11.4 Consider the survival times ( T ) in days and a set of prognostic factors or covariates from 137 lung cancer patients, presented in Appendix I of Kalbfleisch and Prentice (1980). The covariates include the Karnofsky measure of the overall performance status (KPS) of the patient at entry into the trial, time in months from diagnosis to entry into the trial (DIAGTIME), age in years (AGE), prior therapy (INDPRI, yes or no), histological type of tumor, and type of therapy. There are four histological types of tumor: adeno, small, large, and squamous cell and two types of therapies: standard and experimental. The values of KPS have the following meanings: 10  30 completely hospitalized, 40  60 partial confinement, 70  90 able to care for self. Assume that the survival time follows the extended generalized gamma regression model, we wish to identify the most significant prognostic variables.

First we define several index (or dummy) variables for the categorical variables and the censoring status. Let CENS : 0 when the survival time T is censored and 1 otherwise; INDADE : 1, INDSMA : 1, and INDSQU : 1 if the type of cancer cell is adeno, small, and squamous, respectively, and 0 otherwise; INDTHE : 1 if the standard therapy is received and 0 otherwise; and INDPRI : 1 if there is a prior therapy and 0 otherwise. The model is log TG: a; a KPS G; a AGE G ; a DIAGTIME G ; a INDPRI G ; a INDTHE G; a INDADE G; a INDSMA G; a INDSQU G; G (11.6.8) where the density function of G is defined in (11.6.1). Thus, G: a; a KPS G; a AGE G; a DIAGTIME G; a INDPRI G; a INDTHE G ; a INDADE G; a INDSMA G; a INDSQU G (11.6.9) To estimate a, . . . , a, , a, and , we construct the log-likelihood function by replacing in (11.6.7) and (11.6.4) (11.6.6) with (11.6.9), then replacing f ( tG, b) and S( tG,b) in the likelihood function (11.2.10) by those in (11.6.4) and (11.6.5) or (11.6.6). The MLE ( a, . . . , a, , a, ) of ( a, . . . , a, , a, ) can be      279 Table 11.6 Asymptotic Likelihood Inference on Lung Cancer Data Using a Generalized Gamma Regression Model Regression Standard Variable Coefficient Error X* p INTERCPT ( a) 2 . 176 0 . 719 9 . 143 0 . 003 INDADE ( a) 90.759 0.286 7.034 0.008 INDSMA ( a) 90.594 0.264 5.059 0.025 INDSQU ( a) 0.150 0.291 0.266 0.606 KPS ( a) 0.034 0.005 46.443 0.000 AGE ( a) 0.008 0.009 0.845 0.358 DIAGTIME ( a) 0.000 0.009 0.001 0.980 INDPRI ( a) 90.089 0.216 0.171 0.679 INDTHE ( a) 0.168 0.185 0.823 0.364 SCALE () 1.000 0.071 SHAPE () 0.450 0.223 INTERCPT ( a) 2.748 0.396 48.247 0.000 INDADE ( a) 90.766 0.280 7.492 0.006 INDSMA ( a) 90.534 0.258 4.284 0.039 INDSQU ( a) 0.144 0.280 0.264 0.608 KPS ( a) 0.033 0.005 45.497 0.000 SCALE () 1.004 0.070 SHAPE () 0.473 0.206 obtained in a manner similar to that used in Examples 11.2 and 11.3. The hypothesis-testing procedure defined in Section 11.2 can be used to test whether the coefficients a, a, . . . , a are equal to zero. The first part of Table 11.6 shows the results from SAS (where INTERCPT : a, SCALE:, and SHAPE : ).

Table 11.6 shows that a, a, and a are significantly ( p 0.05) different from zero, whereas the other covariates are not ( p 0.05). That is, only KPS and the type of cancer cell have significant effects on the survival time. In particular, adeno cell carcinoma and small cell carcinoma have significant negative effects on survival time. Patients who have better Karnofsky performance status have a longer survival time. If we wish to include only KPS and cell type in the model, the lower part of Table 11.6 gives the results.

Assume that the coded data are saved in C:LCANCER.DAT as a text file with 10 numbers in a row, space-separated, which contains data for T, CENS, KPS, AGE, DIAGTIME, INDPRI, INDTHE, INDADE, INDSMA, and INDSQU, in that order. The SAS code used to obtain Table 11.6 is data w1; infile c:lcancer.dat missover; input t cens kps age diagtime indpri indthe indade indsma indsqu; run; 280         proc lifereg; Model 1: model t*cens(0) : kps age diagtime indpri indthe indade indsma indsqu / d : gamma; Model 2: model t*cens(0) : kps indade indsma indsqu / d : gamma; run; 11.7 LOG-LOGISTIC REGRESSION MODEL Assume that the relationship between the survival time TG for individual i and a set of covariates, x, . . . , xN can be expressed by the AFT model in (11.4.1), where G has a logistic distribution with the density function g( ) : exp( ) (11.7.1) [1 ; exp( )] and survivorship function G( ) : 1 (11.7.2) 1 ; exp( ) This model is the log-logistic regression model. Then T has the log-logistic distribution defined in Section 6.5. The parameter in the distribution is a function of the covariates: G G : exp 9 : 1 (11 . 7 . 3) Substituting (11.7.3) in the survivorship function in (6.5.2), we obtain S( t, b) log : 9log( t A) : 9 log t (11 . 7 . 4) 1 9 S( t, b) or S( t, b) a N log : ; 1 a 1 9 S( t, b) IxI 9 log t (11 . 7 . 5) I where b : ( a, a, . . . , aN, ). Since S( tG,b) is the probability of surviving longer than t, S( tG,b) /[1 9 S( tG,b)] is the odds of surviving longer than t. Let OR G and OR H denote the odds of surviving longer than t for individuals i and j, respectively. The logarithm of the odds ratio is OR N log G : 1 a OR I( xIG 9 xIH) (11 . 7 . 6) H I This ratio is independent of time. Therefore, the log-logistic regression model is a proportional odds model, not a proportional hazards model.

-   281 Example 11.5 We fit the log-logistic regression model above to the data in Example 11.6.1 using only KPS and the three cancer cell type index variables.

That is, log TG : a ; a KPS G ; a INDADE G ; a INDSMA G ; a INDSQU G; G (11.7.7) where the density function of G is defined in (11.7.1). Thus, G: a; a KPS G; a INDADE G; a INDSMA G; a INDSQU G (11.7.8) To estimate b : ( a, a, . . . , a, ), we construct the log-likelihood function by using the and in (11.7.3) as parameters in the density and survivorship functions of the log-logistic distribution in Section 6.5. The resulting log-likelihood function for the 137 observed exact or right-censored survival times is l(b) : 9 G 9 log ; 1 9 log tG 9 2 log 1;exp9 G t N G ; 9log 1;exp9 G t\N G : 91 ( a; a KPS G; a INDADE G; a INDSMA G; a INDSQU G) 9 log ; 1 9 log tG 9 2 log 1;exp91 ( a; a KPS G; a INDADE G; a INDSMA G ; a INDSQU G) t N G 9 log 1;exp91 ( a; a KPS G; a INDADE G; a INDSMA G ; a INDSQU G) t N G The first term in the log-likelihood function sums over the uncensored observations, and the second sums over the right-censored observations. The MLE ( a, . . . , a, a, ) of ( a, . . . , a, a, ) are given in Table 11.7, with their 282         Table 11.7 Asymptotic Likelihood Inference on Lung Cancer Data Using a Log-Logistic Regression Model Regression Standard Variable Coefficient Error X* p exp( aG/a) INTERCPT ( a) 2 . 451 0 . 344 50 . 911 0 . 000  INDADE ( a) 90.749 0.261 8.217 0.004 0.275 INDSMA ( a) 90.661 0.240 7.565 0.006 0.321 INDSQU ( a) 0.029 0.264 0.012 0.913 1.051 KPS ( a) 0.036 0.004 66.885 0.000 1.064 SCALE () 0.581 0.043    standard errors, likelihood ratio test statistics ( X*), and p values. The results are similar to those obtained from fitting the general gamma regression model in Example 11.4.

In addition, using (11.7.5) and (11.7.6), we can obtain odds ratios for the covariates. For example, let the odds of surviving to time t for four patients with the same KPS but different cell type (adeno, small, squamous and large) be denoted by OR " , OR 1+, OR 1/, and OR *, respectively; then the log-odds ratios of the individuals with adeno, small, and squamous cell types to the one with large cell type are, respectively, OR a OR a OR a log " : 1+ : 1/ : OR * log OR * log OR * Replacing a, a, a, and with their estimates, we have OR " :exp a OR * :0.275 OR 1+:exp a OR * :0.321 OR 1/ :exp a OR * :1 . 051 These results mean that in lung cancer patients, persons with adeno and small cell type have odds of only about one-fourth and one-third, respectively, of those with large cell type. The odds of persons with large cell carcinoma are not significantly different from those of patients with squamous cell carcinoma.

Further, when ignoring cell type, exp( a /) represents an increase (or decrease) in the odds for any 1-unit increase in the KPS measure. In this case,     283 exp( a /) : 1 . 064; thus for a 1-unit increase in the KPS measure, the odds increase by 6.4%. The results are, in general, consistent with those obtained in Example 11.4.

The following SAS code can be used to obtain the results in Table 11.7.

data w1; infile c:lcancer.dat missover; input t cens kps age diagtime indpri indthe indade indsma indsqu; run; proc lifereg; model t*cens(0) : kps indade indsma indsqu / d : llogistic; run; The following BMDP 2L code is also applicable.

/input file : c:lcancer.dat.

variables : 10.

format : free.

/print level : brief.

/variable names : t, cens, kps, age, diagtime, indpri, indthe, indade, indsma, indsqu.

/form time : t.

status : cens.

response : 1.

/regress covariates : kps, indade, indsma, indsqu.

accel : llogistic.

/end 11.8 OTHER PARAMETRIC REGRESSION MODELS In this section we discuss two models in which the survival time T is assumed to followthe exponential distribution with density and survivorship functions as defined in (6.1.1) and (6.1.3), respectively, and the mean survival time 1/ or hazard rate has the following linear relationship with the covariates: 1 N Model 1: : a a ; HxHG G H N Model 2: G: a; aHxHG H Model 1 is considered by Feigl and Zelen (1965) and extended to include censored data by Zippin and Armitage (1966). Model 2 is used by Byar et al.

(1974).

284         Model 1 Suppose that n patients are entered in a study; r of these die and s : n 9 r are still alive at the end of the study. Let t, . . . , tP be the exact survival times of the r deaths and t> , . . . , t> Q be the s censoring times. Furthermore, let xHG, i : 1, . . . , n, j : 1, . . . , p, be the observed value of the j th covariate of the i th patient. The model assumes that the mean survival time is linearly related to the covariates: 1 N N : a a a ; HxHG : HxHG (11 . 8 . 1) G H H where x GY 1. The term a represents the underlying hazard in the sense that 1/ a is the hazard rate G when covariates are ignored or all xHGs are zero. Then the likelihood function of the n survival times under the model (11.8.1) can be written as P L ( a, a, . . . , aN) : N aHxHG\exp9 tG N aHxHG\ G H H Q ; exp 9 t>I N aHxHI\ (11 . 8 . 2) I H The log-likelihood is then P P l( a, a, . . . , aN) :9 log N aHxHG 9 tG N aHxHG\ G H G H P 9 t> I N aHxHI\ (11 . 8 . 3) I H The maximum likelihood estimates of aH, j:0, 1, . . . , pH, may be obtained by solving simultaneously the p ; 1 equations: P P Q 9 N aHxHG; tG N aHxHG\; t>I N aHxHI\:0 G H G H I H P P 9 xHG N aHxHG\; tGxHG N aHxHG\ G H G H Q ; t> I xHI N aHxHI\:0 j : 1, . . . , p I H (11 . 8 . 4) Again, this can be done by Newton  Raphson iterative procedures described in Section 7.1.

285 After obtaining the MLE, a H, j :0, 1, . . . , p, the log-likelihood function can be used to test the significance of the covariates. The procedure is exactly the same as those used in Example 11.1.

The survivorship function (for the i th patient) adjusted for the covariates can be obtained from S G( t) :exp(9 Gt) : exp 9 t N a HxHG\ (11.8.5) H Model 2 Byar et al. (1974) developed another exponential model relating survival time to concomitant information for prostate cancer patients in which the individual hazard is linearly related to the possible prognostic variables: N N G: a; aHxHG: aHxHG (11 . 8 . 6) H H where x G :1. Similar to the model of Feigl and Zelen (1965), a is the underlying hazard rate when covariates are ignored, force of mortality or the intercept.

Suppose that r of the n patients are dead and s : n 9 r are still alive at the end of the study; then the likelihood function is P L ( a, a, . . . , aN) : N aHxHG exp9 N aHxHG tG G H H Q ; exp 9 N aHxHI t>I (11 . 8 . 7) I H Taking the logarithms of (11.8.7), we obtain the log-likelihood function P Q l( a, a, . . . , aN) : log N aHxHG 9 N aHxHG tG 9 N aHxHI t>I G H H I H (11 . 8 . 8) To obtain the MLEs of the aHs, we need to solve simultaneously the following p ; 1 equations: P Q xHG 9 xHGtG 9 xHIt>I:0 j:0, 1, ... , p (11.8.9) G NH a HxHG I 286         These equations can be solved simultaneously by using the Newton  Raphson iterative procedure.

After the MLEs of aH, j:0, 1, . . . , p, are obtained, the log-likelihood function can be used to test the significance of the covariates by following the same procedure as that used in Example 11.1.

The survivorship function for the i th individual adjusted for the covariates can be estimated from S G( t) :exp(9 Gt) N : exp 9 t a HxHG (11 . 8 . 10) H 11.9 MODEL SELECTION METHODS To identify important risk factors using a parametric approach, one needs to select a most appropriate parametric model and identify the most significant subset of covariates. In this section we first discuss, for a given parametric model, howto choose an optimal subset of the covariates that have statistically significant effects on the survival time. Second, we consider if the significant covariates are known, how to determine which parametric model is most appropriate. Third, we discuss a method that can be used to compare among parametric models with different subsets of covariates.

11.9.1 Selection of Most Significant Covariates for a Known Parametric Model For a known parametric model, the following methods can be used to select an optimal subset of the covariates in the sense that the subset selected has the most statistically significant effects on the survival time among all subsets of the covariates. These methods include the forward, backward, stepwise, AIC, and BIC selection procedures commonly used in ordinary regression analyses.

We give only a brief outline here. Interested readers are referred to books on ordinary regression analysis.

Forward Selection Procedure The forward selection procedure is an adding process in which one covariate is selected and added to the model at every step. First, we have to estimate the specific parameters that define the parametric model and the coefficients of the adjusting covariates, if any, that are forced into the model. For example, to have age- and gender-adjusted results, age and gender must be included in the model, whether or not they are significant. Then the adjusted chi-square statistics for each covariate not in the model are computed and the largest of these statistics is identified. If the largest chi-square statistic is significant at the    287 level specified (usually, : 0.15) for entry, the corresponding covariate is added to the model.

Let a be the vector of the parameters or coefficients of covariates already in the model and l(  ) be the log-likelihood function. The forward selection procedure will select xH, which is not yet in the model, to enter the model if the difference between the log-likelihood values with xH and without xH is largest among all the xIs that are not in the model. That is, the coefficient aH of xH satisfies X* :2[( l( a H, a)9 l(a H(0))] : max 2[ l( a I I, a) 9 l(a I(0))], for any xI that is not in the model (11.9.1) and X*? where aI is the coefficient of xI not yet in the model, ( a I, a), is the MLE of ( aI, a), a I(0) is the MLE of a given aI:0, and ? is the -level critical point of the chi-square distribution with 1 degree of freedom. In the forward selection procedure, once a covariate is entered into the model, it will never be removed. The process is repeated until none of the remaining covariates meet the level specified for entry or until a predetermined number of covariates have been entered.

Backward Selection Procedure The backward selection procedure is an elimination process in which all the covariates are included in the model at the beginning and are removed one by one according to a significance criterion. The specific parameters that define the parametric model and the coefficients of all the covariates are estimated first. Then the Wald test is used to examine each covariate. The least significant covariate that does not meet the specified level (usually, : 0.15) for staying in the model is removed. That is, covariate xH will be removed from the model if a X H 5 : : min a I for any x v I that is in the model (11.9.2) HH I v II and X5? where aH is the corresponding coefficient for xH and v HH is the estimated variance of a H. In the backward selection procedure, once a covariate is removed from the model, it remains excluded. The process is repeated until all the covariates remained in the model meet the specified significance level for staying or until a predetermined number of covariates remain in the model.

The advantages of the backward procedure have been discussed by Mantel (1970).

288         Stepwise Selection Procedure The stepwise selection procedure is a combination of forward and backward selection procedures. At first, it is similar to the forward selection procedure; however, covariates already in the model do not necessarily remain. Covariates already in the model may be removed later if they are no longer significant. The stepwise selection process terminates if no significant covariate can be added to the model or if the covariate just entered into the model is removed and no more covariates can be added.

Information Criterion (AIC and BIC) Procedures The Baysian information criterion (BIC) selection procedure discussed in Section 9.3 can be used to select the best parametric model with covariates.

This can be done easily by replacing the log-likelihood function l(b) in (9.3.1) with the log-likelihood function with subsets of covariates defined in previous sections of this chapter. The subset of covariates that produces the largest r value in (9.3.1) among all possible subsets is the choice. If the number of covariates is large, one may apply the forward, backward, and stepwise selection method first to reduce the number of candidate covariates, then use the BIC procedure. The AIC criterion can be applied in a similar manner.

11.9.2 Selection of a Parametric Model with a Fixed Subset of Covariates If the most significant subset of covariates is known, selection of an appropriate parametric model can be carried out by using a procedure similar to those based on the likelihood functions and discussed in Section 9.2. The procedures are exactly the same except that all the likelihood functions are replaced by those with covariates, for example, those given in (11.3.10) and Examples 11.2 and 11.5. With computer software packages available commercially, the procedure can easily be applied. The following example illustrates the application.

Example 11.6 Consider the lung cancer patients who did not receive any prior therapy in Example 11.4. Assume that the three covariates KPS, INDADE, and INDSMA are most significant. For these three fixed covariates, the log-likelihood values based on the exponential, Weibull, lognormal, loglogistic, and generalized gamma models are given in Table 11.8. From this table, the lognormal, Weibull and exponential models (relative to the generalized gamma model), with the three covariates, are rejected at : 0.0325, 0.016 and 0.024, respectively. It appears that the exponential model, relative to the Weibull, is not rejected ( p : 0.194). However, since the exponential model belongs to the Weibull distribution family and the Weibull model has been rejected, the exponential model with the three covariates is not appropriate for the data, as noted earlier in Chapter 9. Thus, we conclude that none of the three models (exponential, Weibull, and lognormal), with covariates, provide an appropriate fit to the data. In Example 11.7 we will see that the log-logistic model is the best fit among all these models.

289 Table 11.8 Goodness-of-Fit Tests Based on Asymptotic Likelihood Inference on Lung Cancer Data Distribution LL ?

LLR ?

p?

BIC AIC Extended 9132.793   9146.517 9144.793 generalized gamma Log-logistic 9131.230   9142.667 9141.230 Lognormal 9135.022 4.459 @ 0.035 9146.459 9145.022 Weibull 9135.669 5.752 A 0.016 9147.106 9145.669 Exponential 9136.512 7.438 B 0.024 9145.661 9144.512 Exponential 9136.512 1.686 C 0.194   ? LL, log-likelihood; LLR, log-likelihood ratio statistic; p, probability that the respective chi-square random variable LLR.

@ Lognormal relative to extended generalized gamma.

A Weibull relative to extended generalized gamma.

B Exponential relative to extended generalized gamma.

C Exponential relative to Weibull.

Using the data file C:LCANCER.DAT described in Example 11.4, the following SAS code can be used to obtain Table 11.8.

data w1; infile c:lcancer.dat missover; input t cens kps age diagtime indpri indthe indade indsma indsqu; if indpri : 0; run; proc lifereg; Model 1: model t*cens(0) : kps indade indsma / d : exponential; Model 2: model t*cens(0) : kps indade indsma / d : weibull; Model 3: model t*cens(0) : kps indade indsma / d : lnormal; Model 4: model t*cens(0) : kps indade indsma / d : gamma; Model 5: model t*cens(0) : kps indade indsma / d : llogistic; run; 11.9.3 Selection of a Parametric Model and an Optimal Subset of Covariates Simultaneously: AIC and BIC Procedures The extended AIC and BIC criteria, which include covariates, can be applied not only to select the most significant covariates for a given parametric model, but also, simultaneously, to select the best parametric model. The procedure may be tedious if the number of covariates to be considered is large. However, in practice, the number of covariates worthy of consideration in a model is usually reduced after univariate analyses, as described in Section 11.1. Therefore, the AIC or BIC procedure may not be too difficult to apply. With the aid of software packages, we can apply the forward, backward, and stepwise 290         selection methods in Section 11.9.1 first to fit different parametric regression models to the data and then include in the AIC or BIC procedure all or a subset of the significant covariates identified in each fit.

Example 11.7 Consider the lung cancer data of Example 11.6. We apply the methods of Section 11.9.1 to select the best subset of covariates separately for the exponential, Weibull, lognormal, log-logistic, and generalized gamma models. The same three covariates (KPS, INDADE, and INDSMA) are selected (at the 0.05 level) as the most significant covariates in every of these parametric models. The last column of Table 11.8 gives the r values of the BIC for the different parametric models with the same three covariates. Based on these values, the log-logistic model with the three covariates should be selected as the final model for the data since its BIC or AIC value is the largest among all the models. However, it is not known if the log-logistic model is significantly better than the other models.

11.9.4 Cox--Snell Residual Procedure with Covariates The AFT models in Sections 11.2 to 11.7 assume the following linear relationship between log T and the p covariates: N log TG : a ; aIxIG ; G : G; G (11 . 9 . 3) I where G has survival function G( ). Once a specified parametric model and a subset of covariates are selected, to assess the goodness of fit of this model, one approach is to compute the regression residuals G:log tG 9 G i : 1, 2, . . . , n (11 . 9 . 4) where N G: a; a IxIG I and a, a, a, . . . , a N and are the MLE of a, a, a, . . . , aN and , respectively, and tGs are observed survival times. An G is taken as censored if the corresponding tG is censored. If the model fitted is correct, the corresponding survival function G( ) is the survival function of the fitted model. For example, if T indeed follows the log-logistic regression model with a selected subset of covariates, the corresponding Gs should followthe log-logistic distribution.

Moreover, if the fitted model is correct, the Cox  Snell residuals defined in (8.4.1) are rG :9log G( G; d):9log G log tG 9 G ; d i:1, 2, ... , n (11.9.5)    291 Figure 11.2 Cox  Snell residuals plot from the fitted exponential model on lung cancer data.

where d is the MLE of the parameters of the distribution. Let S( r) denote the estimated survival function of rGs. From Section 8.4, the graph of rG versus 9log S( rG), i:1, 2, . . . , n, should be closed to a straight line with unit slope and zero intercept if the fitted model for the survival time T is correct. This graphical method can be used to assess the goodness of fit of the parametric regression model.

Example 11.8 Figures 11.2 to 11.6 showthe Cox  Snell residuals plots from fitting the exponential, Weibull, lognormal, log-logistic, and extended generalized gamma models, respectively with the three covariates KPS, INDADE, and INDSMA, to the lung cancer data in Example 11.6. The five graphs look similar, and all are close to a straight line with unit slope and zero intercept. No significant differences are observed in these graphs. The results obtained are similar to those from Examples 11.6 and 11.7. The differences among the five distributions are small with the log-logistic distribution being slightly better than the others.

Using the same data file C:LCANCER.DAT as in Example 11.6.1, the following SAS code can be used to obtain the Cox  Snell residuals based on the exponential, Weibull, lognormal, log-logistic, and generalized gamma model with the three covariates, KPS, INDADE, and INDSMA.

292         Figure 11.3 Cox  Snell residuals plot from the fitted Weibull model on lung cancer data.

Figure 11.4 Cox  Snell residuals plot from the fitted lognormal model on lung cancer data.

293 Figure 11.5 Cox  Snell residuals plot from the fitted log-logistic model on lung cancer data.

data w1; infile c:lcancer.dat missover; input t cens kps age diagtime indpri indthe indade indsma indsqu; if indpri : 0; run; proc lifereg noprint; a: model t*cens(0) : kps indade indsma / d : exponential; output out : wa cdf : f; b: model t*cens(0) : kps indade indsma / d : weibull; output out : wb cdf : f; c: model t*cens(0) : kps indade indsma / d : lnormal; output out : wc cdf : f; d: model t*cens(0) : kps indade indsma / d : gamma; output out : wd cdf : f; e: model t*cens(0) : kps indade indsma / d : llogistic; output out : we cdf : f; run; data wa; set wa; model : Exponential; data wb; 294         Figure 11.6 Cox  Snell residuals plot from the fitted extended generalized gamma model on lung cancer data.

set wb; model : Weibull; data wc; set wc; model : LNnormal; data wd; set wd; model : Gamma; data we; set we; model : LLogistic; data w2; set wa wb wc wd we; rcs :9log(1 9 f); run; proc sort; by model; run; proc lifetest notable outs : ws noprint; time rcs*cens(0); by model ;  295 run; data ws; set ws; mls :9log(survival); run; title Cox-Snell Residuals (rcs) and -log(estimated survival function of rcs) (mls); proc print data : ws; var model rcs mls; run; Bibliographical Remarks An excellent expository paper on statistical methods for the identification and use of prognostic factors has been written by Armitage and Gehan (1974).

Many studies of prognostic factors have been published, including Sirott et al.

(1993), Brancato et al. (1997), Linka et al. (1998), and Lassarre (2001). The accelerated failure time (AFT) model was introduced by Cox (1972). The detailed statistical inference of the AFT models and the theoretical aspects of model-selecting methods are included in the works cited in the bibliographical remarks at the end of Chapter 9 and in the papers and books cited in this chapter.

EXERCISES 11.1 Consider the data given in Exercise Table 3.1. In addition to the five skin tests, age and gender may also have prognostic value. Examine the relationship between survival and each of the seven possible prognostic variables as in Table 3.12. For each variable, group the patients according to different cutoff points. Estimate and drawthe survival function for each subgroup by the product-limit method and then use the methods discussed in Chapter 5 to compare survival distributions of the subgroups. Prepare a table similar to Table 3.12. Interpret your results. Is there a subgroup of any variable that shows significantly longer survival times? (For the skin test results, use the larger diameter of the two.) 11.2 Consider the seven variables in Exercise 11.1. Use the Weibull re- gression model to identify the most significant variables. Compare your results with that obtained in Exercise 11.1.

11.3 Consider the data given in Exercise Table 3.3. Examine the relationship between remission duration and survival time and each of the nine possible prognostic variables: age, gender, family history of melanoma, and the six skin tests. Group the patients according to different cutoff 296         points. Estimate and drawremission and survival curves for each subgroup. Compare the remission and survival distributions of sub- groups using the methods discussed in Chapter 5. Prepare tables similar to Table 3.8.

11.4 Perform the following analyses: (1) Use the exponential, Weibull, lognormal, generalized gamma, or log-logistic regression models sepa- rately to identify the significant variables in Exercise 11.3 for their relative importance to remission duration and survival time. (2) Select a model among these final models using the BIC or AIC method. (3) Calculate separately the respective likelihood for the exponential, Weibull, lognormal, or generalized gamma regression model with the fixed variables in the model selected in step (2), then use the method in Section 11.9.2 to choose a model and see whether this model is the model selected in step (2).

11.5 Perform the same analyses as in Exercise 11.4 for survival time in the 157 diabetic patients given in Exercise Table 3.4.

11.6 Using the notations in Example 11.2, show that if we use the follow- ing model to replace the model defined in (11.4.6), log TG : a ; a LOW ; a UNSA ; : ; , the hypothesis H: hQ: hS is equivalent to H: a: 0 .

11.7 Following Examples 11.2 and 11.3, obtain the log-likelihood function based on (11.6.8) for the 137 observed exact and right-censored survival times from the lung cancer patients.

11.8 Using the same notation as in Example 11.5, showthat if w e use the model log TG: a; a KPS G ; a INDLAR G ; a INDSMA G ; a INDSQU G; G, where INDLAR:1 if the type of cancer is large, and 0 otherwise, to replace the model defined in (11.7.8), the hypotheses H: a:0 and H: a:0 are equivalent to H: OR1+: OR" and H: OR1/: OR" , respectively. Moreover, if we use the model log TG : a ; a KPS G ; a INDLAR G ; a INDADE G ; a INDSQU G ; G to replace the model defined in (11.7.8), the hypothesis H: a:0 is equivalent to H: OR1/: OR1+.

11.9 Let be a survival time with the density function g( ):exp[ 9exp( )].

Showthat the survival time T defined by log T : ; has the Weibull distribution with : exp(9/) and : 1/ by applying the density transformation rule in (11.2.11).

11.10 Let be a survival time with the standard normal distribution N(0, 1).

Showthat the survival time T defined by log T : ; has the lognormal distribution by applying the density transformation rule in (11.2.11).

297 11.11 Let u be a survival time with the density function f ( u), f ( u) : exp[ u/ 9 exp( u)] (1 /) where (  ) is the gamma function defined in (6.2.8).

(a) Showthat the survival time defined by : / ; (log )/ has the following density function, [exp( )/]B exp[9exp( )/] g( ) : 9- ;- (1/) and survival function, 1 if 0 G( ) : I exp( ), 1 1 9 I exp( ) , if 0 where I(  ,  ) is the incomplete gamma function defined as in (6.4.4).

(b) Showthat the survival time T defined by log T : ; has the extended gamma density function defined in (11.6.4).

11.12 If has a logistic distribution with the density function g( ) : exp( ) [1 ; exp( )] showthat the survival time T defined by log T : ; has the log-logistic distribution with : exp(9/) and : 1/ by applying the density transformation rule in (11.2.11).

C H A P T E R 12 Identification of Prognostic Factors Related to Survival Time: Cox Proportional Hazards Model In Chapter 11 we discussed parametric survival methods for model fitting and for identifying significant prognostic factors. These methods are powerful if the underlying survival distribution is known. The estimation and hypothesis testing of parameters in the models can be conducted by applying standard asymptotic likelihood techniques. However, in practice, the exact form of the underlying survival distribution is usually unknown and we may not be able to find an appropriate model. Therefore, the use of parametric methods in identifying significant prognostic factors is somewhat limited. In this chapter we discuss a most commonly used model, the Cox (1972) proportional hazards model, and its related statistical inference. This model does not require knowledge of the underlying distribution. The hazard function in this model can take on any form, including that of a stepfunction, but the hazard functions of different individuals are assumed to be proportional and independent of time. The usual likelihood function is replaced by the partial likelihood function. The important fact is that the statistical inference based on the partial likelihood function is similar to that based on the likelihood function.

12.1 PARTIAL LIKELIHOOD FUNCTION FOR SURVIVAL TIMES The Cox proportional hazards model possesses the property that different individuals have hazard functions that are proportional, i.e., [ h( t x)/ h( t x)], the ratio of the hazard functions for two individuals with prognostic factors or covariates x:( x, x, . . . , xN), and x:( x, x, . . . , xN) is a constant (does not vary with time t). This means that the ratio of the risk of dying of two individuals is the same no matter how long they survive. In Sections 11.3 298       299 and 11.4, we showed that the exponential and Weibull regression models possess this property. This property implies that the hazard function given a set of covariates x : ( x, x, . . . , xN) can be written as a function of an underlying hazard function and a function, say g( x, . . . , xN), of only the covariates, that is, h( t x, . . . , xN) : h( t) g( x, . . . , xN) or h( t x) : h( t) g(x) (12.1.1) The underlying hazard function, h( t), represents how the risk changes with time, and g(x) represents the effect of covariates. h( t) can be interpreted as the hazard function when all covariates are ignored or when g(x) : 1, and is also called the baseline hazard function. The hazard ratio of two individuals with different covariates x and x is h( t x) : h( t) g(x) : g(x) (12 . 1 . 2) h( t x) h( t) g(x) g(x) which is a constant, independent of time.

The Cox (1972) proportional hazard model assumes that g(x) in (12.1.1) is an exponential function of the covariates, that is, g( x) : exp N bHxH:exp(bx) H and the hazard function is h( t x) : h( t) exp N bHxH: h( t) exp(bx) (12.1.3) H where b : ( b, . . . , bN) denotes the coefficients of covariates. These coefficients can be estimated from the data observed and indicate the magnitude of the effects of their corresponding covariates. For example, if there is only one covariate treatment, let x:0 if a person receives placebo and x :1 if a person receives the experimental drug. The hazard ratio of the patient receiving the experimental drug and the one receiving placebo based on (12.1.2) and (12.1.3) is h( t x:1) :exp( b h( t x ) : 0) Thus, the two treatments are equally effective if b:0 and the experimental drug introduces lower (higher) risk for survival than placebo if b 0 ( b 0) .

It can be shown that (12.1.3) is equivalent to S( t x) : [ S( t)]exp( NH bHxH) :[ S( t)]exp(bx) (12.1.4) 300         Thus the covariates can be incorporated into the survivorship function. The use of (12.1.3) can be exemplified as follows.

1. Two-sample problems. Suppose that p : 1; that is, there is only one covariate, x, which is an indicator variable: x G:0 if the i th individual is from group0 1 if the i th individual is from group1 Then according to (12.1.3), the hazard functions of groups 0 and 1 are, respectively, h( t) and h( t) : h( t) exp( b). The hazard function of group 1 is equal to the hazard function of group0 multiplied by a constant exp( b), or the two hazard functions are proportional. In terms of the survivorshipfunction, S( t) : [ S( t)] A where the constant c : exp( b) (Nadas, 1970). The two-sample test developed from (12.1.3) is the Cox  Mantel test discussed in Chapter 5. It is now apparent that the test is based on the assumption of a proportional hazard between the two groups.

2. Two-sample problems with covariates. The covariates in (12.1.3) can either be indicator variables such as x in the two-groupproblem above or prognostic factors. Having one or more covariates representing prognostic factors in (12.1.1) enables us to examine the relation between two groups, adjusting for the presence of prognostic factors.

3. Regression problems. Dividing both sides of (12.1.3) by h( t) and taking its logarithm, we obtain h N log G( t) : b b h x G ; b x G ; % ; bNxNG : HxHG : bx G (12.1.5) ( t) H where the xs are covariates for the i th individual. The left side of (12.1.5) is a function of hazard ratio (or relative risk) and the right side is a linear function of the covariates and their respective coefficients.

As mentioned earlier, h( t) is the hazard function when all covariates are ignored. If the covariates are standardized about the mean and the model used is h log G( t) : b h ( x G 9 x) ; b( x G 9 x) ; % ; bN( xNG 9 x N) : b(x G 9 x) ( t) (12.1.6)       301 where x : ( x, x, . . . , x N) and x H is the average of the j th covariate for all patients, the left side of (12.1.6) is the logarithm of the ratio of risk of failure for a patient with a given set of values x G: ( x G, x G, . . . , xNG) to that for an average patient who has an average value for every covariate.

In this chapter we focus on the use of (12.1.5), and the main interest here is to identify important prognostic factors. In other words, we wish to identify from the p covariates a subset of variables that affect the hazard more significantly, and consequently, the length of survival of the patient. We are concerned with the regression coefficients. If bG is zero, the corresponding covariate is not related to survival. If bG is not zero, it represents the magnitude of the effect of xG on hazard when the other covariates are considered simultaneously.

To estimate the coefficients, b, . . . , bN, Cox (1972) proposes a partial likelihood function based on a conditional probability of failure, assuming that there are no tied values in the survival times. However, in practice, tied survival times are commonly observed and Coxs partial likelihood function was modified to handle ties (Kalbfleisch and Prentice, 1980; Breslow, 1974; Efron, 1977). In the following we describe the estimation procedure without and with ties.

12.1.1 Estimation Procedures without Tied Survival Times Suppose that k of the survival times from n individuals are uncensored and distinct, and n 9 k are right-censored. Let t t% t I be the ordered k distinct failure times with corresponding covariates x, x, . . . , x I. Let R( t G) be the risk set at time t G. R( t G) consists of all persons whose survival times are at least t G. For the particular failure at time t G, conditionally on the risk set R( t G), the probability that the failure is on the individual as observed is exp NH bHxH G : exp(bx G) exp N exp(bx l + R( t G) H bHxHJ) l + R( t G) J) Each failure contributes a factor and hence the partial likelihood function is I exp N I exp(bx L (b) : H bHxH G G) : (12.1.7) G exp N exp(bx l + R( t G) H bHxHJ) G l+R( t G) J) and the log-partial likelihood is I N I l(b) : log L (b) : bHxHG 9 log exp N bHxHJ G H G l + R( t G) H I : bx G 9log exp(bx J) (12.1.8) G l + R( t G) 302         The maximum partial likelihood estimator (MPLE) b of b can be obtained by the steps shown in (7.1.2) (7.1.4). That is, b, . . . , b N are obtained by solving the following simultaneous equations: ( l(b)) : 0 b or l(b) I : [ x b S G 9 ASG(b)] : 0 u : 1, 2, . . . , p (12 . 1 . 9) S G where x x A l + R( t SJ exp NH bHxHJ) l + R( t SJ exp(bx J) SG(b) : G) : G) (12.1.10) exp N exp(bx l + R( t G) H bHxHJ l + R( t G) J) by applying the Newton  Raphson iterated procedure. The second partial derivatives of l(b) with respective to bS and bT, u, v: 1, 2, . . . , p, in the Newton  Raphson iterative procedure are l(b) I I IST(b) : : 9 C C b STG( b, . . . , bN) : 9 STG(b) u, v : 1, 2, . . . , p S bT G G (12 . 1 . 11) where x C l + R( t SJxTJ exp NH bHxHJ) STG(b) : G) 9 A exp N SG(b) ATG(b) (12 . 1 . 12) l + R( t G) H bHxHJ) The covariance matrix of the MPLE b, defined similarly as V (b) defined in (7.1.5), is l(b) V (b) : Cov (b) : 9bb\ (12.1.13) where 9 l(b) / bb is called the observed information matrix with 9 IST(b) as its ( u, v) element and where IST(b) is defined in (12.1.11). Let the ( i, j) element of V (b) in (12.1.13) be vGH; then the 100(19)% confidence interval for bG is, according to (7.1.6), b G 9 Z?( vGG, b G; Z?( vGG (12 . 1 . 14) 12.1.2 Estimation Procedure with Tied Survival Times Suppose that among the n observed survival times there are k distinct uncensored times t t% t I. Let m G denote the number of people       303 who fail at t G or the multiplicity of t G; m G 1 if there are more than one observation with value t G; m G:1 if there is only one observation with value t G. Let R( t G) denote the set of people at risk at time t G [i.e., R( t G) consists of those whose survival times are at least t G] and rG be the number of such persons. For example, in the following set of survival times from eight subjects, 15, 16;, 20, 20, 20, 21, 24, 24, n : 8, k : 4, t:15, t:20, t:21, t:24, m:1, m:3, m:1, and m:2. Then R( t) includes all eight subjects. R( t) :those subjects with survival times 20, 21, and 24, R( t) : those subjects with survival times 21 and 24, and R( t) : those subjects with survival time 24; thus, r:8, r:6, r:3, and r: 2.

To discuss the methods for ties, we introduce a few additional notations.

From every R( t G), we can randomly select m G subjects. Donate each of these m G selections by u H. There are P C : r G K G G!/[ m G! ( rG 9 m G)!] possible u Hs. Let U G denote the set that contains all the u Hs. For example, from R( t), we can randomly select any m :3 out of the 6 ( r: 6) subjects. There are a total of C : 20 such selections (or subsets), and one of u Hs is, for example, three subjects with survival times 20, 20, and 24. U :u, u, . . . , u contains all 20 subsets.

Now let us focus on the tied observations.

Let x I:( x I, x I, . . . , xNI) denote the covariates of the k th individual, z : x , z , . . . , z ), where z is the sum of the l th covariate u( j) k + u H I : ( z 1u( j) 2u( j) p u( j) l u( j) of the m G persons who are in u H. Let u * G denotes the set of m G people who failed at time t G, and z : x , z* , . . . , z* ), where z* be u *( i) k + u* G I : ( z* 1u *( i) 2u *( i) p u *( i) l u *( i) the sum of the l th covariate of the m G persons who are in u * G (failed at time t G). For example, for the set of survival times above, z* equals the sum of 1u *(2) the first covariate values of three persons who failed at time 20. With these notations we are ready to introduce the following method for ties.

Continuous Time Scale In the case of a continuous time scale, for the m G persons failing at t G, it is reasonable to say that the survival times of the m G people are not identical since the ties are most likely to be the results of imprecise measurements. If the precise measurements could be made, these m G survival times could be ordered and we could use the likelihood function in (12.1.7). In the absence of knowledge of the true order (the real case), we have to consider all possible orders of these observed m G tied survival times. For each t G, the observed m G tied survival time can be ordered in m G! ( m G factorial) different possible ways.

For each of these possible orders we will have a product as in (12.1.7) for the corresponding m G survival times. Therefore, when the survival time is measured at a continuous time scale, construction and computation of the exact partial likelihood function is a very tedious task if m G is larger. Readers interested in the details of the exact partial likelihood function are referred to Kalbfleisch and Prentice (1980) and Delong et al. (1994). The formula provided by Delong et al. makes computation of the partial likelihood function for tied continuous survival times more feasible. We will not discuss the exact partial likelihood function further due to its complexity. Among the statistical sof- 304         tware packages, SAS includes a procedure based on the exact partial likelihood function. Use of this procedure is illustrated in Example 12.3.

To approximate the exact partial likelihood function, the following two likelihood functions can be used when each m G is small compared to rG.

Breslow (1974) provided the following approximation: I exp(z b) L u *( i) (b) : (12.1.15) G [ exp(x l + R( t G) J b)] m G An alternative approximation was provided by Efron (1977): I exp(z b) L u *( i) #(b) : (12.1.16) G K G H [ exp(x exp(x l + R( t G) J b) 9 [( j 9 1) /m G] l+u * G J b)] Discrete Time Scale If survival times are observed at discrete times, the tied observations are true ties: that is, these events really happen at the same time. Cox (1972) proposed the following logistic model: hG( t) dt : h( t) dt exp N b exp(bx 1 9 h HxHG: h( t) dt G) G( t) dt 1 9 h( t) dt H 1 9 h( t) dt This model reduces to (12.1.3) in the continuous time scale. Using the model and replacing the i th term in (12.1.7) with the following term with tied observations at t G: exp(z b) u *( i) exp(z b) u H +U G u( j) the partial likelihood function with tied observations at a discrete time scale is I exp(z b) L u *( i) B(d) : (12.1.17) G exp(z u H +U G S H b) The i th term in this expression represents the conditional probability of observing the m G failures given that there are m G failures at time t G and the risk set R( t G) at t G. The number of terms in the denominator of the i th term is P C : r G K G G!/[ m G!( rG 9 mG)!], as noted earlier, and will be very large if the m G is large. Fortunately, a recursive algorithm proposed by Gail et al. (1981) makes the calculation manageable. Equation (12.1.17) can also be considered as an approximation of the partial likelihood function for continuous survival times with ties by assuming that the ties are true as if they were observed at a discrete time scale.

305 As shown in many papers in literature, in most practical situations, the three partial likelihood functions above are reasonably good approximations of the exact partial likelihood function for continuous survival time with ties. When there are no ties on the event times (i.e., m G Y 1), (12 . 1 . 15) (12.1.17) reduce to (12.1.7). The maximum partial likelihood estimate of b in (12.1.15) (12.1.17) can be estimated using procedures similar to those in (12.1.8) (12.1.14).

Once the coefficients are estimated, relative risk (or relative hazard) in (12.1.2) or (12.1.5) can be obtained. For example, if x represents hypertension and is defined as x :1 if patient is hypertensive 0 otherwise the hazard rate for hypertensive patients is exp( b) times that for normotensive patients. That is, the risk associated with hypertension is exp( b) adjusting for the other covariates in the model. A 100(1 9 )% confidence interval for the relative risk can be obtained by using the confidence interval for b. Let ( b *, b 3) be the 100(19)% confidence interval for b; a 100(19)% confidence interval for the relative risk is (exp( b *), exp( b 3)) according to (7.1.8). This application of the proportional hazards model has been used extensively, particularly by epidemiologists.

The following three examples illustrate the use of Coxs regression model.

Example 12.1 Consider the survival data from 30 patients with AML in Table 11.4. Recall that the two possible prognostic factors are x:1 if patient is 50 years 0 otherwise x: 1 if cellularity of marrow clot section is 100% 0 otherwise We fit the Cox proportional hazard model to the data. The results are presented in Table 12.1 In this case, Breslows approximation in (12.1.15) is used to handle ties. The positive signs of the regression coefficients indicate that the older patients (50 years) and patients with 100% cellularity of the marrow clot section have a higher risk of dying. Furthermore, age is significantly related to survival after adjustment for cellularity. The results are consistent with those from fitting the lognormal regression model in Example 11.3. The coefficients of the binary covariates can be interpreted in terms of relative risk. The estimated risk of dying for patients at least 50 years of age is 2.75 times higher than that for patients younger than 50. Patients with 100% cellularity have a 42% higher risk of dying than patients with less than 100% cellularity.

306         Table 12.1 Results of a Proportional Hazards Regression Analysis of Data in Table 11.4 Regression Standard Covariate Coefficient Error p Value exp(coefficient) x (age) 1.01 0.46 0013 2.75 x (cellularity) 0.35 0.44 0.212 1.42 The 95% confidence intervals for b (age) and b (cellularity) are 1.01<1.96 (0.46) or (0.11, 1.91) and 0.35 < 1.96 (0.44) or (90.51, 1.21), respectively.

Consequently, the 95% confidence intervals for the relative risks are ( e, e) or (1.12, 6.75) and ( e\, e) or (0.60, 3.35), respectively. The small number of patients (30) may have contributed to the large standard errors of b and b and consequently, the wide confidence intervals. The lower bound of the confidence interval for age is only slightly above 1. This suggests that the importance of age should be interpreted carefully. In general, if the number of subjects is small and the standard errors of the estimates are large, the estimates may be unreliable.

When the two covariates are considered simultaneously, the risk for a patient with x:1 and x :1 relative to patients with x:0 and x :0 can be estimated. The relative risk is estimated as exp(1.01 ; 0.35) : 3.90 for a patient who is over 50 years of age and whose cellularity is 100%, compared to patients who are younger than 50 and whose cellularity is less than 100%.

Using the same data set C:AML.DAT defined in Example 11.3, the following SAS code can be used to obtain the results in Table 12.1.

data w1; infile c:aml.dat missover; input t cens x1 x2; run; proc phreg; model t*cens(0) : x1 x2 / rl; run; If BMDP 2L is used, the following code is applicable.

/input file : c:aml.dat .

variables : 4.

format : free.

/print cova.

/variable names : t, cens, x1, x2.

/form time : t.

status : cens.

response : 1.

/regress covariates : x1, x2.

307 If SPSS is used, the following code suffices.

data list file : c:aml.dat free / t cens x1 x2.

coxreg t with x1 x2 /status : cens event (1) /print : all.

Example 12.2 In a study (Buzdar et al., 1978) to evaluate a combination of 5-flourouracil, adramycin, cyclophosphamide, and BCG (FAC-BCG) as adjuvant treatment in stage II and III breast cancer patients with positive axillary nodes, 131 patients receiving FAC-BCG after surgery and radiation therapy were compared with 151 patients receiving surgery and radiation therapy only (control group).

Coxs regression model was used to identify prognostic factors and to evaluate the comparability of the two treatment groups. The model was fitted to the data from 151 patients to determine the variables related to length of remission. The possible prognostic variables considered were age (years), menopausal status (1, premenopausal; 0, other), size of primary tumor (2, 3 cm; 4, 3  5 cm; 7, 5 cm), state of disease (2, stage II; 3, stage III), location of surgery (1, M. D. Anderson Hospital; 0, other), number of nodes involved (2, 4; 7, 4  10; 12, 10), and race (1, Caucasian; 2, other). The covariates were selected by the forward selection method outlined in Section 11.9. Three variables  number of nodes involved, state of disease, and menopausal status  were selected for use in the model, all related significantly ( p 0.1) to disease-free time. The regression equation including these variables only is h log G( t) : 0 . 111(number of nodes 9 6.16) ; 0.8122(stage 9 2.39) h( t) ;0.872(menopausal90.26) Table 12.2 gives the details of the fit. Relative risk was taken as hG( t) /h( t), the ratio of the risk of death per unit of time for a patient with a given set of prognostic variables to the risk for a patient whose prognostic variables were average in value. The relative risk for each variable was calculated by considering favorable or unfavorable values of that variable, assuming that other variables were at their average value. Note that the risk of relapse per unit time for a patient with 12 positive nodes is 3.04 (ratio or risk) times that for a patient with only two positive nodes. The risk of relapse per unit time for a stage III patient was 2.25 times that of a stage II patient.

The Coxs regression model was also fitted to the combined groupof FAC-BCG and control patients, including type of treatment (0, control; 1, FAC-BCG), menopausal status, size of primary tumor, and number of involved nodes as potential prognostic variables. The regression equation with three 308         Table 12.2 Patient Characteristics Related to Disease-Free Time in Coxs Regression Model Fit to Control Patients Maximum Relative Risk ?

Prognostic Regression Significance Log Ratio of Variable Coefficient Level ( p) Likelihood Favorable Unfavorable Risks Number of nodes 0.1110 0.01 9257.407 0.63 1.91 3.04 Stage 0.8122 0.016 9254.533 0.73 1.64 2.25 Menopausal status 0.8720 0.1 9250.576 0.80 1.91 2.39 Source: Buzdar et al. (1978). Reprinted by permission of the editor.

? Favorable variables: number of nodes : 2, stage II, postmenopausal. Unfavorable variables: number of nodes : 12, stage III, premenopausal.

significant ( p 0.05) variables obtained was as follows: h log G( t) : 91.8792(treatment 9 0.47) ; 0.9644(menopausal status 9 0.33) h( t) ;0.1611(size of primary tumor94.04) Table 12.3 gives the details of the fit. The most important variable in predicting survival time was the type of treatment (FAC-BCG favorable); other significantly important variables were menopausal status and size of primary tumor.

The risk of death per unit of time for a patient receiving no adjuvant treatment (control group) was 6.55 times that for a patient receiving the treatment, showing that FAC-BCG can prolong life considerably.

Table 12.3 Patient Characteristics Related to Survival, Treatment Included Maximum Relative Risks ?

Prognostic Regression Significance Log Ratio of Variable Coefficient Level ( p) Likelihood Favorable Unfavorable Risks Treatment 91.8792 0.01 9201.200 0.37 2.42 6.55 Menopausal 0.9644 0.01 9197.719 0.73 1.91 2.62 status Size of 0.1611 0.05 9195.865 0.72 1.61 2.24 primary tumor Source: Buzdar et al. (1978). Reprinted by permission of the editor.

? Favorable variables: treatment  FAC-BCG, postmenopausal, size of primary tumor 2 cm.

Unfavorable variables: no adjuvant treatment, premenopausal, size of primary tumor 7 cm.

309 Example 12.3 Suppose that demographic, personal, clinical, and labora- tory data are collected from an interview and physical examination of 200 participants in a study of cardiovascular disease (CVD). These participants, aged 50  79 years and free of CVD at the time of the baseline examination, are then followed for 10 years. During the follow-upp eriod, 96 of the 200 participants develop or die of CVD. We use this set of simulated data to illustrate further the use of the proportional hazards model in identifying important risk factors. Table 12.4 gives a subset of the simulated data of 68 participants.

The event time T of interest is CVD-free time, which is defined as the time in years from baseline examination to the first time that a participant was diagnosed as having CVD or confirmed as a CVD death. CVD includes coronary heart disease (CHD) and stroke. The covariates of interest are age (AGE), gender (SEX : 1 if male and :0 if female); smoking status (SMOKE : 1 if current smoker, and 0 otherwise); body mass index (BMI : weight in kilograms divided by height in meter squared); systolic blood pressure (SBP); logarithm of ratio of urinary albumin and creatinine (LACR); logarithm of triglycerides (LTG); hypertension status (HTN : 1 if SBP 140 mmHg or DBP 90 mmHg or under treatments of hypertension, and :0 otherwise); and diabetes status (DM : 1 if fasting glucose 126 mg/dL or under the treatments of diabetes, and :0 otherwise). For the CVD outcome of interest, we let DG denote the type of CVD. DG : 0 if the participant is free of CVD at the end of the study or confirmed as a non-CVD death (thus the CVD-free time is censored), :1 if the participant had a stroke, :2 if the participant had a CHD, and :3 if the participant had other CVDs.

It is of interest to compare the risk of CVD among the three age groups: 50  59, 60  69, and 70  79. We create two dummy variables: AGEA : 1 if aged 50  69, :0 otherwise; and AGEB : 1 if aged 60  69, and :0 otherwise. Thus for a 70 to 79-year-old, AGEA : 0 and AGEB : 0. We also create a variable to denote the censoring status: CENS : 0 if t is censored, and : 1 if uncensored.

To illustrate the different methods to handle ties, we fit the Cox proportional hazards model with the following six covariates: AGEA, AGEB, SEX, SMOKE, BMI, and LACR. The approximated partial likelihood function defined in (12.1.15) (12.1.17) as well as the exact partial likelihood function (Delong et al., 1994) are applied. As noted in Sections 11.3 and 11.4, the exponential and Weibull regression models are also proportional hazard models. Therefore, for comparisons we also fit an exponential and a Weibull regression model with the same covariates to the data. The estimated regression coefficients obtained from the proportional hazards model with approximated discrete, Breslow, Efron, and exact partial likelihood functions as well as those from the exponential and Weibull regression models are given in Table 12.5. All of the estimates based on the Cox model and an approximated partial likelihood function are very closed to those based on the exact partial likelihood. Those based on Efrons approximation are almost identical to those (different only at the fourth decimal place) based on the exact partial M 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 D NT 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 H .4 .0 .5 GE 7.8 6.9 6.3 2.2 6.0 4.5 0.7 5.2 4.9 0.2 4.4 8.8 4.4 0.8 4 1.6 5.3 5.7 5.4 4.5 2 0.7 2 5.9 3.4 1.0 0.6 7 7 7 7 7 7 7 7 6 6 6 6 6 6 6 6 6 6 6 6 5 5 5 5 5 5 5 ?

A .321 G 4 6 7 1 2 8 0 2 4 1 6 5 3 4 9 5 3 1 2 4 4 1 0 3 1 3 7 T .9 .6 .2 .5 .8 .8 .1 .1 .2 .4 .4 .5 .3 .6 .9 .7 .9 .9 .9 .5 .7 .5 .5 .6 ple L 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4.6 4 4 4 4 4 4.4 4 4.6 4 4 4 4 am Ex .23 .31 .38 .11 .19 .20 .53 .73 .92 .47 .37 .58 .11 .39 .96 .59 .99 .17 .04 .84 .85 .87 .41 .45 .88 .34 .44 in ACR 4 4 4 1 1 1 3 3 2 2 2 3 2 3 1 2 2 2 4 2 1 2 2 1 1 2 1 L y tud P 1 4 1 0 6 2 4 6 7 8 8 7 0 1 0 8 7 6 1 8 0 0 8 0 S B 4 2 1 4 4 4 5 3 2 1 1 2 0 2 98 5 2 1 3 2 95 2 96 3 4 1 1 S 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 sease I Di 78 02 05 92 30 76 01 21 13 68 34 92 68 93 47 65 28 21 82 58 83 61 32 41 98 00 05 BM 31.

25.

26.

26.

34.

31.

25.

28.

28.

25.

34.

28.

24.

21.

29.

28.

32.

29.

28.

30.

27.

26.

30.

30.

29.

26.

29.

sculara iovd OKE 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 M Car S ar X fo E 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 S ta Da BE 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 ed GA lat A imu 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 S GEA thef G o 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 D et SN Subs E 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 A C .4 T .4 .9 .4 .1 .0 .5 .3 .9 .6 2 7 7 6 7 6 6 8 7 7 8.4 7.4 7.7 6.9 7.2 6.3 7.4 4.5 7.0 2.8 7.2 7.4 5.2 7.7 7.8 7.6 7.9 7.3 1 Table 1 2 3 4 5 6 7 8 9 ID 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 310 ) f 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 rleaveo 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 ed ontinu .7 .6 7 8.7 3.6 1.2 5.2 3.7 4.9 0.7 1.3 3.9 7.2 3.5 1.1 8.2 7.3 9.1 1.0 2.5 5.7 1.8 3.1 2.2 6.8 6.7 3.1 9.3 8.9 8 3.5 2.6 ( C 5 5 5 5 5 5 5 5 5 7 7 7 7 6 6 6 6 5 5 5 5 7 7 7 7 6 6 6 6 5 8 5 6 8 8 2 5 9 2 2 6 0 8 2 9 8 0 1 2 0 5 5 0 5 4 6 4 0 9 3 .6 .2 .2 .4 .4 .4 .4 .4 .5 .7 .8 .1 .1 .5 .6 .4 .9 .1 .3 .0 .9 .2 .5 .9 .5 .6 .2 .3 .9 4 4 4 4 4 4 4 4 4 4 4 5 4 4 4 4 4 5 4 4 3 5 4 3 4 4 5 4.4 4 3 0.5 .60 .89 .48 .92 .39 .39 .96 .68 .38 .37 .31 .53 .64 .61 .38 .36 .93 .54 .16 .87 .08 .16 .69 .40 .43 .94 .01 .74 .39 2 4 2 3 2 2 1 2 1 5 3 2 3 2 4 1 4 9 3 4 5 5 5 2 4 5 1 2 0 2 1 1 5 4 2 5 4 0 5 9 0 0 1 4 5 1 4 2 4 4 6 8 6 0 7 8 4 1 8 4 1 5 2 3 1 2 1 8 0 3 1 1 2 3 3 3 3 2 2 2 2 3 2 1 5 97 4 1 13 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 7 4 5 3 2 4 4 9 8 5 0 7 3 9 5 8 8 4 8 3 3 7 9 8 0 3 5 6 2 .2172 36.9 29.4 33.8 32.1 27.5 30.6 29.9 29.8 30.8 25.0 26.8 21.6 36.8 21.4 31.0 26.7 35.7 28.4 24.3 34.1 43.2 38.6 34.4 20.7 28.4 28.7 44.2 32.4 39.7 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 .8 .9 .1 .2 .4 .0 .5 .4 .6 .7 .7 .3 .9 .2 .1 .8 .7 .1 .6 .3 .6 .3 .0 .2 .6 .2 .5 .5 .1 8.

3 6 6 7 8 5 6 6 2 2 2 3 2 0 2 6 5 1 6 1 4 6 2 4 3 3 4 4 6 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 311 t f t a 0 1i : D and rren M 1 1 1 0 1 1 0 1 1 0 1 V : u in D -C A fc m and n u o 1i lb g a H N fn AGE : T 0 0 1 1 0 1 1 0 1 1 1 s; H 0i ary mm : VD OKE rin 90 G C M u .6 S f ) GE 6.0 4.3 9.2 5.4 5.7 1.7 5 8.6 9.4 4.2 9.1 D; o A 5 5 5 7 7 7 6 6 5 5 5 ther e; o o al sored rati the fem pressure G 1 1 3 0 0 3 2 5 2 1 8 en e if if T .6 .7 .4 .9 .4 .6 .6 .8 .1 .9 th do L 5 4 4 3 4 5 4.1 4 4 4 4 nc 3 0 u fo lo if : : b 1 d d n n c : a li rithm o ACR .45 .03 .94 .69 .46 .25 .93 .09 .24 .96 .70 7 7 3 6 2 6 3 3 8 6 4 ),a le L a ast and m loga (di d, f P 7 9 1 9 0 8 6 4 4 5 (CHD 1i P B 1 1 5 2 3 8 96 2 4 3 1 S 1 1 1 1 1 1 1 1 1 1 sore se : LACR, DB cen isea XE if d or I rt g 90 77 03 22 29 03 76 53 63 39 29 0 ssure; : ea ise;S H BM 27.

27.

31.

25.

45.

25.

46.

28.

23.

31.

30.

h S pre m N ry erw d m E a th o on o 140 ise.

);C 0o bl cor : P erw OKE 1 0 1 0 1 0 0 1 0 0 1 lic if d B th M time S e 2 an fS : systo 0o -fre 69 1i : e,  P, X D k 0 B : d E 0 1 1 0 0 1 1 1 0 1 1 6 S na S N (CV stro ; T L f edg dex H B 1i fa g/d E time in 0 0 0 0 0 0 1 1 0 0 0 es; m G :, 1i ss 6 A ent a th : erid 12 ev B m A ea y lyc D d E d se 1 1 1 0 0 0 0 0 1 1 1 G GE D bo trig co A CV V u I, f T, o gl ise;A M G n-C 2 2 2 3 3 3 3 3 3 3 3 B ng D er;b no erw thm ti m r th se; fas nued S u o n 0o gari if nti N dy lo 1 E 1 1 1 1 1 1 1 1 1 1 1 id : therwi , : Co C stu o e 0 pant and M th LTG .4 D T 2 3.0 2.1 1.3 4.9 2.5 3.8 5.0 1.5 4.1 0.5 2.7 tici of 59 e; 1  and n se; par d 50 er en tini erwi e ed ok h Table ID 58 59 60 61 62 63 64 65 66 67 68 ? ID, th ag sm crea ot 312       313 Table 12.5 Results fromFitting a Cox Proportional Hazards Model Based on Different Methods for Ties on the CVD Data Regression Coefficient Variable Breslow Discrete Efron Exact Exponential Weibull AGEA 91.3478 91.3662 91.3558 91.3560 91.2550 91.0436 AGEB 90.7709 90.7828 90.7753 90.7755 90.7107 90.5966 SEX 0.7134 0.7233 0.7187 0.7189 0.6862 0.5659 SMOKE 0.3762 0.3810 0.3776 0.3776 0.3440 0.2855 BMI 0.0253 0.0256 0.0255 0.0255 0.0233 0.0194 LACR 0.1735 0.1759 0.1739 0.1740 0.1658 0.1357 likelihood function. The estimated regression coefficients based on the two parametric models, particularly the exponential regression model, are also close to those based on the Cox hazards model. From the signs of the coefficients, we see that men, current smokers, and persons with high BMI and albumin  creatinine ratios have a higher hazard (risk) of CVD and shorter CVD-free time. The coefficients of the two age variables are both negative, indicating that persons in the younger age groups have a lower hazard (risk) of CVD.

Suppose that C:EX12d2d1.DAT contains eight successive columns, for T, CENS, AGEA, AGEB, SEX, SMOKE, BMI, and LACR, and that the numbers in each row are space-separated. The following code for the SAS PHREG and LIFEREG procedures can be used to obtain the results in Table 12.5.

data w1; infile c:ex12d2d1.dat missover; input t cens agea ageb sex smoke bmi lacr; run; proc phreg; model t*cens(0) : agea ageb sex smoke bmi lacr / ties : breslow; run; proc phreg; model t*cens(0) : agea ageb sex smoke bmi lacr / ties : discrete; run; proc phreg; model t*cens(0) : agea ageb sex smoke bmi lacr / ties : efron; run; proc phreg; model t*cens(0) : agea ageb sex smoke bmi lacr / ties : exact; run; proc lifereg; Model a: model t*cens(0) : agea ageb sex smoke bmi lacr / d : exponential; Model b: model t*cens(0) : agea ageb sex smoke bmi lacr / d : weibull; run; 314         12.2 IDENTIFICATION OF SIGNIFICANT COVARIATES As noted earlier, one principal interest is to identify significant prognostic factors or covariates. This involves hypothesis testing and covariate selection procedures, similar to those discussed in Chapter 11 for parametric methods.

The differences are that the Cox proportional hazard model has a partial likelihood function in which the only parameters are the coefficients associated with the covariates. However, statistical inference based on the partial likelihood function has asymptotic properties similar to those based on the usual likelihood. Therefore, the estimation procedure (discussed in Section 12.1) is similar to those in Section 7.1, and the hypothesis-testing procedures are similar to those in Sections 9.1 and 11.2. For example, the Wald statistic in (9.1.4) can be used to test if any one of the covariates has no effect on the hazard, that is, to test H: bG: 0. By replacing the log-likelihood function with the log partial likelihood function, the log-likelihood ratio statistic, the Wald statistic, and the score statistic in (9.1.10), (9.1.11), and (9.1.12) can be used to test the null hypothesis that all the coefficients are equal to zero, that is, to test H: b :0, b :0, . . . , bN:0 or H:b:0 in (9.1.9). Similarly the forward, backward, and stepwise selection procedures discussed in Section 11.9.1 are applicable to the Cox proportional hazard model.

The following example, using the SAS PHREG procedure, illustrates these procedures.

Example 12.4 We use the entire CVD data set in Example 12.3 to demonstrate how to identify the most important risk factors among all the covariates. Suppose that the effects of age, gender, and current smoking status on CVD risk are of fundamental interest and we wish to include these variables in the model. In epidemiology this is often referred to as adjusting for these variables. Thus, AGEA, AGEB, SEX, and SMOKE are forced into the model and we are to select the most important variables from the remaining covariates (BMI, SBP, LACR, LTG, HTN, and DM), adjusting for age, gender, and current smoking status.

The SAS procedure PHREG is used with Breslows approximation for ties (default procedure) and three variable selection methods (forward, backward, and stepwise). Two covariates, BMI and LACR, are selected at the 0.05 significance level by all three selection methods. The final model, in the form of (12.1.5), including only the four covariates that we purposefully included and the two most significant ones identified by the selection method, is     315 h( t log G) : b h AGEA G ; b AGEB G ; b SEX G ; b SMOKE G ( tG) ; b BMI G; b LACR G : 91.3558AGEA G 907753AGEB G;0.7187SEX G ; 0.3776SMOKE G;0.0255BMI G;0.1739LACR G (12.2.1) The regression coefficients, their standard errors, the Wald test statistics, p values, and relative hazards (relative risks as they are termed by many epidemiologists) are given in Table 12.6. The estimated regression coefficients b G, i :1, 2, . . . , 6, are solutions of (12.1.9) using the Newton  Raphson iterated procedure (Section 7.1). The estimated variances of b G, i :1, 2, . . . , 6, are the respective diagonal elements of the estimated covariance matrix defined in (12.1.13). The square roots of these estimated variances are the standard errors in the table. The Wald statistics are for testing the null hypothesis that the covariate is not related to the risk of CVD or H: bG : 0, i:1, . . . , 6, respectively. For example, the Wald statistic equals 10.7457 for gender with a p value Table 12.6 Asymptotic Partial Likelihood Inference on the CVD Data from the Final Cox Proportional Hazards Model ?

95% Confidence Interval Regression Standard Wald Relative Variable Coefficient Error Statistic p Hazards Lower Upper Final Model for the Cohort CV D Data AGEA 91.3558 0.2712 24.9910 0.0001 0.258 0.151 0.439 AGEB 90.7753 0.2618 8.7709 0.0031 0.461 0.276 0.769 SEX 0.7187 0.2193 10.7457 0.0010 2.052 1.335 3.153 SMOKE 0.3776 0.2208 2.9235 0.0873 1.459 0.946 2.249 BMI 0.0255 0.0124 4.2113 0.0402 1.026 1.001 1.051 LACR 0.1739 0.0446 15.2112 0.0001 1.190 1.090 1.299 b 9 b 90 . 580 4 . 9443 0 . 0262 0 . 560 b; b 1 . 096 11 . 5409 0 . 0007 2 . 993 b 9 b 0 . 341 1 . 3001 0 . 2542 1 . 407 Hypothesis Testing Results ( H:all bG:0) Log-partial-likelihood ratio statistic 42.1130 0.0001 Score statistic 43.1750 0.0001 Wald statistic 41.3830 0.0001 ? The covariates, except AGEA, AGEB, SEX, and SMOKE, in the final model are selected among BMI, SBP, LACR, LTG, HTN, and DM.

316         of 0.0010 and b : 0.7187. It indicates that after adjusting for all the variables in the model (12.2.1), gender is a significant predictor for the development of CVD, with men having a higher risk than women. The relative hazard (or risk) is exp( b), and for the covariate gender, it is exp(0.7187):2.052, which implies that men aged 50  79 years have about twice the risk of developing CVD in 10 years. The 95% confidence interval for the relative risk is (1.335, 3.153), which is calculated according to (7.1.8). For a continuous variable, exp( b G) represents the increase in risk corresponding to a 1-unit increase in the variable. For example, for BMI, exp (0.0255) : 1.026; that is, for every unit increase in BMI, the risk for CVD increases 2.6%.

To compare hazards among different age groups, between genders, or between smokers and nonsmokers, let h%#( t), h%# ( t), h%#!( t), h+*( t), h$#+( t), h 1+( t), and h,1+( t) denote hazard functions for participants that are 50  59, 60  69, 70  79 years old, male, female, current smoker, and not current smoker, respectively. The log hazard ratio of a person in the 50 to 59-year age group to a person in the 70 to 79-year group assuming the two people are of same gender and the same current smoking status, BMI and LACR, is log[ h%#( t) /h%#!( t)] : b; similarly, log[ h%# ( t) /h%#!( t)] : b and log[ h%#( t) /h%# ( t)] : b 9 b. Assuming that the two people are in the same age groupand have the same BMI and LACR, the log hazard ratio of male to females is h log +*( t) : b h $#+( t) Similarly, assuming that the two people are in the same age group, of the same gender, and have the same BMI and LACR, the hazard ratio of a smoker to a nonsmoker is h log 1+( t) : b h ,1+( t) Thus, testing whether risk of CVD are the same among different age groups is equivalent to testing H: b:0, H: b:0, and H: b 9 b :0. Similarly, to test if the risk of CVD is the same between males and females or between smokers and nonsmokers is equivalent to tasting the null hypothesis H: b: 0 or H: b: 0, respectively.

To consider more than one covariate, we also can formulate the null hypothesis by using (12.2.1). For example, if we wish to compare male nonsmokers to female smokers, from (12.2.1), h log +*\,1+ : b h 9 b $#+\1+     317 assuming that they are in the same age groupand have the same BMI and LACR. Thus to test if these two groups of people have the same risk of CVD, we test the null hypothesis H: b 9 b:0. Similarly, to compare male smokers to female nonsmokers, we can test the null hypothesis H: b; b :0.

These null hypotheses are in the form of linear combinations of the coefficients.

Using the notations in Section 11.2, the hypotheses H: b 9 b:0 and H: b; b: 0 are the hypotheses in (11.2.13) with c:0, L :(1 91 0 0 0 0), and L : (0 0 1 1 0 0), respectively. The Wald statistics in Table 12.6 are calculated according to (11.2.14). By assuming that the patients have the same BMI and LACR, we can construct hypotheses to compare subgroups defined by age groups, gender, and current smoking status.

The last part of Table 12.6 shows the results of testing the null hypothesis that none of these covariates have any effect on the development of CVD. The log partial likelihood ratio, Wald, and score statistics, X*, X5, and X1 are calculated according to (9.1.10), (9.1.11), and (9.1.12), respectively. Table 12.6 indicates that the hypotheses, H: b:0, H: b:0, H: b 9 b :0, H: b:0, H: b: 0, H: b: 0, and H: b; b:0 are rejected at a significance level of p : 0.05.

However, the hypotheses H: b:0 and H: b 9 b: 0 are not rejected at a 0.05 level. The null hypothesis H: all bG :0, i:1, . . . , 6, is rejected with p :0.0001 by using any of these tests.

Assuming that the other covariates are the same, based on the relative hazards shown in the table, we conclude that (1) participants aged 50  59 and 60  69 have, respectively, about 25% and 50% lower CVD risk than those aged 70  79 ( H: b :0 and H: b:0 are rejected); (2) participants aged 50  59 have 50% lower CVD risk than those aged 60  69 ( H: b 9 b: 0 is rejected); (3) mens CVD risk is twice as high as that of women ( H: b: 0 is rejected); (4) BMI and LACR have a significant effect on CVD risk ( H: b: 0 and H: b :0 are rejected) and the risk increases about 3% and 19%, respectively, for every 1-unit increase in BMI and LACR, respectively; (5) male smokers have a CVD risk three times higher than that of female nonsmokers ( H: b; b:0 is rejected); (6) male nonsmokers have CVD risk similar to that of female smokers ( H: b 9 b: 0 is not rejected); (7) considering current smoking status alone, smokers had similar CVD risk as non- smokers ( H: b:0 is not rejected). This example is solely for the purpose of illustrating the use of the proportional hazards model and the interpretation of its results. Other hypotheses of interest can be constructed in a similar manner. The construction of null hypotheses for comparisons among subgroups defined by AGEGROUP*SEX*SMOKE are left to the reader as exercises.

Suppose that C:EX12d4d1.DAT is a text data file that contains 12 successive columns for T, CENS, AGEA, AGEB, SEX, SMOKE, BMI, LACR, SBP, LTG, HTN, and DM. The following SAS code is used to obtained the results in Table 12.6.

318         data w1; infile c:ex12d4d1.dat missover; input t cens agea ageb sex smoke bmi lacr sbp ltg htn dm; run; proc phreg data : w1; model t*cens(0) : agea ageb sex smoke bmi lacr sbpltg htn dm / include : 4 selection : f ; run; proc phreg data : w1; model t*cens(0) : agea ageb sex smoke bmi lacr sbpltg htn dm / include : 4 selection : b; run; proc phreg data : w1 outest : wcov covout; model t*cens(0) : agea ageb sex smoke bmi lacr sbpltg htn dm / include : 4 selection : s; run; proc phreg data : w1; model t*cens(0) : agea ageb sex smoke bmi lacr sbpltg htn dm / include : 4 selection : score best : 3; run; data wcov; set wcov; if -type- : cov; keepagea ageb sex smoke bmi lacr sbpltg htn dm; run; title The estimated covariance of the estimated coefficients; proc print data : wcov; run; The following SPSS code can be used to select an optimal subset of covariates among all covariates by the forward and backward selection methods defined in Section 11.9.1 and to obtain the estimated coefficients and the other results in Table 12.6.

data list file : c:ex12d4d1.dat free / t cens agea ageb sex smoke bmi lacr sbpltg htn dm.

coxreg t with agea ageb sex smoke bmi lacr sbpltg htn dm /status : cens event (1) /method : fstepbmi lacr sbpltg htn dm /criteria pin (0.05) pout (0.05) /print : all.

coxreg t with agea ageb sex smoke bmi lacr sbpltg htn dm /status : cens event (1) /method : bstepbmi lacr sbpltg htn dm /criteria pin (0.05) pout (0.05) /print : all.

319 If BMDP 2L is used, the following code is applicable when selecting an optimal subset of covariates among all covariates by the stepwise selection method defined in Section 11.9.1 and to obtain the results in Table 12.6.

/input file : c:ex12d4d1.dat .

variables : 12.

format : free.

/print cova.

/variable names : t,cens, agea, ageb, sex, smoke, bmi, lacr, sbp, ltg, htn, dm.

/form time : t.

status : cens.

response : 1.

/regress covariates : agea, ageb, sex, smoke, bmi, lacr, sbp, ltg, htn, dm.

Step : phh.

Example 12.5 If we do not force age, gender, and current smoking status on the model and are not interested in the three age groups, we can fit the proportional hazard model with age as a continuous variable and the other covariates: SEX, SMOKE, BMI, SBP, LACR, LTG, HTN, and DM. Using Breslows method for ties, the stepwise selection method, and the SAS procedure PHREG, the final model with significant ( p 0.05) covariates is h( t) log : 0 . 697AGE ; 0.7528SEX ; 0.1111LACR ; 0.3987LTG h( t) (12.2.2) The details are given in Table 12.7; all four covariates in the model have positive coefficients, indicating that the risk of developing CVD increases with age, gender, albumin/creatinine ratio, and triglyceride values. The relative hazards represent the increase in risk of CVD per unit increase in the covariates. For example, for every 1-unit increase in log(albumin/creatinine), the risk of developing CVD increases 12% after adjusting for age, gender, and log triglyceride. Men have more than twice the risk of CVD as women. The global null hypothesis that all four coefficients equal zero ( H:all bG :0) is rejected by all three tests, as given in the lower part of Table 12.7.

12.3 ESTIMATION OF THE SURVIVORSHIP FUNCTION WITH COVARIATES When parametric regression models (Chapter 11) are used, we can estimate the survivorship function simply by replacing the parameters and coefficients in the survival function with their estimates. This is not the case when the Cox 320         Table 12.7 Asymptotic Partial Likelihood Inference on the CVD Data from the Final Cox Proportional Hazards Model Selected by the Stepwise Model Selection Method ?

95% Confidence Interval for Relative Hazards Regression Standard Chi-Square Relative Variable Coefficient Error Statistic p Hazards Lower Upper AGE 0.0697 0.0136 26.1393 0.0001 1.07 1.04 1.10 SEX 0.7528 0.2192 11.7893 0.0006 2.12 1.38 3.26 LACR 0.1111 0.0459 5.8602 0.0155 1.12 1.02 1.22 LTG 0.3987 0.1976 4.0722 0.0436 1.49 1.01 2.20 H: All coefficients equal zero Log-partial-likelihood ratio statistic 44.002 0.0001 Score statistic 44.278 0.0001 Wald statistic 42.527 0.0001 ? The covariates in the final model are selected among AGE, SEX, SMOKE, BMI, LACR, LTG, HTN, and DM using the stepwise selection method.

proportional hazards model is used since we do not know the exact form of the baseline hazard function or the survival function. In this section we introduce briefly two estimators of the survival function, one proposed by Breslow (1974) and the other by Kalbfleisch and Prentice (1980). These estimates are available in commercial software packages. Readers interested in details are referred to the corresponding publications.

As indicated earlier, under the Cox model, the survivorshipfunction with covariates xHs is S( t, x) : [ S(t)]exp( NH bHxH) (12 . 3 . 1) Once the regression coefficients, the bHs, are estimated, we need only estimate the underlying survivorshipfunction, S( t). From the estimated survivorship function, we can easily estimate the probability of surviving longer than a given time for a patient with a given set of covariates x, . . . , xN.

By assuming that the baseline hazard function is constant between each pair of successive observed failure times, Breslow has proposed the following estimator of the baseline cumulative hazard function: m H G ( t) : ( 12.3.2) exp(x t G t l + R( t G) J b)        321 Following (2.15), the baseline survival function can be estimated as S( t) :exp[9 H( t)] : exp m G (12.3.3) exp(x t G t l + R( t G) J b) and the survivorshipfunction for a p erson with a set of covariates x : ( x, . . . , xN) is S( t, x) : [ S( t)]exp( NH b HxH): [ S( t)]exp(bx) (12.3.4) Under mild assumptions, S( t, x) has an asymptotic normal distribution with mean S( t, x). Since S( t, x) : exp[9 H( t, x)], the variance estimator Var ( S( t, x)) of S( t, x) is Var ( S( t, x)) < [ S( t, x)] Var ( H( t, x)) We will not give H( t, x) here because of its complexity. The asymptotic confidence bands for the survivorshipfunction is S( t, x) 9 Z?(Var( S( t, x)), S( t, x) ; Z?(Var( S( t, x)) (12.3.5) where Z? is the upper 100(19 /2) percentile point of the standard normal distribution.

An alternative estimator has been suggested by Kalbfleisch and Prentice in which the baseline survivorshipfunction S( t) is estimated to be a stepfunction and G\ S( t) : H t G\ t t G, i:1, . . . , k ;1 (12.3.6) H where Y 1 and , , . . . , I are the solution of the following k simultaneous equations: exp(x H b) : exp(x 1 9 exp(x H b) J b) i : 1, . . . , k (12 . 3 . 7) j + u * G G l + R( t G) When there are no ties, G:19 exp(x G b) exp(9x G b) i:1,..., k (12 . 3 . 8) exp(x l + R( t G) J b) and G\ S( t) : 19 exp(x H b) exp(9x H b) t G\ t t G i:1, ... , k;1 H exp(x l + R( t H) J b) 322         Thus, S( t, x) : [ S( t)]exp(bx) (12.3.9) Under mild assumptions, the Kalbfleisch and Prentice estimator in (12.3.9) also follows an asymptotic normal distribution with mean S( t, x) and a variance that can be estimated. Thus confidence bands for the survivorshipfunction can also be constructed.

Using (12.3.4) with S( t) in (12.3.3) or (12.3.6), the survivorshipfunction can be estimated with any given values of x, . . . , xN. If the observed average of every covariate, x, . . . , xN is used, the estimated survivorshipfunction can be interpreted as the survivorship function of an average person.

Both the Breslow and Kalbfleisch  Prentice estimators are available in the SAS procedure PHREG. The Breslow estimator is also available in BMDP (program 2L) and SPSS (program COXREG). The following example illus- trates the procedures.

Example 12.6 Again, we use the CVD data in the Example 12.3, the data set C:EX12d2d1.DAT, and the SAS procedure PHREG. We use the average of each of the covariates in (12.2.1), and therefore the estimated survivorship function is for an average person. The Kalbfleisch  Prentice and Breslow estimates of the survival function, defined in (12.3.9) and (12.3.4) (Efron adjustment for ties is used), and the lower and upper 95% confidence bands, calculated based on (12.3.5), are shown in Figures 12.1 and 12.2. These estimated survival functions, using all the covariates in the model with average values, are often referred to as the global covariate  adjusted survivorship functions. The two figures are almost identical, which indicates that the two methods produce very similar results for this set of data. From Figure 12.1 it appears that the global covariates  adjusted survivorshipfunction decreases somewhat more rapidly after 3.5 years. This means that the process to develop CVD accelerates after 3.5 years.

Using the data set C:EX12d2d1.DAT defined in Example 12.3, the SAS code used for this example is the following.

data w1; infile c:ex12d2d1.dat missover; input t cens agea ageb sex smoke bmi lacr; run; proc phreg data : w1 noprint; model t*cens(0) : agea ageb sex smoke bmi lacr / ties : efron; baseline out : base1 survival : survival l: lowb u : uppb / method : pl; run; title K-P estimate of the survival function and its lower and upper bands; proc print data : base1; var t survival lowb uppb; run;        323 Figure 12.1 Kalbfleisch  Prentice estimate of survivorshipfunction and its 95% confidence bands at the averages of the covariates from the fitted Cox proportional hazards model on the CVD data.

proc phreg data : w1 noprint; model t*cens(0) : agea ageb sex smoke bmi lacr / ties : efron; baseline out : base1 survival : survival l : lowb u : uppb / method : ch; run; title Breslow estimate of the survival function and its lower and upper bands; proc print data : base1; var t survival lowb uppb; run; The following SPSS code can be used to obtain the Breslow estimate of the survival function and its standard error at each uncensored observation. The confidence bands can then be calculated according to (12.3.5).

data list file : c:ex12d2d1.dat free / t cens agea ageb sex smoke bmi lacr.

coxreg t with agea ageb sex smoke bmi lacr /status : cens event (1) /print : all.

324         Figure 12.2 Breslow estimate of the survivorshipfunction and its 95% confidence bands at the averages of the covariates from the fitted Cox proportional hazards model on the CVD data.

The corresponding BMDP 2L code is /input file : c:ex12d2d1.dat .

variables : 8.

format : free.

/print cova.

Survival.

/variable names : t,cens, agea, ageb, sex, smoke, bmi, lacr.

/form time : t.

status : cens.

response : 1.

/regress covariates : agea, ageb, sex, smoke, bmi, lacr.

In addition to the global covariates  adjusted survivorshipfunction defined as S( t, x), where x : ( x, x, . . . , x N), the survivorshipfunction can be estimated with any specific values of one or more of the covariates and interactions. We can also estimate the probability of surviving longer than a given time for individuals with a given set of values for covariates. The following is an example.

325 Figure 12.3 Breslow estimate of survivorshipfunctions at the averages of BMI and LACR from SEX*SMOKER subgroups in aged 70  79 participants from the fitted Cox proportional hazards model on the CVD data.

Example 12.7 For the same model as in Example 12.6, we can estimate the covariate-specific survivorship function for female nonsmokers, female smokers, male smokers, and male nonsmokers. Let us use the 70  79 age group and assume that BMI and LACR are at the average of the respective SEX  SMOKE subgroup. Thus, the specific covariate vector (AGEA, AGEB, SEX, SMOKE, BMI, LACR) for female nonsmokers is (0, 0, 0, 0, 30.69, 4.62), where 30.69 and 4.62 are the average values of BMI and LACR for female nonsmokers. Similarly, the specific covariate vectors for female smokers, male nonsmokers, and male smokers are, respectively, (0, 0, 0, 1, 31.19, 2.67), (0, 0, 1, 0, 28.19, 3.43), and (0, 0, 1, 1, 25.76, 3.47). The estimated survival curves are shown in Figure 12.3. Similarly, Figures 12.4 and 12.5 give the estimated survival curves of the four groups in persons aged 60  69 years and 50  59 years, respectively. The groups show that in all these age groups, females have a lower risk of developing CVD (longer CVD-free time) than males. Female nonsmokers have a slightly lower risk than female smokers and the differences increase as age decreases. However, among males, the differences in the risk of CVD between smokers and nonsmokers are almost negligible in the youngest groupand much larger in the two older groups. Male smokers have the highest risk of developing CVD (shortest CVD-free time) among the four groups.

326         Figure 12.4 Breslow estimate of survivorshipfunctions at the averages of BMI and LACR from SEX*SMOKER subgroups in aged 60  69 participants from the fitted Cox proportional hazards model on the CVD data.

12.4 ADEQUACY ASSESSMENT OF THE PROPORTIONAL HAZARDS MODEL The validity of statistical inferences that leads to the identification of important risk or prognostic factors depends largely on the adequacy of the model selected. The proportional hazards model is used widely in medical and epidemiological studies. The adequacy of this model, including the assumption of proportional hazards and the goodness of fit, needs to be assessed. In this section we introduce several methods for this purpose. A major reason for selecting these methods to present here is the availability of computer software that can perform the calculations.

12.4.1 Checking the Proportional Hazards Assumption The proportional hazards models defined in (12.1.1) and (12.1.3) assume that the hazard ratio of two people is independent of time. This requires that covariates not be time-dependent. If any of the covariates varies with time, the proportional hazards assumption is violated. This fact can be used to test the assumption by including a time  covariate interaction term in the model and        327 Figure 12.5 Breslow estimate of survivorshipfunctions at the averages of BMI and LACR from SEX*SMOKER subgroups in aged 50  59 participants from the fitted Cox proportional hazards model on the CVD data.

testing if the coefficient for interaction is significantly different from zero. For example, we can add an interaction term xGt or xG log t in the model, that is, h( t) log : b h x ; % ; bGxG ; bG xGt ; bG> xG> ; % ; bNxN ( t) or h( t) log : b h x ; % ; bGxG ; bG xG log t ; bG> xG> ; % ; bNxN ( t) With the added interaction term, the partial likelihood function becomes more complicated. Fortunately, computer software is available to carry out the calculations. Testing procedures similar to those discussed earlier (e.g., the Wald test), can be used to test the null hypothesis H: bG:0. If H is rejected, we conclude that Coxs proportional hazard model is not appropriate for the data. The interaction term with log t can be included in the model for each of the covariates separately. If none of the corresponding p null hypotheses H: bG:0 is rejected, we may conclude that the proportional hazards assumption is appropriate.

328         Example 12.8 Consider the fitted proportional hazards model in (12.2.2) for the CVD data. To check the proportional hazards assumption, we add a term L T G;log( t ; 1) to the model. We use t ; 1 instead of t to avoid negative values. Table 12.8( a) gives the results. The p value for the interaction term is 0.1910. Similarly, the results in Table 12.9( b) and ( c) suggest that LACR;log( t ; 1) and AGE;log( t ; 1) are not significant either. Since gender is time-independent, we may conclude that the data satisfy the proportional hazards assumption since every covariate in the model is time-independent.

Another method to check the proportional hazards assumption is to stratify the data based on some values of a covariate, fit a stratified Cox proportional hazards model (this is discussed in Chapter 13), and then construct the survivorship function separately for the each stratum and plot log(9log( S H( t; x H))) j : 1, 2, . . . , m Table 12.8 Asymptotic Partial Likelihood Inference on the CVD Data from the Cox Proportional Hazards Model with Time-Dependent Covariate 95% Confidence Interval for Relative Hazards Regressor Regressor Standard Wald Relative Variable Coefficient Error Statistic p Hazards Lower Upper (a) AGE 0.068 0.014 25.249 0.0001 1.07 1.04 1.1 SEX 0.759 0.218 12.056 0.0005 2.14 1.39 3.28 LACR 0.111 0.046 5.781 0.0162 1.12 1.02 1.22 LTG 0.915 0.435 4.420 0.0355 2.50 1.06 5.86 LTG* 90.390 0.298 1.710 0.1910 0.68 0.38 1.22 log( t;1) (b) AGE 0.071 0.014 26.635 0.0001 1.07 1.05 1.1 SEX 0.741 0.220 11.327 0.0008 2.10 1.36 3.23 LACR 90.087 0.120 0.519 0.4714 0.92 0.72 1.16 LTG 0.395 0.199 3.917 0.0478 1.48 1 2.19 LACR* 0.143 0.079 3.269 0.0706 1.15 0.99 1.35 log( t;1) (c) AGE 0.038 0.033 1.330 0.2488 1.04 0.97 1.11 SEX 0.764 0.220 12.020 0.0005 2.15 1.39 3.31 LACR 0.111 0.046 5.888 0.0152 1.12 1.02 1.22 LTG 0.417 0.197 4.469 0.0345 1.52 1.03 2.24 AGE*log( t ;1) 0.023 0.023 1.046 0.3064 1.02 0.98 1.07        329 against time t, where m is the number of strata defined by the covariate, x H is the vector of the average values of the other covariates for the j th stratum, and S H( t;x H) is the estimated survivorshipfunction of the j th stratum evaluated at t and x H. If the hazards are proportional, the m curves should be parallel. Nonparallel curves indicate departure from the proportional hazards assumption. This is because if hazard functions from any two people are proportional, it can be shown from (12.1.1) that, for any j " k and 1 j, k m, there exists a constant dHI such that S H( t; x H) : ( S I( t; x I)) BHI (12.4.1) Taking the logarithm twice, we have log[9log( S H( t; x H))]: log dHI ;log[9log( S I( t; x I))] (12.4.2) Thus the curves of log[9log( S H( t; x H))] and log[9log( S I( t; x I))] versus t should be parallel.

Example 12.9 Consider again the fitted model in (12.2.2); using the stratified analysis (more details are given in Chapter 13), we plot log[9log S H( t; x H)] against t for two age strata (50  64 and 65  79 years) and two gender strata separately, where x H denotes the average values of the other covariates for the j th stratum. These graphs are given in Figures 12.6 and 12.7, Figure 12.6 Log[9log( S( t))] plots for the age-stratified Cox proportional hazards model on the CVD data.

330         Figure 12.7 Log[9log( S( t))] plots for gender-stratified Cox proportional hazards model on the CVD data.

respectively. The two curves in Figure 12.6 are roughly parallel. The two curves in Figure 12.7 are also parallel over time. The results suggest that the proportional hazards assumption holds.

In Chapter 11 we discussed several parametric models. Among these models, the exponential and the Weibull are proportional hazards models, but the others are not. Thus, if one of the other models provides a good fit to data, we would know that the data do not meet the proportional hazards assumption.

This procedure can also be served as an alternative for checking the proportional hazards assumption.

12.4.2 Assessing Goodness of Fit by Residuals There are several other graphical methods available for assessing the goodness of fit of a proportional hazards model. These graphical methods are based on residuals and are often used as diagnostic tools. In multiple regression methods, residuals are referred to as the difference between the observed and the predicted values (based on the regression model) of the dependent variable.

However, when censored observations are present and only a partial likelihood function is used in the proportional hazards model, the usual concept of residuals is not applicable. In the following we introduce three different types        331 of residuals: the extended Cox  Snell, deviance, and Schoenfeld residuals. These can be plotted versus the survival time or a covariate. The pattern of the graph provides some information about the appropriateness of the proportional hazards model. It also provides information about outliers and other patterns.

Similar to other graphical methods, interpretation of the residual plots may be subjective.

The Cox  Snell method discussed in Section 8.4 can easily be extended to the proportional hazards model. The extended Cox  Snell residual, RG, for the i th individual with observed survival time t and covariates at values x G is defined as RG: 9log S( tG;x G), which is the estimated accumulated hazard based on the proportional hazards model. If the tG observed is censored, the corresponding RG is also censored. If the proportional hazards model is appropriate, the plot of RG and its Kaplan  Meier estimate of survival function ( S( R)) would appear as a 45 straight line. The Cox  Snell residual method is useful in assessing the goodness of fit of a parametric model (Section 11.9.4).

However, it is not so desirable for a proportional hazards model where a partial likelihood function is used and the survivorship function is estimated by nonparametric methods.

The deviance residuals (Therneau et al., 1990) are defined as R"G:sign( R+G)(2[9 R+G 9 G log( G 9 R+G)] i : 1, 2, . . . , n (12 . 4 . 3) where sign (  ) is the sign function, which takes value 1 if its argument is positive, 0 if zero, and 91 if negative, R+G is the martingale residual (Fleming and Harrington, 1991) for the i th individual, R+G : G 9 RG i : 1, . . . , n and G: 1 if the observed survival time tG is uncensored and 0 otherwise.

The martingale residuals have a skewed distribution with mean zero (Anderson and Gill, 1982). The deviance residuals also have a mean of zero but are symmetrically distributed about zero when the fitted model is adequate.

Deviance residuals are positive for persons who survive for a shorter time than expected and negative for those who survive longer. The deviance residuals are often used in assessing the goodness of fit of a proportional hazards model.

Another residual method was proposed by Schoenfeld (1982) and modified by Grambsch and Therneau (1994). The original Schoenfeld residuals are defined for each person and each covariate and are based on the first derivative of the log-likelihood function in (12.1.9). A Schoenfeld residual for the j th covariate of the i th person with the observed survival time tG is x R l + R( t HJ exp(bx J) HG : G xHG 9 G) j:1,2, ... , p; i:1,2, ... , n exp(bx l + R( t G) J) (12 . 4 . 4) 332         where b is the maximum partial likelihood estimator of b. The Schoenfeld residuals are defined only at uncensored survival times; for censored observations they are set as missing. Since b is the solution of (12.1.9), the sum of the Schoenfeld residuals for a covariate is zero. Thus asymptotically, the Schoenfeld residuals have a mean of zero. It can also be shown that these residuals are not correlated with one another.

Grambsch and Therneau (1994) suggested that the Schoenfeld residuals be weighted by the inverse of the estimated covariance matrix of R G : ( R G, . . . , RNG) denoted by V (R G), that is, R * G : [ V (R G)]\R G (12.4.5) The weighted Schoenfeld residuals have better diagnostic power and are used more often than the unweighted residuals in assessing the proportional hazards assumption. To simplify the computations, Grambsch and Therneau (1994) suggested an approximation of [ V (R G)]\ in (12.4.5): [ V (R G)]\< rV (b) where r is the number of events or the number of observed uncensored survival times and V (b) is the estimated covariance matrix of b in (12.1.13). With this approximation, the weighted Schoenfeld residuals in (12.4.5) can be approximated by R * G : rV (b)R G (12.4.6) The graphs of deviance and Schoenfeld residuals against survival time or a covariate can be used to check the adequacy of the proportional hazards model.

The presence of certain patterns in these graphs may indicate departures from the proportional hazards assumption, while extreme departures from the main cluster indicate possible outliers or potential stability problems of the model.

Example 12.10 Consider the proportional hazards model (12.2.2) for the CVD data. Using the estimated survivorshipfunction with covariates, we obtain the extended Cox  Snell residual RG values and plot the Kaplan  Meier estimate of the survivorshipfunction of the RGs. Figure 12.8 gives the extended Cox  Snell residual plot. The configuration is very close to a 45 line, indicating that the proportional hazards model (12.2.2) provides a reasonable fit to the data.

Figure 12.9 plots the deviance residuals against t. Roughly speaking, the residuals are distributed symmetrically around zero between 93 and 3 with no peculiar patterns. Larger positive (negative) residuals are associated with smaller (larger) t values. The deviance residuals suggest that the proportional hazards model provides a reasonable fit to the data.

333 Figure 12.8 Cox  Snell residuals plot from the fitted Cox proportional hazards model on the CVD data.

The weighted Schoenfeld residuals versus AGE, LACR, and LTG are given in Figures 12.10 to 12.12. In all these graphs, the residuals are distributed symmetrically around zero except that in Figure 12.12, there are two outliers in the upper right corner. These extremely large residuals are from people with exceptionally high values of triglyceride. A large number of the residuals equal zero or are very close to zero, particularly those for AGE and LACR, suggesting that the model is accurate in predicting the risk of developing CVD for these people.

We also fit several parametric models to the data. Table 12.9 gives the goodness of fit assessments for five parametric models. The likelihood ratio test results suggest that the Weilbull regression model provides an adequate fit ( p : 0.2534). The Weilbull fit also gives the largest BIC and AIC values, suggesting that the Weilbull fit is best among these five models. As mentioned earlier, the Weilbull model is a proportional hazards model. Thus, the parametric model fitting provides additional evidence that the proportional hazards model is adequate.

Using the data set C:EX12d4d1.DAT in Example 12.4, the following SAS code is used to obtain the Cox  Snell, deviance, and weighted Schoenfeld residuals for AGE, LTG, and LACR in Example 12.10.

334         Figure 12.9 Deviance residuals from the fitted Cox proportional hazards model on the CVD data.

data w1; infile c:ex12d4d1.dat missover; input t cens agea ageb sex smoke bmi lacr sbp ltg age htn dm; run; proc phreg data : w1 noprint; model t*cens(0) : age sex lacr ltg / ties : efron; output out : out1 logsurv : ls resdev : rdev wtressch : rage r2 rlacr rltg; run; data out1; set out1; rcs : -ls; run; proc lifetest data : out1 notable outs : ws noprint; time rcs*cens(0); run; data ws; set ws; mls : -log(survival); run; title Cox-Snell Residuals (rcs) and -log(estimated survival function of rcs) (mls); proc print data : ws; var rcs mls;        335 Figure 12.10 Weighted Schoenfeld residuals from the fitted Cox proportional hazards model on the CVD data.

Figure 12.11 Weighted Schoenfeld residuals from the fitted Cox proportional hazards model on the CVD data.

336         Figure 12.12 Weighted Schoenfeld residuals from the fitted Cox proportional hazards model on the CVD data.

run; title Deviance residuals (rdev) and weighted Schoenfeld residuals for AGE, LACR and LTG; proc print data : out1; var t age lacr ltg rage rlacr rltg rdev; run; The following SPSS code can be used to obtain Cox  Snell and Schoenfeld residuals for AGE, and LACR and LTG.

data list file : c:ex12d4d1.dat free / t cens agea ageb sex smoke bmi lacr sbpltg age htn dm coxreg t with age sex lacr ltg /status : cens event (1) /print : all /save : hazard resid presid.

Bibliographical Remarks An excellent expository paper on statistical methods for the identification and  337 Table 12.9 Goodness-of-Fit Tests Based on Asymptotic Likelihood Inference in Fitting the CVD Data ?

Model LL LLR p BIC AIC Generalized gamma 9198.842   9217.113 9212.842 Log-logistic 9203.322   9218.983 9215.322 Lognormal 9206.017 14.3505 0.0002 9221.678 9218.017 Weibull 9199.494 1.3046 0.2534 9215.155 9211.494 Exponential 9203.061 8.4385 @ 0.0147 9216.112 9213.061 Exponential 9203.061 7.1339 A 0.0076 9216.112 9213.061 ? LL, log likelihood; LLR, log-likelihood ratio statistic; p, probability that the respective chi-square random variable LLR.

@ Compared to the generalized gamma fit.

A Compared to the Weibull fit.

use of prognostic factors is that of Armitage and Gehan (1974). Many studies of prognostic factors have been published. A few recent ones are cited here: Well et al. (1998), Shipley et al. (1999), Marrison and Siu (2000), Seaman and Bird (2001), Bolard et al. (2001), Vasan et al. (2001), Young et al. (2001), Meisinger et al. (2002), Feskanich et al. (2002), Williams et al. (2002), and Bliwise et al. (2002).

Coxs regression model has stimulated the interest of many statisticians. A large number of papers on this model and related areas have been published since 1972. In addition to the articles cited earlier, the following are a few examples: Sasieni (1996), Alioum and Commenges (1996), Farrington (2000), Vaida and Xu (2000), and Zhang and Klein (2001). Survival data analysis methods are closely related to counting processes, particularly the proportional hazards model and residual analysis. The counting process approach requires a strong background in probability theory and stochastic processes and is beyond the scope of this book. Interested readers are referred to Fleming and Harrington (1991) and Andersen et al. (1993).

EXERCISES 12.1 (a) Consider the data in Exercise Table 3.1. In addition to the five skin tests, age and gender may also have prognostic values. Examine the relationship between survival and each of seven possible prognostic variables, as in Table 3.8. For each variable, groupthe p atients according to different cutoff points. Estimate and draw the survival function for each subgroupusing the product-limit method and then use the methods discussed in Chapter 5 to compare the survival 338         distribution of the subgroups. Prepare a table similar to Table 3.8.

Interpret your results. Is there a subgroup of any variable that shows significantly longer survival times? (For the skin test results, use the larger diameter of the two.) (b) Consider the seven variables in part (a). Use Coxs model to identify the most significant variables. Compare your results with those obtained in part (a).

12.2 (a) Consider the data given in Exercise Table 3.3. Examine the relation- shipbetween remission duration and survival time for each of the nine possible prognostic variables: age, gender, family history of melanoma, and the six skin tests. Groupthe patients according to different cutoff points. Estimate and draw remission and survival curves for each subgroup. Compare remission and survival distribu- tion of subgroups using the methods discussed in Chapter 5. Prepare tables similar to Table 3.8.

(b) Use Coxs regression model to identify the significant variables in part (a) for their relative importance to remission duration and survival time. Check the appropriateness of the proportional hazards model using the significant variables identified and the stratified analysis and weighted Shoenfeld residuals. Interpret the results.

12.3 Use the proportional hazards model to identify the most important factors related to survival time in the 157 diabetic patients in Exercise Table 3.4. Check the appropriateness of the model using all the methods discussed in Section 12.4 and interpret the results.

12.4 (a) Construct a table similar to Table 3.8 using the data given in Table 3.6.

(b) Use the proportional hazards model to identify the most important factors related to survival time.

(c) Is the proportional hazards model appropriate for this data set?

12.5 Using the data given in Table 12.4, perform similar analyses as in Examples 12.3 to 12.10 and discuss the results obtained.

C H A P T E R 13 Identification of Prognostic Factors Related to Survival Time: Nonproportional Hazards Models In Chapter 12 we discussed the proportional hazards model for the identification of important prognostic factors, in which the covariates are assumed to be independent of time. We also assume that there is only one cause of failure; that is, the event or failure is allowed to occur only once for each person, and there is no correlation among failure times of different persons. However, in practice, the covariates may be observed more than once during the study, and their values change with time, failure may be due to more than one event or cause, the same event or failure may recur during a follow-upstudy, and the event or failure time observed may be from related persons in a family or from the same person at different times. In this chapter we discuss several models for these situations. The first two models are extensions of the proportional hazards model to handle time-dependent covariates and to perform stratified analysis. Other models introduced in this chapter are for multiple causes of failure, recurrent events, and related observations.

13.1 MODELS WITH TIME-DEPENDENT COVARIATES In the Cox proportional hazards model, the ratio of hazard functions for any two persons is assumed to be independent of time t, or the covariates are not time-dependent. However, it is common in practice that a study include both time-dependent and time-independent covariates. For example, in a longitudi-nal study of heart disease, certain demographic variables, such as gender and race, do not change with time and are usually collected only once at the baseline examination. Other variables, such as lipids, may vary with time and are often collected in subsequent examinations. The partial likelihood function allowing time-dependent covariates has the same form as that in (12.1.7) except 339 340         that the covariates are now a function of time. That is, the partial likelihood function with time-dependent covariates is I exp[ N I exp[bx L (b) : H bHxH G( t G)] G( t G)] (13.1.1) G exp[ N exp[bx l + R( t G) H bHxHJ( t G)] : G l+ R( t G) J( t G)] where k is the number of distinct failure times, R( t G) is the risk set that contains all persons at risk at time t G, x J( t G) :( x J( t G), x J( t G), . . . , xNJ( t G)) denotes the covariates observed from person l at the ordered uncensored event time t G, and b : ( b, b, . . . , bN) denotes the unknown coefficients. For covariates that are not time varying, their values are constant over time. For example, let x I denote gender of person k, then x I( t) : x I(0) : x I for all t. Thus, in practice, we usually have a mixture of non-time-dependent and time-dependent covariates in the likelihood function. The estimation procedure for the coefficients, bH, is similar to that discussed in Chapter 12. We can also apply the model selection methods mentioned in Chapter 11 to select the optimal subset of covariates as the most important prognostic or risk factors.

There are two kinds of time-dependent covariates: (1) covariates that are observed repeatedly at different follow-up time points prior to the occurrence of the event or the end of a study or the censored time; and (2) covariates that change with time according to a known mathematical function and covariates that have different values due to therapy, age, or the changes in medical conditions.

The following example illustrates how the Cox proportional hazards model is extended to fit observed survival or event time data with the first kind of time-dependent covariates, that is, covariates observed several times before the event.

Example 13.1 A study was conducted to examine whether biomarker profiles could be used for risk assessment and bladder cancer detection in a cohort of workers occupationally exposed to benzidine and at risk of bladder cancer (Hemstreet et al., 2001). These workers were free of bladder cancer at the time of initial (or baseline) examination and were reexamined at least once based on their risk assessments in a seven-year period. The event time considered in this study is the cancer-free time from baseline examination to last follow-up. To simplify the analysis, we consider only four covariates: age, level of benzidine exposure, and two biomarkers, M1 and M2. The level of benzidine exposure (LEX) is scored based on the workers job position in the factory and is considered fixed (time independent). In addition, age (AGEB) and the two biomarkers M1B (:0 is negative, :1 if positive) and M2B (:0 if negative, :1 if positive) were measured at baseline examination (they are not changed with time). At subsequent examinations, age (AGET) and the two biomarkers, M1T and M2T, were measured again (they are changed with time) with the status of bladder cancer and the cancer-free time from baseline examination to subsequent examination (TR). We selected a subset of 61   -  341 persons from this study for this example. The data reproduced in Table 13.1 are solely for the purpose of illustrating the proportional hazards model with time-dependent covariates. Thus, the results should not be interpreted as the true findings of this large study.

Table 13.1 gives the baseline and follow-up data from the 61 participants selected from the study. We use ID numbers to distinguish the data observed from different participants. For example, the person in the table with ID : 4 had LEX : 36, diagnosed as M1 positive and M2 negative (M1B : 1 and M2B : 0), and was 47.82 years old (AGEB : 47.82) at the baseline examin- ation (time 0). He was diagnosed with negative M1 and M2 (M1T : 0 and M2T : 0) and without cancer at 42.94 months (TR : 42.94) from the baseline examination and at 51.39 years of age (AGET : 51.39) (thus 42.94 was considered a censored event time, CS : 0). His third examination was conducted at 67.06 months (TR : 67.06) and he was still cancer free with both M1 and M2 negative (M1T : 0 and M2T : 0) at 53.40 years old (AGET : 53.40) (thus 67.06 was considered a censored event time, CS : 0). In other words, for this person, AGET : 51.39, M1T : 0, and M2T : 0 during the time interval (0, 42.94] and AGET : 53.40, M1T : 0, and M2T : 0 during the time interval (42.94, 67.06]. The event time TR was censored at the end of the first time interval (TR : 42.94 months, CS : 0) and also at the end of the second time interval (TR : 67.06 months, CS : 0). The left endpoint of a time interval is denoted as TL in the table. Thus, in this example, covariates LEX, AGEB, M1B, and M2B are fixed for all time intervals, but AGET, M1T, and M2T are time-dependent covariates, which may change from one interval to another.

To facilitate better understanding of (13.1.1.), we use only the data from the first six people to illustrate how to construct the likelihood function (13.1.1.).

If we have only the data from the first six people, there are two ( k : 2) distinct uncensored cancer-free times, t:14 . 65 (observed from the person with ID : 2) and t:24 . 61 (observed from the persons with ID: 1). At t, all six people are at risk and R( t) contains all six. At time t, only four people (ID : 1, 3, 4, and 6) are at risk and R( t) contains these four. The person with ID : 5 is censored at 14.78 months, prior to t. Table 13.2 gives those in the risk sets for t and t with values of the seven covariates.

Let x J( t G) :(LEX J, AGEB J, M1B J, M2B J, AGET J( t G), M1T J( t G), M2T J( t G)) denote the covariates from person l (ID : l) evaluated at the ordered uncensored event time t G, i:1, 2; l: 1, 2, . . . , 6, and b:( b, b, . . . , b) denote the unknown coefficients. Then the first term in (13.1.1) for t is exp[bx( t)] J exp[bx J( t)] 342         Table 13.1 Cancer-Free Times for Workers Exposed to Some Chemical Elements ?

ID LEX AGEB M1B M2B AGET M1T M2T CS TR TL 1 180 58.64 0 0 60.70 1 0 1 24.61 0.00 2 69 40.99 0 0 42.21 1 0 1 14.65 0.00 3 36 57.14 0 0 60.72 0 0 0 42.97 0.00 4 36 47.82 1 0 51.39 0 0 0 42.94 0.00 4 36 47.82 1 0 53.40; 0 0 0 67.06 42.94 5 36 34.85 1 0 36.08 0 0 0 14.78 0.00 6 15 64.24 0 0 67.66 0 1 0 41.03 0.00 7 15 60.72 0 0 64.14 0 0 0 41.00 0.00 8 15 58.97 0 0 61.54 0 0 0 30.82 0.00 8 15 58.97 0 0 62.01 1 0 0 36.40 30.82 8 15 58.97 0 0 62.41 1 0 0 41.26 36.40 8 15 58.97 0 0 63.00 0 0 0 48.33 41.26 8 15 58.97 0 0 63.54 0 0 0 54.83 48.33 8 15 58.97 0 0 64.03 1 0 0 60.71 54.83 8 15 58.97 0 0 64.49 0 0 0 66.17 60.71 8 15 58.97 0 0 65.06 1 0 0 73.07 66.17 9 15 49.95 0 0 49.95 0 0 0 41.00 0.00 10 15 69.19 0 0 72.61 0 0 0 41.03 0.00 11 15 48.98 0 0 52.41 0 0 0 41.20 0.00 12 15 65.52 0 0 68.95 0 0 0 41.17 0.00 13 15 47.86 0 0 47.86 0 0 0 41.43 0.00 14 15 47.82 0; 0 51.28 0 1 0 41.43 0.00 14 15 47.82 0 0 52.41 0 0 0 54.97 41.43 15 15 43.49 1 0 46.53 0 0 0 36.50 0.00 15 15 43.49 1 0 46.94 0 0 0 41.43 36.50 15 15 43.49 1 0 47.53 0 0 0 48.46 41.43 15 15 43.49 1 0 48.56 0 0 0 60.85 48.46 16 15 41.28 0 0 44.74 0 1 0 41.56 0.00 16 15 41.28 0 0 45.86 0 0 0 54.93 41.56 17 15 49.09 0 0 52.54 0 0 0 41.43 0.00 18 15 46.03 0 0 49.45 0 0 0 41.03 0.00 19 15 64.41 0 0 67.85 0 0 0 41.23 0.00 20 164 52.52 0 0 53.54 1 1 1 12.32 0.00 21 15 61.51 0 0 64.94 0 0 0 41.10 0.00 22 144 64.59 0 0 68.01 1 0 0 41.13 0.00 22 144 64.59 0 0 68.60 1 1 1 48.16 41.13 23 192 62.26 0 1 64.88 1 0 0 31.47 0.00 23 192 62.26 0 1 65.27 0 0 1 36.17 31.47 24 54 57.56 0 0 57.95 1 0 1 4.67 0.00 25 264 60.03 0 0 73.03 1 0 0 36.07 0.00 25 264 60.03 0 0 73.71 1 0 0 44.19 36.07 25 264 60.03 0 0 64.17 1 0 0 49.68 44.19 25 264 60.03 0 0 65.15 1 0 1 61.44 49.68 26 40 44.30 0 0 45.48 1 0 0 14.13 0.00 26 40 44.30 0 0 46.49 1 0 1 26.25 14.13 27 265 52.84 0 1 53.98 0 0 0 13.73 0.00 27 265 52.84 0 1 55.43 0 0 0 31.18 13.73 27 265 52.84 0 1 55.83 0 0 0 35.91 31.18 27 265 52.84 0 1 56.42 0 0 1 42.97 35.91   -  343 Table 13.1 Continued ID LEX AGEB M1B M2B AGET M1T M2T CS TR TL 28 132 68.19 0 1 69.31 0 0 1 13.50 0.00 29 24 62.22 1 1 64.39 0 0 0 26.02 0.00 29 24 62.22 1 1 64.85 0 0 0 31.54 26.02 29 24 62.22 1 1 65.22 0 0 0 36.01 31.54 29 24 62.22 1 1 65.82 0 1 0 43.27 36.01 29 24 62.22 0 1 66.89 1 0 1 56.02 43.27 30 132 68.27 0 0 70.12 0 0 1 22.14 0.00 31 178 64.07 0 0 64.07 1 0 1 21.95 0.00 32 50 65.88 0 0 65.88 0 0 0 25.43 0.00 33 50 70.82 0 1 74.40 0 0 0 42.97 0.00 34 50 60.53 0 1 63.54 0 0 0 36.14 0.00 34 50 60.53 0 1 64.67 0 0 0 49.68 36.14 34 50 60.53 0 1 66.18 0 0 0 67.88 49.68 35 50 62.99 0 0 66.00 0 0 0 36.11 0.00 36 50 63.01 1 1 65.15 0 0 0 25.76 0.00 36 50 63.01 1 1 66.01 0 0 0 36.04 25.76 36 50 63.01 1 1 66.60 0 0 0 43.07 36.04 36 50 63.01 1 1 67.68 1 0 0 56.05 43.07 37 50 63.86 0 0 66.89 0 0 0 36.40 0.00 38 50 61.15 0 0 62.33 0 0 0 14.16 0.00 38 50 61.15 0 0 63.32 0 0 0 26.02 14.16 38 50 61.15 0 0 63.78 0 0 0 31.57 26.02 38 50 61.15 0 0 64.75 0 0 0 43.20 31.57 38 50 61.15 0 0 65.30 1 0 0 49.87 43.20 39 50 61.02 0 0 64.03 1 0 0 36.14 0.00 40 50 61.08 0 0 61.08 0 0 0 36.17 0.00 41 50 49.50 0 1 52.51 0 0 1 36.14 0.00 42 50 49.81 0 0 52.81 0 0 0 35.94 0.00 43 50 49.09 0 0 52.10 0 0 0 36.17 0.00 44 50 47.07 0 0 50.08 0 0 0 36.14 0.00 45 50 63.69 0 1 64.84 0 0 0 13.90 0.00 45 50 63.69 0 1 66.30 0 0 0 31.41 13.90 45 50 63.69 0 1 66.69 0 0 0 36.01 31.41 45 50 63.69 0 1 67.28 0 0 0 43.10 36.01 46 50 55.77 0 0 58.77 0 0 0 36.01 0.00 47 50 60.84 0 1 61.99 1 0 0 13.83 0.00 47 50 60.84 0 1 64.98 0 0 0 49.71 13.83 48 50 50.09 1 1 51.24 1 0 0 13.90 0.00 48 50 50.09 1 1 52.70 0 0 0 31.41 13.90 48 50 50.09 1 1 53.09 0 0 0 36.01 31.41 48 50 50.09 1 1 54.23 0 0 0 49.77 36.01 48 50 50.09 1 1 54.76 0 0 0 56.05 49.77 48 50 50.09 1 1 55.75 0 0 0 67.98 56.05 49 50 62.41 1 0 63.53 0 0 0 13.50 0.00 49 50 62.41 1 0 65.38 0 0 0 35.61 13.50 50 50 73.88 0 1 78,03 0 0 0 49.81 0.00 51 50 44.68 0 0 47.68 1 0 0 35.98 0.00 51 50 44.68 0 0 49.36 0 0 0 56.12 35.98 52 50 62.67 0 0 65.66 0 0 0 35.91 0.00 ( Continued overleaf ) 344         Table 13.1 Continued ID LEX AGEB M1B M2B AGET M1T M2T CS TR TL 53 275 74.28 0 1 75.34 1 1 0 12.75 0.00 53 275 74.28 0 1 77.28 0 0 0 36.04 12.75 53 275 74.28 0 1 77.70 1 0 0 41.07 36.04 53 275 74.28 0 1 78.26 1 0 1 47.80 41.07 54 57 39.52 0 0 43.50 0 0 0 47.80 0.00 5 57 76.22 1 0 79.23 1 0 0 36.07 0.00 5 57 76.22 1 0 79.64 0 0 0 41.10 36.07 5 57 76.22 1 0 80.21 0 0 0 47.84 41.10 5 57 76.22 1 0 81.24 0 0 0 60.29 47.84 56 57 62.41 0 0 65.83 0 0 0 41.10 0.00 57 57 67.64 0 0 71.06 0 0 0 41.10 0.00 58 57 80.61 0 0 84.03 0 1 0 41.10 0.00 58 57 80.61 0 0 85.14 0 0 0 54.37 41.10 59 57 67.78 1 0 67.68 1 0 0 72.12 0.00 60 0 47.35 0 1 47.35 0 1 0 13.83 0.00 60 0 47.35 0 1 49.84 0 0 0 43.70 13.83 61 0 40.98 1 0 42.13 0 0 0 13.83 0.00 61 0 40.98 1 0 43.59 0 0 0 31.38 13.83 61 0 40.98 1 0 44.62 0 0 0 43.70 31.38 61 0 40.98 1 0 46.55 0 0 0 66.92 43.70 ? ID, participant ID number; LEX, level of exposure; AGEB, age at the baseline examimation; M1B and M2B, index functions of measure 1 and 2 at the baseline; M1B : 1 if measure 1 is positive and 0 if not; M2B : 1 if measure 2 is positive and 0 if not; AGET, age at the end of each time interval; M1T and M2T, index functions of measure 1 and 2 at the end of each time interval; M1T : 1 if measure 1 is positive and 0 if not; M2T : 1 if measure 2 is positive and 0 if not; CS : 0 if censored and 1 if not; TR, cancer-free time in months (or the right endpoint of time interval); TL, left endpoint of time interval.

where x( t) :(69, 40 . 99, 0, 0, 42 . 21, 1, 0) is the column vector of covariates from person 2, whose cancer-free time is t:14 . 65. The x J( t)s in the denominator are the covariate vectors observed for the six people in the risk set R( t) and are listed in Table 13.2. For example, x( t) :(36, 57 . 14, 0, 0, 60 . 72, 0, 0) . The second and also the last term in (13.1.1) for t: 24.61 is exp[bx( t)] exp[bx( t)] ;exp[bx( t)] ;exp[bx( t)] ;exp[bx( t)] where x( t) :(180, 58 . 64, 0, 0, 60 . 70, 1, 0) and x J( t)s in the denominator are the observed covariate vectors from the four persons (ID : 1, 3, 4, and 6) nt de 2T 0 0 0 1 en M p )1 -De : 1 0 0 0 ime M1T T ID h th 0 2 9 6 it .7 .7 .3 .6 w wi 60 60 51 67 al AGET ple . 61 u eo 24 vid B P 2 0 0 0 0 : di x M in Si t rst from 0 0 1 0 Fi M1B ed the rvse 64 14 82 24 om ob 58.

57.

47.

64.

fr AGEB s 6 6 5 ime 180 3 3 1 T LEX e 2T 0 0 0 0 0 1 r-Fre M )( ance 2 C : 1 1 0 0 0 0 e M1T th ID 0 1 2 9 8 6 for .7 .2 .7 .3 .0 .6 d with 0 0 1 7 AGET 6 42 6 5 36 6 . 65 14 idual 2B ikelihoo iv 0 0 0 0 0 0 L : M l ind t m rtia fro 0 0 0 1 1 0 Pa d M1B the rve 4 4 2 4 f 6 .99 1 8 .85 2 o 0 4 58.

4 57.

47.

3 64.

(obse AGEB ction 0 9 6 6 6 5 ru 8 6 3 3 3 1 st LEX 1 noC e 2 tim 3.

tes ered 1 d ID 1 2 3 4 5 6 ria va Or Event Table Co 345 346         Table 13.3 Asymptotic Partial Likelihood Inference on Cancer-Free Time Data from Fitted Model with Time-Dependent Covariates 95% Confidence Interval Regression Standard Chi-Square Hazards Variable Coefficient Error Statistic p Ratio Lower Upper LEX 0.007 0.003 5.593 0.018 1.01 1.00 1.01 M1T 1.361 0.645 4.449 0.035 3.90 1.10 13.81 in R( t) (see Table 13.2 for details). The partial likelihood function for this reduced data set is the product of these two terms.

The partial likelihood function for the entire data set in Table 13.1 can be constructed in a similar way and estimates of the coefficients can be obtained using the Newton  Raphson method. The data format style in Table 13.1 is referred to as a counting process data format. The results of fitting this model with time-dependent covariates and a stepwise selection method are given in Table 13.3. The coefficients indicate that high levels of exposure and positive M1 at follow-upexamination are p ositively related to the risk of a short cancer-free time. Assuming that other measures are the same, a person with a positive M1 at follow-up examination will have 3.9 times higher risk to develop bladder cancer than will someone with a negative M1. For every 1-unit increase in LEX, the risk will increase by 1%.

Suppose that the text data file C:EX1311.DAT contains the data in Table 13.1 and the successive 11 columns give ID, LEX, AGEB, M1B, M2B, AGET, M1T, M2T, CS, TR, and TL. The following SAS code can be used to obtain the results in Table 13.3.

data w1; infile c:ex13d1d1.dat missover; input id lex ageb m1b m2b aget m1t m2t cs tr tl; run; title Selected Cox proportional hazards model with time dependent covariates; proc phreg data : w1; model (tl,tr)*cs(0) : lex ageb m1b m2b aget m1t m2t / rl ties : efron selection : s; where tltr; run; For the second type of time-dependent covariate (i.e., the covariate known to change with time according to a mathematical function), we simply use the known mathematical function to replace the covariate. Following is a hypothetical example to illustrate the use of SAS, SPSS, and BMDP.

-  347 Example 13.2 Suppose that we wish to fit the proportional hazards model to a set of survival data that has been saved in a text file C:EX1312.DAT.

This set of data consists of survival time t, an indicator variable CENS (:1 for an uncensored observation and 0 for a censored observation) and three covariates, X1, X2, and X3. Furthermore, assume that X3 is known to change with time according to the function X3;log( t ; 1). In this case, the following SAS, SPSS, and BMDP code can be used to incorporate this time-dependent covariate with known mathematical relationship with time into the model.

data w1; infile c:ex1312.dat missover; input t cens x1 x2 x3; run; proc phreg data : w1; model t*cens(0) : x1 x2 z/ rl ties : efron; z : x3*log(t ; 1) run; If the SPSS COXREG procedure is used, the code is data list file : c:ex1312.dat free / t cens x1 x2 x3.

time program Compute z : x3*log(t ; 1).

coxreg t with x1 x2 z /status : cens event (1) /print : all /save : hazard resid presid.

For the BMDP 2L procedure, the code is /input file : c:ex1312.dat .

variables : 6.

format : free.

/print cova.

/variable names : t,cens, x1, x2, x3.

/form time : t.

status : cens.

response : 1.

/regress covariates : x1, x2, z.

add : z.

/function z : x3*ln(time ; 1).

348         13.2 STRATIFIED PROPORTIONAL HAZARDS MODELS The proportional hazards model in (12.1.3) assumes that the ratio of the hazard functions of any two people with prognostic variables x and x is a constant, independent of time. This assumption may not always be met in practical situations. To accommodate the nonproportional cases, Coxs model can be generalized using the concept of stratification (Kalbfleisch and Prentice, 1980). The data can be stratified by a covariate: for example, age. If we consider two strata, say age 50 and 50 years, the model in (12.1.3) becomes two models: hG( t x):h G( t) exp bHxH: h G( t) exp(bx G) (13.2.1) where i : 1, 2 for the two age strata. Notice that the underlying hazard function h G( t) is assumed to be different for the two strata; however, the regression coefficients are the same for all strata. That is, we assume that the hazards for patients may be proportional within each stratum but not among different strata (or levels). The partial (marginal) likelihood function for all observations from the m strata is defined as K L (b) : L H(b) (13.2.2) H where L H(b) is the partial (marginal) likelihood function for the j th stratum.

The regression coefficients b can be estimated by the Newton  Raphson method. For stratified models, the baseline survivorshipfunction for each stratum is estimated separately based on the estimated regression coefficients b and the data in that stratum alone by using the methods discussed in Section 12.3.

Example 13.3 Consider the data given in Example 12.1.1. Suppose that we are not sure if the risk of dying for patients at least 50 years of age is proportional to that for patients less than 50 years and decide to do a stratified analysis. Two regression equations are therefore assumed: h( t x) : h( t) exp( b x) h( t x) : h( t) exp( b x) where h( t x), the hazard function for patients under 50 years of age, and h( t x), the hazard function for patients at least 50 years, are functions of cellularity, and h( t) and h( t) are the underlying hazard functions for the two groups. The results of the stratified analysis, b :0 . 22, SE( b) : 0 . 44, p: 0 . 31, and exp( b):1.24, are close to those obtained earlier in the unstratified model.

349 Table 13.4 Asymptotic Partial Likelihood Inference on CVD-free Time Data from Fitted Models 95% Confidence Interval Regression Standard Chi-Square Hazards Variable Coefficient Error Statistic p Ratio Lower Upper Unstratified Model for All CV Ds AGE 0.070 0.014 26.139 0.0001 1.07 1.04 1.10 SEX 0.753 0.219 11.789 0.0006 2.12 1.38 3.26 LACR 0.111 0.046 5.860 0.0155 1.12 1.02 1.22 LTG 0.399 0.198 4.072 0.0436 1.49 1.01 2.20 Gender-Stratified Model for All CV Ds AGE 0.063 0.013 23.430 0.0001 1.07 1.04 1.09 LACR 0.149 0.043 11.828 0.0006 1.16 1.07 1.26 Gender-Specific Proportional Hazards Models Female SBP 0.022 0.006 13.962 0.0002 1.02 1.01 1.03 DM 0.986 0.373 6.973 0.0083 2.68 1.29 5.57 Male AGE 0.069 0.018 14.453 0.0001 1.07 1.03 1.11 LACR 0.125 0.058 4.555 0.0328 1.13 1.01 1.27 However, this may not always be the case. Because the model is stratified by age groupand no specific relationshipis assumed between the hazard ratio of patients at least 50 years old and those under 50, tests of significance of the regression coefficients for the other variables are adjusted for age.

Example 13.4 In Example 12.5 we used the stepwise selection method to fit the proportional hazards model to the CVD data in Example 12.3. We reanalyze the data using a gender-stratified proportional hazards model.

Results from the unstratified model and the stratified model (with a stepwise selection procedure) are given in Table 13.4.

The unstratified model identifies AGE, SEX, LACR (logarithm of the ratio of urinary albumin and creatinine), and LTG (logarithm of triglycerides) as significant covariates for the time to CVD. The gender-stratified model with the stepwise selection procedure identifies AGE and LACR as the most significant covariates. The coefficients are close to those obtained in the unstratified model. The log[-log( S( t))] at the averages of covariates AGE and LACR for the two strata are plotted in Figure 12.7. The two curves look 350         parallel to each other. It suggests that stratification for this set of data does not provide more information for the study. Moreover, the sex-specific proportional hazards model (at the bottom of Table 13.4) show that systolic blood pressure (SBP) and diabetes are significant covariates related to the risk of CVD in women and AGE and LACR in men. Thus, the gender-specific models provide more information and suggest that there are differences in CVD risk factors among men and women.

The method of stratification is useful in cases when the observations from different strata are considered independent, conditional on the stratified variable, or one is not interested in the effect of the stratified variable itself on the outcome but in the interactions of the stratified variable with the other covariates in the model and does not know the exact forms of the interactions.

It is clear that modeling observations from different strata separately can provide more information than either stratification or unstratification if the sample size in each stratum is large enough.

Using the data file C:EX12d4d1.DAT defined in Example 12.4, the following SAS code can be used to obtain the results in Table 13.4 and Figure 12.7.

data w1; infile c:ex12d4d1.dat missover; input t cens agea ageb sex smoke bmi lacr sbp ltg age htn dm; run; title Unstratified model; proc phreg data : w1; model t*cens(0) : age sex bmi lacr sbpltg smoke htn dm / selection: b ties : efron; run; title gender stratified model; proc phreg data : w1; model t*cens(0) : age bmi lacr sbpltg smoke htn dm / selection : b ties : efron; strata sex; run; proc phreg data : w1 noprint; model t*cens(0) : age lacr / ties : efron; strata sex; baseline out : bas1 loglogs : lmls; run; title Log-logS from fitting a gender stratified model; proc print data : bas1; var sex age lacr t lmls; run; proc sort data : w1; by sex; run; title gender-specific models;     351 proc phreg data : w1; model t*cens(0) : age bmi lacr sbpltg smoke htn dm / selection : b ties : efron; by sex; run; The following SPSS code can also be used. In this case, the data for women and men are assumed to be in the files C:EX12d4d1a.DAT and C:EX12d4d1b.DAT separately.

data list file : c:ex12d4d1.dat free / t cens agea ageb sex smoke bmi lacr sbpltg age htn dm.

coxreg t with age sex bmi lacr sbpltg smoke htn dm /status : cens event (1) /method : bstepage sex bmi lacr sbpltg smoke htn dm /criteria pin (0.05) pout (0.05) /print : all coxreg t with age bmi lacr sbpltg smoke htn dm /status : cens event (1) /strata : sex /method : bstepage bmi lacr sbpltg smoke htn dm /criteria pin (0.05) pout (0.05) /print : all coxreg t with age lacr /status : cens event (1) /strata : sex /print : all /save : lml.

data list file : c:ex12d4d1a.dat free / t cens agea ageb sex smoke bmi lacr sbpltg age htn dm.

coxreg t with age bmi lacr sbpltg smoke htn dm /status : cens event (1) /method : bstepage bmi lacr sbpltg smoke htn dm /criteria pin (0.05) pout (0.05) /print : all data list file : c:ex12d4d1b.dat free / t cens agea ageb sex smoke bmi lacr sbpltg age htn dm.

coxreg t with age bmi lacr sbpltg smoke htn dm /status : cens event (1) /method : bstepage bmi lacr sbpltg smoke htn dm /criteria pin (0.05) pout (0.05) /print : all For the BMDP 2L procedure, the following code can be used.

/input file : c:ex12d4d1.dat .

variables : 13.

format : free.

352         /print cova.

Survival.

/variable names : t,cens, agea, ageb, sex, smoke, bmi, lacr, sbp, ltg, age, htn, dm.

/form time : t.

status : cens.

response : 1.

/regress covariates : age, smoke, bmi, lacr, sbp, ltg, htn, dm.

strata : sex.

step : phh.

/input file : c:ex12d4d1a.dat .

variables : 13.

format : free.

/print cova.

Survival.

/variable names : t,cens, agea, ageb, sex, smoke, bmi, lacr, sbp, ltg, age, htn, dm.

/form time : t.

status : cens.

response : 1.

/regress covariates : age, smoke, bmi, lacr, sbp, ltg, htn, dm.

step : phh.

/input file : c:ex12d4d1b.dat .

variables : 13.

format : free.

/print cova.

Survival.

/variable names : t,cens, agea, ageb, sex, smoke, bmi, lacr, sbp, ltg, age, htn, dm.

/form time : t.

status : cens.

response : 1.

/regress covariates : age, smoke, bmi, lacr, sbp, ltg, htn, dm.

step : phh.

13.3 COMPETING RISKS MODEL All the methods for prognostic factor analysis discussed so far deal with a single type of failure time for each study subject. This may be a perfectly acceptable way to proceed in many cases. However, in some situations, failure on an person may be due to several distinct causes. It may be desirable to distinguish different kinds of events that may lead to failure and treat them differently in the analysis. For example, to evaluate the efficacy of heart transplants, one would certainly want to treat deaths due to heart failure differently from deaths due to other causes, such as accident and cancer. In a    353 mortality study, it may be more interesting to study separately deaths due to heart disease, diabetes, cancer, and others than to combine all the causes. These different causes of failure are considered as competing events, which introduce competing risks. Thus, problems arising in the analysis of data with multiple causes are commonly referred to as competing risk problems. We will see later that competing risk analysis, in general, requires no inference methods other than those introduced in Chapters 11 and 12. We focus on using the proportional hazards model to identify significant prognostic or risk factors when competing risks are present. Readers interested in additional details are referred to Kalbfleisch and Prentice (1980).

Let T be the survival time, x the covariate vector, and J the type or cause of failure. We define a type- or cause-specific hazard function hH( t; x) P( t T t ; t, J : j T t, x) hH( t; x) : lim , j : 1, . . . , m (13.3.1) R t In words, hH( t; x) is the instantaneous failure rate of cause j at time t given x and in the presence of other ( m 9 1) causes of failure. The only difference between (13.3.1) and the hazard function defined in Chapter 2 is the appearance of J : j. Equation (13.3.1) is a type- or cause-specific hazard function, which is very much the same as the ordinary hazard function except that the event is of a specific type. The overall hazard of failure is the sum of all the type-specific hazards, that is, h( t; x) : hH( t; x) (13.3.2) H provided that the failure types are mutually excluded. Based on (2.15), we can define the function .

SH( t; x) : exp9 R hH( u; x) du, j:1, ... , m (13 . 3 . 3) However, these functions cannot, in general, be interpreted as survivorship functions when m 1 . Let tH tH% tHI denote the failure times for H failures of type j, j : 1, . . . , m. Assuming proportional hazards, the hazard function in (13.3.1) can be written as hH( t; x) : h H( t) exp(b H x), j : 1, . . . , m (13.3.4) which can be generalized for time-dependent covariates by replacing x with x( t), that is, hH( t; x) : h H( t) exp[b H x( t)], j : 1, . . . , m (13.3.5) 354         The partial likelihood function for the model in (13.3.5) is K IH exp[b L : H x HG( tHG)] (13.3.6) H G exp[b l + R( tHG) H x J( tHG)] where R( tHG) is the risk set at tHG. The estimation of the coefficients and identification of significant covariates can be carried out exactly the same way as described in Chapters 11 and 12 by treating failure times of types other than j as censored observations. This is perhaps the most important concept in competing risks analysis. It is because the basic assumption for a competing risks model is that the occurrence of one type of event removes the person from risk of all other types of events and the person will no longer contribute to the successive risk set. Furthermore, there is nothing to prevent one from choosing different types of models for different hH( t; x)s. For example, in a mortality study we might choose a proportional hazards model for heart disease and a parametric model for diabetes.

The coefficient vector b H in (13.3.6) indicates the effects of the covariates for event type j. If any covariates are not related to a particular type or cause, they may be set to 0. If b H are the same for all j, the model in (13.3.5) reduces to the proportional hazards model in Chapter 12. The following example illustrates the proportional hazards model with competing risks.

Example 13.5 Let us again use the CVD data in Example 12.3. The event types are non-CVD (DG : 0), stroke (DG : 1), CHD (DG : 2), and the other CVDs (DG : 3). If one is interested in all CVD no matter whether it is stroke, CHD, or the other CVDs, the competing risks model reduces to a general CVD event model, the times (T) to CVD for DG : 1, 2, 3 are uncensored event times, and the other times are censored (DG : 0). An indicator variable, CS, can be used to indicate the censoring status; that is, CS : 1 if DG : 1, 2, 3, and CS : 0 otherwise. The result from fitting the proportional hazards model with the backward selection method is given in section (a) of Table 13.5.

If one considers strokes only, the indicator variable CS has to be defined differently; that is, CS : 1 if DG : 1 and CS : 0 if DG : 0, 2 and 3. This means that in addition to non-CVD, the event time of CHD and the other CVDs are treated as censored observations. Note that we will remove a person from the risk set after his or her first CVD event time in constructing the likelihood function for the modified data even if the event was not a fatal event.

For stroke, age is the only significant variable [section (b) in Table 13.5]. We call this model a marginal model for strokes. Similarly, if only CHD, other CVDs, or either stroke or CHD are of interest, the respective modification will be CS : 1 if DG : 2 and CS : 0 otherwise (CHD only); CS : 1 if DG : 3 and CS : 0 otherwise (other CVD only); or CS : 1 if DG : 1, 2 and CS : 0 otherwise (either stroke or CHD). The results of these three fits with the backward selection method are shown in Table 13.5 (c) (e). The results suggest    355 Table 13.5 Asymptotic Partial Likelihood Inference on CVD Event Time Data from the Fitted Competing Risks Models 95% Confidence Interval Regression Standard Chi-Square Hazards Variable Coefficient Error Statistic p Ratio Lower Upper (a) Model for All CVDs AGE 0.070 0.014 26.139 0.0001 1.07 1.04 1.10 SEX 0.753 0.219 11.789 0.0006 2.12 1.38 3.26 LACR 0.111 0.046 5.860 0.0155 1.12 1.02 1.22 LTG 0.399 0.198 4.072 0.0436 1.49 1.01 2.20 (b) Marginal Model for Strokes AGE 0.072 0.021 12.092 0.0005 1.08 1.03 1.12 (c) Marginal Model for CHDs AGE 0.069 0.020 11.622 0.0007 1.07 1.03 1.12 SEX 0.970 0.329 8.716 0.0032 2.64 1.39 5.02 BMI 0.040 0.017 5.162 0.0231 1.04 1.01 1.08 LTG 1.106 0.266 17.234 0.0001 3.02 1.79 5.09 (d) Margial Model for Other CVDs AGE 0.087 0.033 6.874 0.0087 1.09 1.02 1.17 SEX 1.100 0.555 3.937 0.0472 3.01 1.01 8.91 LACR 0.315 1.101 9.745 0.0018 1.37 1.12 1.67 (e) Marginal Model for Strokes or CHDs AGE 0.072 0.015 23.555 0.0001 1.07 1.04 1.11 SEX 0.692 0.239 8.362 0.0038 2.00 1.25 3.20 LTG 0.665 0.200 11.095 0.0009 1.94 1.32 2.88 that significant risk factors differ for different types of CVD events. Age is the only factor common to all the CVD events.

Thus, competing risks models provide an opportunity to separate any one or more specific types of event or cause of death from all other types or causes.

In practice, it is not necessary to fit a model to every type or cause.

Suppose that C:EX13d3d1.DAT is a text data file that contains 14 columns similar to Table 12.4 and the successive columns give T, CENS, DG, AGEA, AGEB, SEX, SMOKE, BMI, LACR, SBP, LTG, AGE, HTN, and DM. The following SAS code can be used to obtain the model for stroke in Table 13.5. These codes can easily be modified to obtain the results for CHD, 356         other CVD, and stroke/CHD.

data w1; infile c:ex13d3d1.dat missover; input t cens dg agea ageb sex smoke bmi lacr sbp ltg age htn dm; run; title Model for stroke event times; proc phreg data : w1; model t*dg(0, 2, 3) : age sex smoke bmi lacr sbpltg htn dm / rl selection : b ties : efron; run; The following SPSS code can be used.

data list file : c:ex13d3d1.dat free / t cens dg agea ageb sex smoke bmi lacr sbpltg age htn dm.

coxreg t with age sex bmi lacr sbpltg smoke htn dm /status : dg event (1) /method : bstepage sex bmi lacr sbpltg smoke htn dm /criteria pin (0.05) pout (0.05) /print : all The following code is for the BMDP 2L procedure.

/input file : c:ex13d3d1.dat .

variables : 14.

format : free.

/print cova.

Survival.

/variable names : t,cens, dg, agea, ageb, sex, smoke, bmi, lacr, sbp, ltg, age, htn, dm.

/form time : t.

status : dg.

response : 1.

/regress covariates : age, sex, smoke, bmi, lacr, sbp, ltg, htn, dm.

step : phh.

13.4 RECURRENT EVENTS MODELS So far we have considered events or failures that are allowed to occur only once. Even in competing risks models, the occurrence of one type of event removes a person from the risk set thereafter. However, in practice the failures on an individual may be recurrences of essentially the same event, such as tumor recurrences after surgeries, or may be successive events of entirely different types, such as strokes and heart attacks. When data include recurrent events, regression models such as the proportional hazards model become much more mathematically complicated and often involve counting process    357 theory, which is beyond the scope of this book. A number of regression models have been proposed in the literature. In this section we introduce three models that can be considered as extensions of the Cox proportional hazards model.

We keepthe mathematics to a minimum and use examples to show how these models can be used to identify important prognostic or risk factors with the aid of available computer software. The three models are based on Prentice et al. (1981), Andersen and Gill (1982), and Wei et al. (1989). All three models are proportional hazards models, and the likelihood functions of these models are constructed differently, primarily in the risk set at the uncensored observations.

Readers interested in details are referred to the papers cited above.

Prentice et al. Model In their 1981 paper, Prentice, Williams, and Peterson (PWP) proposed two models for recurrent events. Both PWP models can be considered as extensions of the stratified proportional hazards model with strata defined by the number and time of the recurrent events. The hazard function is extended beyond the persons first event to cover subsequent events. In the first PWP model, follow-uptime starts at the beginning of the study (true time 0) and the hazard function of the i th person can be written as h( t b Q, x G( t)) : h Q( t) exp[b Q x G( t)] (13.4.1) where the subscript s represents the stratum that the person is in at time t. The first stratum includes people who have at least one recurrence or are censored without recurrence, the second stratum includes people who have at least two recurrences or are censored after the first recurrence, and so on. A person moves from stratum 1 ( s : 1) to stratum 2 ( s : 2) following his or her first recurrent event and remains in stratum 2 until the second recurrent event takes place or becomes a censor observation (no more recurrent event). The h Q( t) in (13.4.1) is the stratum-specific underlying hazard. Notice that in (13.4.1), the coefficients are stratum-specific also.

Let tQ% tQB denote the d Q Q ordered distinct failure times in stratum s, x QG( tQG) the covariate vector of a subject in stratum s who fails at time tQG, x QJ( tQG) the covariate vector of subject l in stratum s at time tQG, and R( t, s) the set of persons at risk in stratum s just prior to time t. Note that the risk set R( t, s) includes only those persons who have experienced the first s 9 1 recurrent events. Then the partial likelihood for the first model in (13.4.1) is BQ exp[b L ( b) : Q x QG( tQG)] (13 . 4 . 2) exp[b s 1 G l+ R( tQG, s) Q x QJ( tQG)] The following example illustrates the construction of the likelihood function and the necessary data arrangements for using SAS, SPSS, or BMDP to carry out the analysis.

358         Example 13.6 We use the tumor recurrence data from bladder cancer patients (Andrews and Herzberg, 1985; Wei et al., 1989) in a clinical trial to compare three treatments, which was conducted by the Veterans Administration Cooperative Urological Research Group (Byar, 1980). All patients had superficial bladder tumors when they entered the study. These tumors were removed and the patients were randomized into three treatment groups: placebo, thiotepa, and pyridoxine. During the follow-up period many patients had one or more recurrences of tumors and new tumors were removed when discovered. In this example we use the tumor recurrence data from 86 patients who received either placebo or thiotepa. Only the first four recurrence times are considered. The data set, reproduced in Table 13.6, includes treatment (1, placebo; 2, thiotepa) follow-uptime, initial number of tumors (N), initial tumor size (S) in centimeters, and recurrent time. Each recurrent time of a patient was measured from the date of first treatment.

In this case, the event of interest is tumor recurrence and the strata are defined by the number of recurrences (NRs).To use SAS and other software to fit data with the model (13.4.1), the data must be rearranged in a certain format by stratum. To facilitate illustration, we select six patients from Table 13.6 and place the data of these six patients in Table 13.7. The follow-up and recurrence times are also shown in Figure 13.1. From the figure we see that stratum 1 includes patients 1 (censored at 9 months), 2 (censored at 59 months), 3 (first recurrent at 3 months), 4 (first recurrent at 12 months), 5 (first occurrence at 6 months), and 6 (first occurrence at 3 months). The time intervals, (TL, TR], are (0,9], (0,59], (0,3], (0,12], (0,6], and (0,3], respectively. These intervals are used to determine the risk set in the stratum-specific likelihood function in (13.4.2), and the patients in the stratum were at risk only in these time intervals.

To use software packages such as SAS, BMDP, and SPSS, we need to rearrange the data by stratum. Table 13.8 gives the rearranged data. Note that the six patients in stratum 1 are arranged in ascending order according to the right end of the time interval. Also introduced in this table are T1  T4, N1  N4, and S1  S4, giving the treatment received, initial tumor number, and initial tumor size of the patients for the four strata, respectively. These variables are set to be zero in the other strata except the stratum they are in. For example, for patients in stratum 1, T2  T4, N2  N4, and S2  S4 are set to be zero because these six patients are in stratum 1, not in stratum 2, 3, or 4. Stratum 2 includes those patients who had one recurrence and had either another recurrence or were censored at end of follow-up. Therefore, stratum 2 has patients 3 (censored at 14 months after the first recurrence), 4 (second recurrence at 16 months), 5 (second recurrence at 12 months), and 6 (second recurrence at 15 months). The time intervals between successive recurrences for these four patients are (3, 14], (12,16], (6,12], and (3,15], respectively. The rearranged data in order of the right end of the intervals are given in Table 13.8. Strata 3 and 4 are constructed in a similar way. Once the data are rearranged exactly as in Table 13.8, SAS and other software can be used to perform the analysis.

This data arrangement also facilitates explanation of the likelihood function    359 Table 13.6 Tumor Recurrence Data for Patients with Bladder Cancer ?

Recurrence Time Treatment Follow-upInitial Initial GroupTime Number Size 1 2 3 4 1 0 1 1 1 1 1 3 1 4 2 1 1 7 1 1 1 10 5 1 1 10 4 1 6 1 14 1 1 1 18 1 1 1 18 1 3 5 1 18 1 1 12 16 1 23 3 3 1 23 1 3 10 15 1 23 1 1 3 16 23 1 23 3 1 3 9 21 1 24 2 3 7 10 16 24 1 25 1 1 3 15 25 1 26 1 2 1 26 8 1 1 1 26 1 4 2 26 1 28 1 2 25 1 29 1 4 1 29 1 2 1 29 4 1 1 30 1 6 28 30 1 30 1 5 2 17 22 1 30 2 1 3 6 8 12 1 31 1 3 12 15 24 1 32 1 2 1 34 2 1 1 36 2 1 1 36 3 1 29 1 37 1 2 1 40 4 1 9 17 22 24 1 40 5 1 16 19 23 29 1 41 1 2 1 43 1 1 3 1 43 2 6 6 1 44 2 1 3 6 9 1 45 1 1 9 11 20 26 1 48 1 1 18 1 49 1 3 1 51 3 1 35 1 53 1 7 17 1 53 3 1 3 15 46 51 1 59 1 1 1 61 3 2 2 15 24 30 1 64 1 3 5 14 19 27 ( Continued overleaf ) 360         Table 13.6 Continued Recurrence Time Treatment Follow-upInitial Initial GroupTime Number Size 1 2 3 4 1 64 2 3 2 8 12 13 2 1 1 3 2 1 1 1 2 5 8 1 5 2 9 1 2 2 10 1 1 2 13 1 1 2 14 2 6 2 17 5 3 3 1 3 5 2 18 5 1 2 18 1 3 17 2 19 5 1 2 2 21 1 1 17 19 2 22 1 1 2 25 1 3 2 25 1 5 2 25 1 1 2 26 1 1 6 12 13 2 27 1 1 6 2 29 2 1 2 2 36 8 3 26 35 2 38 1 1 2 39 1 1 22 23 27 32 2 39 6 1 4 16 23 27 2 40 3 1 24 26 29 40 2 41 3 2 2 41 1 1 2 43 1 1 1 27 2 44 1 1 2 44 6 1 2 20 23 27 2 45 1 2 2 46 1 4 2 2 46 1 4 2 49 3 3 2 50 1 1 2 50 4 1 4 24 47 2 54 3 4 2 54 2 1 38 2 59 1 3 Source: Wei et al (1989) and StatLib web site: http//lib.stat.cmu.edu/datasets/tumor.

? Treatment group: 1, placebo; 2, thioteps. Follow-up time and recurrence time are measured in months. Initial size is measured in centimeters. Initial number of 8 denotes eight or more initial tumors.

361 Table 13.7 Six of 86 Bladder Cancer Patients from the Tumor Recurrence Data ?

Recurrence Time Patient Treatment Follow-upInitial Initial ID GroupTime Number Size 1 2 3 4 1 1 9 1 2 2 0 59 1 1 3 1 14 2 6 3 4 0 18 1 1 12 16 5 1 26 1 1 6 12 13 6 0 53 3 1 3 15 46 51 ? Treatment group: 0, placebo; 1, thiotepa. Following-up time and recurrence time are measured in months. Initial size is measured in centimeters for the largest initial tumor.

in (13.4.2). We use stratum 2 to show the second product in (13.4.2). In stratum 2 ( s : 2), dQ:3 (there are three uncensored observations: patients 5, 6 and 4, according to the ordered recurrent times, 12, 15, and 16 months). Therefore, the second product is the product of three terms, one for each of these three patients. Using the notations in (13.4.2), we renumber them as patient i : 1, 2, and 3, respectively. The risk set at the first uncensored time t in stratum 2 Figure 13.1 Graphical presentation of recurrence times of the six patients in Table 13.7 (numbers in circle indicate the number of recurrences).

362         Table 13.8 Rearranged Data from Table 13.7 for Fitting PWP Model with NR-Indexed Coefficients ?

ID NR TL TR CS T1 T2 T3 T4 N1 N2 N3 N4 S1 S2 S3 S4 3 1 0 3 1 1 0 0 0 2 0 0 0 6 0 0 0 6 1 0 3 1 0 0 0 0 3 0 0 0 1 0 0 0 5 1 0 6 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 0 9 0 1 0 0 0 1 0 0 0 2 0 0 0 4 1 0 12 1 0 0 0 0 1 0 0 0 1 0 0 0 2 1 0 59 0 0 0 0 0 1 0 0 0 1 0 0 0                                             5 2 6 12 1 0 1 0 0 0 1 0 0 0 1 0 0 3 2 3 14 0 0 1 0 0 0 2 0 0 0 6 0 0 6 2 3 15 1 0 0 0 0 0 3 0 0 0 1 0 0 4 2 12 16 1 0 0 0 0 0 1 0 0 0 1 0 0                                             5 3 12 13 1 0 0 1 0 0 0 1 0 0 0 1 0 4 3 16 18 0 0 0 0 0 0 0 1 0 0 0 1 0 6 3 15 46 1 0 0 0 0 0 0 3 0 0 0 1 0                                             5 4 13 26 0 0 0 0 1 0 0 0 1 0 0 0 1 6 4 46 51 1 0 0 0 0 0 0 0 3 0 0 0 1 ? ID, patient ID number; NR, number of recurrence, where 1 : first recurrence, 2 : second recurrence, and so on; TL and TR, left and right ends of time interval (TL, TR) defined by the successive rcurrence times and the follow-uptime, where TR denotes either the successive recurrence time or the follow-uptime; CS, censoring status, where 0 : censored, 1 : uncensored; T1 to T4, treatment group; N1 to N4, initial number of tumors; S1 to S4, initial size.

(observed from patient 5), or R( t, 2) includes patients in stratum 2, whose recurrent times, censored or not, are at least 12 ( t) months. Therefore, R( t, 2) includes all four patients in stratum 2. Similarly, the risk set at the second uncensored time t in stratum 2, R( t,2), includes two patients (patients 6 and 4), and R( t, 2) includes only one patient (patient 4). Thus, using the ID in Table 13.7, let x  x denote the covariate vectors for patients 3  6 in stratum 2, the second product in (13.4.2) is B exp[bx G( t G)] G exp[b l + R( t G,2) x J( t G)] : exp(bx) exp(bx) ;exp(bx) ;exp(bx) ;exp(bx) ; exp(bx) ; exp(bx) (13.4.3) exp(bx) ;exp(bx) exp(bx) where the xs represent the covariate vector (T1, T2, T3, T4, N1, N2, N3, N4, S1, S2, S3, S4). For example, x :(0, 1,0,0,0,1,0,0,0,1,0,0). It is clear that    363 in this model the regression coefficients are stratum specific. They represent the importance of the coefficient for patients in different strata or patients who had different numbers of recurrent events. If the primary interest is the overall importance of the covariates, regardless of the number of recurrences or if it can be assumed that the importance of covariates is independent of the number of recurrences, T1  T4, N1  N4, and S1  S4 can be combined into a single variable. As shown in Table 13.9, the three covariates are named TRT, N, and S for the six patients, and coefficients common to all strata can be estimated.

Data sets that have been so rearranged are ready for SAS and other software.

To use SAS and other software, the entire data set in Table 13.6 must first be rearranged as in Table 13.8 or 13.9. This can also be accomplished using a computer.

Table 13.10 gives the results from fitting the PWP model to the bladder tumor data in Table 13.6 with stratum-specific coefficients and common coefficients. None of the stratum-specific covariates is significant except N1, the initial number of tumors in stratum 1 patients ( p : 0.0017). There is no significant difference between the two treatments in any stratum, and the size of the initial tumor has no significant effect on tumor recurrence. When stratification is ignored, the results are similar (the second part of Table 13.10).

The number of initial tumors is the only significant prognostic factor, and the risk of recurrence increase would increase almost 13% for every one-tumor increase in the number of initial tumors.

Table 13.9 Rearranged Data from Table 13.7 for Fitting PWP Model with Common Coefficients ?

ID NR TL TR CS TRT N S 3 1 0 3 1 1 2 6 6 1 0 3 1 0 3 1 5 1 0 6 1 1 1 1 1 1 0 9 0 1 1 2 4 1 0 12 1 0 1 1 2 1 0 59 0 0 1 1                                             5 2 6 12 1 1 1 1 3 2 3 14 0 1 2 6 6 2 3 15 1 0 3 1 4 2 12 16 1 0 1 1                                             5 3 12 13 1 1 1 1 4 3 16 18 0 0 1 1 6 3 15 46 1 0 3 1                                             5 4 13 26 0 1 1 1 6 4 46 51 1 0 3 1 ? TRT, treatment group; N, initial number; S, initial size.

364         Table 13.10 Asymptotic Partial Likelihood Inference on the Bladder Cancer Data from Fitted PWP Models with Stratum-specific or Common Coefficients 95% Confidence Interval Regression Standard Chi-Square Hazards Variable Coefficient Error Statistic p Ratio Lower Upper Model with Stratum-Specific Coefficients T1 90.526 0.316 2.774 0.0958 0.591 0.318 1.097 T2 90.504 0.406 1.539 0.2148 0.604 0.273 1.339 T3 0.141 0.673 0.044 0.8345 1.151 0.308 4.305 T4 0.050 0.792 0.004 0.9493 1.052 0.223 4.963 N1 0.238 0.076 9.851 0.0017 1.269 1.094 1.472 N2 90.025 0.090 0.075 0.7840 0.976 0.818 1.164 N3 0.050 0.185 0.072 0.7887 1.051 0.731 1.511 N4 0.204 0.242 0.712 0.3987 1.227 0.763 1.971 S1 0.070 0.102 0.470 0.4931 1.072 0.879 1.308 S2 90.161 0.122 1.722 0.1894 0.852 0.670 1.083 S3 0.168 0.269 0.390 0.5321 1.183 0.698 2.005 S4 0.009 0.339 0.001 0.9786 1.009 0.519 1.961 Model with Common Coefficients TRT 90.333 0.216 2.380 0.1229 0.716 0.469 1.094 N 0.120 0.053 5.029 0.0249 1.127 1.015 1.251 S 90.008 0.073 0.014 0.9071 0.992 0.860 1.144 In the second PWP model, the follow-uptime starts from the immediately preceding event or failure time. Analogous to (13.4.1), the second PWP model can be written in terms of a hazard function as h( t b Q, x G( t)) : h Q( t 9 tQ\) exp[b Q x G( t)] (13.4.4) where tQ\ denotes the time of the preceding event. The time period between two consecutive recurrent events or between the last recurrent event time and the end of follow-upis called the gap time.

For the l th subject, who fails at time tQJ in stratum s, denote the gaptime as uQJ: tQJ 9 tQ\ J, where tQ\ J is the failure time of the l th subject in the stratum s 9 1. Let uQ% uQ BQ denote the ordered observed distinct gaptimes in stratum s and R( u, s) denote the set of subjects at risk in stratum s just prior to gaptime u. Again, R( u, s) includes only those subjects who have experienced the first s 9 1 strata. Then we have the partial likelihood for the second model (13.4.4): BQ exp[b L (b) : Q x QG( tQ G)] ( 13.4.5) exp(b s 1 i : 1 l + R( uQ G, s) Q x QJ( tQ G)]    365 Note that risk sets in (13.4.5) are defined by the ordered distinct gaptimes in the strata rather than by the failure times themselves.

Using the notations in Table 13.9, let GT denote the gaptime, then GT : TR  TL. Replacing TR and TL in Tables 13.8 and 13.9 by GT, the data are ready for SAS and other software. Table 13.11 is the corresponding table for the same six patients in Table 13.9 using gap times. Using the notation of Example 13.6, the second product in (13.4.5) for stratum 2 is B exp[bx G( t G)] G exp[b l + R( u G,2) x J( t J)] : exp(bx) exp(bx) ;exp(bx) ;exp(bx) ;exp(bx) ; exp(bx) ; exp(bx) exp(bx) ;exp(bx) ;exp(bx) exp(bx) Note that this is different from (13.4.3), due to a different definition of the risk set.

The results from fitting the PWP gaptime model to all the data in Table 13.6 with stratum-specific coefficients and common coefficients are given in Table 13.12. Again, the number of initial tumors is the only significant Table 13.11 Rearranged Data from Table 13.9 for Fitting PWP Gap Time Model with Common Coefficients ID NR GT CS TRT N S 3 1 3 1 1 2 6 6 1 3 1 0 3 1 5 1 6 1 1 1 1 1 1 9 0 1 1 2 4 1 12 1 0 1 1 2 1 59 0 0 1 1                             4 2 4 1 0 1 1 5 2 6 1 1 1 1 3 2 11 0 1 2 6 6 2 12 1 0 3 1                             5 3 1 1 1 1 1 4 3 2 0 0 1 1 6 3 31 1 0 3 1                             6 4 5 1 0 3 1 5 4 13 0 1 1 1 366         Table 13.12 Asymptotic Partial Likelihood Inference on the Bladder Cancer Data from the Fitted PWP Gap Time Models with Stratum-Specific or Common Coefficients 95% Confidence Interval Regression Standard Chi-Square Hazards Variable Coefficient Error Statistic p Ratio Lower Upper Model with Stratum-Specific Coefficients T1 90.526 0.316 2.774 0.0958 0.591 0.318 1.097 T2 90.271 0.405 0.448 0.5034 0.763 0.345 1.687 T3 0.210 0.550 0.146 0.7022 1.234 0.420 3.626 T4 90.220 0.639 0.119 0.7301 0.802 0.229 2.807 N1 0.238 0.076 9.851 0.0017 1.269 1.094 1.472 N2 90.006 0.096 0.004 0.9469 0.994 0.823 1.200 N3 0.142 0.162 0.774 0.3791 1.153 0.840 1.582 N4 0.475 0.203 5.492 0.0191 1.609 1.081 2.394 S1 0.070 0.102 0.470 0.4931 1.072 0.879 1.308 S2 90.119 0.119 1.003 0.3166 0.888 0.703 1.121 S3 0.278 0.233 1.425 0.2326 1.321 0.836 2.086 S4 0.043 0.290 0.022 0.8822 1.044 0.592 1.842 Model with Common Coefficients TRT 90.279 0.207 1.811 0.1784 0.757 0.504 1.136 N 0.158 0.052 9.258 0.0023 1.171 1.058 1.297 S 0.007 0.070 0.011 0.9157 1.007 0.878 1.156 covariates. There are no major differences between the two PWP models for this set of data. It is impossible to compare the coefficients obtained in the two models. The first model defines time from the beginning of the study and therefore is recommended if the entire course of recurrent events is of interest.

The second model is the choice if the primary interest is to model the gap time between events.

Suppose that the text file C:EX13d4d1.DAT contains the successive columns in Table 13.8 for the entire data set in Table 13.6: NR, TL, TR, CS, T1, T2, T3, T4, N1, N2, N3, N4, S1, S2, S3, and S4, and the text file C:EX13d4d2.DAT contains the seven successive columns in Table 13.9: NR, TL, TR, CS, TRT, N, and S. The following SAS code can be used to obtain the PWP models in Table 13.10.

data w1; infile c:ex13d4d1.dat missover; input nr tl tr cs t1 t2 t3 t4 n1 n2 n3 n4 s1 s2 s3 s4; run; title PWP model with stratified coefficients; proc phreg data : w1;    367 model (tl, tr)*cs(0) : t1 t2 t3 t4 n1 n2 n3 n4 s1 s2 s3 s4 / ties : efron; where tl tr; strata nr; run; data w1; infile c:ex13d4d2.dat missover; input nr tl tr cs trt n s; run; title PWP model with common coefficients; proc phreg data : w1; model (tl, tr)*cs(0) : trt n s / ties : efron; where tltr; strata nr; run; Suppose that the text file C:EX13d4d3.DAT contains 15 successive columns similar to Table 13.8 but with gaptime GT. The 15 columns are NR, GT, CS, T1, T2, T3, T4, N1, N2, N3, N4, S1, S2, S3, and S4. The text file C:KEX13d4d4.DAT contains the successive six columns from Table 13.11: NR, GT, CS, TRT, N, and S. The following SAS, SPSS, and BMDP codes can be used to obtain the PWP gaptime models in Table 13.12.

SAS code: data w1; infile c:ex13d4d3.dat missover; input nr gt cs t1 t2 t3 t4 n1 n2 n3 n4 s1 s2 s3 s4; run; title PWP gaptime model with stratified coefficients; proc phreg data : w1; model gt*cs(0) : t1 t2 t3 t4 n1 n2 n3 n4 s1 s2 s3 s4 / ties : efron; strata nr; run; data w1; infile c:ex13d4d4.dat missover; input nr gt cs trt n s; run; title PWP gaptime model with common coefficients; proc phreg data : w1; model gt*cs(0) : trt n s / ties : efron; strata nr; run; SPSS code: data list file : c:ex13d4d3.dat free / nr gt cs t1 t2 t3 t4 n1 n2 n3 n4 s1 s2 s3 s4.

coxreg gt with t1 t2 t3 t4 n1 n2 n3 n4 s1 s2 s3 s4 /status : cs event (1) 368         /strata : nr /print : all.

data list file : c:ex13d4d4.dat free / nr gt cs trt n s.

coxreg gt with trt n s /status : cs event (1) /strata : nr /print : all.

BMDP 2L code: /input file : c:ex13d4d3.dat .

variables : 15.

format : free.

/print cova.

Survival.

/variable names : nr, gt, cs, t1, t2, t3, t4, n1, n2, n3, n4, s1, s2, s3, s4.

/form time : gt.

status : cs.

response : 1.

/regress covariates : t1, t2, t3, t4, n1, n2, n3, n4, s1, s2, s3, s4.

strata : nr.

/input file : c:ex13d4d4.dat .

variables : 6.

format : free.

/print cova.

Survival.

/variable names : nr, gt, cs, trt, n, s.

/form time : gt.

status : cs.

response : 1.

/regress covariates : trt, n, s.

strata : nr.

Anderson--Gill Model The model proposed by Andersen and Gill (1982), the AG model, assumes that all events are of the same type and are independent. The risk set in the likelihood function is totally different from that in the PWP models. The risk set of a person at the time of an event would contain all the people who are still under observation, regardless of how many events they have experienced before that time. The multiplicative hazard function h( t, x G) for the i th person is h( t, x G): YG( t) h( t) exp[bx G( t)] where YG( t), an indicator, equals 1 when the i th person is under observation (at risk) at time t and 0 otherwise and h( t) is an unspecified underlying hazard    369 function. The partial likelihood for n independent persons is L L (b) : YG( t) exp(bx G) B G R (13.4.6) G R LH YH( t) exp(bx H) where G( t) :1 if the i th person has an event at t and :0 otherwise. Details of this likelihood function and the estimation of the coefficients can be found in Fleming and Harrington (1991) and Andersen et al. (1993). Similar to the PWP models, software packages are available to carry out the computation provided that the data are arranged in a certain format. The following example illustrates the terms in (13.4.6) and the data format required by SAS.

Example 13.7 We use again the data in Table 13.6 to fit the AG model.

To explain the terms in the likelihood function, we use the data of the six people in Table 13.7. In this model, every recurrent event is considered to be independent. Therefore, we can rearrange the data by person and by event time within an individual. Table 13.13 shows the rearranged data. For example, the person with ID : 4 had two recurrences, at 12 and 16, and the follow-up time ended at 18. The time intervals (TL, TR] are (0, 12], (12, 16], and (16,18], and 12 and 16 are uncensored observations and 18 censored, since there was no tumor recurrence at 18. For patients with ID : 1 and 2 ( i : 1, 2), the respective second product terms in (13.4.6) are equal to 1 since G( t) :0, i :1, 2, for all t. For patient 3 ( i : 3), G( t) :1 only at t: 3 (the first tumor recurrence time of the patient). Thus, the respective second product has only Table 13.13 Rearranged Data from Table 13.7 for Fitting AG Model ID TL TR CS TRT N S 1 0 9 0 1 1 2 2 0 59 0 0 1 1 3 0 3 1 1 2 6 3 3 14 0 1 2 6 4 0 12 1 0 1 1 4 12 16 1 0 1 1 4 16 18 0 0 1 1 5 0 6 1 1 1 1 5 6 12 1 1 1 1 5 12 13 1 1 1 1 5 13 26 0 1 1 1 6 0 3 1 0 3 1 6 3 15 1 0 3 1 6 15 46 1 0 3 1 6 46 51 1 0 3 1 6 51 53 0 0 3 1 370         Table 13.14 Asymptotic Partial Likelihood Inference on the Bladder Cancer Data from the Fitted AG Model 95% Confidence Interval Regression Standard Chi-Square Hazards Variable Coefficient Error Statistic p Ratio Lower Upper TRT 90.412 0.200 4.241 0.0395 0.663 0.448 0.980 N 0.164 0.048 11.741 0.0006 1.178 1.073 1.293 S 90.041 0.070 0.342 0.5590 0.960 0.836 1.102 one term at t : 3 and the denominator of this term sums over all the patients who are under observation and at risk at time t : 3. From Figure 13.1 it is easily seen that the sum is over all six patients; that is, the respective second product is exp(bx) (13.4.7) H exp(bx H) For patient 4 ( i : 4), the second product in (13.4.6) contains two terms. One is for t : 12 (the first recurrence time), and at t : 12, patients 2, 3, 4, 5, and 6 are still under observation, and therefore the denominator of the term sums over patients 2 to 6. The other term is for t : 16 (the second recurrence time) and the denominator sums over patients 2, 4, 5, and 6. Patient 3 is no longer under observation after t : 14. Thus, the second product term for i : 4 is exp(bx) ; exp(bx) ( 13.4.8) H exp(bx H) exp(bx) ; H exp(bx H) Similarly, we can construct each term in (13.4.6) and the partial likelihood function.

Using SAS, we obtain the results in Table 13.14. The AG model identifies treatment and number of initial tumor as significant covariates. Compared with placebo, thiotepa does slow down tumor recurrence.

Readers can construct the SAS codes for the AG model by using Table 13.13 and by following the codes given in Example 13.6.

Wei et al. Model By using a marginal approach, Wei, Lin, and Weissfeld (1989) proposed a model, the WLW model, for the analysis of recurrent failures. The failures may be recurrences of the same kind of event or events of different natures, depending on how the stratification is defined. If the strata are defined by the    371 times of repeated failures of the same type, similar to the strata defined in the PWP models, it can be used to analyze repeated failures of the same kind. The difference between the PWP models and the WLW model is that the latter considers each event as a separate process and treats each stratum-specific (marginal) partial likelihood separately. In the stratum-specific (marginal) partial likelihood of stratum s, people who have experienced the ( s 9 1)th failure contribute either one uncensored or one censored failure time depending on whether or not they experience a recurrence in stratum s, and the other subjects contribute only censored times (forced as censored times). Therefore, each stratum contains everyone in the study. This is different from the PWP models, in which subjects who have not experienced the ( s 9 1)th failure are not included in stratum s. If the strata are defined by the type of failure, the WLW model acts like the competing risks model defined in Section 13.3, and the type-specific (marginal) partial likelihood for the j th type simply treats all failures of types other than j in the data as censored.

For the k th stratum of the i th person, the hazard function is assumed to have the form hIG( t) : YIG( t) hI( t) exp(b I x IG), t 0 (13 . 4 . 9) where YIG( t) :1, if the i th person in the k th stratum is under observation, 0, otherwise, hI( t) is an unspecified underlying hazard function. Let RI( tIG) denote the risk set with people at risk at the i th distinct uncensored time tIG in the k th stratum. Then the specific partial likelihood for the k th stratum is L L I(b I): exp(b I x IG) B G (13.4.10) G exp(b l + RI( tIG) I x IJ) where G :1 if the i th observation in the k th stratum is uncensored and 0 otherwise. The coefficients b I are stratum specific. In practice, if we are interested in the overall effect of the covariates, we can assume that the coefficients from different strata are equal (provided that there are no qualitative differences among the strata), combine the strata and draw conclusions above the average effect of the covariates. We again called the coefficients of these covariates common coefficients. The event time is from the beginning of the study in this model.

Similar to the PWP and AG models, the data must be arranged in a certain format in order to use available software to carry out estimation of the coefficients and tests of significance of the covariates. Using the same data as in Examples 13.6 and 13.7, the following example illustrates the terms in the stratum-specific likelihood function and the use of software.

Example 13.8 First, we use the same six patients to illustrate the compo- nents in the stratum-specific likelihood function in (13.4.10). The format the data have to be in for the available software, such as SAS, SPSS, and BMDP, 372         Table 13.15 Rearranged Data from Table 13.7 for Fitting WLW Model with NR-Indexed Coefficients ID NR TR CS T1 T2 T3 T4 N1 N2 N3 N4 S1 S2 S3 S4 3 1 3 1 1 0 0 0 2 0 0 0 6 0 0 0 6 1 3 1 0 0 0 0 3 0 0 0 1 0 0 0 5 1 6 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 9 0 1 0 0 0 1 0 0 0 2 0 0 0 4 1 12 1 0 0 0 0 1 0 0 0 1 0 0 0 2 1 59 0 0 0 0 0 1 0 0 0 1 0 0 0                                             1 2 9 0 0 1 0 0 0 1 0 0 0 2 0 0 5 2 12 1 0 1 0 0 0 1 0 0 0 1 0 0 3 2 14 0 0 1 0 0 0 2 0 0 0 6 0 0 6 2 15 1 0 0 0 0 0 3 0 0 0 1 0 0 4 2 16 1 0 0 0 0 0 1 0 0 0 1 0 0 2 2 59 0 0 0 0 0 0 1 0 0 0 1 0 0                                             1 3 9 0 0 0 1 0 0 0 1 0 0 0 2 0 5 3 13 1 0 0 1 0 0 0 1 0 0 0 1 0 3 3 14 0 0 0 1 0 0 0 2 0 0 0 6 0 4 3 18 0 0 0 0 0 0 0 1 0 0 0 1 0 6 3 46 1 0 0 0 0 0 0 3 0 0 0 1 0 2 3 59 0 0 0 0 0 0 0 1 0 0 0 1 0                                             1 4 9 0 0 0 0 1 0 0 0 1 0 0 0 2 3 4 14 0 0 0 0 1 0 0 0 2 0 0 0 6 4 4 18 0 0 0 0 0 0 0 0 1 0 0 0 1 5 4 26 0 0 0 0 1 0 0 0 1 0 0 0 1 6 4 51 1 0 0 0 0 0 0 0 3 0 0 0 1 2 4 59 0 0 0 0 0 0 0 0 1 0 0 0 1 is similar to that in the PWP and AG models except that all six people are in each of the four strata (Table 13.15). The first stratum (NR : 1) is exactly the same as in Table 13.8. The six patients are ordered according to the magnitude of the event time (censored or not, TR). In stratum 2(NR : 2), the three people (with ID : 4, 5, and 6) whose times to the second tumor recurrence are uncensored observations. Patients 1 and 2 had censored time at 9 and 59, respectively. Patient 3, who had no second recurrence and was observed until 14 months, is considered censored at 14. The other strata are constructed in a similar manner. Using the data arrangement in Table 13.15, we can see that for the second stratum, the likelihood function in (13.4.10) has three terms, one for each of persons 5, 6, and 4, whose G :1 (CS: 1 in the table). For patient 4, the risk set at time t : 16 has two individuals (ID : 4 and 2); for patient 5, the risk set at time t : 12 contains five individuals (ID : 2, 3, 4, 5, and 6); and for patient 6, the risk set at time t : 15 has three individuals (ID : 2, 4, and 6). Let x H be the covariate vector of the patient with ID: j in stratum 2; then    373 Table 13.16 Rearranged Data from Table 13.7 for Fitting WLW Model with Common Coefficients ID NR TR CS TRT N S 3 1 3 1 1 2 6 6 1 3 1 0 3 1 5 1 6 1 1 1 1 1 1 9 0 1 1 2 4 1 12 1 0 1 1 2 1 59 0 0 1 1                             1 2 9 0 1 1 2 5 2 12 1 1 1 1 3 2 14 0 1 2 6 6 2 15 1 0 3 1 4 2 16 1 0 1 1 2 2 59 0 0 1 1                             1 3 9 0 1 1 2 5 3 13 1 1 1 1 3 3 14 0 1 2 6 4 3 18 0 0 1 1 6 3 46 1 0 3 1 2 3 59 0 0 1 1                             1 4 9 0 1 1 2 3 4 14 0 1 2 6 4 4 18 0 0 1 1 5 4 26 0 1 1 1 6 4 51 1 0 3 1 2 4 59 0 0 1 1 the likelihood function in (13.4.10) is L (b) : exp(bx G) B G: exp(bx) G exp(b exp(b l + R( t G) x J) x) ; exp(bx) ; exp(bx) exp(bx);exp(bx);exp(bx);exp(bx) ; exp(bx) ; exp(bx) (13.4.11) exp(bx);exp(bx);exp(bx) Note that (13.4.11) is different from (13.4.3). The likelihood function for the other strata and for the entire data set in Table 13.6 can be constructed in a similar manner. If we ignore the stratum-specific effect and are interested only in the average overall effect of the covariates, we combine T1  T4, N1  N4, and S1  S4. The rearranged data for the six patients are given in Table 13.16.

374         Table 13.17 Asymptotic Partial Likelihood Inference on the Bladder Cancer Data from the Fitted WLW Models with Stratum-Specific or Common Coefficients 95% Confidence Interval Regression Standard Chi-Square Hazards Variable Coefficient Error Statistic p Ratio Lower Upper Model with Stratum-Specific Coefficients T1 90.526 0.316 2.774 0.0958 0.591 0.318 1.097 T2 90.632 0.393 2.588 0.1077 0.531 0.246 1.148 T3 90.698 0.460 2.308 0.1278 0.496 0.202 1.225 T4 90.635 0.576 1.215 0.2703 0.530 0.171 1.639 N1 0.238 0.076 9.851 0.0017 1.269 1.094 1.472 N2 0.137 0.902 2.229 0.1354 1.147 0.958 1.373 N3 0.174 0.105 2.750 0.0973 1.189 0.969 1.460 N4 0.332 0.125 7.112 0.0077 1.394 1.092 1.780 S1 0.070 0.102 0.470 0.4931 1.072 0.879 1.308 S2 90.078 0.134 0.337 0.5614 0.925 0.712 1.203 S3 90.214 0.183 1.371 0.2416 0.807 0.565 1.155 S4 90.206 0.231 0.800 0.3712 0.813 0.517 1.279 Model with Common Coefficients TRT 90.585 0.201 8.460 0.0036 0.557 0.376 0.826 N 0.210 0.047 20.230 0.0001 1.234 1.126 1.352 S 90.052 0.070 0.548 0.4592 0.950 0.828 1.089 The results from fitting the WLW models to the entire data set in Table 13.6 are given in Table 13.17. The model with stratum-specific coefficients suggests that more initial tumors accelerate tumor recurrence and the acceler-ation is particularly faster for the first recurrence and the third and fourth recurrences. The signs of the coefficients for T1  T4 suggest that thiotepa may slow down tumor growth, but the evidence is not statistically significant. The model with common coefficients suggests that thiotepa is significantly more effective in prolonging the recurrence time. The results suggest that when looking at each stratum independently, there is no strong evidence that thiotepa is more effective than placebo. However, the combined estimate of the common coefficient provides stronger evidence that thiotepa is more effective over the course of the study.

13.5 MODELS FOR RELATED OBSERVATIONS In Coxs proportional hazards model and other regression methods, a key assumption is that observed survival or event times are independent. However, in many practical situations, failure times are observed from related individuals     375 or from successive recurrent events or failures of the same person. For example, in an epidemiological study of heart disease, some of the participants may be from the same family and therefore are not independent. These families with multiple participants may be called clusters. In this case, the regression methods we introduced earlier may not be appropriate. Several types of models introduced especially for related observations are discussed by Andersen et al.

(1993), Liang et al. (1995), Klein and Moeschberger (1997), and Ibrahim et al.

(2001). Details about these models are beyond the scope of this book. In the following, we introduce briefly the frailty models.

The frailty models assume that there is an unmeasured random variable (frailty) in the hazard function. This random variable accounts for the variation or heterogeneity among individuals in a cluster. It is also assumed that the frailty is independent of censoring. Let n be the total number of participants in the study, some of them related and forming clusters. Let vG be the unknown random variable, frailty, associated with the i th cluster, 1 i n. The frailty model associated with the proportional hazards model can be written in terms of the log hazard function as log[ hGH( t; x GH vG)] :log[ h( t)] ; vG ;bx GH (13.5.1) for 1 j mG and 1 i n, where b denotes the p;1 column vector of unknown regression coefficients, x GH is the covariate vector of the j th person in the i th cluster, mG is the number of individuals in the i th cluster, and h( t) is an unknown underlying hazard function. Compared with the Cox proportional hazards model, the difference here is the random effect vG. Because vG remains the same in the i th cluster, the association between failure and covariates within each cluster in this model is assumed to have a symmetric pattern. In a family study, this model can be used, for example, to model failure times observed from siblings by treating each family as a cluster. This model was proposed by Vaupel et al. (1979) and developed and discussed by many researchers, including Clayton and Cuzick (1985). The main approach to this model is to assume that vG follows a parametric distribution.

The frailty model in (13.5.1) can be extended to handle more complicated situations. For example, the frailty can be a time-dependent variable [replace vG by vG( t) in (13.5.1)]. The frailty model with vG( t) can be used to model successive or recurrent failure time as an alternative to the models in Section 13.4. Another example is that there may be more than one type of frailty in each cluster, and vG in (13.5.1) can be replaced by vG ; uG or vG; uG ; wG, and so on.

Inferences of these frailty models are also based on either a likelihood function or a partial likelihood function. Since the models involve a parametric distribution, the likelihood or partial likelihood functions are complicated and are beyond the level of this book.

The frailty models have not been used widely primarily because of the lack of commercially available software. There are some computer programs 376         available; for example, a SAS macro is available for a gamma frailty model at the Web site of Klein and Moeschberger (1997), and another program is described by Jenkins (1997).

Bibliographical Remarks Most of the major references for nonproportional hazards models have been cited in the text of this chapter. Applications of these models include: stratified models: Vasan et al. (1997), Aaronson et al. (1997), and Yakovlev et al. (1999); frailty models: Yashin and Iachine (1997), Kessing et al. (1999), Siegmund et al.

(1999), Albert (2000), Lee and Yau (2001), Wienke el al. (2001), and Xue (2001); competing risks models: Mackenbach et al. (1995), Fish et al. (1998), Albertsen et al. (1998), Blackstone and Lytle (2000), Yan et al. (2000), and Tai et al.

(2001).

EXERCISES 13.1 Consider the cancer-free times from the participants with IDs 15 to 23 in Table 13.1. Follow Example 13.1 to construct the partial likelihood function based on the observed cancer-free times from these nine participants.

13.2 Consider the survival times from 30 resected melanoma patients in Table 3.1. Let AGEG denote age group, AGEG : 1 if age 45 and AGEG : 2 otherwise. Fit the survival times with an AGEG-stratified Cox propor- tional hazards model with the covariates age, gender, initial stage, and treatment received. Discuss the association of the treatment received with the survival time.

13.3 Using the data in Table 12.4, following Example 13.5 and the sample codes for SAS, SPSS, or BMDP, fit the competing risk model for stroke, CHD, other CVD, or STROKE/CHD separately, and discuss the results obtained.

13.4 Using the rearranged data in Tables 13.7 to 13.13 and following Examples 13.6 to 13.8, complete construction of the remaining terms in the partial likelihood function based on the PWP model (13.4.2), PWP gaptime model (13.4.3), and AG model (13.4.9), and the remaining three marginal likelihood functions based on the WLW model (13.4.13).

C H A P T E R 14 Identification of Risk Factors Related to Dichotomous and Polychotomous Outcomes In biomedical research we are often interested in whether a certain survival-related event will occur and the important factors that influence its occurrence.

Such events may involve two or more possible outcomes; examples are the development of a given condition and response to a given treatment. If the given condition is diabetes and we are only interested in whether someone develops the disease (yes or no), the outcome is binary or dichotomous. If we are interested in whether the person develops impaired glucose tolerance, diabetes, or remains having normal glucose tolerance, there are three possible outcomes, or we say the outcome is trichotomous. Similarly, response to a given treatment can have dichotomous (response or no response) or polychotomous outcomes (complete response, partial response, or no response).

To determine whether one is likely to develop a given disease, we need to know the important characteristics (or factors) related to its development.

High- and low-risk groups can then be defined accordingly. Factors closely related to the development of a given disease are usually called risk factors or risk variables by epidemiologists. We shall use these terms in a broader sense to mean factors closely related to the occurrence of any event of interest. For example, to find out whether a woman will develop breast cancer because one of her relatives did, we need to know whether a family history of breast cancer is an important risk factor. Therefore, we need to know the following: 1. Of age, race, family history of breast cancer, number of pregnancies, experience of breast-feeding, and use of oral contraceptives  which are most important?

2. Can we predict, on the basis of the important risk factors, whether a woman will develop breast cancer or is more likely to develop breast cancer than another person?

377 378         In this chapter we introduce several methods for answering these ques- tions. The general approach is to relate various patient characteristics (or independent variables, or covariates) to the occurrence of an event (dependent or response variable) on the basis of data collected from patients in each of the outcome groups. In the case of dichotomous out- comes, there are two outcome groups. For example, to relate variables such as age, race, and number of pregnancies to the development of breast cancer, we need to collect information about these variables from a group of breast cancer patients as well as from a group of healthy normal women. For an event with polychotomous outcomes, we need to collect data from each outcome group.

Often, a large number of patient characteristics deserve consideration.

These characteristics may be demographic variables such as age; genetic variables such as gene variant or phenotype; behavioral variables such as smoking or drinking behavior and use of estrogen or progesterone medic-ation; environmental variables such as exposure to sun, air pollution, or occupational dust; or clinical variables such as blood cell counts, weight, and blood pressure. The number of possible risk factors can be reduced through medical knowledge of the disease and careful examination of the possible risk factors individually.

In Section 14.1 we present two methods for examination of individual variables. One is to compare the distribution of each possible risk variable among the outcome groups. The other method is the chi-square test for a contingency table. This test is particularly useful when the risk variables are categorical: for example, dichotomous or trichotomous. In this case, a 2; c or r; c contingency table can be set up and a chi-square test performed. In Section 14.2 we discuss logistic, conditional logistic, and other regression models for binary responses and for examining the possible risk variables simultaneously. Models for multiple outcomes are discussed in Section 14.3.

14.1 UNIVARIATE ANALYSIS 14.1.1 Comparing the Distributions of Risk Variables Among Groups When the outcome is binary, it is often convenient to call an observation a success or a failure. Success may mean that a survival-related event occurred, and failure that it failed to occur. Thus, a success may be a responding patient, a patient who survives more than five years after surgery, or a person who develops a given disease. A failure may be a nonrespond-ing patient, a patient who dies within five years after surgery, or a person who does not develop a given disease. A preliminary examination of the data can compare the distribution of the risk variables in the success and failure groups. This method is especially appropriate if the risk variable is   379 Table 14.1 Ages of 71 Leukemia Patients (Years) Responders 20, 25, 26, 26, 27, 28, 28, 31, 33, 33, 36, 40, 40, 45, 45, 50, 50, 53 56, 62, 71, 74, 75, 77, 18, 19, 22, 26, 27, 28, 28, 28, 34, 37, 47, 56, 19 Nonresponders 27, 33, 34, 37, 43, 45, 45, 47, 48, 51, 52, 53, 57, 59, 59, 60, 60, 61, 61, 61, 63, 65, 71, 73, 73, 74, 80, 21, 28, 36, 55, 59, 62, 83 Source: Hart et al. (1977). Data used by permission of the author.

continuous. If, for example, the risk factor x is weight and the dependent variable y is having cardiovascular disease, we may compare the weight distribution of patients who have developed disease to that of disease-free patients. If the disease group has significantly higher weights than those of the disease-free group, we may consider weight an important risk factor. Commonly used statistical methods for comparing two distributions are the t-test for two independent samples if the assumption of normality holds and the Mann  Whitney U-test if the normality assumption is violated and a nonparametric test is preferred.

Similarly, if there are more than two possible outcomes, we can use analysis of variance or the Kruskal  Wallis nonparametric test to compare the multiple distributions of a continuous variable. The following example compares the age distribution of responders with that of nonresponders in a cancer clinical trial.

Example 14.1 Consider the ages of 71 leukemia patients  37 responders and 34 nonresponders (response is defined as a complete response only)  given in Table 14.1. Figure 14.1 gives us the estimated age distributions of the two groups. By using the Mann  Whitney U-test (or Gehans generalized Wilcoxon test), we find that the difference in age between responders and nonresponders is statistically significant ( p 0.01). In consequence, a question may arise as to what age is critical. Can we say that patients under 50 may have a better chance of responding than do patients over 50? To answer this question, one can dichotomize the age data and use the chi-square test, discussed next.

14.1.2 Chi-Square Test and Odds Ratio The chi-square test and the odds ratio are most appropriate when the independent variable is categorical. If the independent variable is dichotomous, a 2;2 table can be used to represent the data. Any variables that are not dichotomous can be made so (with a loss of some information) by choosing a cutoff point: for example, age less than 50 years. For multiple- outcome events, 2; c or r; c tables can be constructed. The independent 380         Figure 14.1 Age distribution of responders and nonresponders.

variables are then examined to find which ones (in some sense) provide the best risk associations with the dependent variable. We first consider binary outcomes and independent variables that have two categories; that is, we set up a 2;2 contingency table similar to Table 14.2 for each independent variable and look for a high degree of proportionality.

The first step is to calculate the sample proportion of successes in the two risk groups, a/C and b/C. Further analysis of the table is concerned with the precision of these proportions. A standard chi-square test can be used.

381 Table 14.2 General Setup of a 2;2 Contingency Table Risk Factor Present ( E ) Absent ( E) Total Dependent variable Success a b R Failure c d R Total C C N Proportion of successes (success rate) a/C b/C If the rates of success for the two groups E and E are exactly equal, the expected number of patients in the ij th cell ( i th row and j th column) is R C R E G H G; CH GH : N; ; : (14.1.1) N N N For example, in the top left cell, the expected number is R E ; C : N since the overall success rate is R /N and there are C individuals in the E group. Similar expected numbers can be obtained for each of the four cells. Let OGH be the number of patients observed in the ij th cell. Then the discrepancies can be measured by the differences ( OGH 9 EGH). In a rough sense, the greater the discrepancies, the more evidence we have against the null hypothesis that the success rates are the same for the two groups. The chi-square test is based on these discrepancies. Let ( O X : GH 9 EGH) (14 . 1 . 2) G H EGH Under the null hypothesis, X follows the chi-square distribution with 1 degree of freedom (df). The hypothesis of equal success rates for groups E and E is rejected if X ?, where ? is the 100 percentage point of the chi-square distribution with 1 degree of freedom. An alternative way to compute X is X : ( ad 9 bc) N (14 . 1 . 3) R R C C 382         The odds ratio (Cornfield, 1951) is a commonly used measure of association in 2;2 tables. The odds ratio (OR) is the ratio of two odds: the odds of success when the risk factor is present and the odds of success when the risk factor is absent. In terms of probabilities, OR : P(success E) /P(failure E) (14.1.4) P(success E) /P(failure E) Using the notation in Table 14.2, P(success E) and P(failure E) may be estimated by a/C and c/C, respectively. Similarly, P(success E) and P(failure E) may be estimated, respectively, by b/C and d/C. Therefore, the numerator and denominator of (14.1.4) may be estimated, respectively, by a/C a : c/C c and b/C b : d/C d Consequently, the OR may be estimated by a/c ad OR : : (14.1.5) b/d bc which is also referred to as the cross-product ratio.

Several methods are available for an interval estimate of OR: for example, Cornfield (1956) and Woolf (1955). Cornfields method, which requires an iterative procedure, is considered more accurate but more complicated than Woolfs method. Woolf suggests using the logarithm of OR. The standard error of log OR may be estimated by SE (log OR ) : 1;1;1;1 (14 . 1 . 6) a b c d Then a 100(1 9 )% confidence interval (CI) for log OR is log OR < Z?SE(logOR) The confidence interval for OR can be obtained by taking the antilog of the confidence limits for log OR. If log OR 3 and logOR * are the upper and lower   383 confidence limits for log OR, e logOR 3 and e logOR * are the upper and lower confidence limits for OR.

Notice that in (14.1.5), if b or c is zero, OR is undefined. If any one of the four cell frequencies is zero, the estimated standard error in (14.1.6) is also undefined. Should this occur, some statisticians (Haldane, 1956; Fleiss, 1979, 1981) suggest that 0.5 be added to each cell before using (14.1.5) and (14.1.6) to solve the computational problem. However, if the cell frequencies are as small as zero, the addition of 0.5 to each cell will substantially affect the resulting estimate of OR and its standard error (Mantel, 1977; Miettinen, 1979). The estimates so obtained must be interpreted with caution.

An odds ratio of 1 indicates that the odds of success are the same whether or not the risk factor is present. An odds ratio greater than 1 means that the odds in favor of success is higher when the risk factor is present, and therefore there is a positive association between the risk factor and success. Similarly, an odds ratio of less than 1 signifies a negative association between the risk factor and success. The interpretation should not be based totally on the point estimate. A confidence interval is always more meaningful, just as in any other estimation procedure.

The chi-square statistic in (14.1.2) may be used to test the null hypothesis that there is no association between the risk factor and success, or H: OR:1.

The following example illustrates the chi-square test and odds ratio.

Example 14.2 In the study of the response rate of 71 leukemia patients (Example 14.1), age is considered one of the possible risk variables. The following 2;2 table is constructed.

Age 50 Age 50 Total Response 27 10 37 Nonresponse 12 22 34 Total 39 32 71 The question is whether the response rates in the two age groups differ significantly or whether age is associated with response.

The X value according to (14.1.3) is X : (594 9 120)(71) : 10.16 (37)(34)(39)(32) with 1 degree of freedom. Reference to Table B-2 shows that the probability of 384         getting a X value of 10.16 if the two response rates are equal in the population is less than 0.01. Hence the difference between the two response rates is significant at the 1% level.

The estimate odds ratio, according to (14.1.5), is (27)(22) OR : : 4.95 (10)(12) The data show that the odds in favor of response are almost five times higher in patients under 50 years of age than in patients at least 50 years old. The difference is significantly different, as indicated by the chi-square test above.

To obtain a confidence interval for OR, we first compute log OR : 1.60.

The estimated standard error of log OR following (14.1.6) is SE (log OR ) : 1 ; 1 ; 1 ; 1:0.515 27 10 12 22 A 95% confidence interval for log OR is 1.60 < 1.96(0.515), or (0.59, 2.61), and a 95% confidence interval for OR is ( e, e), or (1.80, 13.60). The wide interval may be due to the small cell frequencies. Note that the standard error of log OR is inversely related to the cell frequencies.

In this example, the cutoff point, 50, was chosen arbitrarily. It is often of interest to try more than one cutoff point if the number of observations in each cell is not too small.

There are cases where the independent variable has c 2 classes. The chi-square test can be extended to 2; c tables. The odds ratio method can also be extended to handle polychotomous independent variables. It is done by selecting one of the classes as the reference class (the E group) and calculating the measure of association of each of the other classes relative to the reference class. For multiple-outcome events, the chi-square test can be extended to r; c tables. The expected frequencies are computed just as in (14.1.1), and computation of X [chi-square distributed with ( r 9 1)( c 9 1) degrees of freedom] is the same as in (14.1.2) except that the sum is over all r; c cells. For details, see Snedecor and Cocharan (1967, Sec. 9.7). The following example illustrates the procedures.

Example 14.3 Suppose that in the study of response rates of leukemia patients, another possible risk variable is the marrow absolute leukemic infiltrate, which is defined as the percentage of the total marrow that is either blast cells or promyelocytes. It is believed that patients should be classified into three classes: 45%, 46  90%, and 90%. The 2;3 table is given below. Numbers in parentheses are expected frequencies. For example, 18.68 : (39)(34)/71.

385 Marrow Absolute Infiltrate 45% 46  90% 90% Total Response 4 (8.34) 20 (20.32) 13 (8.34) 37 Nonresponse 12 (7.66) 19 (18.68) 3 (7.66) 34 Total 16 39 16 71 Response rate, (%) 25 51 81 OR 1 3.16 13.0 95% CI for OR (0.86, 11.52) (2.40, 70.46) The question is whether the difference in marrow absolute leukemic infiltrate is related to response. The value of X is (4 9 8.34) (12 9 7.66) (3 9 7.66) X : ; ; % ; : 10.17 8.34 7.66 7.66 The number of degrees of freedom is 3 9 1 : 2. With X : 10 . 17 and 2 degrees of freedom, the probability that the three absolute infiltrate groups have the same response rate is less than 0.01. The data suggest that patients with a high percentage of marrow absolute infiltrate tend to have a high response rate.

Marrow absolute infiltrate may be an important factor in predicting response.

The OR s given in the table above are calculated using the 45% class as the reference class (or group). For example, for the 90% class, the odds ratio is 13;12/4;3 : 13. The 95% confidence intervals for the ORs are obtained using (14.1.6). Although the odds ratio for the 46  90% group is larger than 1, the 95% confidence intervals covers 1. Therefore, the point estimate, 3.16, cannot be taken too seriously. It appears that the major difference is between the 90% and 45% groups.

Individual examination of each independent variable can provide only a preliminary idea of how important each variable is by itself. The relative importance of all the variables has to be examined simultaneously using multivariate methods. In the following section we discuss the linear logistic regression analysis.

14.2 LOGISTIC AND CONDITIONAL LOGISTIC REGRESSION MODELS FOR DICHOTOMOUS RESPONSES 14.2.1 Logistic Regression Model for Prospective Studies In a typical prospective study, a random sample of subjects is taken and the values of the independent variables are measured at a given time (usually called baseline measurements). The subjects are then followed for a given period of 386         time and the outcome (dependent) variable is measured at the end of the follow-up. Therefore, for a prospective study, the independent variables are regarded as fixed quantities during the follow-up, but the outcomes are random and unknown. The purpose of a prospective study is to examine the outcomes and relate them to the baseline measurements. Examples of prospective studies are cohort epidemiologic studies and clinical trials.

Suppose that there are n subjects and to some of whom the event of interest occurred. They are called successes; the others are failures. Let yG :1 if the i th subject is a success and yG : 0 if the i th subject is a failure. Suppose that for each of the n subjects, p independent variables xG, xG, . . . , xGN are measured.

These variables can be either qualitative, such as gender and race, or quantitative, such as blood pressure and white blood cell count. The problem is to relate the independent variables, xG, . . . , xGN, to the dichotomous dependent variable yG.

Let PG be the probability of success, PG : P( yG :1 xG, . . . , xGN), for the i th subject. The logistic regression model, proposed by Cox (1970) assumes that the dependence of the probability of success on independent variables is PG: P( yG :1 x G): exp( NH bHxGH) (14 . 2 . 1) 1 ; exp( NH bHxGH) and 1 9 PG: P( yG :0 x G) : 1 (14 . 2 . 2) 1 ; exp( NH bHxGH) where x G :( xG% xGN), xG Y 1, and bH are unknown coefficients. The logarithm of the ratio of PG and 19 PG is a simple linear function of the xGHs.

Let P N G G : log : b 1 9 P HxGH (14 . 2 . 3) G H G:log[ PG/(1 9 PG)] is called the logistic transform of PG and (14.2.3) is a linear logistic model. Another name for G is log odds. Thus, the model relates the independent variables to the logistic transform of PG, or log odds. The probability of success PG can then be found from (14.2.3) or (14.2.1). In many ways (14.2.3) is the most useful analog for dichotomous response data of the ordinary regression model for normally distributed data.

To estimate the coefficients bHs, Cox suggests the maximum likelihood method. Let y, y, . . . , yL be observations with dichotomous values on n subjects. The likelihood function based on the binomial distribution contains a factor (14.2.1) whenever yG :1 and (14.2.2) whenever yG: 0. Thus, the likeli-       387 hood function is L L ( b, b, . . . , bN) : PWGG(1 9 PG)\ WG G L : G exp( yG NH bHxGH) : exp( NH bHtH) LG[1;exp( NH bHxGH)] LG[1;exp( NH bHxGH)] (14 . 2 . 4) where tH: LG xGHyG. The log-likelihood function is N L l( b, b, . . . , bN) :log L : bHtH 9 log1;exp N bHxGH (14 . 2 . 5) H G H The maximum likelihood estimates of bHs that maximize the log-likelihood function in (14.2.5) can be obtained by solving the following p equations simultaneously: L x t GH exp( NH bHxGH) H 9 : 0 j : 0, 1, . . . , p (14 . 2 . 6) G 1 ; exp( NH bHxGH) This can be done by an iterative procedure such as the Newton  Raphson procedure. The second derivative of l in (14.2.5) is l L x x exp( N I* GH GH H bHxGH) H : : 9 H bH b 1 ; exp( N H G H bHxGH) j:0, . . . , p; j: 0, . . . , p (14.2.7) Let IH :(91) I* . Then the estimated inverse of the I matrix, I\, is the H H H asymptotic covariance matrix of the bHs. If we use the notation in Section 7.1 and let b : ( b, b, . . . , b N) denote the MLE of b, the estimated covariance matrix of the MLE b is V (b) : ( vGH) :(9 l(b) / b b)\ : I\, where vGH denotes the ij th element of V (b) or the ij th element of I\.

The coefficients so obtained indicate the relationships between the variables and the log odds in favor of success. For a continuous variable, the corresponding coefficient gives the change in the log odds for an increase of 1 unit in the variable. For a categorical variable, the coefficient is equal to the log odds ratio (see Section 14.1).

An approximate 100(1 9 )% confidence interval for bH is b H < Z?( vHH (14.2.8) where Z? is the 100(19/2) percentile of the standard normal distribution.

388         To test the hypothesis that some of the bHs are zero, a likelihood ratio test can be used. For example, to test H: bH:0, the log-likelihood ratio test statistic is X*:92[ l( b, b, . . . , b H\, 0, b H> , . . . , b N) 9 l( b, b, b, . . . , b N)] (14.2.9) where the first term is the maximized log-likelihood subject to the constraint bH:0. If the hypothesis is true, X* is distributed asymptotically as chi-square with 1 degree of freedom.

An alternative test for the significance of the coefficients is the Wald test, which can be written as b X H 5 : (14.2.10) vHH Under the null hypothesis that bH:0, X5 has an asymptotic chi-square distribution with 1 degree of freedom. Although the Wald test is used by many, it is less powerful than the likelihood ratio test (Hauck and Donner, 1977; Jennings, 1986). In other words, the Wald test often leads the user to conclude that the coefficient (consequently, the respective risk factor) is not significant when, in fact, it is significant.

Similar to earlier discussion of model selection, forward, backward, and stepwise variable selection methods can be used to select the risk factors that are significantly associated with a dichotomous response. The independent variables xGH in this model do not have to be the original variables. They can be any meaningful transforms of the original variables: for example, the logarithm of the original variable, log xGH, and the deviation of the variable from its mean, xGH 9 x H.

From (14.2.1) and (14.2.2), the logarithm of the odds ratio for i th and k th subjects is P N log G/(1 9 PG) : b P H( xGH 9 xIH) (14.2.11) I/(1 9 PI) H Thus, an estimate of the odds ratio can be obtained by replacing bH in (14.2.11) with its MLE, b H.

From the estimated regression equation, a predicted probability of success can be computed by substituting the values of the risk factors in the equation.

Using these predicted probabilities, a goodness-of-fit test can be performed to test the hypothesis that the model fits the data adequately. Several such tests are available (Lemeshow and Hosmer, 2000): for example, the Pearson chi-square test, the Hosmer  Lemeshow (Hosmer and Lemeshow, 1980) test, a test statistic suggested by Tsiatis (1980), and the score of Brown (1982). In the following, we introduce the HosmerL emeshow test.

389 Let pG be the estimate of PG obtained from the fitted logistic regression equation for the i th subject, i : 1, . . . , n. The pGs can be arranged in ascending order from smallest to largest. Those probabilities and the corresponding subjects are then divided into g groups according to some cutoff points of the probability. For example, let g : 10 and the cutoff points of the probability be equal to k/10, k : 1, 2, . . . , 10. Thus, the first group contains all subjects whose estimated probabilities are less than or equal to 0.1, the second group contains all subjects whose estimated probabilities are less than or equal to 0.2, and so on. Let nI be the number of subjects in the k th group. The estimated expected number of successes for the k th group is LI EI: pH k : 1, 2, . . . , g H The Hosmer  Lemeshow test statistic is defined as E ( O C : I 9 EI) (14.2.12) I nIp I(1 9 p I) where OI is the observed number of successes in the k th group and p I is the average estimated probability of the k th group, that is, LI p I: 1 p n H I H Under the null hypothesis that the model is adequate, the distribution of C in (14.2.12) is well approximated by the chi-square distribution with g 9 2 degrees of freedom. The test is basically a chi-square test of the discrepancy between the observed and predicted frequencies of success. Thus, a C value larger than the 100 percentage point of the chi-square distribution (or p value less than ) indicates that the model is inadequate.

Similar to other chi-square goodness-of-fit tests, the approximation depends on the estimated expected frequencies being reasonably large. If a large number (say, far more than 20%) of the expected frequencies are less than 5, the approximation may not be appropriate and the p value must be interpreted carefully. If this is the case, adjacent groups may be combined to increase the estimated expected frequencies. However, Hosmer and Lemeshow warn that if fewer than six groups are used to calculate C, the test would be insensitive and would almost always indicate that the model is adequate.

Most statistical software packages provide programs for logistic regression analysis: for example, SAS (procedures LOGISTIC, PHREG, and CATMOD), BMDP (procedures LR and PR), and SPSS (procedures NOMREG, PROBIT, PLUM, and LOGISTIC). Most of them provide estimates of the coefficients and test statistics, variable selection procedures, and tests of goodness of fit.

390         Example 14.4 In a study of 238 non-insulin-dependent diabetic patients, 10 covariates are considered possible risk factors for proteinuria (the outcome variable). The logistic regression method is used to identify the most important risk factors and to predict the probability of proteinuria on the basis of these risk factors. The 10 potential risk factors are age, gender (1, male; 2, female), smoking status (0, no; 1, yes), percentage of ideal body mass index, hypertension (0, no; 1, yes), use of insulin (0, no; 1, yes), glucose control (0, no; 1, yes), duration of diabetes mellitus (DM) in years, total cholesterol, and total triglyceride. Among the 238 patients, 69 have proteinuria ( yG:1).

Using the stepwise procedure in BMDP, it is estimated that at step 1, the model contains only b and b: 90 . 896 and l( b) in (14.2.5) is 9143.292. At step 2, duration of diabetes is added to the model because its maximum log-likelihood value is the largest among all the covariates. The MLEs of the two coefficients are b:91 . 467 and b:90 . 055, and l( b, b) :9139.429.

Since X*:92[ l( b) 9 l( b, b)] : 7 . 726 which is significant ( p : 0.005), the duration of DM is related significantly to the chance of proteinuria. The Hosmer  Lemeshow test statistic for goodness of fit with only duration of DM in the model, C : 9.814 with 8 degrees of freedom, gives a p value of 0.278.

At step 3, gender is added to the model because its addition yields the largest maximum log-likelihood value among all the remaining covariates. The maximum log-likelihood value, l( b, b, b) :9137 . 749, b:91 . 453, b:90 . 060, and b:90 . 279. To test if gender is significantly related to proteinuria after duration of DM, we perform the likelihood ratio test X* :92[ l( b, b) 9 l( b, b, b)] :3 . 360 which is significant at p : 0.067. The stepwise procedure terminates after the third step because no other covariates are significant enough to enter the regression model; that is, none of the other covariates have a p value less than 0.15, which is set by the program (BMDP). If any covariate already in the regression becomes insignificant after some other variables are in, the insignificant variable would be removed. The p values for entering and removing a variable can be determined by the user. The default values for entering and removing a variable are, respectively, 0.10 and 0.15. Thus, the procedure identifies duration of DM and gender as the two most important risk factors based on the data given. A question that may be raised at this point is whether one should include gender in the equation since its significance level is larger than the commonly used 0.05. The recommendation is to include it since it is close to 0.05 and since the p value should not be the only basis for determining whether a covariate should be included in the model. In addition, the Hosmer  Lemeshow goodness of fit test statistic C : 5.036, when gender is       391 Table 14.3 Estimated Coefficients for a Linear Logistic Regression Model Using Data from Diabetic Patients Estimated Standard Variable Coefficient Error Coefficient/SE exp(coefficient) Constant 91.453 0.264 95.504 0.234 Duration of DM 0.060 0.020 2.956 1.062 Sex 90.279 0.152 91.836 0.756 included, yields a p value of 0.754. Thus, inclusion of this covariate improves considerably the adequacy of the model. Thus, the final regression equation with the two significant risk factors is P log G : 91 . 453 ; 0 . 060 (duration of DM) 9 0.279 (gender) 1 9 PG Table 14.3 gives the details for the estimated coefficients.

The signs of the coefficients indicate that male patients and patients with a longer duration of diabetes have a higher chance of proteinuria. Furthermore, for each increase of one year in duration of diabetes, the log odds increase by 0.060. Probabilities of proteinuria can be estimated following (14.2.1). For example, the probability of developing proteinuria for a male patient who has had diabetes for 15 years is e\ P : : 0 . 303 1 ; e\ where 90.832 is obtained by substituting the values of the two covariates in the fitted equation; that is, 91.453;0.060(15)90.279(1) : 90.832. Similarly, for a female patient who has the same duration of diabetes, the probability is 0.248.

In addition to individual variables, interaction terms can be included in the logistic regression model. If the association between an independent variable x and the dependent variable y is not the same in different levels of another variable, x, there is interaction between x and x. To check if there is interaction, one can include the product of x and x in the regression model and test the significance of this new variable. The following example illustrates the procedure.

Example 14.5 It is well known that adriamycin is effective for treating certain types of cancer. It is also well known that adriamycin is highly toxic.

392         Some patients develop congestive heart failure (CHF), but others who receive a similar dose of adriamycin do not. In an attempt to detect factors that would increase the risk of developing adriamycin cardotoxicity, various patient characteristics of 53 cancer patients were studied. Seventeen of these patients developed CHF and 36 patients did not. After a careful investigation, it was found that the total dose ( z) and percentage decrease in electrocardiographic QRS voltage ( z) are most closely related to CHF. Table 14.4 shows the data and some summary statistics. The following linear logistic regression model with transformed variables z: z 9 z and x: z 9 z is used: p : log : b 1 9 p ; b x ; b x ; b x x The stepwise procedure selects percentage decrease in QRS as the most important variable, followed by the total dose (TD) and interaction (TD;QRS). The logistic regression analysis results are given in Table 14.5.

The stepwise log-likelihood values given in the last column indicate that only QRS is significant since 2(910.185 ; 33.254) : 46.138, which yields a p value less than 0.001. Neither the total dose nor the interaction is significant.

Suppose that the last three columns of Table 14.4, Y, Z1, and Z2, are stored in a text data file C:EX14d2d2.DAT, separated by a space. The following SAS, SPSS, or BMDP codes can be used to obtain the results in Table 14.5.

SAS code: data w1; infile c:ex14d2d2.dat missover; input y z1 z2; x1 : z1-517.679; x2 : z2-26.019; x12 : x1*x2; run; proc logistic data : w1 descending; model y : x1 x2 x12/ selection : s plcl plrl lackfit; run; SPSS code (forward selection method): data list file : c:ex14d2d2.dat free / y z1 z2.

Compute x1 : z1-517.679.

Compute x2 : z2-26.019.

Compute x12 : x1*x2.

Logistic regression y with x1 x2 x12 /method : fstep /print : all.

393 Table 14.4 Total Dose and Percent Decrease in QRS of 53 Patients Receiving Adriamycin Total Percent Decrease Patient CHF ? , y Dose, z in QRS, z 1 1 435 41 2 1 600 71 3 1 600 51 4 1 540 40 5 1 510 63 6 1 740 79 7 1 825 61 8 1 535 44 9 1 510 53 10 1 483 27 11 1 460 53 12 1 460 60 13 1 550 65 14 1 540 58 15 1 310 41 16 1 500 64 17 1 400 44 18 0 440 9 19 0 600 42 20 0 510 19 21 0 410 24 22 0 540 924 23 0 575 39 24 0 564 35 25 0 450 10 26 0 570 6 27 0 480 6 28 0 585 21 29 0 420 14 30 0 470 1 31 0 540 33 32 0 585 33 33 0 600 4 34 0 570 2 35 0 570 5 36 0 510 12 37 0 470 91 38 0 405 44 39 0 575 14 40 0 540 910 41 0 500 943 42 0 450 23 43 0 520 91 ( Continued overleaf ) 394         Table 14.4 Continued Total Percent Decrease Patient CHF ? , y Dose, z in QRS, z 44 0 495 29 45 0 585 40 46 0 450 30 47 0 450 23 48 0 500 12 49 0 540 911 50 0 440 7 51 0 480 922 52 0 550 20 53 0 500 19 Source: Minow et al. (1977).

? 1, yes; 0, no; z:517 . 679, z:26 . 019 .

BMDP codes for procedure LR: /input file : c:ex14d2d2.dat .

variables : 3.

format : free.

/variable names : y, z1, z2.

/transform x1 : z1-517.679.

x2 : z2-26.019.

x12 : x1*x2.

/regress depend : y.

Interval : x1, x2, x12.

Model : x1, x2, x12.

Start : in, in, in.

Move : 0, 0, 0.

Table 14.5 Linear Logistic Regression Analysis Results of Data in Table 14.4 Estimated Standard Variable Coefficient Error Coefficient/SE Log Likelihood Constant 93.757 1.576 92.384 933.254 QRS 0.254 0.102 2.480 910.185 TD 90.024 0021 91.160 99.225 TD;QRS 0.001 0.001 0.677 98.803       395 Method : mlr.

/print cell : used.

/end When the independent variables are dichotomous or polychotomous, the logistic regression coefficients can be linked with odds ratios. Consider the simplest case, where there is one independent variable, x, which is either 0 or 1. The linear regression model in (14.2.1) and (14.2.2) becomes eb; b x P( y : 1 x) :1; eb; b x P( y : 0 x) : 1 1 ; eb; b x Values of the model when x:0, 1 are eb P( y : 1 x:0) :1; eb eb; b P( y : 1 x :1) :1; eb; b P( y : 0 x :0) : 1 1 ; eb P( y : 0 x :1) : 1 1 ; eb; b The odds ratio in (14.1.4) is P( y : 1 x eb; b OR : : 1) /P( y : 0 x : 1) : : eb P( y : 1 x: 0) /P( y:0 x:0) eb and the log odds ratio is log(OR) : log( eb) : b [this can also be derived directly from (14.2.11)]. Thus, the estimated logistic regression coefficient also provides an estimate of the odds ratio, that is, OR : eb. If ( b *, b 3) is the confidence interval for b, the corresponding interval for OR is ( eb *, eb 3).

Example 14.6 Consider the age ( x) and response ( y) data from the 71 leukemia patients presented in Table 14.6 (Examples 14.1 and 14.2). The logistic regression analysis results are given in Table 14.7. Notice that exp( b) :exp(1.5994):4.95, which is equal to the estimate of OR obtained in Example 14.2 using (14.1.5), and the standard error of b is the same as that of log OR except for a small rounding-off error. The confidence interval for OR can also be obtained from the logistic regression analysis results.

396         Table 14.6 Age and Response Data of 71 Leukemia Patients Response x 50(1) x 50(0) Total Yes (1) 27 10 37 No (0) 12 22 34 Total 39 32 71 Table 14.7 Results of Logistic Regression Analysis of Data in Table 14.6 Estimated Standard Variable Coefficient Error Coefficient/SE exp(coefficient) Constant ( b) 90 . 7885 0 . 3814 92 . 067 0 . 45 Age( b) 1.5994 0.5156 3.102 4.95 The relationship between the logistic regression coefficient and odds ratio can be extended to polychotomous variables by creating dummy variables (or design variables). The following example illustrates the procedure.

Example 14.7 Consider the data in Example 14.3. The variable marrow absolute infiltrate (MAI) has three levels. As in Example 14.3, the 45% level is considered as the reference group. In this case, two design variables will be used and their values are assigned as follows: D :1 if MAI:46  90% D 0 otherwise : 1 if MAI90% 0 otherwise For MAI, the design variable values and the respective number of responders (Event) and total number of patient in each MAI level (N) are listed in the following table.

MAI(%) D D Event N 45 0 0 4 16 46  90 1 0 20 39 90 0 1 13 16 Using these design variables, the logistic regression analysis gives the results in Table 14.8.

397 Table 14.8 Results of Logistic Regression Analysis of Data in Example 14.7 and Two Design Variables Estimated Standard Variable Coefficient Error Coefficient/SE exp(coefficient) Constant 91.0986 0.5774 91.903 0.33 MAI ( D) 1.1499 0.6603 1.742 3.16 MAI ( D) 2.5649 0.8623 2.974 13.00 The coefficient corresponding to D, 1.1499, is the log odds ratio between the 46  90% group and the 45% group. The odds ratio is exp(1.1499) : 3.16, which is exactly equal to the estimate obtained in Example 14.3. Similarly, the coefficient corresponding to D is the log odds ratio between the 90% group and the 45% group. The odds ratio obtained from the regression coefficient, 13.00, is the same as that obtained in Example 14.3.

The estimated standard error for D, 0.6603, is also the standard error of log OR . A 95% confidence interval for the coefficient is 1.1499 < 1.96(0.6603), or (90.1443, 2.4441), and consequently, a 95% confidence interval for OR is ( e\, e), or (0.86, 11.52), which is identical to that obtained in Example 14.3 using Woolfs estimate of SE(log OR).

Suppose that the data in Example 14.6 are arranged in four columns for D, D, Event, and N as in the table above and are saved in a text data file C:EX14d2d4.DAT. The values of D, D, Event, and N in each row are separated by a space. The following SAS, SPSS, or BMDP codes can be used to obtain the results in Table 14.8.

SAS code: data w1; infile c:ex14d2d4.dat missover; input d1 d2 event n; run; proc logistic data : w1 ; model event/n : d1 d2 / plcl plrl; run; SPSS code: data list file : c:ex14d2d4.dat free / d1 d2 event n.

Probit event OF n WITH d1 d2 /model : logit /log : 2.718 /print : all.

398         BMDP code for procedure LR: /input file : c:ex14d2d4.dat .

variables : 4.

format : free.

/variable names : d1, d2, event, n.

/regress count is n.

fcount is event.

Interval : d1, d2.

/print cell : used.

/end For a continuous independent variable, the logistic regression coefficient gives the change in log odds for an increase of 1 unit in the variable. In general, for an increase of m units in the variable, the log odds ratio is equal to m times the logistic regression coefficient. The derivation is left to the reader as an exercise.

When more than one independent variable is included in the logistic regression model, each estimated coefficient can be interpreted as an estimate of the log odds ratio statistically adjusting for all the other variables. For example, in Example 14.4, the regression coefficient for the gender variable, 90.279, is an estimate of the log odds ratio for females versus males, adjusting for duration of diabetes. Or the adjusted odds ratio for females versus males is estimated as exp(90.279) : 0.76; suggesting that female diabetic patients have a lower risk of having proteinuria than that of male patients, after adjusting for duration of diabetes. This interpretation, commonly used by epidemiologists, is appropriate if the linear relationship between the log odds and the independent variables holds.

Press and Wilson (1978) compare the logistic regression method to the discriminant analysis and find that if the independent variables are normal with identical covariance matrices, discriminant analysis is preferred. Under abnormality, the logistic regression method is preferred. In particular, if the independent variables are dichotomous, we cannot expect to predict accurately the probability of success with a discriminant function, even with a large amount of data. Their examples show that the logistic regression gives a higher correct classification rate.

14.2.2 Logistic and Conditional Logistic Regression Model for Retrospective Studies As mentioned earlier, the logistic regression model defined in (14.2.3) is originally designed for prospective studies, where a set of covariates or independent variables are measured at a baseline examination on a group of people without the disease of interest. These subjects are then followed for a period of time and development of the disease among them are recorded during       399 follow-up. The model can be extended to analyze data from retrospective studies, such as a case  control study. In a casecontrol study, cases (subjects with the disease of interest) and controls (subjects without the disease) are first selected and risk factor data such as exposure variables and other covariates are collected retrospectively. For example, in a case  control study of lung cancer and cigarette smoking, a group of lung cancer patients and a group of people without lung cancer are selected. Their smoking histories are then collected along with other risk factors. Therefore, in a case  control study, participants are selected first based on their disease status, and their history of risk factor exposures is collected later. The purpose of a case  control study is to estimate the association between the risk factors and the disease under study. Using probability terms, we are dealing with the probability that the risk factors take on certain values given that a person is a case or a control. We denote this conditional probability by P(x y), where x denote the covariates and y the outcome variable. Using the same notation, the probability of interest in a prospective study is P( y x). Based on conditional probability theory, P(x y) can be written as P(x y) : P( y x) P(x) (14 . 2 . 13) P( y) where y : 1 for cases and 0 for controls. Thus, P(x y) is a function of P( y x), P(x), and P( y) .

The likelihood function of the logistic regression model for a retrospective study, similar to (14.2.4), is the product of terms in the form of P(x y) in (14.2.13) for the cases and controls selected [( P(x y : 1) from a case and P(x y : 0) from a control)]. We introduce here two most widely used approaches to this likelihood function. One approach considers the probability of case/control selection. Since in case  control studies, the cases and controls are selected from the population and the likelihood function is based on subject selection, we introduce an indicator variable to denote whether a person is selected ( s : 1) or is not selected ( s : 0). Let n and n be, respectively, the numbers of selected cases and controls in the study. The likelihood function is L L L : P(x G yG:1, s:1) P(x G yG:0, s :1) (14 . 2 . 14) G G Define : P( s :1 y:1) to be the probability that a diseased person is selected for the study as a case and : P( s :1 y:0) 400         to be the probability that a disease-free person is selected for the study as a control. Assume that the sampling probabilities depend only on disease status and not on the covariates. Using Bayes theorem in probability theory and (14.2.1), it can be shown (the derivation is left to the reader as an exercise) that the probability that a person is diseased given that he or she has risk factors x and was selected for the study can be written as P( yG:1 x G, s:1) : exp( b*; NH bHxGH) (14.2.15) 1 ; exp( b* ; NH bHxGH) where b* : b ; log ( 14.2.16) According to the conditional probability in (14.2.13), the first term in the likelihood function in (14.2.14) is P( x G yG :1, s: 1) : exp( b*; NH bHxGH) P(x G s:1) (14 . 2 . 17) 1 ; exp( b* ; NH bHxGH) P( y:1 s:1) Similarly, the second term in (14.2.14) for yG:0 can be obtained: P(x G yG : 0, s:1) : 1 P(x G s:1) (14 . 2 . 18) 1 ; exp( b*; NH bHxGH) P( y :0 s:1) Substituting (14.2.17) and (14.2.18) into (14.2.14), we obtain the likelihood function for a case  control study: L P(x L G s : 1) : L ( b*, b, . . . , bN); (14 . 2 . 19) G P( y s : 1) where n : n; n, L ( b*, b, . . . , bN) is the likelihood function for prospective studies in (14.2.4) except that the intercept term b is replaced by b* in (14.2.16). If we assume that the probability distribution of the covariates, P(x), contains no information about the parameters of interest, or P(x) is independent of the coefficients bH, and the selection is independent of x, then maximizing L to obtain estimates of bH is equivalent to maximizing only L ( b*, b, . . . , bN) since P( y:1 s :1) : n /n and P( y:0 s:1) : n /n. This implies that we can use the computer program for prospective studies to analyze case  control study data except that the intercept term cannot be interpreted meaningfully unless and are known.

In most practical situations, the assumption made above about P(x) is reasonable. Historically, in early applications of the logistic regression method, the covariates were assumed to have multivariate normal distribution. Then       401 estimation of the coefficients, bH in (14.2.19), would involve the distribution P(x) and thus became much more complicated. However, in practice, many of the covariates are categorical or discrete and are therefore distinctly nonnormal.

Thus, it is appropriate to allow P(x) to remain completely arbitrary and use simply L ( b* , b, . . . , bN) in (14.2.19) in case  control studies.

Another approach to the likelihood function based on (14.2.13) is to consider a conditional probability instead. Suppose that n cases and n controls were selected in a case  control study and n : n; n; let x, x, . . . , x L be the risk factor sets of the n subjects without specifying which of them pertain to the cases and which to the controls. Then the conditional probability that the first n xs are observed from the n cases and the remainder are from the n controls may be written as L G P(x G y : 1) LG L > P(x G y : 0) (14 . 2 . 20) y : 1) L y : 0)) l, ... , lL ( L G P(x JG G L > P(x JG where the summation in the denominator is over the n! /( n! n!) possible ways of selecting n individuals as cases from the n subjects, with the remaining n as controls. By using (14.2.13) and (14.2.1), (14.2.20) reduces to L G exp( NH bHxGH) ( 14.2.21) l, ... , lL L G exp( NH bHxJGH) Comparing with (12.1.17), (14.2.21) can be considered as a special case of (12.1.17) in which there is only one distinct uncensored failure time, say at t : 1, and all of the n persons failed at t: 1. The remaining n subjects survive longer than 1 and are censored, say at t : 2, while all n subjects are at risk at t : 1. This interpretation of (14.2.21) permits us to apply the method and computer software for the Cox proportional hazards model with a discrete time scale and ties to obtain an estimate of b in the logistic regression model and to perform the corresponding inferences. The procedure is illustrated in Example 14.8. When n and n are large enough, it can be shown that an analysis based on this conditional probability will produce results equivalent to those based on the likelihood function defined in (14.2.19) (Efron, 1975; Farewell, 1979; Breslow and Day, 1980). When n and n are large, one may prefer using (14.2.19) to (14.2.21) since the former is easier. However, for a case  control study with a matched or stratified design, analysis based on the conditional probability defined in (14.2.21) is a better choice than (14.2.19) (Efron, 1975; Farewell, 1979; Breslow and Day, 1980). In the following section we discuss the application of logistic regression analysis for two widely accepted matched designs in case  control studies.

1 : R Matched Design A widely used case  control design is to have one or more controls matched 402         for each case based on matching variables such as age and gender. Suppose that for each case there are R( 1) matched controls. Let xGHI denote the observed value of the j th covariate ( j : 1, . . . , p) from the k th subject ( k : 1 for the case and k : 2, . . . , R ; 1 for matched controls) in the i th matched set ( i : 1, . . . , n). The n matched sets are considered as the samples from the n different strata defined by the matching variables. Following (14.2.21) with n:1 and n: R, the conditional probability for the matched set (1 case and R controls) in the i th stratum is exp( NH bHxGH) : 1 exp( NH bHxGH) ; 0> I exp( NH bHxGHI) 1 ; 0> I exp[ NH bH( xGHI 9 xGH)] (14.2.22) and thus the conditional likelihood function for all n strata is the product of the n terms in (14.2.22), that is, L 1 (14 . 2 . 23) G 1 ; 0> I exp[ NH bH( xGHI 9 xGH)] When R : 1, that is, a one-to-one pair matching, the conditional likelihood function obtained from (14.2.23) reduces to L 1 L ( b, . . . , bN): G 1;exp[ NH bH( xGH 9 xGH)] L : exp[ NH bH( xGH 9 xGH)] (14 . 2 . 24) G 1;exp[ NH bH( xGH 9 xGH)] Compared with the likelihood function for the ordinary logistic regression in (14.2.4), the conditional likelihood function (14.2.24) can be treated as a special case of (14.2.4) with yGY 1, b Y 0, and xGH can be replaced by the difference in xGH between the case and its matched control. This fact permits the use of computer programs for ordinary logistic regression in one-to-one matched case  control studies. The procedure is as follows: 1. Let n be the number of case  control pairs.

2. Use xGH 9 xGH, the difference between covariates for the case ( xGH) and its matched control ( xGH), as the independent variable in the model.

3. Let yG Y 1 for all pairs.

4. Delete the intercept term b from the model.

403 n : n Matched Design or Stratified Design 1 0 Suppose that there are n cases and n controls in the i th stratum and n : n; n. Let xGHI denote the observed value of the j th covariate ( j : 1, . . . , p) from the k th subject ( k : 1, 2, . . . , n for the n cases and k : n;1, . . . , n for the n controls) in the i th stratum ( i :1, . . . , m). From (14.2.21), the contribution of the i th stratum to the conditional likelihood function is L I exp( NH bHxGHI) (14.2.25) ) k, ... , kL L J exp( NH bHxGHIJ where the summation in the denominator is over all the n!/( n! n!) possible ways to select n out of the n subjects as cases and the remaining n as controls.

The term in (14.2.25) has the same mathematical form as (14.2.21). Thus, as discussed earlier, the computer software for the proportional hazards model can be used to estimate the coefficients.

In both 1 : R and n: n matched designs, most of the other features in the ordinary logistic regression model fitting, including the use of design (dummy) variables and statistical inferences, remain the same. However, the goodness of fit test of Hosmer and Lemeshow is not applicable to matched designs. Readers who are interested in assessing the logistic regression model in matched case  control studies are referred to Pregibon (1984) and Moolgavkar et al.

(1985).

The following example illustrates the basic procedure for the one-to-one matched design using (14.2.24).

Example 14.8 To study the effect of obesity, family history of diabetes, and level of physical activity to non-insulin-dependent diabetes (NIDDM), 30 nondiabetic persons are matched with 30 NIDDM patients by age and gender.

Obesity is measured by body mass index (BMI), which is defined as weight in kilograms divided by height in meters squared. Family history of diabetes (FH) and levels of physical activity (PHY) are binary variables. Table 14.9 gives the partially fictitious data. Following the procedure given above, the results of fitting the three variables using BMDP are given in Table 14.10.

Suppose that text data file C:EX14d2d5.DAT contains six successive columns of data: BMIC, FHC, PHYC, BMIN, FHN, and PHYN, as in Table 14.9, separated by a space. The following SAS, SPSS, or BMDP code can be used to generate the results in Table 14.10.

SAS code: data w1; infile c:ex14d2d5.dat missover; input bmic fhc phyc bmin fhn phyn; bmi : bmic-bmin; 404         Table 14.9 Data of 30 Matched Case--Control Pairs Case (Diabetic) Control (Nondiabetic) Pair BMI FH ?

PHY @ BMI FH ?

PHY @ 1 22.1 1 1 26.7 0 1 2 31.3 0 0 24.4 0 1 3 33.8 1 0 29.4 0 0 4 33.7 1 1 26.0 0 0 5 23.1 1 1 24.2 1 0 6 26.8 1 0 29.7 0 0 7 32.3 1 0 30.2 0 1 8 31.4 1 0 23.4 0 1 9 37.6 1 0 42.4 0 0 10 32.4 1 0 25.8 0 0 11 29.1 0 1 39.8 0 1 12 28.6 0 1 31.6 0 0 13 35.9 0 0 21.8 1 1 14 30.4 0 0 24.2 0 1 15 39.8 0 0 27.8 1 1 16 43.3 1 0 37.5 1 1 17 32.5 0 0 27.9 1 1 18 28.7 0 1 25.3 1 0 19 30.3 0 0 31.3 0 1 20 32.5 1 0 34.5 1 1 21 32.5 1 0 25.4 0 1 22 21.6 1 1 27.0 1 1 23 24.4 0 1 31.1 0 0 24 46.7 1 0 27.3 0 1 25 28.6 1 1 24.0 0 0 26 29.7 0 0 33.5 0 0 27 29.6 0 1 20.7 0 0 28 22.8 0 0 29.2 1 1 29 34.8 1 0 30.0 0 1 30 37.3 1 0 26.5 0 0 ? 1, yes; 0, no.

@ 1, physically active; 0, sedentary.

fh : fhc-fhn; phy : phyc-phyn; y : 1; run; proc logistic data : w1; model y : bmi fh phy / noint plcl plrl lackfit; run;       405 Table 14.10 Results of a Logistic Regression Analysis of Data in Table 11.13 Estimated Estimated Variable Coefficient Standard Error Coefficient/SE exp(coefficient) BMI 0.090 0.065 1.381 1.094 FH 0.968 0.588 1.646 2.633 PHY 90.563 0.541 91.041 0.569 SPSS code: data list file : c:ex14d2d5.dat free / bmic fhc phyc bmin fhn phyn.

Compute bmi : bmic-bmin.

Compute fh : fhc-fhn.

Compute phy : phyc-phyn.

Compute y : 1.

Logistic regression y with bmi fh phy /origin /print : all.

BMDP LR code: /input file : c:ex14d2d5.dat .

variables : 6.

format : free.

/variable names : bmic, fhc, phyc, bmin, fhn, phyn.

/transform bmi : bmic-bmin.

fh : fhc-fhn.

phy : phyc-phyn.

y : 1.

/regress depend : y.

Interval : bmi, fh, phy.

Model : bmi, fh, phy.

Start : in, in, in.

Constant : out.

Move : 0, 0, 0.

Method : mlr.

/print cell : used.

/end The following example illustrates the estimating procedures for the 1 : R and n: n matched case  control designs.

Example 14.9 Table 14.11 lists a subset of simulated data from a case  control diabetes study that is based on a cohort study of heart disease with a 406         Table 14.11 A Subset of Age-Group and Gender-Matched DM Data in Example 14.9 ?

AGE AGEG SEX SBP DBP LACR HDL LINSUL SMOKE DMS DM SN 51.8 50 1 148 91 1.35 37 2.81 0 1 0 1 50.9 50 1 116 95 1.04 43 2.74 0 1 0 1 50.9 50 1 114 85 1.26 64 1.98 1 1 0 1 50.9 50 1 120 80 1.56 52 2.53 1 1 0 1 54.6 50 1 119 71 1.55 30 2.87 0 2 0 1 50.8 50 1 123 78 1.40 33 3.31 0 2 0 1 53.3 50 1 119 75 1.69 40 2.13 1 3 1 1 72.0 70 0 129 73 1.06 25 2.69 0 1 0 2 73.1 70 0 120 68 0.87 30 2.76 0 1 0 2 72.8 70 0 111 66 2.52 73 3.17 0 2 0 2 70.3 70 0 115 65 3.16 42 2.96 0 2 0 2 72.1 70 0 140 66 3.18 52 3.48 0 2 0 2 72.8 70 0 136 72 3.36 59 3.22 0 2 0 2 71.1 70 0 133 85 2.95 73 3.25 0 3 1 2 56.4 55 1 110 74 0.58 43 2.18 0 1 0 3 55.7 55 1 122 77 1.18 34 2.76 1 1 0 3 56.9 55 1 114 74 1.10 25 2.62 0 1 0 3 58.5 55 1 104 74 1.24 23 2.58 0 1 0 3 55.2 55 1 128 77 1.25 43 2.77 0 2 0 3 55.9 55 1 130 83 1.34 44 2.34 1 2 0 3 57.4 55 1 116 79 2.23 38 2.46 1 3 1 3 60.7 60 0 136 85 2.04 42 3.66 0 1 0 4 62.0 60 0 115 74 1.32 33 2.85 0 1 0 4 64.7 60 0 155 89 2.55 46 3.73 1 1 0 4 64.4 60 0 191 107 3.66 34 2.67 1 2 0 4 60.5 60 0 109 74 0.89 64 2.88 0 2 0 4 62.4 60 0 106 72 0.88 35 3.44 1 2 0 4 62.8 60 0 234 91 7.28 49 2.38 1 3 1 4 73.2 70 0 119 72 1.00 47 2.53 0 1 0 5 73.0 70 0 128 70 2.87 51 2.62 0 1 0 5 72.2 70 0 124 69 1.43 33 2.49 0 1 0 5 73.7 70 0 128 72 2.12 38 3.30 0 2 0 5 71.7 70 0 111 68 3.16 64 3.14 0 2 0 5 71.2 70 0 104 67 3.00 40 3.30 0 2 0 5 74.5 70 0 140 82 2.84 46 2.95 1 3 1 5 58.2 55 0 112 77 2.84 71 2.23 0 1 0 6 57.3 55 0 111 77 2.23 41 2.57 0 1 0 6 58.7 55 0 120 76 1.85 60 2.57 0 1 0 6 57.2 55 0 120 73 0.55 48 3.10 0 2 0 6 57.2 55 0 112 73 0.49 45 2.86 0 2 0 6 55.5 55 0 120 73 90.53 49 3.12 0 2 0 6 59.5 55 0 156 76 3.22 59 3.14 1 3 1 6 78.4 75 0 119 75 1.28 53 1.72 1 1 0 7 77.8 75 0 112 74 1.39 44 1.80 1 1 0 7 75.5 75 0 123 74 1.41 72 1.93 0 1 0 7 78.3 75 0 149 84 0.53 40 2.84 0 1 0 7       407 Table 14.11 Continued AGE AGEG SEX SBP DBP LACR HDL LINSUL SMOKE DMS DM SN 76.9 75 0 153 75 3.78 43 2.95 0 2 0 7 75.4 75 0 144 77 4.57 45 2.54 0 2 0 7 77.9 75 0 156 86 5.38 39 3.34 0 3 1 7 68.0 65 0 123 70 1.62 48 2.49 0 1 0 8 66.2 65 0 131 72 1.71 56 2.47 0 1 0 8 65.8 65 0 136 80 3.82 56 2.84 1 1 0 8 68.8 65 0 120 66 2.20 45 2.45 0 1 0 8 68.0 65 0 162 60 2.35 62 3.86 0 2 0 8 67.9 65 0 115 54 2.33 39 3.92 0 2 0 8 67.8 65 0 132 79 2.68 42 2.47 0 3 1 8 63.1 60 1 123 80 1.81 46 1.93 1 1 0 9 61.3 60 1 122 78 1.41 85 1.88 0 1 0 9 60.8 60 1 131 83 2.43 31 1.90 1 1 0 9 61.8 60 1 109 69 1.27 61 2.35 1 2 0 9 63.1 60 1 114 73 1.04 38 2.53 0 2 0 9 60.7 60 1 130 76 0.84 46 2.59 0 2 0 9 62.2 60 1 133 85 2.10 37 3.04 0 3 1 9 78.7 75 0 147 85 0.48 58 2.62 0 1 0 10 77.4 75 0 167 84 0.92 71 2.66 0 1 0 10 78.0 75 0 165 85 0.44 49 3.02 0 1 0 10 75.2 75 0 117 70 2.05 42 2.88 0 2 0 10 77.8 75 0 151 75 4.27 41 2.76 0 2 0 10 78.5 75 0 137 74 2.13 40 2.86 0 2 0 10 78.5 75 0 156 81 5.33 52 327 0 3 1 10 56.5 55 0 108 71 1.58 41 2.27 0 1 0 11 58.8 55 0 104 73 2.55 34 2.53 0 1 0 11 55.7 55 0 135 77 2.06 106 2.32 1 1 0 11 57.8 55 0 110 74 2.59 49 2.37 0 1 0 11 57.3 55 0 153 91 0.54 44 3.13 0 2 0 11 55.4 55 0 141 94 1.47 61 3.15 0 2 0 11 56.9 55 0 123 78 3.72 40 3.18 0 3 1 11 53.3 50 0 113 74 1.19 46 2.71 0 1 0 12 50.8 50 0 143 89 3.45 78 1.84 0 1 0 12 50.3 50 0 136 79 91.44 48 2.48 1 2 0 12 55.0 50 0 131 77 0.23 49 2.57 1 2 0 12 54.4 50 0 132 77 90.08 34 2.45 0 2 0 12 53.3 50 0 135 77 0.48 37 2.93 1 2 0 12 50.7 50 0 114 78 2.52 41 4.37 0 3 1 12 ? AGEG : 50 if 50age55, :55 if 55age60, :60 if 60age65, :65 if 65age70, :70 if 70age75, :75 if 75age80; SEX : 1 if male and :0 if female; SMOKE : 1 if current smoker and 0 otherwise; SBP, systolic blood pressure; DBP, diastolic blood pressure; LACR, logarithm of the ratio of urinary albumin and creatinine; HDL, high-density lipoprotein in cholesterol; LINSUL, logarithm of insuline; DM : 1 if fasting glucose 126 mg/dL and :0 otherwise; DMS, diabetic status defined by ADA fasting glucose criterion: DMS : 1 if normal fasting glucose, :2 if impaired fasting glucose, and :3 if diabetic; SN, stratum number.

408         Table 14.12 Results from the Conditional Logistic Regression Model for the DM Data in Example 14.9 95% Confidence Interval for Odds Ratio Regression Standard Chi-Square Odds Variable Coefficient Error Statistic p Ratio Lower Upper AGE 0.327 0.161 4.127 0.0422 1.39 1.01 1.90 DBP 0.046 0.020 5.639 0.0176 1.05 1.01 1.09 LACR 0.395 0.133 8.776 0.0031 1.48 1.14 1.93 LINSUL 0.860 0.288 8.900 0.0029 2.36 1.34 4.16 baseline and second examinations (about five years after the baseline examination). In this study, 33 persons with diabetes at the second examination are selected, and for each of these cases, six age group (in five-year interval)- and gender-matched diabetes-free controls are selected randomly from all participants without diabetes in the second examination. There are 33 strata and each stratum contains one case (DM : 1) and its six matched controls (DM : 0), for a total of 231 participants. The demographic, physical, blood, and urinary data collected at the baseline examination of the first 12 strata are listed in Table 14.11 and arranged by stratum. The conditional logistic model based on (14.2.20) is used for these 1:6 matched data to identify risk factors for diabetes.

The stepwise selection method is used to select the significant risk factors. The results are shown in Table 14.12. AGE, DBP, LACR, and LINSUL are significant risk factors for diabetes. The larger the values of AGE, DBP, LACR, and LINSUL, the higher is the risk of being diabetic.

As noted earlier, for (14.2.21), the computer software for a Cox proportional model with discrete time scale can be used to obtain an estimate of parameter b. Suppose that the text data file C:EX14d2d6.DAT contains 12 successive columns, separated by a space, with data as in Table 14.11: AGE, AGEG, SEX, SBP, DBP, LACR, HDL, LINSUL, SMOKE, DMS, DM, and SN. The following SAS code shows how the SAS procedure for the proportional hazards model with discrete time scale can be used to obtain an estimate of parameter b for the conditional logistic regression model in a matched case  control study (the results are given in Table 14.12). In the SAS code, first, we define a nominal variable (for survival time), TIME, and let TIME : 1 if a case (DM : 1), and : 2 if a control (DM : 0). This is accomplished by the statement time : 2-dm;. Second, DM is also used to indicate censoring status, DM : 0 meaning censored, and : 1 uncensored. Thus, a case will have an uncensored time 1 and a control will have a censored time 2.

data w1; infile c:ex14d2d6.dat missover;       409 Table 14.13 Data from Example 14.9 If Stratified by Age Group Only Number of Number of Stratum AGEG DMs Non-DMs Total 1 50  54 9 54 63 2 55  59 8 48 56 3 60  64 4 24 28 4 65  69 4 24 28 5 70  74 5 30 35 6 75  79 3 18 21      Total 33 198 231 input age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn; time : 2-dm; run; proc phreg data : w1 noprint; model time*dm(0) : age sbp dbp lacr hdl linsul smoke / ties : discrete selection : s; strata sn; run; Using the same data, if we stratify by age group only, Table 14.13 lists the number of cases and controls in each age group (stratum). This can be considered as an example of a stratified design with a different numbers of cases and controls in each stratum: stratum 1 has a 9 : 54 match, stratum 2 an 8 : 48 match, and so on. The results from the conditional logistic regression model based on this new stratification are given in Table 14.14.

Table 14.14 Results from the Conditional Logistic Regression Model for the Data in Example 14.9 with Strata Defined by Age Groups 95% Confidence Interval for Odds Ratio Regression Standard Chi-Square Odds Variable Coefficient Error Statistic p Ratio Lower Upper DBP 0.050 0.020 6.304 0.0120 1.05 1.01 1.09 LACR 0.391 0.124 9.876 0.0017 1.48 1.16 1.89 HDL 90.037 0.019 4.034 0.0446 0.96 0.93 1.00 LINSUL 0.694 0.292 5.668 0.0173 2.00 1.13 3.55 410         The following SAS code can be used to generate the results in Table 14.14.

The code can be modified to perform conditional logistic regression analysis for data from any n : n matched design or a stratified design.

data w1; infile c:ex14d2d6.dat missover; input age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn; time : 2-dm; run; proc phreg data : w1 noprint; model time*dm(0) : age sex sbp dbp lacr hdl linsul smoke / ties : discrete selection : s; strata ageg; run; 14.2.3 Other Models for Dichotomous Outcomes In the logistic regression model (14.2.3), the left side is a function of the probability of success, PG, and the right side is the linear combination of covariates. The function, called a link function, defines the relationship between the covariates and PG. In general, a link function represents the underlying biological, physical, or epidemiological relationship between the mean of the dependent variable (probability of success) and the covariates x, x, . . . , xN. In the logistic regression model the link function, say g, is the logit function of PG, that is, P g( P G G) : logit( PG) : log 1 9 PG and g( PG) is assumed to be linearly related to the covariates, that is, P N log G : b 1 9 P HxGH G H or PG : exp( .H bHxGH) (14 . 2 . 26) 1 ; exp( .H bHxGH) Two other forms of link function g( P) that assume a linear relationship with the covariates have been proposed and used in the literature. In the following, we introduce these two link functions and the corresponding regression model.

1. T he probit ( or normit) function. This is the link function defined by the inverse of the cumulative standard normal distribution function, \(  ): g( PG) :\( PG) (14 . 2 . 27)       411 The corresponding model is N \( PG) : bHxGH H or PG: . bHxGH (14.2.28) H 2. The complementary log-log link function. This function is defined by g( PG) :log[9log(19 PG)] (14.2.29) The corresponding model is N log[9log(1 9 PG)] : bHxGH H or PG:1 9exp 9exp . bHxGH (14 . 2 . 30) H The logistic regression model in (14.2.26) is for binary outcomes such as diseased versus nondiseased. The model (14.2.28) can be thought of as an alternative model for binary outcome. In addition, it can be used to model those binary outcomes that are defined by a cutoff point on the basis of a normally distributed variable. For example, the cutoff point may be defined by the last quintile or quartile of a continuous measurement in an epidemiological study. When the binary outcomes are defined by a cutoff point in an asymmetric distribution, the model in (14.2.30) may be appropriate. The model (14.2.30) can also be considered as a version of the Cox proportional hazards model for grouped survival times (Kalbfleisch and Prentice, 1973).

Let y, y, . . . , yL be the observations with dichotomous values on the n subjects: yG :1 for success and yG :0 for failure. Similar to (14.2.4), the likelihood functions for the models in (14.2.28) and (14.2.30) can be obtained by replacing the corresponding PG in the following formula: L L ( b, b, . . . , bN) : PWGG(1 9 PG)\ WG G The MLEs of the coefficients and the asymptotic likelihood inferences are similar to those given in Section 14.2.1 for the ordinary logistic regression model except that interpretation of the odds ratio is not possible for the latter two models. The procedure LOGISTIC in SAS provides options for all three models.

412         Example 14.10 Consider the data in Example 14.9 as nonstratified data, Table 14.15 gives the results from the regression models defined in (14.2.26), (14.2.28), and (14.2.30) by using the stepwise selection method. Based on Hosmer  Lemeshow test statistics, the regression model with the inverse normal link function gives a good fit to the data ( p : 0.4956), whereas the other two models do not ( p : 0.0152 and p : 0.0261). All three models identify DBP, LACR, and LINSUL as significant covariates for the development of diabetes.

The following SAS, SPSS, and BMDP codes may be used to generate the results in Table 14.15.

SAS code: data w1; infile c:ex14d2d6.dat missover; input age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn; run; Table 14.15 Asymptotic Partial Likelihood Inference from the Regression Models with Different Link Functions for the Data in Example 14.9 95% Confidence Interval for Odds Ratio Regression Standard Chi-Square Odds Variable Coefficient Error Statistic p Ratio Lower Upper Model with L ogit L ink Function INTERCPT 98.419 1.792 22.061 0.0001 DBP 0.044 0.018 5.673 0.0172 1.05 1.01 1.08 LACR 0.343 0117 8.627 0.0033 1.41 1.13 1.79 LINSUL 0.870 0.287 9.191 0.0024 2.39 1.38 4.27 Hosmer  Lemeshow test statistic 18.9460 0.0152 Model with Inverse Normal Link Function INTERCPT 94.532 0.953 22.597 0.0001 DBP 0.023 0.010 5.302 0.0213 LACR 0.186 0.065 8.060 0.0045 LINSUL 0.445 0.156 8.146 0.0043 Hosmer  Lemeshow test statistic 7.386 0.4956 Model with Log-Log Link Function INTERCPT 97.740 1.530 25.589 0.0001 DBP 0.038 0.016 5.919 0.0150 LACR 0.305 0.096 10.153 0.0014 LINSUL 0.785 0.241 10.592 0.0011 Hosmer  Lemeshow test statistic 17.415 0.0261     413 title Regression model with the logit link function-generalized logistic regression; proc logistic data : w1 descending; model dm : age sex sbp dbp lacr hdl linsul smoke / selection : s lackfit link : logit; run; title Regression model with the inverse normal link function; proc logistic data : w1 descending; model dm : age sex sbp dbp lacr hdl linsul smoke / selection : s lackfit link : probit; run; title Regression model with the log-log link funtion; proc logistic data : w1 descending; model dm : age sex sbp dbp lacr hdl linsul smoke / selection : s lackfit link : cloglog; run; SPSS code for the model in (14.2.28) with the forward selection method: data list file : c:ex14d2d6.dat free / age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn.

Logistic regression dm with age sex sbp dbp lacr hdl linsul smoke htn /method : fstep /print : all.

BMDP code for procedure LR and the model in (14.2.28): /input file : c:ex14d2d6.dat .

variables : 12.

format : free.

/variable names : age, ageg, sex, sbp, dbp, lacr, hdl, linsul, smoke, dms, dm, sn.

Use : age, sex to smoke.

/regress depend : dm.

Interval : age, sex to smoke.

Method : mlr.

/print cell : used.

/end 14.3 MODELS FOR POLYCHOTOMOUS OUTCOMES The regression models in Section 14.2 can be extended to handle outcomes that have more than two categories. These categories may be nominal, for example, different types of heart disease or psychological conditions; or ordinal, for example, different levels of glucose intolerance or different severity of communi-cation disorders. An outcome variable with more than two possibilities is called polychotomous or polytomous. In this section we discuss first the model for 414         nominal polychotomous outcomes (generalized logistic regression model), then the model for ordinal polychotomous outcomes (ordinal regression model).

Details regarding these models can be found in Aitchison and Silvey (1957), McCullagh (1980), Green (1984), McCullagh and Nelder (1989), Hosmer and Lemeshow (1989, 2000), Cox and Snell (1989), Afifi and Clark (1990), Agresti (1990), Collett (1991), and Ananth and Kleinbaum (1997).

14.3.1 Models for Nominal Polychotomous Outcomes: Generalized Logistic Regression Models Let YG denote the outcome for individual i. The outcome can be one of the m nominal categories, such as different cell types of lung cancer. Let YG : k denote that YG belongs to the k th category and k:1,2, . . . , m. Suppose that for each of n subjects, p independent variables x G :( xG, xG, . . . , xGN) are measured.

These variables can be either qualitative or quantitative. Let P( YG : k x G) be the probability that YG: k given the p measured covariates x G; then KI P( YG: k x G):1. Without loss of generality, using the last catalog as the reference, the generalized logistic regression model P( Y N log G : k x G) : a b P( Y I ; IHxGH k : 1, 2, . . . , m 9 1 (14 . 3 . 1) G : m x G) H can be used to study the association of the covariates x to the outcome. To simplify the notation, let uIG: aI ; NH bIHxGH. Similar to (14.2.1) and (14.2.2), the model in (14.3.1) assumes that the dependence on the covariates of the probability of being in the k th category is k : 1, 2, . . . , m 9 1 P( YG: k x G): This model reduces to exp( uIG) 1 ; K\ H exp( uHG) (14 . 3 . 2) 1 k : m 1 ; K\ H exp( uHG) the logistic regression model in (14.2.1) and (14.2.2) when m : 2.

Let k, . . . , kL be the outcomes observed for the n subjects. Then the log-likelihood function based on the n outcomes observed is the logarithm of the product of all P( YG: kG x G)s from the n subjects, that is, l( a, a, . . . , aK\, b, b, . . . , b K\):log L : log L P( YG: kG x G) (14.3.3) G where P( YG : kG x G) is given in (14.3.2) and b I:( bI, . . . , bIN), k :1, 2, . . . , m 9 1. There are a total of ( m 9 1)( p ; 1) unknown coefficients. The estimation and hypothesis testing procedures for the coefficients are similar to     415 those in the logistic regression model for dichotomous outcomes. Strictly speaking, the models in (14.3.1) are not logistic regression models if m 2.

Therefore, the interpretation of the coefficients in these models needs to be clarified. Let us consider modeling the relationship between gender and cardiovascular disease status, NORMAL, STROKE, and CHD (coronary heart disease). Let the outcome variable Y be defined as Y : 1 if CHD, :2 if STROKE, and :3 if NORMAL, and the covariate SEX defined as SEX : 1 if male and :0 if female. Then the two models according to (14.3.1) are P( Y log G : 1 SEX G) : a P( Y ; b  SEX G G : 3 SEX G) P( Y log G : 2 SEX G) : a P( Y ; b  SEX G G : 3 SEX G) It is clear that neither of them is a logistic regression model. In the following, we show how to interpret the coefficients b and b in these models. From the first model, P( Y : 1 SEX : 1)/ P( Y : 3 SEX : 1) log P( Y :1SEX:0)/ P( Y :3SEX:0) P P : ( Y : 1 SEX : 1) ( Y : 1 SEX : 0) log 9 log P( Y : 3 SEX : 1) P( Y : 3 SEX : 0) : ( a; b) 9 a : b and thus P( Y : 1 SEX : 1)/ P( Y : 3 SEX : 1) :exp( b P( Y : 1 SEX : 0)/ P( Y : 3 SEX : 0) ) (14 . 3 . 4) Now let us cast the data into a 3;2 contingency table as in Table 14.16. The left side of (14.3.4) can be estimated by ( f /n) /( b/n) : fa ( e/n) /( a/n) be However, if only the data from the normal and CHD participants are used, f a :[ f/( b ; f )] /[ b/( b ; f )] be [ e/( e ; a)] /[ a/( e ; a)] 416         Table 14.16 Nominal Cross-Classification of Cardiovascular (CVD) Status by Gender SEX CVD Status (Y) Female (0) Male (1) NORMAL (3) a b STROKE (2) c d CHD (1) e f   Total n n which is an estimate of P(CHD Male)/[1 9 P(CHD male)] P(CHD female)/[1 9 P(CHD female)] or the ratio of the odds of a male having CHD to the odds of a female having CHD. Therefore, the exp( b) obtained from the first model can be interpreted as an estimate of the ratio of the odds of a male having CHD to the odds of a female having CHD if only the data from the normal and CHD participants are used. Similarly, exp( b) obtained from the second model can be interpreted as an estimate of the ratio of the odds of a male having STROKE to the odds of a female having STROKE if only the data from the normal and STROKE participants are used. The same interpretation also holds for coefficients of continuous covariates in the models of (14.3.1); that is, an exponentiated coefficient for a continuous covariate is the odds ratio of a 1-unit increase in the covariate assuming that other covariates are the same.

Example 14.11 We use the data in Example 14.9 and assume that DM ( Y : 1), IFG ( Y : 2), and NFG ( Y : 3) are three nominal categories. Let the referent category be NFG. For simplicity, only two covariates, systolic blood pressure (SBP) and log insulin (LINSUL), are included. Table 14.17 gives the results from fitting these covariates to the model (14.3.1).

P( i th participant is DM) P( Y log : log G : 1 x G) P( i th participant is NFG) P( YG :3 x G) : 97.648 ; 0.026SBP G;1.047LINSUL G P( i th participant is IFG) P( Y log : log G : 2 x G) P( i th participant is NFG) P( YG :3 x G) : 94.949 ; 0.011SBP G;0.876LINSUL G - - - 1 er 5 3 1 4.1 val p ---- ---- ---- 1 p .0 .17 .0 .0 ter tioa 1 5 1 4 1.04 2.28 le U In R ---- ---- ---- s ce d 95% en d ---- ---- ---- Examp O r r 1 9 4 nfid 57 for fo owe .0 ---- .9 .4 ---- .99 .62 ---- 1 1.

0 1 0 0 el Co L ---- ---- ---- Mod s ---- ---- ---- ion d o 3 5 1 0 d .0 8 .0 .4 O Rati 1 2.

---- 1 2 ---- 1.02 1.19 ---- Regress ---- ---- ---- 1 1 6 8 9 6 istic 445 239 066 p 000 012 0006 ---- 0005 234 ---- ---- .000 . 223 . 606 0.

0.

0 0 0.

0 0.1 0.2 0.6 0 0 Log ---- ---- ---- d re ---- ---- ---- ralize a c u 0 0 0 0 q sti 3 00 7 G 2 10 5 ene FG 5 .3 8 ---- 0 .4 1 ---- G ---- . 48 . 27 6 F 1 2.130 0.480 1.270 1 0 G i-S tati IF h S N 21.

11.

N 12.

11.

.

.

C ---- ---- vs ---- the vs vs.

---- ---- ---- om d DM IFG DM fr ar r 8 0 4 7 0 2 d ce n 64 01 30 ---- 42 01 26 ---- ---- .850 .333 ta Erro 1.

0.

0.

1.

0.

0.

1 0.012 0 eren S ---- ---- ---- Infd n ---- ---- 9 1 ---- cient 9 15 7 648 026 .047 949 011 .876 .6 .0 .1 lihoo ressio fi 7.

0.

1 ---- 4.

0.

0 ---- 2 0 0 ---- ike eg 9 9 9 L R Coef ---- ---- ---- ial e P CP L ---- CP L ---- ---- L Part abl U U U ri S ---- S ---- S ---- tic a TER TER TERC P V BP IN BP IN B IN S L IN S L IN S LIN pto ---- ---- ---- m k 1 1 1 ---- 2 2 2 ---- ---- Asy s ---- ---- ---- 17 b b f nt 14.

o ie S ---- ---- ---- : : er A ble d effic : b : b o ---- ---- ---- Ta Or C byS b b b - b b b - - H H 417 418         Consequently, P( i th participant is DM) P( Y log : log G : 1 x G) P( i th participant is IFG) P( YG :2 x G) P P : ( Y ( Y log G : 1 x G) 9 log G : 2 x G) P( YG :3 x G) P( YG:3x G) : (97.648 ; 4.949) ; (0.026 9 0.011)SBP G ; (1.047 9 0.876)LINSUL G : 92.699 ; 0.015SBP G;0.171LINSUL G Thus, the odds ratio is 1.03 [exp(0.026)] times (or 3% higher) for a 1-unit increase in SBP, and 2.85 [exp(1.047)] times (or 185% higher) for a 1-unit increase in LINSUL from the model for DM vs. NFG. The odds ratio is 2.40 [exp(0.876)] times (or 140% higher) for a 1-unit increase in LINSUL from the model for IFG versus NFG. SBP is not significant in the model for IFG versus NFG ( p : 0.2346). Neither SBP nor LINSUL is significant in the model for DM versus IFG ( p : 0.2239 and p : 0.6066, respectively). One can also follow the examples in Chapter 7, 9, 11, and 12 to perform additional statistical inferences. For instance, we can test whether the coefficients for SBP in the first two models are equal (whether the odds ratio for a 1-unit increase of SBP in the model for DM versus NFG is equal to that in the model for IFG versus NFG), that is, H: b 9 b:0 (where the subscripts 3 and 4 are the orders of the coefficients given by SAS). From (11.2.13), under H, Walds statistic, X5 :( b 9 b) /( v; v 92 v), has an asymptotic chi-square distribution with 1 degree of freedom, where v and v are the estimated variance of b and b, respectively, and v is the estimated covariance of b and b. From Table 14.17, the hypothesis is not rejected ( p : 0.2239). Similarly, the hypothesis H: b 9 b:0 is not rejected ( p:0.6066); that is, there is insufficient evidence to say that the change in odds ratio for a 1-unit increase in LINSUL in the model for DM versus NFG is not equal to that in the model for IFG versus NFG.

The following SAS, SPSS, and BMDP codes can be used to obtain the results in Table 14.17.

SAS code: data w1; infile c:ex14d2d6.dat missover; input age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn; y : 4-dms; run; title Generalized logistic regression model; proc catmod data : w1; direct sbp linsul;     419 model y : sbp linsul / ml covb; contrast Equal coefficients for SBP all  parms 0 0 1 91 0 0; contrast Equal coefficients for LINSUL all  parms 0 0 0 0 1 91; run; SPSS code: data list file : c:ex14d2d6.dat free / age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn.

Compute y : 4-dms.

nomreg y with sbp linsul /print : fit history parameter lrt.

BMDP PR code: /input file : c:ex14d2d6.dat .

variables : 12.

format : free.

/variable names : age, ageg, sex, sbp, dbp, lacr, hdl, linsul, smoke, dms, dm, sn.

Use : age, sex to smoke.

/transform y : 4-dms.

/group codes(y) : 1, 2, 3.

Names(y) : DM, IFG, NFG.

/regress depend : y.

Level : 3.

Type : nom.

Interval : age, sex to smoke.

enter : .05, .05.

remove : : .05, .05.

/print cell : model.

/end 14.3.2 Model for Ordinal Polychotomous Outcomes: Ordinal Regression Models If the outcomes involve a rank ordering, that is, the outcome variable is ordinal, several multivalued regression models are available. Readers interested in these models are referred to McCullagh and Nelder (1989), Agresti (1990), Ananth and Kleinbaum (1997), and Hosmer and Lemeshow (2000). In the following discussion, we introduce the most frequently used model, the proportional odds model. In this model, the probability of an outcome below or equal to a given ordinal level, P( Y k), is compared to the probability that it is higher than the level given, P( Y k) .

Let YG be the outcome of the i th subject. Assume that YG can be classified into m ordinal levels. Let YG: k if YG is classified into the k th level and 420         k : 1, 2, . . . , m. Suppose that for each of n subjects, p independent variables x G :( xG, xG, . . . , xGN) are measured. These variables can be either qualitative or quantitative. If the logit link function defined in Section 14.2.3 is used, similar to the logistic regression model (14.2.3), we consider the following models: P( Y N logit( P( Y G k x G) G k x G)) : log : a b 1 9 P( Y I ; HxGH G k x G) H k : 1, 2, . . . , m 9 1 (14.3.5) or, equivalently, let uIG : aI ; NH bHxGH, P( YG k x G): exp( aI ; NH bHxGH) : exp( uIG) 1 ; exp( aI ; NH bHxGH) 1;exp( uIG) k : 1, 2, . . . , m 9 1 (14 . 3 . 6) Therefore, P( YG : k x G): P( YG k x G)9 P( YG k 91 x G) k : 1 : If m : 2, that exp( u G) 1 ; exp( u G) exp( uIG) 9 exp( uI\ G) k : 2, . . . , m 9 1 (14 . 3 . 7) 1 ; exp( uIG) 1;exp( uI\ G) 1 9 exp( uK\ G) k : m 1 ; exp( uK\ G) is, there are only two outcome levels, (14.3.7) reduces to the logistic regression model in (14.2.3). The models in (14.3.5) can be thought of as having only two outcomes [( Y k) versus ( Y k)] and therefore are logistic regression models. Thus, interpretation of the coefficients, bH, such as the exponentiated coefficient [exp( bH)] for a discrete or a continuous covariate is similar to that in a logistic regression model.

Let k, . . . , kL be observed outcomes from n subjects. Then the log-likelihood function based on the n outcomes observed is the logarithm of the product of all P( YG: kG x G)s from the n subjects, that is, l( a, a, . . . , aK\, b, b, . . . , bN) :log L :log L P( YG: kG x G) (14.3.8) G where P( YG : kG x G) is as given in (14.3.7). The maximum likelihood estimation and hypothesis-testing procedures for the coefficients are similar to those discussed previously. If the probit link function in (14.2.27) is used, the models     421 and formula corresponding to (14.3.5) (14.3.7) are N \( P( YG k x G)): aI; bHxGH k : 1, 2, . . . , m 9 1 H P( YG k x G) :( uIG) k : 1, 2, . . . , m 9 1 P( YG : k x G) : P( YG k x G) 9 P( YG k 91 x G) : ( u G) k : 1 ( uIG) 9( uI\ G) k : 2, . . . , m 9 1 1 9 ( uK\ G) k : m If the complementary log-log link function in (14.2.29) is used, the models and formula corresponding to (14.3.5) (14.3.7) are N log[9log(1 9 P( YG k x G))] : aI; bHxGH k : 1, 2, . . . , m 9 1 H P( YG k x G) :19exp[9exp( uIG)] k : 1, 2, . . . , m 9 1 P( YG : k x G) : P( YG k x G) 9 P( YG k 91 x G) : 19exp[9exp( u G)] k : 1 exp[9exp( uI\ G)] 9exp[9exp( uIG)] k : 2, . . . , m 9 1 exp[9exp( uK\ G)] k : m The log-likelihood function based on these two models can be obtained by replacing P( YG: kG x G) in (14.3.8) with the respective expressions above.

Example 14.12 Now consider the NFG, IFG, and DM categories in Example 14.9 that represent three levels of severity in glucose intolerance. DM (diabetes) is defined as fasting plasma glucose (FPG) 126 mg/dL, IFG (impaired fasting glucose) as FPG between 110 and 125 mg/dL, and NFG (normal fasting glucose) as FPG 110 mg/dL. Thus, it is reasonable to consider the outcome variable as ordinal. Let the outcome variable Y : 1 if DM, 2 if IFG, and 3 if NFG. We fit the models in (14.3.5) using the SAS procedure LOGISTIC with all the covariates. The SAS program allows users to use a variable selection method (forward, backward, and stepwise). In this case, we use the stepwise selection method, and the results are given in the first part of Table 14.18. The stepwise method identifies SBP and LINSUL as significant independent variables. For k : 1 [i.e., we compare diabetes with fors o n ati erp 03 90 ctio ce R p 1.

3.

en sd U Fun d d k Or Lin Confi fo r 95% owe .00 .67 ferent terval 1 1 L In Difhitwl ds o 02 52 ode Od Rati 1.

2.

on Mno ion unctiF essi 1 1 1 01 01 34 01 unct 01 01 20 01 ink 01 01 68 01 egr p F L R ctionn 00 00 01 00 . 000 k 00 00 01 00 . 000 g 00 00 01 00 . 000 l u 0.

0.

0.

0.

0 0.

0.

0.

0.

0 0.

0.

0.

0.

0 F Lin ina k g-Lo rd in al O L rm Lo ic ry the uare st No ta ti ogit .571 .708 114 .803 . 831 e .415 .790 311 .674 . 261 .813 .025 721 .534 . 835 m i-Sq L ta 2 2 6.

8 4 3 6.

8 6 en 7 6 5.

9 5 S h 3 2 1 26 3 2 1 3 2 1 fro vers Ch it lem .

w In p ce l ely om v ?

ith ti w C ec feren 02 rd 0 02 r Mode m In a : : : resp rro .183 .151 .007 .213 .677 .664 .004 .123 fro .915 .894 .006 .162 , E 1 1 0 0 b 0 0 0 0 b l 0 0 0 0 b L 9 Model Stand : : de : SU lihood 14.

o b M IN ike le : b : : b L L p n t d l m o 3 5 5 H 1 0 0 H 6 2 5 H n a a si 5 8 19 2 r 7 4 11 3 r 2 6 14 1 r a x cien 7 4 .0 9 fo 9 2 .0 5 fo 6 5 .0 7 fo P E es effi 6.

5.

0 0.

3.

3.

0 0.

5.

4.

0 0.

B Parti S in egr o 9 9 9 9 9 9 istic istic istic r ic R C fo ot ata stat stat stat ts D io io io cien ympt tus ble CP1 CP2 L rat CP1 CP2 L rat CP1 CP2 L rat effi As ta a S ri U d U d U d co S o S o S o 8 c a TER TER P re N o TER TER P N o TER TER P N o a .1 V B h B h B h 4 1 IN IN S LI eli IN IN S LI eli IN IN S LI eli b iabeti lik lik lik d ble D an e Ta th k 1 2 Log- 1 2 Log- 1 2 Log- ?b 422     423 nondiabetes (NFG ; IFG)] the estimated model in (14.3.5) is P( Y P(participant i is diabetic) log G 1 x G) : log 1 9 P( YG 1 x G) P(participant i is nondiabetic) : 96.753 ; 0.019SBP G;0.925LINSUL G For k : 2, the estimated model in (14.3.5) is P( Y P(participant i is either DM or IFG) log G 2 x G) : log 1 9 P( YG 2 x G) P(participant i is NFG) : 95.485 ; 0.019SBP G;0.925LINSUL G According to (14.3.7), we can estimate the probability of developing DM, IFG, or remaining NFG. For example, the probability of developing IFG is P( YG :2 x G): P(participant i is IFG) : exp(95.485 ; 0.019SBP G ; 0.925LINSUL G) 1 ; exp(95.485 ; 0.019SBP G;0.925LINSUL G) 9 exp(96.753 ; 0.019SBP G ; 0.925LINSUL G) 1 ; exp(96.753 ; 0.019SBP G ;0.925LINSUL G) Thus, for a person whose systolic blood pressure is 140 mmHg and whose log insulin is 3, the probability of developing IFG can be obtained by plugging these values into the preceding equation. The result is P(participant is IFG) : 0.951 9 0.268 1 ; 0.951 1 ; 0.268 : 0.276 As noted earlier, the coefficients in these models can be interpreted as those in the ordinary logistic regression model for binary outcomes. In this example, the higher SBP and LINSUL are, the higher the odds of having DM than of not having DM, or the higher the odds of having either DM or IFG than of being NFG. The odds ratio is 1.02 [exp(0.019)] times (or 2% higher) for a 1-unit increase in SBP assuming that LINSUL is the same, and 2.52 times (or 152% higher) for a 1-unit increase in LINSUL assuming that SBP is the same.

From the table, SBP and LINSUL are related significantly to the diabetic status in all models with different link functions.

SAS and SPSS can also be used for the other two link functions: the inverse of the cumulative standard normal distribution and the complementary log-log 424         link functions introduced in Section 14.2.3. Table 14.18 includes the results from models with these two link functions. The results are very similar to those obtained using the logit link function.

The following SAS, SPSS, and BMDP codes can be used to obtain the results in Table 14.18.

SAS code: data w1; infile c:ex14d2d6.dat missover; input age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn; run; title Ordinal regression model with logic link function; proc logistic data : w1 descending; model dms : age sex sbp dbp lacr hdl linsul smoke / selection : s lackfit link : logit; run; title Ordinal regression model with inverse normal link function; proc logistic data : w1 descending; model dms : age sex sbp dbp lacr hdl linsul smoke / selection : s lackfit link : probit; run; title Ordinal regression model with complementary log-log link function; proc logistic data : w1 descending; model dms : age sex sbp dbp lacr hdl linsul smoke / selection : s lackfit link : cloglog; run; SPSS code: data list file : c:ex14d2d6.dat free / age ageg sex sbp dbp lacr hdl linsul smoke dms dm sn.

Compute y : 4-dms.

plum y with sbp linsul /link : logit /print : fit history parameter.

plum y with sbp linsul /link : probit /print : fit history parameter.

plum y with sbp linsul /link : cloglog /print : fit history parameter.

BMDP PR code for the logit link function only: /input file : c:ex14d2d6.dat .

variables : 12.

format : free.

425 /variable names : age, ageg, sex, sbp, dbp, lacr, hdl, linsul, smoke, dms, dm, sn.

Use : age, sex to smoke.

/transform y : 4-dms.

/group codes(y) : 1, 2, 3.

Names(y) : DM, IFG, NFG.

/regress depend : y.

Level : 3.

Type : ord.

Interval : age, sex to smoke.

enter : .05, .05.

remove : : .05, .05.

/print cell : used.

/end Note that the model for ordinal polychotomous outcomes in BMDP PR is defined as P( Y N log G k x G) : 1 9 P( Y I ; HxGH : u IG k : 1, 2, . . . , m 9 1 G k x G) H Compared with (14.3.5), I:9 aI, k: 1, 2, . . . , m 91; H:9 bH, j:1, 2, . . . , p.

Bibliographical Remarks The linear logistic regression method is discussed extensively in Cox (1970), Cox and Snell (1989), Collett (1991), Kleinbaum (1994), and Hosmer and Lemeshow (2000). Coxs book provides the theoretical background, and Hosmer and Lemeshow discuss broad application of the method, including model-building strategies and interpretation and presentation of analysis results. In addition to the papers and books cited in this chapter, other works on the subject include Anderson (1972), Mantel (1973), Prentice (1976), Prentice and Pyke (1979), Holford et al. (1978), and Breslow and Day (1980).

Applications of the logistic regression model can easily be found in various biomedical journals.

EXERCISES 14.1 Consider the study presented in Example 3.5 and the data for the 40 patients in Table 3.10.

(a) Construct a summary table similar to Table 3.11.

(b) Construct a table similar to Table 3.12.

(c) Use the chi-square test to detect any differences in retinopathy rates among the subgroups obtained in part (b).

426         (d) On the basis of these 40 patients, identify the most important risk factors using a linear logistic regression method.

14.2 Consider the data for the 33 hypernephroma patients given in Exercise Table 3.1. Let response be defined as stable, partial response, or complete response.

(a) Compare each of the five skin test results of the responders with those of the nonresponders.

(b) Use a linear logistic regression method to identify the most import- ant risk factors related to response.

(i) Consider the five skin tests only.

(ii) Consider age, gender, and the five skin tests.

14.3 Consider all nine risk variables (age, gender, family history of melanoma, and six skin tests) in Exercise 3.3 and Exercise Table 3.3.

Identify the most important prognostic factors that are related to remission. Use both univariate and multivariate methods.

14.4 Consider the data of 58 hypernephroma patients given in Exercise Table 3.2. Apply the logistic regression method to response (defined as complete response, partial response, or stable disease). Include gender, age, nephrectomy treatment, lung metastasis, and bone metastasis as independent variables.

(a) Identify the most significant independent variables.

(b) Obtain estimates of odds ratios and confidence intervals when applicable.

14.5 Consider the case where there is one continuous independent variable X. Show that the log odds ratio for X: x; m versus X: x is mb, where b is the logistic regression coefficient.

14.6 Using the data in Table 12.4, define the index function CVD as CVD : 1 if dg 1, and CVD : 0 otherwise, and fit a logistic re- gression model for CVD by using the stepwise selection method to select risk factors among the same factors as those noted at the bottom of Table 12.7. Compare the results obtained with those in Table 12.7.

14.7 Assuming that P(a person is sampled y, x) : P(a person is sampled y), that is, the sampling probability is independent of the risk factors x, derive (14.2.15).

14.8 By using (14.2.14) and (14.2.1), show that (14.2.20) reduces to (14.2.21).

14.9 Derive (14.3.2).

427 14.10 Consider the data in Table 12.4. Fit the generalized logistic regression model in (14.3.1) for DG with covariates AGE, SEX, LACR, and LTG by using the SAS CATMOD, SPSS NOMREG, or BMDP PR procedure. Select risk factors among those noted at the bottom of Table 12.7 using the stepwise selection method in the BMDP PR procedure. Compare the results with those given in Table 13.5.

14.11 Using the same notation and data as in Table 14.11, (1) fit the outcome variable Y with the generalized logistic regression model in (14.3.1) with SEX as the covariate; (2) fit a logistic regression for the binary outcome DM versus NFG, with SEX as the covariate, by using the data from DM and NFG participants only; (3) fit a logistic regression for the binary outcome IFG versus NFG, with SEX as the covariate, by using the data from IFG and NFG participants only; (4) compare the coefficients obtained from (2) and (3) with the coefficients obtained from (1), and (5) report what you have found.

14.12 Perform the same analyses as in Exercise 14.11 but use SBP as the covariate, and discuss your findings.

A P P E N D I X A Newton--Raphson Method The Newton  Raphson method (Ralston and Wilf, 1967;Carnahan et al., 1969) is a numerical iterative procedure that can be used to solve nonlinear equations. An iterative procedure is a technique of successive approximations, and each approximation is called an iteration. If the successive approximations approach the solution very closely, we say that the iterations converge. The maximum likelihood estimates of various parameters and coefficients discussed in Chapters 7, 9, and 11 to 14 can be obtained by using the Newton  Raphson method. In this appendix we discuss and illustrate the use of this method, first considering a single nonlinear equation and then a set of nonlinear equations.

Let f ( x) : 0 be the equation to be solved for x. The Newton  Raphson method requires an initial estimate of x, say x, such that f( x) is close to zero preferably, and then the first approximate iteration is given by f ( x x ) : x 9 (A.1) f ( x) where f ( x) is the first derivative of f ( x) evaluated at x : x. In general, the ( k ; 1)th iteration or approximation is given by f ( x x I) I> : x I 9 (A.2) f ( xI) where f ( x I) is the first derivative of f ( x) evaluated at x: x I. The iteration terminates at the k th iteration if f ( x I) is close enough to zero or the difference between x I and x I\ is negligible. The stopping rule is rather subjective.

Acceptable rules are that f ( x I) or d: x I 9 x I\ is in the neighborhood of 10\ or 10\.

Example A.1 Consider the function f ( x) : x 9 x ; 2 428 -  429 Figure A.1 Graphical presentation of the Newton  Raphson method for Example A.1.

We wish to find the value of x such that f ( x) : 0 by the Newton  Raphson method. The first derivative of f ( x) is f ( x) : 3 x 9 1 Since f (91) : 2 and f (92) : 94, graphically (Figure A.1), we see that the curve cuts through the x axis [ f ( x) : 0] between 91 and 92. This gives us a good hint of an initial value of x. Suppose that we begin with x :91; f ( x) :2 and f ( x) :2. Thus, the first iteration, following (A.1), gives x: 9192 :92 2 and f ( x) :94 and f ( x) :11. Following (A.2), we obtain the following: Second iteration: x:92; 4 :91 . 6364 11 f ( x) :90 . 7456 f ( x) :7 . 0334 430 -  Third iteration: x: 91 . 6364;0 . 7456:91 . 5304 7 . 0334 f ( x) :90 . 054 f ( x) :6 . 0264 Fourth iteration: x:91 . 5304; 0 . 054 :91 . 52144 6 . 0264 f ( x) :90 . 00036 f ( x) :5 . 9443 Fifth iteration: x: 91 . 52144; 0 . 00036:91 . 52138 5 . 9443 f ( x) :0 . 0000017 At the fifth iteration, for x : 91 . 52138, f ( x) is very close to zero. If the stopping rule is that f ( x) - 10\, the iterative procedure would terminate after the fifth iteration and x : 91 . 52138 is the root of the equation x 9 x ; 2 : 0.

Figure A.1 gives the graphical presentation of f ( x) and the iteration.

It should be noted that the Newton  Raphson method can only find the real roots of an equation. The equation x 9 x ; 2 : 0 has only one real root, as shown in Figure A.1;the other two are complex roots.

The Newton  Raphson method can be extended to solve a system of equations with more than one unknown. Suppose that we wish to find values of x, x, . . . , xN such that f( x, . . . , xN) :0 f( x, . . . , xN) :0 $ fN( x, . . . , xN) :0 Let aGH be the partial derivative of fG with respect to xH;that is, aGH:* fG/* xH.

-  431 The matrix a % a N a J : % a N $ $ aN % aNN is called the Jacobian matrix. Let the inverse of J, denoted by J\, be b % b N b J\ : % b N $ $ bN % bNN Let xI, xI, . . . , xIN be the approximate root at the k th iteration;let f I, . . . , f IN be the corresponding values of the functions f, . . . , fN, that is, f I: f( xI, . . . , xIN) $ f IN: fN( xI, . . . , xIN) and let bIGH be the ij th element of J\ evaluated at xI, . . . , xIN. Then the next approximation is given by xI> : xI 9 ( bI f I ; bI f I ; % ; bI N f IN) xI> : xI 9 ( bI f I ; bI f I ; % ; bI N f IN) ( A. 3) $ xI> N : xIN 9 ( bIN f I ; bIN f I ; % ; bINN f IN) The iterative procedure begins with a preselected initial approximate x, x, . . . , x N, proceeds following (A.3), and terminates either when f, f, . . . , fN are close enough to zero or when differences in the x values at two consecutive iterations are negligible.

Example A.2 Suppose that we wish to find the value of x and x such that x; x x 92 x 91 :0 x 9 x; x 92:0 432 -  In this case, p : 2: f: x; x x 92 x 91 f : x 9 x; x 92 Since * f /* x:2 x; x 9 2, * f /* x: x, * f /* x:3 x 91, and * f /* x :1, the Jacobian matrix is x J : 2 x; x 92 (A.4) 3 x 91 1 Let the initial estimates be x:0, x:1, f :91, and f :91 : J : 91 0 9 J\:91 0 1 1 91 1 Iteration 1. Following (A.3), we obtain x:09[(91)(91) ;0(91)] :91 x:1 9[(91)(91) ;1(91)] :1 With these values, f : 1, f :91, and J : 93 91 J\:91 91 2 1 2 3 Iteration 2. From (A.3) we obtain x:91 9[(91)(1) ;(91)(91)] :91 x:1 9[(2)(1) ;(3)(91)] : 2 With these values, f :0 and f : 0. Therefore, the iteration procedure terminates and the solution of the two simultaneous equations is x :91, x:2 .

The number of iterations required depends strongly on the initial values chosen. In Example A.2, if we use x :0, x:0, it requires about 11 iterations to find the solution. Interested readers may try it as an exercise.

A P P E N D I X B Statistical Tables 433 Table B-1 Normal Curve Areas Source: Abridged from Table 1 of Statistical Tables and Formulas, by A. Hald, JohnWiley & Sons, 1952. Reproduced by permissionof JohnWiley & Sons.

434 Table B-2 Percentage Points of the 2-Distribution Source: Tables of the Percentage Points of the -Distribution, by Catherine M. Thompson, Biometrika, Vol. 32, pp. 188  189 (1941). Reproduced by permissionof the editor of Biometrika.

435 n tioub istri -D F the of ints Po %5 -3B ble Ta 436 437 n tio tribu -Dis F thefosnt Poi %52.

-3B Table 438 439 tionub stri -Di F eth ofs Point %1 -3B Table 440 441 n tio tribu -Dis F thefosnt Poi %50.

-3B Table 442 ,n psom hoT.

M ne eri athC dna nogt riner M .

e ka n ri xia et M om y Bi b for ion, ito ut ed b e ri th ist f D) no ( F io iss etaB ermpybertedvdceInud the ro ep of R ts ).

n 943 Poi (1 ega 88  3ent7.ercpPp,3ofl.3lesob,V Ta trika rce:u iome So B 443 Table B-4 Upper Tail Probabilities for the Null Distribution of the Kruskal--Wallis H Statistic: k : 3, n : 1(1)5, n : n (1)5, 2 n : n (1)5 1 2 1 3 2 444 Table B-4 ( continued) 445 Table B-4 ( continued) 446 Table B-4 ( continued) 447 Table B-4 ( continued) 448 Table B-4 ( continued) 449 Table B-4 ( continued) 450 Table B-4 ( continued) 451 Table B-4 ( continued) 452 Table B-4 ( continued) 453 Table B-4 ( continued) 454 Table B-4 ( continued) 455 Table B-4 ( continued) 456 Table B-4 ( continued) 457 Table B-4 ( continued) Source: Table F of A Nonparametric Introduction to Statistics, by C. H. Kraft and C van Eedan, Macmillan, New York, 1968. Reproduced by permission of the Macmillan Publishing Company.

458 Table B-5 Selected Critical Values for All Treatments: Multiple Comparisons Based on Kruskal--Wallis Rank Sums Source: Rank Sum Multiple Comparisons in One- and Two-Way Classification, by B. J.

McDonald and W. A. Thompson, Biometrika, Vol. 54, pp. 487  497 (1967). Reproduced by permissionof the editor of Biometrika. The starred values are from Distribution-Free Multiple Comparisons, Ph.D. thesis (1963), P. Nemenyi, Princeton University, with permission of the author.

459 Table B-6 Selected Critical Values for the Range of k Independent N(0, 1) Variables: k : 2(1)20(2)40(10)100 For a given k and , the tabled entry is q(, k, -) .

Source: Table of Range and Studentized Range, by H. L. Harter, Ann. Math. Statist. , Vol. 31, pp.

1122  1147 (1960). Reproduced by permissionof the editor of the Annals of Mathematical Statistics.

460 Table B-7Percentage Points of the t-Distribution Source: Table of Percentage Points of the t-Distribution, by Maxine Merrington, Biometrika, Vol. 32, p. 300 (1941). Reproduced by permissionof the editor of Biometrika.

461 Table B-8 Coefficients ( a and b ) of the Best Estimates of the Mean () and Standard i i Deviation () in Censored Samples Up to n : 20 from A Normal Population 462 Table B-8 ( continued) 463 Table B-8 ( continued) 464 ) d uein cont( 8 B- le Tab 465 ) d uein cont( 8 B- le Tab 466 467 ) d uein cont( 8 B- le Tab 468 469 ) d uein cont( 8 B- le Tab 470 471 E.

fo A.y nals b An II,d the na fo I r ts to arP edie les, th p amS nof d ssio ensore ermi C p ly yb uboD ced ) ud nd o a nued y epr ti gl R n n ).

co Si ( m 956(1 -8 fro B 451 stics  tiat 274 Table S .

er pp rdO 27, y .

b olV, eters st.ti ram taS Pa .

le tha caS M.

nd n a nA, tion erg ca b oL reen of .G stics.

tion .G tatiS ima dB cal n Est ati na ce: a em rha Sour S Math 472 ro )f( n tio eviaD rd andaSt and )( ean Meth of tes imastE onti inear la L est Popu B lam the of Nor s a m riance fro a 0 ov 2 C eiz nd S a to s pUsriancele Va mpaS -9 d B sore en Table C 473 ics le thef ca tist S ta no d S na e.

er issio ffic rd on m ti O O erp cao rch by h L it f sea w o eters Re ), n y 58 ioat Arm Param (19 e 5 stim .S.

10  E U Scal 9 , ,7 d 7. erg 9 p 5 p nb 1 ,9 ct ree e tionan 2 G ca l.

.

roj o o G P L .

, f B R o ndV O n ),a and -O tio 4 56 n .

(19 rha ep stima R ) 1 Sa .

E 45 ,  E.

ech ued .

T in A berg 427 , .

m p III cont p ( reen , fro rt G 7 a .

2 ed P -9 G l.

uc o B .

es, B V od pl d ., pr ble ist is amS Ta tat le S b d rhanan ta a e S nsore .

th E Math.

f Ce .

o y A st bl m Ann.

re uo fro II, he D T d .

ced n s nd u a a I istic ly rtsa tat ing reprod S P S l is ca e les, ti bl p from ta ma cs is Sam the sti th a ti f M ta o red f S o 15 enso er : C nals n d Ord n An y to a b y eth rs Up ngl te of Si me rce:u tor raa So from edi P 474 Table B-10 1/(1 9 R) and for the Estimation of the Parameters of the Gamma Distribution When There Are No Censored Observations Source: Estimationof Parameters of the Gamma DistributionUsing Order Statistics, by M. B.

Wilk, R. Gnanadesikan, and Marilyn J. Huyett, Biometrika, Vol. 49, pp. 525  545 (1962).

Reproduced by permissionof the editor of Biometrika.

475 Table B-11 ( P, S) and ( P, S) for Various Values of n/r: n/r : 1.0 For P 0.52 read S from the left-hand margin, and for P 0.56 read S from the right-hand margin. Note that the figures in region 2 are printed in bold roman type and those in region 3 in bold italic type; the remainder of the table (outside of regions 2 and 3) is region1.

476 Table B-11 ( continued) 477 Table B-11 ( continued) 478 Table B-11 ( continued) 479 Table B-11 ( continued) 480 Table B-11 ( continued) 481 Table B-11 ( continued) 482 Table B-11 ( continued) 483 Table B-11 ( continued) 484 Table B-11 ( continued) Source: Estimationof Parameters of the Gamma DistributionUsing Order Statistics, by M. B.

Wilk, R. Gnanadesikan, and Marilyn J. Huyett, Biometrika, Vol. 49, pp. 525  545 (1962).

Reproduced by permissionof the editor of Biometrika.

485 Table B-12 Percentage Points l Such That P( / l 1 2 ) : 1 9 Source: Two Sample Test in the Weibull Distribution, by D. R. Thoman and L. J. Bain, Technometrics, Vol. 11, pp. 805  815 (1969). Reproduced by permissionof the editor of Technometrics.

486 Table B-13 Percentage Points z Such That P( G z) : 1 9 Source: Two Sample Test in the Weibull Distribution, by D. R. Thoman and L. J. Bain, Technometrics, Vol. 11, pp. 805  815 (1969). Reproduced by permissionof the editor of Technometrics.

487 References Aaronson, K. D., Schwartz, J. S., Chen, T. M., Wong, K. L., Goin, J. E, and Mancini,D.

M. (1997). Development and Prospective Validation of a Clinical Index to Predict Survival in Ambulatory Patients Referred for Cardiac Transplant Evaluation.

Circulation, 95, 2660  2667.

Abramowitz, M., and Stegun, I. A. (1964). Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables. Applied Mathematics Series 55.

National Bureau of Standards, Washington, DC.

Afifi, A. A., and Clark, V. (1990). Computer-Aided Multivariate Analysis, 2nd ed.

Lifetime Learning Publications, Belmont, CA.

Agresti, A. (1990). Categorical Data Analysis. Wiley, New York.

Aitchison, J. (1970). Statistical Problems of Treatment Allocation. Journal of the Royal Statistical Society, Series A, 133, 206  238 Aitchison, J., and Brown, J. A. C. (1957). The Lognormal Distribution. Cambridge University Press, Cambridge.

Aitchison, J., and Silvey, S. D. (1957). The Generalization of Probit Analysis to the Case of Multiple Responses. Biometrika, 44, 131  140.

Aitkin, M., Laird, N., and Francis, B. (1983). A Reanalysis of the Stanford Heart Transplant Data (with discussion). Journal of the American Statistical Association, 78, 264  292.

Akaike, H. (1969). Fitting Autoregressive Models for Prediction. Annals of the Institute of Statistical Mathematics, 21, 243  247.

Akaike, H. (1974). A New Look at the Statistical Model Identification. IEEE Transactions on Automatic Control, AC-19, 716  723.

Albert, I. J. (2000). The Use of Frailty Models in Genetic Studies: Application to the Relationship between End-Stage Renal Failure and Mutation Type in Alport Syndrome. European Community Alport Syndrome Concerted Action Group (ECASCA). Journal of Epidemiology and Biostatistics, 5(3), 169  175.

Albertson, P. C., Hanley, J. A., Gleason, D. F., and Barry, M. J. (1998). Competing Risk Analysis of Men Aged 55 to 74 Years at Diagnosis Managed Conservatively for Clinically Localized Prostate Cancer. Journal of the American Medical Association, 280(11), 9 75  980.

488  489 Alioum, A., and Commenges, D. (1996). A Proportional Hazards Model for Arbitrarily Censored and Truncated Data. Biometrics, 52, 512  524.

Altshuler, B. (1970). Theory for Measurement of Competing Risks in Animal Experiments. Mathematical Biosciences, 6, 1  11.

Ananth, C. V., and Kleinbaum, D. G. (1977). Regression Models for Ordinal Data: A Review of Methods and Application. International Journal of Epidemiology, 26, 1323  1333.

Andersen, P. K. (1982). Testing Goodness of Fit of Coxs Regression Model. Biometrics, 38, 67  77.

Andersen, P. K. (1992). Repeated Assessment of Risk Factors in Survival Analysis.

Statistical Methods in Medical Research, 1, 29 7  315 Andersen, P. K., Borgan, O., Gill, R. D., and Keiding, N. (1993). Statistical Models Based on Counting Processes. Springer-Verlag, New York.

Andersen, P. K., and Gill, R. D. (1982). Coxs Regression Model Counting Process: A Large Sample Study. Annals of Statistics, 10, 1100  1120 Anderson, J. A. (1972). Separate Sample Logistic Discrimination, Biometrika, 59, 19  35.

Andrews, D. F., and Herzberg, A. M. (1985). Data: A Collection of Problems from Many Fields for the Student and Research Worker. Springer-Verlag, New York.

ARIC Investigators. (1989). The Atherosclerosis Risk in Communities (ARIC) Study: Design and Objectives. American Journal of Epidemiology, 129, 687  702.

Arjas, E. (1988). A Graphical Method for Assessing Goodness of Fit in Coxs Proportional Hazards Model. Journal of the American Statistical Association, 83, 204  212.

Armitage, P. (1959). The Comparison of Survival Curves. Journal of the Royal Statistical Society, Series A, 122, 279  300.

Armitage, P. (1971). Statistical Methods in Medical Research. Blackwell Scientific Publications, Oxford.

Armitage, P. (1981). Importance of Prognostic Factors in the Analysis of Data from Clinical Trials. Controlled Clinical Trials, 1, 347  353.

Armitage, P., and Gehan, E. A. (1974). Statistical Methods for the Identification and Use of Prognostic Factors. International Journal of Cancer, 13, 16  35.

Asal, N. R., Geyer, J. R., Risser, D. R., Lee, E. T., Kadamani, S., and Cherng, N. (1988a).

Risk Factors in Renal Cell Carcinoma, Part I. Methodology, Demographics, Tobacco, Beverage and Obesity. Cancer Detection and Prevention, 11, 359  377.

Barnard, G. A. (1963). Some Aspects of the Fiducial Argument. Journal of the Royal Statistical Society, Series B, 34, 216  217.

Bartholomew, D. J. (1957). A Problem in Life Testing. Journal of the American Statistical Association, 52, 350  355.

Bartholomew, D. J. (1963). The Sampling Distribution of an Estimate Arising in Life Testing. Technometrics, 5, 361  374.

Baumgartner, R. N., Roche, A. F., et al. (1987). Fatness and Fat Patterns: Associations with Plasma Lipids and Blood Pressure in Adults, 18 to 57 Years of Age. American Journal of Epidemiology, 126, 614  628.

490  Beale, E. M. L., Kendall, M. G., and Mann, D. W. (1976). The Discarding of Variable in Multivariate Analysis. Biometrika, 54, 357  366.

Berkson, J. (1942). The Calculation of Survival Rates, in Carcinoma and Other Malignant Lesions of the Stomach, edited by W. Walters, H. K. Gray, and J. T.

Priestley. W.B. Saunders, Philadelphia.

Berkson, J., and Gage, R. R. (1950). Calculation of Survival Rates for Cancer.

Proceedings of Staff Meetings, Mayo Clinic, 25, 250.

Birnbaum, Z. W., and Saunders, S. C. (1958). A Statistical Model for Life-Length of Materials. Journal of the American Statistical Association, 53, 151  160.

Blackstone, E. H., and Lytle, B. W. (2000). Competing Risks after Coronary Bypass Surgery: The Influence of Death on Reintervention. Journal of Thoracic and Cardiovascular Surgery, 119(6), 1221  1230.

Bliwise, D. L., Kutner, N. G., Zhang, R., and Parker, K. P. (2002). Survival by Time of Day of Hemodialysis in an Elderly Cohort. Journal of the American Medical Association, 286(21), 2690  2694.

Boag, J. W. (1949). Maximum Likelihood Estimates of Proportion of Patients Cured by Cancer Therapy. Journal of the Royal Statistical Society, Series B, 11, 15.

Bolard, P., Quantin, C. P., Esteve, J., Faivre, J., and Abrahamowicz, M. (2001).

Modeling Time-Dependent Hazard Ratios in Relative Survival: Application to Colon Cancer. Journal of Clinical Epidemiology, 54 (10) 986  996.

Bonadonna, G., et al. (1976). Combination Chemotherapy as an Adjuvant Treatment in Operable Breast Cancer. New England Journal of Medicine, 294, 405  410.

Brancato, G., Pezzotti, P., Rapiti, E., Perucci, C. A., Abeni, D., Babbalacchio, A., and Rezza, G. (1997). Multiple Imputation Method for Estimating Incidence of HIV Infection: The Multicenter Prospective HIV Study. International Journal of Epidemiology, 26(5), 1107  1114.

Breslow, N. (1970). A Generalized Kruskal  Wallis Test for Comparing K Samples Subject to Unequal Pattern of Censorship. Biometrika, 57, 579  594.

Breslow, N. (1974). Covariance Analysis of Survival Data under the Proportional Hazards Model. International Statistical Review, 43, 43  54.

Breslow, N. E. (1975). Analysis of Survival Data under the Proportional Hazards Model. International Statistical Review, 43, 45  48.

Breslow, N. E., and Crowley, J. (1974). A Large Sample Study of the Life Table and Product Limit Estimates under Random Censoring. Annals of Statistics, 2, 437  453.

Breslow, N. E., and Day, N. E. (1980). Statistical Methods in Cancer Research, Vol. 1, The Analysis of Case-Control Studies. International Agency for Research on Cancer, Lyon, France.

Breslow, N., and Powers, W. (1978). Are There Two Logistic Regressions for Retrospective Studies? Biometrics, 34, 100  105.

Breslow, N. E., Day, N. E., Halvorsen, K. T., Prentice, R. L., and Sabai, C. (1978).

Estimation of Multiple Relative Risk Functions in Matched Case-Control Studies.

American Journal of Epidemiology, 108, 29 9  307.

Broadbent, S. (1958). Simple Mortality Rates. Journal of Applied Statistics, 7, 86.

491 Broderick, A., Mori, M., Nettleman, M. D., Streed, S. A., and Wenzel, R. P. (1990).

Nosocomial Infections: Validation of Surveillance and Computer Modeling to Identify Patients at Risk. American Journal of Epidemiology, 131, 734  742.

Brookmeyer, R., and Goedert, J. J. (1989). Censoring in an Epidemic with an Application to Hemophilia-Associated AIDS. Biometrics, 45, 325  335.

Brown, B. W., and Hollander, M. (1977). Statistics: A Biomedical Introduction. Wiley, New York.

Brown, C. C. (1982). On a Goodness-of-Fit Test for the Logistic Model Based on Score Statistics. Communications in Statistics, 11, 1087  1105.

Brown, G. W., and Flood, M. M. (1947). Tumbler Mortality. Journal of the American Statistical Association, 42, 562  574.

Burdette, W. J., and Gehan, E. A. (1970). Planning and Analysis of Clinical Studies.

Charles C. Thomas, Springfield, IL.

Buzdar, A. U., Gutterman, J. U., Blumehscein, G. R., Hortobagiji, G. H., Tashima, C.

K., Smith, T. L, Hersh, E. M., Freiriech, E. J., and Gehan, E. A. (1978). Intensive Postoperative Chemoimmunotherapy for Patients with Stage II and Stage III Breast Cancer. Cancer, 41, 1064  1075.

Byar, D. P. (1974). Selecting Optimum Treatment in Clinical Trials Using Covariate Information. Presented at the 1974 Annual Meeting of the American Statistical Association, August 28.

Byar, D. P. (1980). The Veterans Administration Study of Chemoprophylaxis for Recurrent Stage I Bladder Tumors: Comparisons of Placebo, Pyridoxine, and Topical Thiotepa, In Bladder Tumors and Other Topics in Urological Oncology, edited by M. Pavone-Macaluso, P. H. Smith, and F. Edsmyn. Plenum Press, New York, pp. 363  370.

Byar, D. P., Huse, R., and Bailar, J. C. III, and the Veterans Administration Cooperative Urological Research Group (1974). An Exponential Model Relating Censored Survival Data and Concomitant Information for Prostatic Cancer Patients.

Journal of the National Cancer Institute, 52, 321  326.

Byers, R. H. Jr., Morgan, W. M., Darrow, W. W., Doll, L., Jaffe, H. W., Rutherford, G., Hessol, N., and OMalley, P. M., (1988). Estimating AIDS Infection Rates in the San Francisco Cohort. AIDS, 2(3), 207  210.

Carbone, P., Kellerhouse, L., and Gehan, E. (1967). Plasmacytic Myeloma: A Study of the Relationship of Survival to Various Clinical Manifestations and Anomalous Protein Type in 112 Patients. American Journal of Medicine, 42, 9 37  948.

Carnahan, B., Luther, H. A., and Wilkes, J. O. (1969). Applied Numerical Methods.

Wiley, New York.

Carter, S. K., Oleg, S., and Slavik, M. (1977). Phase I Clinical Trials, in Methods of Development of New Anticancer Drugs. National Cancer Institute Monograph 45.

U.S. Department of Health, Education, and Welfare Publication (NIH) 76  1037.

National Cancer Institute, Bethesda, MD.

Chernoff, H., and Leiberman, G. J. (1954). Use of Normal Probability Paper. Journal of the American Statistical Association, 49, 778  785.

Chiang, C. L. (1961). Standard Error of the Age-Adjusted Death Rate. Vital Statistics: Special Reports, Selected Studies, 47, 9. U.S. Department of Health, Education, and Welfare, Washington, DC.

492  Chiang, C. L. (1968). Introduction to Stochastic Processes in Biostatistics. Wiley, New York.

Chiasson, M. A., Stoneburner, R. L., et al. (1990). Risk Factors for Human Immunodeficiency Virus Type 1 (HIV-1) Infection in Patients at a Sexually Transmitted Disease Clinic in New York City. American Journal of Epidemiology, 131, 208  220.

Clayton, D., and Cuzick, J. (1985). The Em algorithm for Coxs regression model using GLIM. Applied Statistics, 34, 148  156.

Cochran, W. G., and Cox, G. M. (1957). Experimental Designs, 2nd ed. Wiley, New York.

Cohen, A. C., Jr. (1951). Estimating Parameters of Logarithmic-Normal Distributions by Maximum Likelihood. Journal of the American Statistical Association, 46, 206  212.

Cohen, A. C., Jr. (1959). Simplified Estimators for the Normal Distribution When Samples Are Singly Censored or Truncated. Technometrics, 1(3), 217  237.

Cohen, A. C., Jr. (1961). Table for Maximum Likelihood Estimates: Singly Truncated and Singly Censored Samples. Technometrics, 3, 535  541.

Cohen, A. C., Jr. (1963). Progressively Censored Sample in Life Testing. Technometrics, 5, 327  339.

Cohen, A. C., Jr. (1976). Progressively Censored Sampling in the Three Parameter Log-Normal Distribution. Technometrics, 18.

Cohen, J., and Cohen, P. (1975). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences. Lawrence Erlbaum Associates, Hillsdale, NJ.

Collett, D. (1991). Modelling Binary Data. Chapman & Hall, London.

Collins, J. A., Garner, J. B., Wilson, E. H., Wrixon, W., and Casper, R. F. (1984). A Proportional Hazards Analysis of the Clinical Characteristics of Infertile Couples.

American Journal of Obstetrics and Gynecology, 148, 527  532.

Connelly, R. R., Cutler, S. J., and Baylis, P. (1966). End Result in Cancer of the Lung: Comparison of Male and Female Patients. Journal of the National Cancer Institute, 36, 277  287.

Cornfield, J. (1951). A Method of Estimating Comparative Rates from Clinical Data: Applications to Cancer of the Lung, Breast and Cervix. Journal of the National Cancer Institute, 11, 1269  1275.

Cornfield, J. (1956). A Statistical Problem Arising from Retrospective Studies, in Proceedings of the 3rd Berkeley Symposium on Mathematical Statistics and Probability, Vol. 4, edited by J. Neyman. University of California Press, Berkeley, CA, 135  148.

Cornfield, J. (1962). Joint Dependence of Risk of Coronary Heart Disease in Serum Cholesterol and Systolic Blood Pressure: A Discriminant Function Analysis.

Federation Proceedings, 21, 58  61.

Correa, P., Pickle, L. W., Fortham, E., et al. (1983). Passive Smoking and Lung Cancer.

Lancet, 2, 59 5  597.

Cox, D. R. (1961). Tests of Separate Families of Hypotheses. Proc. Fourth Berkeley Symposium in Mathematical Statistics, I, Berkeley: University of California Press, 105  123.

493 Cox, D. R. (1962). Further Results on Tests of Separate Families of Hypotheses. J. R.

Stat. Soc. B, 24, 406  424.

Cox, D. R. (1953). Some Simple Tests for Poisson Variates. Biometrika, 40, 354  360.

Cox, D. R. (1959). The Analysis of Exponentially Distributed Life-Times with Two Types of Failures. Journal of the Royal Statistical Society, Series B, 21, 411  421.

Cox, D. R. (1962). Renewal Theory. Methuen, London.

Cox, D. R. (1964). Some Applications of Exponentially Distributed Life-Times with Two Types of Failures. Journal of the Royal Statistical Society, Series B, 26, 103  110.

Cox, D. R. (1970). Analysis of Binary Data. Methuen, London.

Cox, D. R. (1972). Regression Models and Life Tables. Journal of the Royal Statistical Society, Series B, 34, 187  220.

Cox, D. R., and Hinkley, D. V. (1974). T heoretic Statistics, Chapman and Hall, London.

Cox, D. R., and Oakes, D. (1984). Analysis of Survival Data. Chapman & Hall, New York.

Cox, D. R., and Snell, E. J. (1968). A General Definition of Residuals. Journal of the Royal Statistical Society, Series B, 30, 248  275.

Cox, D. R., and Snell, E. J. (1989). The Analysis of Binary Data, 2nd ed. Chapman & Hall, London.

Crawford, S. L., Tennstedt, S. L., and McKinlay, J. B. (1995). A Comparison of Analytic Methods for Non-random Missingness of Outcome Data. J. Clin Epidemiol, 48, 209  219.

Crist, W., Boyett, J., and Jackson, J., et al. (1989). Prognostic Importance of the Pre-B-Cell Immunophenotype and Other Presenting Features in B-Lineage Childhood Acute Lymphoblastic Leukemia: A Pediatric Oncology Group Study. Blood, 74, 1252  1259.

Crowley, J., and Hu, M. (1977). Covariance Analysis of Heart Transplant Survival Data.

Journal of the American Statistical Association, 72, 27  36.

Crowley, J., and Thomas, D. R. (1975). Large Sample Theory for the Log Rank Test.

Technical Report 415. Department of Statistics, University of Wisconsin, Madison, WI.

Cutler, S. J., and Ederer, F. (1958). Maximum Utilization of the Life Table Method in Analyzing Survival. Journal of Chronic Diseases, 8, 69 9  712.

Cutler, S. J., Griswold, M. H., and Eisenberg, H. (1957). An Interpretation of Survival Rates: Cancer of the Breast. Journal of the National Cancer Institute, 19, 1107  1117.

Cutler, S. J., Ederer, F., Griswold, M. H., and Greenberg, R. A. (1959). Survival of Breast-Cancer Patients in Connecticut, 1935  54. Journal of the National Cancer Institute, 23, 1137  1156.

Cutler, S. J., Ederer, F., Griswold, M. H., and Greenberg, R. A. (1960a). Survival of Patients with Uterine Cancer, Connecticut, 1935  54. Journal of the National Cancer Institute, 24, 519  539.

Cutler, S. J., Ederer, F., Griswold, M. H., and Greenberg, R. A. (1960b). Survival of Patients with Ovarian Cancer, Connecticut, 1935  54. Journal of the National Cancer Institute, 24, 541  549.

494  Cutler, S. J., Axtell, L., and Heise, H. (1967). Ten Thousand Cases of Leukemia: 1940  62. Journal of the National Cancer Institute, 39, 9 9 3  1026.

Daniel, C. (1959). Use of Half-Normal Plots in Interpreting Factorial Two-Level Experiments. Technometrics, 1, 311  341.

Daniel, W. W. (1987). Biostatistics: A Foundation for Analysis in the Health Sciences.

Wiley, New York.

Davis, D. J. (1952). An Analysis of Some Failure Data. Journal of the American Statistical Association, 47, 113  150.

Davis, H. T., and Feldstein, M. L. (1979). The Generalized Pareto Law as a Model for Progressively Censored Survival Data. Biometrika, 66, 29 9  306.

Dawber, T. R. (1980). The Framingham Study. Harvard University Press, Cambridge, MA.

Dawber, T. R., Meadors, G. F., and Moore, F. E. Jr. (1951). Epidemiological Approaches to Heart Disease: The Framingham Study. American Journal of Public Health, 41, 279  286.

Delong, D. M., Guirguis, G. H., and So, Y. C. (1994). Efficient Computation of Subset Selection Probablilities with Application to Cox Regression. Biometrica. 81 607  611.

Dharmalingam, A., Pool, I., and Dickson, J. (2000). Biosocial Determinants of Hyster-ectomy in New Zealand. American Journal of Public Health, 90(9), 1455  1458.

Dixon, W. J., Brown, M. B., Engelman, L., Hill, M. A., and Jennrich, R. I. (1990). BMDP Statistical Software Manual. University of California Press, Berkeley, CA.

Draper, N. R., and Smith, H. (1966). Applied Regression Analysis. Wiley, New York.

Drenick, R. F. (1960). The Failure Law of Complex Equipment. Journal of Social and Industrial Applied Mathematics, 8, 680.

Dunn, O. J. (1964). New Table for Multiple Comparisons with a Control. Biometrics, 20, 482  491.

Ederer, F., Axtell, L. M., and Cutler, S. J. (1961). The Relative Survival Rate: A Statistical Methodology. National Cancer Institute Monographs, 6, 101  121.

Efron, B. (1975). The Efficiency of Logistic Regression Compared to Normal Discriminant Analysis. Journal of the American Statistical Association, 70, 89 2  898.

Efron, B. (1977). The Efficiency of Coxs Likelihood Function for Censored Data.

Journal of the American Statistical Association, 72, 557  565.

Efron, B. (1994). Missing Data, Imputation, and the Bootstrap. Journal of the American Statistical Association, 89, 463  475.

Eisenberger, M., Krasnow, S., Ellenberg, S., et al. (1989). A Comparison of Carboplatin Plus Methotrexate versus Methotrexate Alone in Patients with Recurrent and Metastatic Head and Neck Cancer. Journal of Clinical Oncology, 7, 1341  1345.

Elaad, E., and Ben-Shakhar, G. (1989). Effects of Motivation and Verbal Response Type on Psychophysiological Detection of Information. Psychophysiology, 26, 442  451.

Elandt-Johnson, R. C., and Johnson, N. L. (1980). Survival Models and Data Analysis.

Wiley, New York.

Enas, G. G., Dornseit, B. E., Sampson, C. B., Rockhold, F. W., and Wuu, J. (1989).

Monitoring versus Interim Analysis of Clinical Trials: A Perspective from the Pharmaceutical Industry. Controlled Clinical Trials, 10, 57  70.

495 Epstein, B. (1958). The Exponential Distribution and Its Role in Life Testing. Industrial Quality Control, 15, 2  7.

Epstein, B. (1960a). Estimation of the Parameters of Two Parameter Exponential Distribution from Censored Samples. Technometrics, 2, 403  406.

Epstein, B. (1960b). Estimation from Life Test Data. Technometrics, 2, 447  454.

Epstein, B., and Sobel, M. (1953). Life Testing. Journal of the American Statistical Association, 48, 486  502.

Farewell, V. T. (1979). Some Results on the Estimation of Logistic Models Based on Retrospective Data. Biometrika, 66, 27  32.

Farrington, C. P. (2000). Residuals for Proportional Hazards Models with Interval-Censored Survival Data. Biometrics, 56(2), 473  482.

Feigl, P., and Zelen, M. (1965). Estimation of Exponential Survival Probabilities with Concomitant Information. Biometrics, 21, 826  838.

Feinleib, M. (1960). A Method of Analyzing Log-Normally Distributed Survival Data with Incomplete Follow-up. Journal of the American Statistical Association, 55, 534  545.

Feinleib, M., and MacMahon, B. (1960). Variation in the Duration of Survival of Patients with Chronic Leukemias. Blood, 17, 332  349.

Feskanich, D., Singh, V., Willett, W. C., and Colditz, G. A. (2002). Vitamin A Intake and Hip Fractures among Postmenopausal Women. Journal of the American Medical Association, 287(1) 47  54.

Fish, E. B., Chapman, J. A. and Link, M. A. (1998). Competing Causes of Death for Primary Breast Cancer. Annals of Surgical Oncology, 5(4), 368  375.

Fisher, R. A. (1922). On the Mathematical Foundation of Theoretical Statistics.

Philosophical Transactions of the Royal Society of London, Series A, 222.

Fisher, R. A. (1936). The Use of Multiple Measurements in Toxonomic Problems.

Annals of Eugenics, 7, 312  330.

Fleiss, J. L. (1979). Confidence Intervals for the Odds Ratio in Case-Control Studies: The State of the Art. Journal of Chronic Diseases, 32, 69  82.

Fleiss, J. L. (1981). Statistical Methods for Rates and Proportions. Wiley, New York.

Fleming, T. R., and Harrington, D. P. (1979). Non-parametric Estimation of the Survival Distribution in Censored Data. Unpublished manuscript.

Fleming, T. R., and Harrington, D. P. (1991). Counting Processes and Survival Analysis.

Wiley, New York.

Fleming, T. R., OFallon, J. R., OBrian, P. C., and Harrington, D. P. (1980). Modified Kolmogorov  Smirnov Test Procedures with Application to Arbitrarily Right Censored Data. Biometrics, 36, 607  626.

Fleming, T. R., Harrington, D. P., and OBrien, P. C. (1984). Designs for Group Sequential Tests. Controlled Clinical Trials, 5, 348  361.

Florin, V., and Ronghui, X. (2000). Proportional Hazards Model with Random Effects.

Statistics in Medicine, 19(24), 3309  3324.

Fraser, D. A. S. (1968). The Structure of Inference. Wiley, New York.

Freedman, L. S. (1982). Tables of the Number of Patients Required in Clinical Trials Using the Log Rank Test. Statistics in Medicine, 1, 121  129.

496  Frei, E., et al. (1961). Studies of Sequential and Combination Antimetabolite Therapy in Acute Leukemia: 6  Mercaptopurine and Methotrexate. Blood, 18, 431  454.

Freireich, E. J., Gehan, E. A., Frei, E., et al. (1963). The Effect of 6-Mercaptopurine on the Duration of Steroid-Induced Remissions in Acute Leukemia: A Model for Evaluation of Other Potential Useful Therapy. Blood, 21(6), 69 9  716.

Freireich, E. J., Gehan, E. A., Rall, D. P., Schmidt, L. H., and Skipper, H. E. (1966).

Quantitative Comparison of Toxicity of Anticancer Agents in Mouse, Rat, Hamster, Dog, Monkey, and Man. Cancer Chemotherapy Report, 50, 4.

Freireich, E. J., Gehan, E. A., Bodey, G. P., Hersh, E. M., Hart, J. S., Gutterman, J. U., and McCredie, K. B. (1974). New Prognostic Factors Affecting Response and Survival in Adult Leukemia. Transactions of the Association of American Physicians, 87, 29 8  305.

Friedman, L. M., Furberg, C. D., and DeMets, D. L. (1985). Fundamentals of Clinical Trials, 2nd ed. PSG Publishing, Littleton, MA.

Gaddum, J. H. (1945a). Log Normal Distributions. Nature, London, 156, 463.

Gaddum, J. H. (1945b). Log Normal Distributions. Nature, London, 156, 747.

Gail, M., and Gart, J. J. (1973). The Determination of Sample Sizes for Use with the Exact Conditional Test in 2;2 Comparative Trials. Biometrics, 29, 441  448.

Gail, M. H., Lubin, J. H., and Rubinstein, L. V. (1981). Likelihood Calculations for Matched Case-Control Studies and Survival Studies with Tied Death Times.

Biometrika, 68, 703  707.

Gajjar, A. V., and Khatri, C. G. (1969). Progressively Censored Samples from LogNormal and Logistic Distributions. Technometrics, 11, 79 3  803.

Garside, M. J. (1965). The Best Sub-set in Multiple Regression Analysis. Applied Statistics, 14, 19 6  200.

Gehan, E. A. (1965a). A Generalized Wilcoxon Test for Comparing Arbitrarily Singly-Censored Samples. Biometrika, 52, 203  223.

Gehan, E. A. (1965b). A Generalized Two-Sample Wilcoxon Test for Doubly-Censored Data. Biometrika, 52, 650  653.

Gehan, E. A. (1970). Unpublished notes on survival time studies. The University of Texas M. D. Anderson Cancer Center, Houston, Texas.

Gehan, E. A. (1969). Estimating Survival Function from the Life Table. Journal of Chronic Diseases, 21, 629  644.

Gehan, E. A., and Thomas, D. G. (1969). The Performance of Some Two-Sample Tests in Small Samples with and without Censoring. Biometrika, 56, 127  132.

Gelenberg, A. J., Kane, J. M., Keller, M. B., et al. (1989). Comparison of Standard and Low Serum Levels of Lithium for Maintenance Treatment of Bipolar Disorder.

New England Journal of Medicine, 321, 1489  1493.

George, S. L., Fernback, D. J., et al. (1973). Factors Influencing Survival in Pediatric Acute Leukemia: The SWCCSG Experience, 1959  1970. Cancer, 32, 1542  1553.

Gertsbakh, I. B. (1989). Statistical Reliability Theory. Marcel Dekker, New York.

Gill, R., and Schumacher, M. (1987). A Simple Test of the Proportional Hazards Assumption. Biometrika, 74, 289  300.

497 Gillum, R. F., Fortmann, S. P., Prineas, R. J., and Kottke, T. E. (1984). International Diagnostic Criteria for Acute Myocardial Infarction and Acute Stroke. American Heart Journal, 108, 150  158.

Glasser, M. (1967). Exponential Survival with Covariance. Journal of the American Statistical Association, 62, 561  568.

Gompertz, B. (1825). On the Nature of the Function Expressive of the Law of Human Mortality and on the New Mode of Determining the Value of Life Contingencies.

Philosophical Transactions, 513.

Gore, S. M. (1983). Graft Survival after Renal Transplantation: Agenda for Analysis.

Kidney Int. , 24, 516  525.

Grambsch, P M., Therneau, T. M. (1994). Proportional Hazards Tests in Diagnostics Based on Weighted Residuals. Biometrika, 81, 515  526.

Gray, R. J. (1990). Some Diagnostic Methods for Cox Regression Models through Hazard Smoothing. Biometrics, 46, 9 3  102.

Green, P. J. (1984). Iteratively Reweighted Least Squares for Maximum Likelihood Estimation, and Some Robust and Resistant Alternatives (with discussion). Journal of the Royal Statistical Society, 46(2), 149  192.

Greenwood, J. A., and Durand, D. (1960). Aids for Fitting the Gamma Distribution by Maximum Likelihood. Technometrics, 2, 55  65.

Greenwood, M. (1926). The Natural Duration of Cancer. Reports on Public Health and Medical Subjects, Her Majestys Stationary Office, London, 33, 1  26.

Griswold, M. H., and Cutler, S. J. (1956). The Connecticut Cancer Register: Seventeen Years of Experience. Connecticut Medical Journal, 20, 366  372.

Griswold, M. H., Wilder, C. S., Cutler, S. J., and Pollack, E. S. (1955). Cancer in Connecticut, 19351951. Monograph. Connecticut State Department of Health, Hartford, CT.

Grizzle, J. E. (1967). Continuity Correction in the -Test for 2;2 Tables. American Statistician, 21, 28  32.

Gross, A. J., and Clark, V. A. (1975). Survival Distributions: Reliability Applications in the Biomedical Sciences. Wiley, New York.

Grove, R. D., and Hetzel, A. M. (1963). Vital Statistics Rates in the United States, 19401960. National Center for Health Statistics, Washington, DC.

Gupta, A. K. (1952). Estimation of the Mean and Standard Deviation of a Normal Population from a Censored Sample. Biometrika, 39, 260  273.

Gupta, S. S. (1960). Order Statistics from the Gamma Distribution. Technometrics, 2, 243  262.

Hagar, H. W., and Bain, L. J. (1970). Inferential Procedures for the Generalized Gamma Distribution. Journal of the American Statistical Association, 65, 1601  1609.

Hahn, G. J., and Shapiro, S. S. (1967). Statistical Models in Engineering. Wiley, New York.

Haldane, J. B. S. (1956). The Estimation and Significance of the Logarithm of a Ratio of Frequencies. Annals of Human Genetics, 20, 309  311.

Halperin, M. (1952). Maximum Likelihood Estimation in Truncated Samples. Annals of Mathematical Statistics, 23, 226  238.

498  Halperin, M., Blackwelder, W. C., and Verter, J. I. (1971). Estimation of the Multivariate Logistic Risk Function: A Comparison of the Discriminant Function and Maximum Likelihood Approaches. Journal of Chronic Diseases, 24, 125  158.

Hammond, I. W., Lee, E. T., Davis, A. W., and Booze, C. F. (1984). Prognostic Factors Related to Survival and Complication-Free Times in Airmen Medically Certified after Coronary Bypass Surgery. Aviation, Space, and Environmental Medicine, April, pp. 321  331.

Hannan, E. J. (1979). The Determination of the Order of an Autoregression. Journal of the Royal Statistical Society, Series B, 41, 19 0  195.

Hanson, B. S., Isacsson, S-O., Janzon, L., and Lindell, S. E. (1989). Social Network and Social Support Influence Mortality in Elderly Men. American Journal of Epidemiology, 130, 100  111.

Harrison, J. D., Jones, J. A., and Morris, D. L. (1990). The Effect of the Gastrin Receptor Antagonist Proglumide on Survival in Gastric Carcinoma. Cancer, 66, 1449  1452.

Hart, J. S., George, S. L., Frei, E., Bodey, G. P., Nickerson, R. C., and Freireich, E. J.

(1977). Prognostic Significance of Pretreatment Proliferative Activity in Adult Acute Leukemia. Cancer, 39, 1603  1617.

Harter, H. L., and Moore, A. H. (1965). Maximum Likelihood Estimation of the Parameters of Gamma and Weibull Populations from Complete and from Censored Samples. Technometrics, 7, 639  643.

Harter, H. L., and Moore, A. H. (1966). Local Maximum Likelihood Estimation of the Parameters of Three-Parameter Log-Normal Population from Complete and Censored Sample. Journal of the American Statistical Association, 61, 842  851.

Harter, H. L., and Moore, A. H. (1967). Asymptotic Variance and Covariances of Maximum Likelihood Estimators, from Censored Samples, of the Parameters of Weibull and Gamma Parameters. Annals of Mathematical Statistic s, 38, 557  570.

Hastings, N. A. J., and Peacock, J. B. (1974). Statistical Distributions. Butterworth, London.

Hauck, W. W., Jr., and Donner, A. (1977). Walds Test as Applied to Hypotheses in Logit Analysis. Journal of the American Statistical Association, 72, 851  853.

Haughton, D. M. A. (1988). On the Choice of a Model to Fit Data from an Exponential Family. Annals of Statistics, 16, 342  355.

Heitjan, D. F. (1997). Annotation: What Can be Done About Missing Data? Approaches to imputation, Am. J. Public Health, 87, 548  550.

Hemstreet, G. P., Yin, S., Ma, Z., Bonner, R. B., Bi, W., Rao, J. Y., Zang, M., Zheng, Q., Bane, B., Asal, N., Li, G., Feng, P., Hurst, R. E., and Wang, W. (2001).

Biomarker Risk Assessment and Bladder Cancer Detection in a Cohort Exposed to Benzidine, Journal of the National Cancer Institute, 93, 427  436.

Hill, A. B. (1960a). Controlled Clinical Trials. Blackwell Scientific, Oxford Hill, A. B. (1960b). Statistical Methods in Clinical and Preventive Medicine. Oxford University Press, Oxford.

Hill, A. B. (1971). Principles of Medical Statistics. Oxford University Press, New York.

Hirayama, T. (1981). Non-smoking Wives of Heavy Smokers Have a Higher Risk of Lung Cancer: A Study from Japan. British Medical Journal, 282, 183  185.

499 Hoel, D. G., Sobel, M., and Weiss, G. H. (1975). A Survey of Adaptive Sampling for Clinical Trials. Perspectives in Biometrics, 1, 29  61.

Holford, T. R., White, C., and Kelsey, J. L. (1978). Multivariate Analysis for Matched Case-Control Studies. American Journal of Epidemiology, 107, 245  256.

Hollander, M., and Proschan, F. (1979). Testing to Determine the Underlying Distribution Using Randomly Censored Data. Biometrics, 35, 39 3  401.

Hollander, M., and Wolfe, D. A. (1973). Nonparametric Statistical Methods. Wiley, New York.

Horner, R. D. (1987). Age at Onset of Alzheimers Disease: Clue to the Relative Importance of Etiologic Factors? American Journal of Epidemiology, 126, 409  414.

Hosmer, D. W., and Lemeshow, S. (1980). A Goodness-of-Fit Test for the Multiple Logistic Regression Model. Communications in Statistics, A10, 1043  1069.

Hosmer, D. W., and Lemeshow, S. (1999). Applied Survival Analysis, 2nd ed. Wiley, New York.

Hosmer, D. W., and Lemeshow, S. (2000). Applied Logistic Regression. Wiley, New York.

Howell, D. W. (1987). Statistical Methods for Psychology. Duxbury Press, Boston.

Hung, C. T., Lim, J. K. C., and Zoest, A. R. (1988). Optimization of High-Performance Liquid Chromatographic Analysis for Isoxazolye Penicillins Using Factorial Design. Journal of Chromatography, 425, 331  341.

Ibrahim, J. G., Chen, M. H., and Sinha, D. (2001). Bayesian Survival Analysis.

Springer-Verlag, New York Ingram, D. D., and Kleinman, J. C. (1989). Empirical Comparisons of Proportional Hazards and Logistic Regression Models. Statistics in Medicine, 8, 525  538.

Irwin, J. O. (1949). The Standard Error of an Estimate of Expectational Life. Journal of Hygiene, 47, 188  189.

Jenkins, S. P. (1997). Discrete Time Proportional Hazards Regression. Stata Technical Bulletin, 39, 17  32.

Jennings, D. E. (1986). Judging Inference Adequacy in Logistic Regression. Journal of the American Statistical Association, 81, 471  476.

Johnson, N. L., and Kotz, S. (1970a). Distributions in Statistics: Continuous Univariate Distributions (Vol. 1) Houghton Mifflin, Boston.

Johnson, N. L., and Kotz, S. (1970b). Distributions in Statistics: Continuous Univariate Distributions. (Vol. 2) Houghton Mifflin, Boston Johnson, P., and Pearce, J. M. (1990). Recurrent Spontaneous Abortion and Polycystic Ovarian Disease: Comparison of Two Regimens to Induce Ovulation. British Medical Journal, 300, 154  156.

Kahn, H. A. (1983). An Introduction to Epidemiologic Methods. Oxford University Press, New York.

Kalbfleisch, J. D. (1974). Some Extensions and Applications of Coxs Regression and Life Model. Presented at the joint meeting of the Biometric Society and the American Statistical Association, Tallahassee, FL, March 20  22.

Kalbfleisch, J. D., and Prentice, R. L. (1973). Marginal Likelihoods Based on Coxs Regression and Life Table Model. Biometrika, 60, 267  278.

500  Kalbfleisch, J. D., and Prentice, R. L. (1980). The Statistical Analysis of Failure Time Data. Wiley, New York.

Kao, J. H. K. (1958). Computer Methods for Estimating Weibull Parameters in Reliability Studies. I.R.E. Transactions on Reliability and Quality Control, PGRQC 13, 15  22.

Kaplan, E. L., and Meier, P. (1958). Nonparametric Estimation from Incomplete Observations. Journal of the American Statistical Association, 53, 457  481.

Kay, R. (1979). Proportional Hazard Regression Models and the Analysis of Censored Survival Data. Applied Statistics, 26, 227  237.

Kay, R. (1984). Goodness of Fit Methods for the Proportional Hazards Model: A Review. Revue Epidemiologie et de Sant Publique, 32, 185  198.

Kelsey, J. L., Thompson, W. D., and Evans, A. S. (1986). Methods in Observational Epidemiology. Oxford University Press, New York.

Kessing, L.V., Olsen, E. W., and Andersen, P. K. (1999). Recurrence in Affective Disorder: Analyses with Frailty Models. American Journal of Epidemiology, 149(5), 404  411.

King, J. R. (1971). Probability Charts for Decision Making. Industrial Press, New York.

King, M., Bailey, D. M., Gibson, D. G., Pitha, J. V., and McCay, P. B. (1979). Incidence and Growth of Mammary Tumors Induced by 7,12-Dimethylbenz()antheacene as Related to the Dietary Content of Fat and Antioxidant. Journal of the National Cancer Institute, 63, 656  664.

Kitagawa, E. M. (1964). Standardized Comparisons in Population Research. Demography, 1, 29 6  315.

Klein, J. P., and Moeschberger, M. L. (1997) Survival Analysis. Springer-Verlag, New York.

Kleinbaum, D. G. (1994). L ogistic Regression: A Self-L earning Text. Springer-Verlag, New York.

Kleinbaum, D. G., Kupper, L. L., and Muller, K. E. (1988). Applied Regression Analysis and Other Multivariate Methods, 2nd ed. PWS-Kent, Boston.

Kodlin, D. (1967). A New Response Time Distribution. Biometrics, 23, 227  239.

Krishna, I. P. V. (1951). A Non-parametric Method of Testing k Samples. Nature, 167, 33.

Kruskal, W. H., and Wallis, W. A. (1952). Use of Ranks in One-Criterion Variance Analysis. Journal of the American Statistical Association, 47, 583  621.

Kuzma, J. W. (1967). A Comparison of Two Life Table Methods. Biometrics, 23, 51  64.

Lagakos, S. W. (1980). The Graphical Evaluation of Explanatory Variables in Proportional Hazard Regression Models. Biometrika, 68, 9 3  98.

Lan, K. K. G., and DeMets, D. L. (1983). Discrete Sequential Boundaries for Clinical Trials. Biometrika, 70, 659  663.

Lan, K. K. G., and DeMets, D. L. (1989). Changing Frequency of Interim Analysis in Sequential Monitoring. Biometrics, 45, 1017  1020.

Lassare, S. (2001). Analysis of Progress in Road Safety in Ten European Countries.

Accident Analysis and Prevention, 33(6), 743  751.

Lawless, J. F. (1982). Statistical Methods and Model for Lifetime Data. Wiley, New York.

501 Lawless, J. F. (1983). Statistical Methods in Reliability. Technometrics, 25, 305  316.

Lee, A. H., and Yau, K. K. (2001) Determining the Effects of Patient Case Mix on Length of Hospital Stay: A Proportional Hazards Frailty Model Approach.

Methods of Information in Medicine, 40(4), 288  292.

Lee, E. T. (1980). Statistical Methods for Survival Data Analysis. Lifetime Learning Publications, Belmont, CA.

Lee, E. T. (1992). Statistical Methods for Survival Data Analysis, second edition, Wiley, New York.

Lee, E. T., and Thomas, D. R. (1980). Confidence Interval for Comparing Two Life Distributions. IEEE Transactions on Reliability, R-29, 51  56.

Lee, E. T., Desu, M. M., and Gehan, E. A. (1975). A Monte-Carlo Study of the Power of Some Two-Sample Tests. Biometrika, 62, 425  432.

Lee, E. T., Ishmael, D. R., Bottomley, R. H., and Murray, J. L. (1982). An Analysis of Skin Tests and Their Relationship to Recurrence and Survival in Stage III and Stage IV Melanoma Patients. Cancer, 49, 2336  2341.

Lee, E. T., Yeh, J. L., Cleves, M. A., and Shafer, D. (1988). Vascular Complications in Noninsulin Dependent Diabetic Oklahoma Indians. Diabetes, 37(Suppl. 1).

Lee, E. T., Lee, V. S., Lu, M., et al. (1992). Incidence and Risk Factors of Diabetic Retinopathy in Oklahoma Indians with NIDDM. Diabetes Care, 15, 1620  1627.

Lee, E. T., Russell, D., Jorge, N., Kenny, S., and Yu, M. (1993). A Follow-up Study of Diabetic Oklahoma Indians: Mortality and Causes of Death. Diabetes Care, 16, 300  305.

Leenen, F. H. H., Balfe, J. A., Pelech, A. N., et al. (1987). Postoperative Hypertension after Repair of Coarctation of Aorta in Children: Protective Effect of Propranolol.

American Heart Journal, 113, 1164  1173.

Lehmann, E. L. (1953). The Power of Rank Tests. Annals of Mathematical Statistics, 24, 23  43.

Leitner, L. M., Roumy, M. Ruckebusch, M., Sutra, J. F. (1986). Monoamines and Their Catabolites in the Rabbit Carotid Body. Effets of reserpine, sympathectomy and carotid sinus nerve section, European Journal of Physiology, 406, 552  556.

Lemeshow, S., and Hosmer, D. W. (1982). A Review of Goodness-of-Fit Statistics for Use in the Development of Logistic Regression Models. American Journal of Epidemiology, 115, 9 2  106.

Leyland-Jones, B., Donnelly, H., Groshen, S., Myskowski, P., Donner, A. L., Fanucchi, M., Fox, J., and the Memorial Sloan-Kettering Antiviral Working Group (1986).

2-Fluror-5-Iodoarabinosylcytosine, A New Potent Antiviral Agent: Efficacy in Immunosuppressed Individuals with Herpes Zoster. Journal of Infectious Diseases, 154, 430  436.

Liang, K. Y., Self, S. G., and Liu, X. (1990). The Cox Proportional Hazards Model with Change Point: An Epidemiologic Application. Biometrics, 46, 783  793.

Liang, K. Y., Self, S. G., Bandeen-Roche, K. J., and Zeger, S. L. (1995). Some Recent Developments for Regression Analysis of Multivariate Failure Time Data. Lifetime Data Analysis, 1, 403  415.

Lieblein, J., and Zelen, M. (1956). Statistical Investigation of the Fatigue Life of Deep-Grove Ball Bearings. Journal of Research of the National Bureau of Standards, 57, 273  316.

502  Lilliefors, H. W. (1971). Reducing the Bias of Estimators of Parameters for the Erlang and Gamma Distribution. Unpublished manuscript.

Lindley, D. V. (1968). The Choice of Variables in Multiple Regression. Journal of the Royal Statistical Society, Series B, 30, 31  53.

Linka, A. Z., Sklenar, J., Wei, K. I., Jayaweera, A. R., Skyba, D. M., and Kaul, S. (1998).

Assessment of Transmural Distribution of Myocardial Perfusion with Contrast Echocardiography. Circulation 3; 98(18); 1912  1920.

Little, R. J., and Rubin, D. B. (1987). Statistical Analysis with Missing Data, John Wiley & Sons, New York.

Liu, P. Y., and Crowley, J. (1978). Large Sample Theory of the MLE Based on Coxs Regression Model for Survival Data. Technical Report 1. Wisconsin Clinical Cancer Center (Biostatistics), University of Wisconsin, Madison, WI.

Lubin, J. H. (1981). A Computer Program for the Analysis of Matched Case-Control Studies. Computers and Biomedical Research, 14, 138  143.

McAlister, D. (1879). The Law of the Geometric Mean. Proceedings of the Royal Society, 29, 367.

McCracken, D. D., and Dorn, W. S. (1964). Numerical Methods and Fortran Programming. Wiley, New York.

McCullagh, P. (1980). Regression Model for Ordinal Data. Journal of the Royal Statistical Society, 42(2), 109  142.

McCullagh, P., and Nelder, J. A. (1989). Generalized Linear Models. Chapman & Hall, London.

McFadden, D. (1976). A Comment on Discriminant Analysis versus Logit Analysis.

Annals of Economic and Social Measurement, 5, 511  523.

Mackenbach, J. P., Kunst, A. E., Lautenbach, H., Bijlsma, F., and Oei, Y.B. (1995).

Competing Causes of Death: An Analysis Using Multiple-Cause-of-Death Data from The Netherlands. 141(5), 466  475.

Mafart, P., Couvert, O., Gaillard, S., and Leguerinel, I. (2002). On Calculating Sterility in Thermal Preservation Methods: Application of the Weibull Frequency Distribution Model. International Journal of Food Microbiology, 72(12); 107  113.

Mann, H. B., and Whitney, D. R. (1947). On a Test of Whether One of Two Random Variables Is Stochastically Larger Than the Other. Annals of Mathematical Statistics, 18, 50  60.

Mann, N. R. (1970). Estimators and Exact Confidence Bounds for Weibull Parameters Based on a Few Ordered Observations. Technometrics, 12, 345  361.

Mann, N. R., Schafer, R. E., and Singpurwalla, N. D. (1974). Methods for Statistical Analysis of Reliability and Life Data. Wiley, New York.

Manninen, O. (1988). Changes in Hearing, Cardiovascular Functions, Haemodynamics, Upright Body Sway, Urinary Catecholamines and Their Correlates after Prolonged Successive Exposure to Complex Environmental Conditions. International Archives of Occupational and Environmental Health, 60, 249  272.

Mantel, N. (1966). Evaluation of Survival Data and Two New Rank Order Statistics Arising in Its Consideration. Cancer Chemotherapy Reports, 50, 163  170.

Mantel, N. (1967). Ranking Procedures for Arbitrarily Restricted Observations. Biometrics, 23, 65  78.

503 Mantel, N. (1970). Why Stepdown Procedures in Variable Selection. Technometrics, 12, 621  625.

Mantel, N. (1973). Synthetic Retrospective Studies and Related Topics. Biometrics, 29, 479  486.

Mantel, N. (1977). Test and Limits for the Common Odds Ratio of Several 2;2 Contingency Tables: Methods in Analogy with the Mantel  Haenszel Procedure.

Journal of Statistical Planning Information, 1, 179  189.

Mantel, N., and Haenszel, W. (1959). Statistical Aspects of the Analysis of Data from Retrospective Studies of Disease. Journal of the National Cancer Institute, 22, 719  748.

Mantel, N., and Hankey, B. F. (1978). A Logistic Regression Analysis of Response-Time Data Where the Hazard Function Is Time Dependent. Communications in Statistics A: Theory and Methods, 7, 333  347.

Mantel, N., and Myers, M. (1971). Problems of Convergence of Maximum Likelihood Iterative Procedures in Multiparameter Situation. Journal of the American Statistical Association, 66, 484  491.

Mantel, N., and Stark, C. R. (1968). Computation of Indirect Adjusted Rates in the Presence of Confounding. Biometrics, 24, 9 9 7  1005.

Marascuilo, L. A., and McSweeney, M. (1977). Nonparametric and Distribution-Free Methods for the Social Sciences. Brooks/Cole, Monterey, CA.

Marubini, E., and Valsecchi, M. G. (1995). Analyzing Survival Data from Clinical Trials and Observational Studies. Wiley, New York.

Matthews, D. E., and Farewell, V. (1985). Using and Understanding Medical Statistics.

S. Karger, New York.

Mausner, J. S., and Kramer, S. (1985). Epidemiology: An Introductory Text. W.B.

Saunders, Philadelphia.

Meier, P. (1975a). Statistics and Medical Experimentation. Biometrics, 31, 511  529.

Meier, P. (1975b). Estimation of a Distribution Function from Incomplete Observations, in Perspectives in Probability and Statistics, edited by J. Gaui. Applied Probability Trust, Sheffield, England.

Meisinger, C., Thorand, B., Schneider, A., Stieber, J., Doring, A., and Lowel, H. (2002) Sex Differences in Risk Factors for Incident Type 2 Diabetes Mellitus: the MONICA Augsburg Cohort Study. Arch Intern Med, 162, 82  89.

Miettinen, O. S. (1979). Comments on Confidence Intervals for the Odds Ratio in Case-Control Studies: The State of the Art, by J. L. Fleiss. Journal of Chronic Diseases, 32, 80  82.

Miller, R. G., Jr. (1966). Simultaneous Statistical Inference. McGraw-Hill, New York.

Miller, R. G. (1981). Survival Analysis. Wiley, New York.

Minow, R. A., Benjamin, R. S., Lee, E. T., and Gottlieb, J. A. (1977). Adriamycin Cardiomyopathy: Risk Factors. Cancer, 39, 1397  1402.

Molloy, D. W., Guyatt, G. H., Wilson, D. B., et al. (1991). Effect of Tetrahydroaminoac-ridine on Cognition, Function and Behaviour in Alzheimers Disease. Canadian Medical Association Journal, 144, 29  34.

Montaner, J. S. G., Lawson, L. M., Levitt, N., et al. (1990). Costicorsteroids Prevent Early Deterioration in Patients with Moderately Severe Pneumocystis Carinii 504  Pneumonia and the Acquired Immunodeficiency Syndrome (AIDS). Annals of Internal Medicine, 113, 14  20.

Moolgavkar, S., Lustbader, E., and Venzon, D. J. (1985). Assessing the Adequacy of the Logistic Regression Model for Matched Case-Control Studies. Statistics in Medicine, 4, 425  435.

Moreau, T., OQuigley, J., and Mesbah, M. (1985). A Global Goodness-of-Fit Statistic for the Proportional Hazards Model. Applied Statistics, 34, 212  218.

Morrison, D. F. (1967). Multivariate Statistical Methods. McGraw-Hill, New York.

Morrison, R. S., and Siu, A. L. (2000). Survival in End-Stage Dementia Following Acute Illness. Journal of the American Medical Association, 284(1), 47  52.

Myers, M., Hankey, B. F., and Mantel, N. (1973). A Logistic-Exponential Model for Use with the Response-Time Data Involving Regressor Variables. Biometrics, 29, 257  269.

Myers, M. H. (1969). A Computing Procedure for a Significance Test of the Difference between Two Survival Curves. Methodological Note 18 in Methodological Notes.

End Results Sections, National Cancer Institute, National Institutes of Health, Bethesda, MD.

Nadas, A. (1970). On Proportional Hazard Functions. Technometrics, 12, 413  416.

National Cancer Institute (1970). Proceedings of the Symposium on Statistical Aspects of Protocol Design, San Juan, Puerto Rico, December 9  10.

Natrella, M. G. (1963). Experimental Statistics. National Bureau of Standards Handbook 91. U.S. Government Printing Office, Washington, DC, Tables A-25, A-26.

Nelson, W. (1972). Theory and Applications of Hazard Plotting for Censored Failure Data. Technometrics, 14, 9 45  966.

Nelson, W. (1982). Applied Life Data Analysis. Wiley, New York.

Nemenyi, P. (1963). Distribution-Free Multiple Comparisons. Ph.D. dissertation, Princeton University.

Neter, J., and Wasserman, W. (1974). Applied Linear Statistical Models. Richard D.

Irwin, Homewood, IL.

Nie, N. H., Hull, C. H., Jenkins, J. G., Steinbrenner, K., and Bent, D. H. (1975). SPSS: Statistical Package for the Social Sciences. McGraw-Hill, New York.

OBrien, P. C., and Fleming, T. R. (1979). A Multiple Testing Procedure for Clinical Trials. Biometrics, 35, 549  556.

Osgood, E. W. (1958). Methods for Analyzing Survival Data, Illustrated by Hodgkins Disease. American Journal of Medicine, 24, 40  47.

Parker, R. L., Dry, T. J., Willius, F. A., and Gage, R. P. (1946). Life Expectancy in Angina Pectoris. Journal of the American Medical Association, 131, 9 5  100.

Parzan, E. (1974). Some Recent Advances in Time Series Modeling. IEEE Transactions on Automatic Control. AC-19, 723  730.

Pearson, E. S., and Hartely, N. O. (1958). Biometrika Tables for Statisticians, Vol. 1.

Cambridge University Press, Cambridge.

Pearson, K. (1922, 1957). Tables of the Incomplete -Function. Cambridge University Press, Cambridge.

Pershagen, G. (1986). Review of Epidemiology in Relation to Passive Smoking. Archives of Toxicology, 9(Suppl.), 63  73.

505 Pershagen, G., Hrubec, Z., and Svensson, C. (1987). Passive Smoking and Lung Cancer in Swedish Women. American Journal of Epidemiology, 125, 17  24.

Peto, R., and Lee, P. N. (1973). Weibull Distributions for Continuous Carcinogenesis Experiments. Biometrics, 29, 457  470.

Peto, R., and Peto, J. (1972). Asymptotically Efficient Rank Invariant Procedures.

Journal of the Royal Statistical Society, Series A, 135, 185  207.

Peto, R., Lee, P. N., and Paige, W. S. (1972). Statistical Analysis of the Bioassay of Continuous Carcinogens. British Journal of Cancer, 26, 258  261.

Peto, R., Pike, M. C., Armitage, P., Breslow, N. E., Cox, D. R., Howard, S. V., Mantel, N., McPherson, K., Peto, J., and Smith, P. G. (1976, 1977). Design and Analysis of Randomized Clinical Trials Requiring Prolonged Observation of Each Patient.

British Journal of Cancer, Part I, 34, 585  612, 1976; Part II, 35, 1  39, 1977.

Pierce, M., Borges, W. H., Heyn, R., Wolfe, J., and Gilbert, E. S. (1969). Epidemiological Factors and Survival Experience in 1770 Children with Acute Leukemia. Cancer, 23, 1296  1304.

Pike, M. C. (1966). A Method of Analysis of a Certain Class of Experiments in Carcinogenesis. Biometrics, 22, 142  161.

Piper, J. M., Matanoski, G. M., and Tonascia, J. (1986). Bladder Cancer in Young Women. American Journal of Epidemiology, 123, 1033  1042.

Pregibon, D. (1984). Data Analytic Methods for Matched Case-Control Studies.

Biometrics, 40, 639  651.

Prentice, R. L. (1973). Exponential Survivals with Censoring and Explanatory Variables. Biometrika, 60, 279  288.

Prentice, R. L. (1974). A Log-Gamma Model and Its Maximum Likelihood Estimation.

Biometrica. 61 539  544.

Prentice, R. L. (1976). Use of the Logistic Model in Retrospective Studies. Biometrics, 32, 59 9  606.

Prentice, R. L., and Gloeckler, L. A. (1978). Regression Analysis of Grouped Survival Data with Application to Breast Cancer Data. Biometrics, 34, 57  67.

Prentice, R. L., and Kalbfleisch, J. D. (1979). Hazard Rate Models with Covariates.

Biometrics, 35, 25  39.

Prentice, R. L., and Marek, P. (1979). A Quantitative Discrepancy between Censored Data Rank Tests. Biometrics, 35, 861  867.

Prentice, R. L., and Pyke, R. (1979). Logistic Disease Incidence Models and Case-control Studies. Biometrica, 73, 403  411.

Prentice, R. L., Williams, B. J., and Peterson, A. V. (1981). On the Regression Analysis of Multivariate Failure Time Data. Biometrica, 68, 373  379.

Press, S. J. (1972). Applied Multivariate Analysis. Holt, Rinehart & Winston, New York.

Press, S. J., and Wilson, S. (1978). Choosing between Logistic Regression and Discriminant Analysis. Journal of the American Statistical Association, 73, 69 9  705.

Ralston, A., and Wilf, H. (1967). Mathematical Methods for Digital Computers. Wiley, New York.

Rao, C. R. (1952). Advanced Statistical Methods in Biometric Research. Wiley, New York.

506  Rao, C. R. (1973). Linear Statistical Inference and Its Application, 2nd ed. Wiley, New York.

Riffenburgh, R. H., and Johnstone, P. A. (2001). Survival Patterns of Cancer Patients.

Cancer, 91(12), 2469  2475.

Rissanen, J. (1986). A Predictive Least-Squares Principle. IMA Journal of Mathematical Control of Information, 3, 211  222.

Rowe-Jones, D. C., Peel, A. L. G., Kingston, R. D., Shaw, J. F. L., Teasdale, C., and Cole, D. S. (1990). Single Dose Cefotaxime Plus Metronidazole versus Three Dose Cefuroxime Plus Metronidazole as Prophylaxis against Wound Infection in Colorectal Surgery: Multicentre Prospective Randomised Study. British Medical Journal, 300, 18  22.

Sacher, G. A. (1956). On the Statistical Nature of Mortality, with Special Reference to Chronic Radiation Mortality. Radiology, 67, 250  257.

Sarhan, A. E., and Greenberg, B. G. (1956). Estimation of Location and Scale Parameters by Order Statistics from Singly and Doubly Censored Samples, Part I, The Normal Distribution up to Samples of Size 10. Annals of Mathematical Statistics, 27, 427  451.

Sarhan, A. E., and Greenberg, B. G. (1957). Estimation of Location and Scale Parameters by Order Statistics from Singly and Doubly Censored Samples, Part III. Technical Report 4-OOR, Project 1597. U.S. Army Research Office.

Sarhan, A. E., and Greenberg, B. G. (1958). Estimation of Location and Scale Parameters by Order Statistics from Singly and Doubly Censored Samples, Part II. Annals of Mathematical Statistics, 29, 79  105.

Sarhan, A. E., and Greenberg, B. G. (1962). Contribution to Order Statistics. Wiley, New York.

Sacks, H., Chalmers, T. C., and Smith, H. (1982). Randomized versus Historical Control for Clinical Trials. American Journal of Medicine, 72, 233  240.

SAS Institute. (2000). SAS/STAT Users Guide, Version 8.1. SAS Institute, Cary, NC.

Sasieni, P. D. (1996). Proportional Excess Hazards. Biometrika, 83(1), 127  141.

Savage, I. R. (1956). Contributions to the Theory of Rank Order Statistics: The Two Sample Case. Annals of Mathematical Statistics, 27, 59 0  615.

Saw, J. G. (1959). Estimation of the Normal Population Parameters Given a Singly Censored Sample. Biometrika, 46, 150  159.

Schade, D. S., Mitchell, W. J., and Griego, G. (1987). Addition of Sulfonylurea to Insulin Treatment in Poorly Controlled Type II Diabetes. Journal of the American Medical Association, 257, 2441  2445.

Schafer, J. L. (1999). Multiple Imputation: a Primer. Stat Methods, 8, 3  15.

Schlesselman, J. J. (1982). Case-Control Studies. Oxford University Press, New York.

Schoenfeld, D. (1982). Partial Residuals for Proportional Hazards Regression Model.

Biometrica. 69, 239  241.

Schwarz, G. (1978). Estimating the Dimension of a Model. Annals of Statistics 6, 461  222.

Seaman, S. R., and Bird, S. M. (2001). Proportional Hazards Model for Interval-Censored Failure Times and Time-Dependent Covariates: Application to Hazard of HIV Infection of Injecting Drug Users in Prison. Statistics in Medicine, 20(12), 1855  1870.

507 Segal, M. R., and Bloch, D. A. (1989). A Comparison of Estimated Proportional Hazards Models and Regression Trees. Statistics in Medicine, 8, 539  550.

Sellke, T., and Siegmund, D. (1983). Sequential Analysis of the Proportional Hazards Model. Biometrika, 70, 315  326.

Shapiro, S. S., and Wilk, M. B. (1965a). An Analysis of Variance Test for Normality (Complete Samples). Biometrika, 52, 591.

Shapiro, S. S., and Wilk, M. B. (1965b). Testing for Distributional Assumptions: Exponential and Uniform Distributions. Unpublished manuscript.

Shibata, R. (1980). Asymptotically Efficient Selection of the Order of the Model for Estimating Parameters of a Linear Process. Annals of Statistics, 8, 147  165.

Shipley, W. U., Thames, H. D., Sandler, H. M., Hanks, G. E., Zietman, Perez, C. A., Kuban, D. A., Hancock, S. L., and Smith, C. D. (1999). Radiation Therapy for Clinically Localized Prostate Cancer. Journal of the American Medical Association, 281(17), 1598  1604.

Shryock, H. S., Sigel, J. S., and Associates (1971). The Methods and Materials of Demography, Vols. I and II. U.S. Department of Commerce, Bureau of the Census, U.S. Government Printing Office, Washington, DC.

Sichieri, R., Everhart, J. E., and Roth, H. P. (1990). Low Incidence of Hospitalization with Gallbladder Disease among Blacks in the United States. American Journal of Epidemiology, 131, 826  835.

Siegmund, K. D., Todorov, A. A., and Province, M. A. (1999). A Frailty Approach for Modelling Diseases with Variable Age of Onset in Families: The NHLBI Family Heart Study. Statistics in Medicine, 18(12), 1517  1528 Sillitto, G. P. (1949). Note on Approximations to the Power Function of the 2;2 Comparative Trial. Biometrika, 36, 347  352.

Sirott, M. N., Bajorin, D. F., Wong, G. Y., Tao, Y., Chapman, P. B., Templeton, M. A., and Houghton, A. N. (1993). Prognostic Factors in Patients with Metastatic Malignant Melanoma: A Multivariate Analysis. Cancer, 72(10), 3091  3098.

Slud, E. V., and Wei, L. J. (1982). Two-Sample Repeated Significance Tests Based on the Modified Wilcoxon Statistic. Journal of the American Statistical Society, 77, 862  868.

Snedecor, G. W., and Cochran, W. G. (1967). Statistical Methods. Iowa State University Press, Ames, IA.

SPSS (2000). SPSS-S Users Guide, Version 10.1. SPSS, Chicago.

Stacy, E. W. (1962). A Generalization of the Gamma Distribution. Annals of Mathematical Statistics, 33, 1187  1192.

Stacy, E. W., and Mihram, G. A. (1965). Parameter Estimation for a Generalized Gamma Distribution. Technometrics, 7, 349  358.

Statistics and Epidemiology Research Corporation (SERC) (1988). EGRET Statistical Software. SERC, Seattle, WA.

Steering Committee on the Physicians Health Study Research Group (1989). Final Report on the Aspirin Component of the Ongoing Physicians Health Study. New England Journal of Medicine, 321, 129  135.

Tai, B. C., Peregoudov, A., and Machin, D. (2001). A Competing Risk Approach to the Analysis of Trials of Alternative Intra-uterine Devices (IUDs) for Fertility Regulation. Statistics in Medicine, 20(23), 3589  3600.

508  Tarone, R. E. (1982). The Use of Historical Control Information in Testing a Trend in Poisson Means. Biometrics, 38(2), 457  462.

Tarone, R. E., and Ware, J. (1977). On Distribution-Free Tests for Equality of Survival Distribution. Biometrics, 64, 156  160.

Teitelman, A. M., Welch, L. S., Hellenbrand, K. G., and Bracken, M. B. (1990). Effect of Maternal Work Activity on Preterm Birth and Low Birth Weight. American Journal of Epidemiology, 131, 104  113.

Therneau, T. M., Grambsch, P. M., and Fleming, T. R. (1990). Martingale-Based Residuals and Survival Models. Biometrica, 77, 147  160.

Thoman, D. R., and Bain, L. J. (1969). Two Sample Tests in the Weibull Distribution.

Technometrics, 11, 805  815.

Thoman, D. R., Bain, L. J., and Antle, C. E. (1969). Inferences on the Parameters of the Weibull Distribution. Technometrics, 11, 445  460.

Thoman, D. R., Bain, L. J., and Antle, C. E. (1970). Maximum Likelihood Estimation, Exact Confidence Intervals for Reliability and Tolerance Limits in the Weibull Distribution. Technometrics, 12, 363  373.

Truett, J., Cornfield, J., and Kannel, W. B. (1967). A Multivariate Analysis of the Risk of Coronary Heart Disease in Framingham. Journal of Chronic Diseases, 20, 511  524.

Tsiatis, A. A. (1980). A Note of a Goodness-of-Fit Test for the Logistic Regression Model. Biometrika, 67, 250  251.

Tsiatis, A. A. (1981). A Large Sample Study of Coxs Regression Model. Annals of Statistics, 9, 9 3  108.

Tsiatis, A. A. (1982). Repeated Significance Testing for a General Class of Statistics Used in Censored Survival Analysis. Journal of the American Statistical Association, 77, 855  861.

Tsumagari, K., Yamamoto, H., Suganuma, N., Kato, M., Ikeda, S., Imai, K., Kira, S., and Taketa, K. (2000). Epidemiological Studies of Coincidental Outbreaks of Enterohemorrhagic Escherichia Coli O157:H7 Infection and Infectious Gastroen-teritis in Niimi City, Acta Medica Okayama, 54, 265  273.

Upton, G. J. G. (1978). The Analysis of Cross-Tablated Data. Wiley New York.

Vaida, F., and Xu, R. (2000). Proportional Hazards Model with Random Effects.

Statistics in Medicine, 19(22), 339  3324.

Vasan, R. S., Larson, M. G., Leip, E. P., Evans, J. C., ODonnell, C. J., Kannel, W. B., and Levy, D. (2001). Impact of High-Normal Blood Pressure on the Risk of Cardiovascular Disease. New England Journal of Medicine. 345(18), 1337  1340.

Vaupel, J. W., Manton, K. G., and Stallard, E. (1979). The Impact of Heterogenity in Individual Frailty on the Dynamics of Mortality. Demography, 16, 439  454.

Vasan, R. S., Larson, M. G., Levy, D., Evans, J. C., and Benjamin, E. J. (1997).

Distribution and Categorization of Echocardiographic Measurements in Relation to Reference Limits: the Framingham Heart Study: Formulation of a Height-and Sex-specific Classification and Its Prospective Validation. Circulation, 96, 1863  1873.

Vega, G. L., and Grundy, S. M. (1989). Comparison of Lovastatin and Gemfibrozil in Normolipidemic Patients with Hypoalphalipoproteinemia. Journal of the American Medical Association, 262, 3148  3153.

509 Wald, A. (1947). Sequential Analysis. Wiley, New York.

Wang, Wenyu (1984). The Bayesian Estimater of the Orders of AR( k) and ARMA( p,q) Models of Time Series. Acta Mathematicae Applicatae Sinica, 7(2), 185  195.

Wang, Wenyu (1989). Statistical Inference on Aggregated Markov Processes. Ph.D.

dissertation. Department of Mathematics, University of Maryland.

Waters, M. A., Selvin, S., and Rappaport, S. M. (1991). A Measure of Goodness-of-fit for the Lognormal Model Applied to Occupational Exposures, American Industrial Hygiene Association Journal, 52, 49 3  502.

Watson, G. S., and Wells, W. T. (1961). On the Possibility of Improving the Mean Useful Life of Items by Eliminating Those with Short Lives. Technometrics, 3, 281  298.

Wei, L. J. (1984). Testing Goodness of Fit for Proportional Hazards Model with Censored Observations. Journal of the American Statistical Association, 79, 649  652.

Wei, L. J. (1992). On Predictive Least Squares Principle. Annals of Statistics, 20, 1  42.

Wei, L. J., Lin, D. Y., and Weissfeld, L. (1989). Regression Analysis of Multivariate Incomplete Failure Time Data by Modeling Marginal Distribution. Journal of the American Statistical Association, 84, 1065  1073.

Weibull, W. (1939). A Statistical Theory of the Strength of Materials. Ingenioers vetenskaps akakemien Handlingar, 151, 29 3  297.

Weibull, W. (1951). A Statistical Distribution of Wide Applicability. Journal of Applied Mathematics, 18, 29 3  297.

Weiss, H. (1963). A Survey of Some Mathematical Methods in the Theory of Reliability, in Statistical Theory of Reliability, edited by M. Zelen. University of Wisconsin Press, Madison, WI.

Well, M. D., Lamborn, K., Edwards, M. S. B., and Wara, W. M. (1998). Influence of a Childs Sex on Medulloblastoma. Journal of the American Medical Association, 279(18).

Whayne, T. F., Alaupovic, P., Curry, M. D., Lee, E. T., Anderson, P. S., and Schechter, E. (1981). Plasma Apolipoprotein B and VLDL-, LDL-, and HDL-Cholesterol as Risk Factors in the Development of Coronary Heart Disease in Male Patients Examined by Angiography. Atherosclerosis, 39, 411  424.

Wienke, A., Holm, N. V., Skytthe, A., and Yashin, A. L. (2001). The Heritability of Mortality Due to Heart Diseases: A Correlated Frailty Model Applied to Danish Twins. Twin Research, 4(4), 266  274.

Wilcoxon, F. (1945). Individual Comparison by Ranking Methods. Biometrics, 1, 80  83.

Wilk, M. B., Gnanadesikan, R., and Huyett, M. J. (1962a). Estimation of Parameters of the Gamma Distribution Using Order Statistics. Biometrika, 49, 525  545.

Wilk, M. B., Gnanadesikan, R., and Huyett, M. J. (1962b). Probability Plots for the Gamma Distribution. Technometrics, 4, 1  20.

Wilkinson, L. (1987). SYSTAT: The System for Statistics. Systat, Inc., Evanston, IL.

Wilks, S. S. (1948). Order Statistics. Bulletin of the American Mathematical Society, 54, 6  50.

Wilks, S. S. (1950). Mathematical Statistics. Princeton University Press, Princeton, NJ.

510  Williams, C. A., Jr. (1950). On the Choice of the Number and Width of Classes for the Chi-Square Test of Goodness of Fit. Journal of the American Statistical Association, 45, 77  86.

Williams, J. E., Nieto, F. J., Sanford, C. P., and Tyroler, H. A. (2002). The Association between Trait Anger and Incident Stroke Risk: The Atherosclerosis Risk in Communities (ARIC) Study. Stroke, 33(1), 13  20.

Winkleby, M. A., Ragland, D. R., and Syme, L. (1988). Self-Reported Stressors and Hypertension: Evidence of an Inverse Association. American Journal of Epidemiology, 127, 124  134.

Winter, F. D., Snell, P. G., and Stray-Gundersen, J. (1989). Effects of 100% Oxygen on Performance of Professional Soccer Players. Journal of the American Medical Association, 262, 227  229.

Woolf, B. (1955). On Estimating the Relation between Blood Group and Disease.

Annals of Human Genetics, 19, 251  253.

Wurpel, J. N., Dundore, R. L., Barbella, Y. R., Balaban, C. D., Keil, L. C., and Severs, W. B. (1986). Barrel Rotation Evoked by Intracerebroventricular Vasopressin Injections in Conscious Rats. I. Description and General Pharmacology. Brain Research, 365, 21  29.

Xue, X. (2001). Analysis of Childhood Brain Tumour Data in New York City Using Frailty Models. Statistics in Medicine, 20(22), 3459  3473.

Yakovlev, A. Y., Tsodikov, A. D., Boucher, K., and Kerber, R. (1999). The Shape of the Hazard Function in Breast Carcinoma: Curability of the Disease Revisited.

Cancer, 85, 1789  1798.

Yan, Y., Moore, R. D., and Hoover, D. R. (2000). Competing Risk Adjustment Reduces Overestimation of Opportunistic Infection Rates in AIDS. Journal of Clinical Epidemiology. 53(8), 817  822.

Yashin, A. I., and Iachine, I. A. (1997). How Frailty Models Can Be Used for Evaluating Longevity Limits: Taking Advantage of an Interdisciplinary Approach. Demography, 34(1), 31  48.

Young, E. M., and Fors, S. W. (2001). Factors Related to the Eating Habits of Students in Grades 9  12. Journal of School Health, 71, 483  488.

Zelen, M. (1966). Applications of Exponential Models to Problems in Cancer Research.

Journal of the Royal Statistical Society, Series A, 129, 368  398.

Zhang, M. J., and Klein, J. P. (2001). Confidence Bands for the Difference of Two Survival Curves under Proportional Hazards Model. L ifetime Data Analysis, 7, 243  254.

Zippin, C., and Armitage, P. (1966). Use of Concomitant Variables and Incomplete Survival Information in the Estimation of an Exponential Survival Parameter.

Biometrics, 22, 665  672.

Index Accelerated failure time (AFT) model, 259 Density function: Age-specific failure rate, 11 definition of, 10 AIC, 230, 241, 288, 289 types of: Anderson  Gill model, 368 exponential, 135 Annual survival ratio, 94 extended generalized gamma, 153 gamma, 150 BIC, 230, 241, 288, 289 generalized gamma, 152 BMDP, 7, 94, 115, 173, 180, 188, 196, 235, 269, log-logistic, 154 273, 277, 283, 306, 319, 324, 347, lognormal, 145 351, 356, 367, 368, 389, 394, 398, 403, Weibull, 139 405, 413, 419, 424 Deviance residual, 331 Dichotomous outcomes, 377 Case-control study, 399 Exponential distribution, 134, 263 Censored observations, 2 unit exponential distribution, 135 progressively censored data, 4 two-parameter, 136 singly censored data, 4 goodness-of-fit test, 226, 233 Censoring test for equality of two distributions, 246, 249 interval, 4, 260 left, 4, 260 random, 4 Five-year survival rate, 94 right, 4, 260 Force of mortality, 11 type I, 2 Frailty model, 375 type II, 2 type III, 3 Gamma and generalized gamma distribution, Chi-square test, 379, 381 148, 277 Competing risk, 352 goodness-of-fit test, 227, 234, 235 Conditional mortality rate, 11 test for equality of two distributions, 252 Conditional probability, 399, 401 Gap time, 364 Corrected survival rate, 94 Gehans generalized Wilcoxon test, 107 Coxs F-test, 116, 249 Gompertz distribution, 157, 242 Cox  Mantel test, 109 Guarantee time, 136, 173, 175 Cox  Snell residual, 199, 215, 290, 331 Cross-product ratio, 382 Hazard function: Cumulative hazard function, 13 definition of, 11 Cumulative survival rate, 9 exponential, 135 511 512  Hazard function ( Continued ) interval-censored data, 165, 260 gamma, 152 left-censored data, 165, 260 log-logistic, 155 log-logistic, 195 lognormal, 145 lognormal, 180 Weibull, 140 right-censored data, 162, 260 Hazard plotting, 29, 209 standard and generalized gamma, 188 exponential, 210 two-parameter exponential, 174 log-logistic, 215 Weibull, 178 lognormal, 213 Martingale residual, 331 Weibull, 212 Matched design, 401 Hollander  Proschans test, 236 1 : R, 401 Hosmer  Lemeshow test of goodness-of-fit, 388 n: n, 4 03 Median remaining lifetime, 91 Incomplete gamma function, 151 Model selection method, 230, 233, 286, 288, Instantaneous failure rate, 11 289, 310 Kaplan  Meier method, 20, 68, 216, 237 Normit function, 410 Kruskal  Wallis test, 125 multiple comparison, 128 Odds ratio, 379, 382 K-sample test for censored data, 130 Life tables: Partial likelihood function, 301, 304, 340, 348, abridged, 86 354, 357, 364, 369, 371 clinical, 87 Peto and Petos generalized Wilcoxon test, 116 cohort, 77 Polychotomous outcomes, 377, 413 current, 77 nominal, 414 population, 77 ordinal, 419 Likelihood ratio test, 243, 246 Printice, Williams, and Peterson (PWP) model, Link function, 410 357, 363 logit, 410 Probability density function, 10 probit, 410 Probability plotting, 29, 200 complementary log-log, 411 exponential, 204 Linear exponential distribution, 155 log-logistic, 208 Log-logistic distribution, 154, 280 lognormal, 206 goodness-of-fit test, 235 normal, 203 Log odds, 386 Weibull, 205 Logistic regression, 45, 385 Probit function, 410, 420 conditional, 398 Product-limit estimate, 65 dichotomous outcomes, 377 estimate of mean survival time, 74 polychotomous outcomes, 377, 413 variance, 70 nominal, 414 variance of estimated mean survival time, 75 ordinal, 419 Prognostic factors, 32, 256, 339, 377 Logistic transform, 386 Prognostic homogeneity, 21 Log-likelihood ratio statistic, 223, 224, 388 Proportional hazard model, 264, 270, 298 Lognormal distribution, 143, 274 assessment of, 326 three-parameter, 146 Proportional odds, 280 goodness-of-fit test, 227, 234 Logrank test, 111 Rayleigh distribution, 158 Recurrent events, 356 Mantel  Haenszel method, 28, 121 Related observations, 374 Maximum likelihood estimate: Relative mortality, 32 exponential, 166 Relative survival rate, 94 Gompertz, 196 Retrospective study, 398  513 SAS, 7, 94, 115, 172, 173, 80, 188, 194, 196, 235, types: 268, 273, 276, 279, 283, 289, 291, exponential, 135 306, 310, 317, 322, 333, 346, 350, 355, gamma, 152 366, 389, 392, 397, 403, 408, 410, log-logistic, 154 412, 418, 424 lognormal, 145 Schoenfeld residual, 331 two-parameter-exponential, 136 weighted, 332 Weibull, 140 Score statistic, 225 SPSS, 7, 94, 115, 318, 323, 336, 347, 351, 356, Test of goodness of fit, 221, 222, 226, 227, 233, 367, 389, 392, 397, 405, 413, 419, 424 234, 235, 330 Standardized rate and ratio, 97 Tied survival times, 302 direct method, 98 Time-dependent covariates, 326, 339 indirect method, 99 SIR, 97 Unconditional failure rate, 11 SMR, 97 Standardized mortality ratio, 97 Wald statistic, 223, 224, 262, 388 Stritification, 328, 348 Wei, Lin, and Weissfeld (WLW) model, 370 Survival curve, 9 Weibull distribution, 138, 269 Survivorship function: three-parameter, 141 definition of, 8 goodness-of-fit test, 226, 234 estimation of, 319 test for equality of two distributions, 251 p&s-cp.qxd 3/25/03 9:47 AM Page 1 WILEY SERIES IN PROBABILITY AND STATISTICS Established by WALTER A. SHEWHART and SAMUEL S. WILKS Editors: David J. Balding, Peter Bloomfield, Noel A. C. Cressie, Nicholas I. Fisher, Iain M. Johnstone, J. B. Kadane, Louise M. Ryan, David W. Scott, Adrian F. M. Smith, Jozef L. Teugels Editors Emeriti: Vic Barnett, J. Stuart Hunter, David G. Kendall A complete list of the titles in this series appears at the end of this volume.

p&s-cp.qxd 3/25/03 9:47 AM Page 2 WILEY SERIES IN PROBABILITY AND STATISTICS ESTABLISHED BY WALTER A. SHEWHART AND SAMUEL S. WILKS Editors: David J. Balding, Peter Bloomfield, Noel A. C. Cressie, Nicholas I. Fisher, Iain M. Johnstone, J. B. Kadane, Louise M. Ryan, David W. Scott, Adrian F. M. Smith, Jozef L. Teugels Editors Emeriti: Vic Barnett, J. Stuart Hunter, David G. Kendall The Wiley Series in Probability and Statistics is well established and authoritative. It covers many topics of current research interest in both pure and applied statistics and probability theory. Written by leading statisticians and institutions, the titles span both state-of-the-art developments in the field and classical methods.

Reflecting the wide range of current research in statistics, the series encompasses applied, methodological and theoretical statistics, ranging from applications and new techniques made possible by advances in computerized practice to rigorous treatment of theoretical approaches.

This series provides essential and invaluable reading for all statisticians, whether in aca-demia, industry, government, or research.

ABRAHAM and LEDOLTER  Statistical Methods for Forecasting AGRESTI  Analysis of Ordinal Categorical Data AGRESTI  An Introduction to Categorical Data Analysis AGRESTI  Categorical Data Analysis, Second Edition ANDEL  Mathematics of Chance ANDERSON  An Introduction to Multivariate Statistical Analysis, Second Edition *ANDERSON  The Statistical Analysis of Time Series ANDERSON, AUQUIER, HAUCK, OAKES, VANDAELE, and WEISBERG  Statistical Methods for Comparative Studies ANDERSON and LOYNES  The Teaching of Practical Statistics ARMITAGE and DAVID (editors)  Advances in Biometry ARNOLD, BALAKRISHNAN, and NAGARAJA  Records *ARTHANARI and DODGE  Mathematical Programming in Statistics *BAILEY  The Elements of Stochastic Processes with Applications to the Natural Sciences BALAKRISHNAN and KOUTRAS  Runs and Scans with Applications BARNETT  Comparative Statistical Inference, Third Edition BARNETT and LEWIS  Outliers in Statistical Data, Third Edition BARTOSZYNSKI and NIEWIADOMSKA-BUGAJ  Probability and Statistical Inference BASILEVSKY  Statistical Factor Analysis and Related Methods: Theory and Applications BASU and RIGDON  Statistical Methods for the Reliability of Repairable Systems BATES and WATTS  Nonlinear Regression Analysis and Its Applications BECHHOFER, SANTNER, and GOLDSMAN  Design and Analysis of Experiments for Statistical Selection, Screening, and Multiple Comparisons BELSLEY  Conditioning Diagnostics: Collinearity and Weak Data in Regression BELSLEY, KUH, and WELSCH  Regression Diagnostics: Identifying Influential Data and Sources of Collinearity BENDAT and PIERSOL  Random Data: Analysis and Measurement Procedures, Third Edition *Now available in a lower priced paperback edition in the Wiley Classics Library.

p&s-cp.qxd 3/25/03 9:47 AM Page 3 BERRY, CHALONER, and GEWEKE  Bayesian Analysis in Statistics and Econometrics: Essays in Honor of Arnold Zellner BERNARDO and SMITH  Bayesian Theory BHAT and MILLER  Elements of Applied Stochastic Processes, Third Edition BHATTACHARYA and JOHNSON  Statistical Concepts and Methods BHATTACHARYA and WAYMIRE  Stochastic Processes with Applications BILLINGSLEY  Convergence of Probability Measures, Second Edition BILLINGSLEY  Probability and Measure, Third Edition BIRKES and DODGE  Alternative Methods of Regression BLISCHKE AND MURTHY (editors)  Case Studies in Reliability and Maintenance BLISCHKE AND MURTHY  Reliability: Modeling, Prediction, and Optimization BLOOMFIELD  Fourier Analysis of Time Series: An Introduction, Second Edition BOLLEN  Structural Equations with Latent Variables BOROVKOV  Ergodicity and Stability of Stochastic Processes BOULEAU  Numerical Methods for Stochastic Processes BOX  Bayesian Inference in Statistical Analysis BOX  R. A. Fisher, the Life of a Scientist BOX and DRAPER  Empirical Model-Building and Response Surfaces *BOX and DRAPER  Evolutionary Operation: A Statistical Method for Process Improvement BOX, HUNTER, and HUNTER  Statistics for Experimenters: An Introduction to Design, Data Analysis, and Model Building BOX and LUCEO  Statistical Control by Monitoring and Feedback Adjustment BRANDIMARTE  Numerical Methods in Finance: A MATLAB-Based Introduction BROWN and HOLLANDER  Statistics: A Biomedical Introduction BRUNNER, DOMHOF, and LANGER  Nonparametric Analysis of Longitudinal Data in Factorial Experiments BUCKLEW  Large Deviation Techniques in Decision, Simulation, and Estimation CAIROLI and DALANG  Sequential Stochastic Optimization CHAN  Time Series: Applications to Finance CHATTERJEE and HADI  Sensitivity Analysis in Linear Regression CHATTERJEE and PRICE  Regression Analysis by Example, Third Edition CHERNICK  Bootstrap Methods: A Practitioners Guide CHERNICK and FRIIS  Introductory Biostatistics for the Health Sciences CHILS and DELFINER  Geostatistics: Modeling Spatial Uncertainty CHOW and LIU  Design and Analysis of Clinical Trials: Concepts and Methodologies CLARKE and DISNEY  Probability and Random Processes: A First Course with Applications, Second Edition *COCHRAN and COX  Experimental Designs, Second Edition CONGDON  Bayesian Statistical Modelling CONOVER  Practical Nonparametric Statistics, Second Edition COOK  Regression Graphics COOK and WEISBERG  Applied Regression Including Computing and Graphics COOK and WEISBERG  An Introduction to Regression Graphics CORNELL  Experiments with Mixtures, Designs, Models, and the Analysis of Mixture Data, Third Edition COVER and THOMAS  Elements of Information Theory COX  A Handbook of Introductory Statistical Methods *COX  Planning of Experiments CRESSIE  Statistics for Spatial Data, Revised Edition CSRGO nd HORVTH  Limit Theorems in Change Point Analysis DANIEL  Applications of Statistics to Industrial Experimentation DANIEL  Biostatistics: A Foundation for Analysis in the Health Sciences, Sixth Edition *Now available in a lower priced paperback edition in the Wiley Classics Library.

p&s-cp.qxd 3/25/03 9:47 AM Page 4 *DANIEL  Fitting Equations to Data: Computer Analysis of Multifactor Data, Second Edition DASU and JOHNSON  Exploratory Data Mining and Data Cleaning DAVID  Order Statistics, Second Edition *DEGROOT, FIENBERG, and KADANE  Statistics and the Law DEL CASTILLO  Statistical Process Adjustment for Quality Control DETTE and STUDDEN  The Theory of Canonical Moments with Applications in Statistics, Probability, and Analysis DEY and MUKERJEE  Fractional Factorial Plans DILLON and GOLDSTEIN  Multivariate Analysis: Methods and Applications DODGE  Alternative Methods of Regression *DODGE and ROMIG  Sampling Inspection Tables, Second Edition *DOOB  Stochastic Processes DOWDY and WEARDEN  Statistics for Research, Second Edition DRAPER and SMITH  Applied Regression Analysis, Third Edition DRYDEN and MARDIA  Statistical Shape Analysis DUDEWICZ and MISHRA  Modern Mathematical Statistics DUNN and CLARK  Applied Statistics: Analysis of Variance and Regression, Second Edition DUNN and CLARK  Basic Statistics: A Primer for the Biomedical Sciences, Third Edition DUPUIS and ELLIS  A Weak Convergence Approach to the Theory of Large Deviations *ELANDT-JOHNSON and JOHNSON  Survival Models and Data Analysis ENDERS  Applied Econometric Time Series ETHIER and KURTZ  Markov Processes: Characterization and Convergence EVANS, HASTINGS, and PEACOCK  Statistical Distributions, Third Edition FELLER  An Introduction to Probability Theory and Its Applications, Volume I, Third Edition, Revised; Volume II, Second Edition FISHER and VAN BELLE  Biostatistics: A Methodology for the Health Sciences *FLEISS  The Design and Analysis of Clinical Experiments FLEISS  Statistical Methods for Rates and Proportions, Second Edition FLEMING and HARRINGTON  Counting Processes and Survival Analysis FULLER  Introduction to Statistical Time Series, Second Edition FULLER  Measurement Error Models GALLANT  Nonlinear Statistical Models GHOSH, MUKHOPADHYAY, and SEN  Sequential Estimation GIFI  Nonlinear Multivariate Analysis GLASSERMAN and YAO  Monotone Structure in Discrete-Event Systems GNANADESIKAN  Methods for Statistical Data Analysis of Multivariate Observations, Second Edition GOLDSTEIN and LEWIS  Assessment: Problems, Development, and Statistical Issues GREENWOOD and NIKULIN  A Guide to Chi-Squared Testing GROSS and HARRIS  Fundamentals of Queueing Theory, Third Edition *HAHN and SHAPIRO  Statistical Models in Engineering HAHN and MEEKER  Statistical Intervals: A Guide for Practitioners HALD  A History of Probability and Statistics and their Applications Before 1750 HALD  A History of Mathematical Statistics from 1750 to 1930 HAMPEL  Robust Statistics: The Approach Based on Influence Functions HANNAN and DEISTLER  The Statistical Theory of Linear Systems HEIBERGER  Computation for the Analysis of Designed Experiments HEDAYAT and SINHA  Design and Inference in Finite Population Sampling HELLER  MACSYMA for Statisticians HINKELMAN and KEMPTHORNE:  Design and Analysis of Experiments, Volume 1: Introduction to Experimental Design *Now available in a lower priced paperback edition in the Wiley Classics Library.

p&s-cp.qxd 3/25/03 9:47 AM Page 5 HOAGLIN, MOSTELLER, and TUKEY  Exploratory Approach to Analysis of Variance HOAGLIN, MOSTELLER, and TUKEY  Exploring Data Tables, Trends and Shapes *HOAGLIN, MOSTELLER, and TUKEY  Understanding Robust and Exploratory Data Analysis HOCHBERG and TAMHANE  Multiple Comparison Procedures HOCKING  Methods and Applications of Linear Models: Regression and the Analysis of Variance, Second Edition HOEL  Introduction to Mathematical Statistics, Fifth Edition HOGG and KLUGMAN  Loss Distributions HOLLANDER and WOLFE  Nonparametric Statistical Methods, Second Edition HOSMER and LEMESHOW  Applied Logistic Regression, Second Edition HOSMER and LEMESHOW  Applied Survival Analysis: Regression Modeling of Time to Event Data HYLAND and RAUSAND  System Reliability Theory: Models and Statistical Methods HUBER  Robust Statistics HUBERTY  Applied Discriminant Analysis HUNT and KENNEDY  Financial Derivatives in Theory and Practice HUSKOVA, BERAN, and DUPAC  Collected Works of Jaroslav Hajek with Commentary IMAN and CONOVER  A Modern Approach to Statistics JACKSON  A Users Guide to Principle Components JOHN  Statistical Methods in Engineering and Quality Assurance JOHNSON  Multivariate Statistical Simulation JOHNSON and BALAKRISHNAN  Advances in the Theory and Practice of Statistics: A Volume in Honor of Samuel Kotz JUDGE, GRIFFITHS, HILL, LTKEPOHL, and LEE  The Theory and Practice of Econometrics, Second Edition JOHNSON and KOTZ  Distributions in Statistics JOHNSON and KOTZ (editors)  Leading Personalities in Statistical Sciences: From the Seventeenth Century to the Present JOHNSON, KOTZ, and BALAKRISHNAN  Continuous Univariate Distributions, Volume 1, Second Edition JOHNSON, KOTZ, and BALAKRISHNAN  Continuous Univariate Distributions, Volume 2, Second Edition JOHNSON, KOTZ, and BALAKRISHNAN  Discrete Multivariate Distributions JOHNSON, KOTZ, and KEMP  Univariate Discrete Distributions, Second Edition JURECKOV and SEN  Robust Statistical Procedures: Aymptotics and Interrelations JUREK and MASON  Operator-Limit Distributions in Probability Theory KADANE  Bayesian Methods and Ethics in a Clinical Trial Design KADANE AND SCHUM  A Probabilistic Analysis of the Sacco and Vanzetti Evidence KALBFLEISCH and PRENTICE  The Statistical Analysis of Failure Time Data, Second Edition KASS and VOS  Geometrical Foundations of Asymptotic Inference KAUFMAN and ROUSSEEUW  Finding Groups in Data: An Introduction to Cluster Analysis KEDEM and FOKIANOS  Regression Models for Time Series Analysis KENDALL, BARDEN, CARNE, and LE  Shape and Shape Theory KHURI  Advanced Calculus with Applications in Statistics, Second Edition KHURI, MATHEW, and SINHA  Statistical Tests for Mixed Linear Models KLUGMAN, PANJER, and WILLMOT  Loss Models: From Data to Decisions KLUGMAN, PANJER, and WILLMOT  Solutions Manual to Accompany Loss Models: From Data to Decisions *Now available in a lower priced paperback edition in the Wiley Classics Library.

p&s-cp.qxd 3/25/03 9:47 AM Page 6 KOTZ, BALAKRISHNAN, and JOHNSON  Continuous Multivariate Distributions, Volume 1, Second Edition KOTZ and JOHNSON (editors)  Encyclopedia of Statistical Sciences: Volumes 1 to 9 with Index KOTZ and JOHNSON (editors)  Encyclopedia of Statistical Sciences: Supplement Volume KOTZ, READ, and BANKS (editors)  Encyclopedia of Statistical Sciences: Update Volume 1 KOTZ, READ, and BANKS (editors)  Encyclopedia of Statistical Sciences: Update Volume 2 KOVALENKO, KUZNETZOV, and PEGG  Mathematical Theory of Reliability of Time-Dependent Systems with Practical Applications LACHIN  Biostatistical Methods: The Assessment of Relative Risks LAD  Operational Subjective Statistical Methods: A Mathematical, Philosophical, and Historical Introduction LAMPERTI  Probability: A Survey of the Mathematical Theory, Second Edition LANGE, RYAN, BILLARD, BRILLINGER, CONQUEST, and GREENHOUSE  Case Studies in Biometry LARSON  Introduction to Probability Theory and Statistical Inference, Third Edition LAWLESS  Statistical Models and Methods for Lifetime Data, Second Edition LAWSON  Statistical Methods in Spatial Epidemiology LE  Applied Categorical Data Analysis LE  Applied Survival Analysis LEE and WANG  Statistical Methods for Survival Data Analysis, Third Edition LEPAGE and BILLARD  Exploring the Limits of Bootstrap LEYLAND and GOLDSTEIN (editors)  Multilevel Modelling of Health Statistics LIAO  Statistical Group Comparison LINDVALL  Lectures on the Coupling Method LINHART and ZUCCHINI  Model Selection LITTLE and RUBIN  Statistical Analysis with Missing Data, Second Edition LLOYD  The Statistical Analysis of Categorical Data MAGNUS and NEUDECKER  Matrix Differential Calculus with Applications in Statistics and Econometrics, Revised Edition MALLER and ZHOU  Survival Analysis with Long Term Survivors MALLOWS  Design, Data, and Analysis by Some Friends of Cuthbert Daniel MANN, SCHAFER, and SINGPURWALLA  Methods for Statistical Analysis of Reliability and Life Data MANTON, WOODBURY, and TOLLEY  Statistical Applications Using Fuzzy Sets MARDIA and JUPP  Directional Statistics MASON, GUNST, and HESS  Statistical Design and Analysis of Experiments with Applications to Engineering and Science, Second Edition McCULLOCH and SEARLE  Generalized, Linear, and Mixed Models McFADDEN  Management of Data in Clinical Trials McLACHLAN  Discriminant Analysis and Statistical Pattern Recognition McLACHLAN and KRISHNAN  The EM Algorithm and Extensions McLACHLAN and PEEL  Finite Mixture Models McNEIL  Epidemiological Research Methods MEEKER and ESCOBAR  Statistical Methods for Reliability Data MEERSCHAERT and SCHEFFLER  Limit Distributions for Sums of Independent Random Vectors: Heavy Tails in Theory and Practice *MILLER  Survival Analysis, Second Edition MONTGOMERY, PECK, and VINING  Introduction to Linear Regression Analysis, Third Edition MORGENTHALER and TUKEY  Configural Polysampling: A Route to Practical Robustness *Now available in a lower priced paperback edition in the Wiley Classics Library.

p&s-cp.qxd 3/25/03 9:47 AM Page 7 MUIRHEAD  Aspects of Multivariate Statistical Theory MURRAY  X-STAT 2.0 Statistical Experimentation, Design Data Analysis, and Nonlinear Optimization MYERS and MONTGOMERY  Response Surface Methodology: Process and Product Optimization Using Designed Experiments, Second Edition MYERS, MONTGOMERY, and VINING  Generalized Linear Models. With Applications in Engineering and the Sciences NELSON  Accelerated Testing, Statistical Models, Test Plans, and Data Analyses NELSON  Applied Life Data Analysis NEWMAN  Biostatistical Methods in Epidemiology OCHI  Applied Probability and Stochastic Processes in Engineering and Physical Sciences OKABE, BOOTS, SUGIHARA, and CHIU  Spatial Tesselations: Concepts and Applications of Voronoi Diagrams, Second Edition OLIVER and SMITH  Influence Diagrams, Belief Nets and Decision Analysis PANKRATZ  Forecasting with Dynamic Regression Models PANKRATZ  Forecasting with Univariate Box-Jenkins Models: Concepts and Cases *PARZEN  Modern Probability Theory and Its Applications PEA, TIAO, and TSAY  A Course in Time Series Analysis PIANTADOSI  Clinical Trials: A Methodologic Perspective PORT  Theoretical Probability for Applications POURAHMADI  Foundations of Time Series Analysis and Prediction Theory PRESS  Bayesian Statistics: Principles, Models, and Applications PRESS  Subjective and Objective Bayesian Statistics, Second Edition PRESS and TANUR  The Subjectivity of Scientists and the Bayesian Approach PUKELSHEIM  Optimal Experimental Design PURI, VILAPLANA, and WERTZ  New Perspectives in Theoretical and Applied Statistics PUTERMAN  Markov Decision Processes: Discrete Stochastic Dynamic Programming *RAO  Linear Statistical Inference and Its Applications, Second Edition RENCHER  Linear Models in Statistics RENCHER  Methods of Multivariate Analysis, Second Edition RENCHER  Multivariate Statistical Inference with Applications RIPLEY  Spatial Statistics RIPLEY  Stochastic Simulation ROBINSON  Practical Strategies for Experimenting ROHATGI and SALEH  An Introduction to Probability and Statistics, Second Edition ROLSKI, SCHMIDLI, SCHMIDT, and TEUGELS  Stochastic Processes for Insurance and Finance ROSENBERGER and LACHIN  Randomization in Clinical Trials: Theory and Practice ROSS  Introduction to Probability and Statistics for Engineers and Scientists ROUSSEEUW and LEROY  Robust Regression and Outlier Detection RUBIN  Multiple Imputation for Nonresponse in Surveys RUBINSTEIN  Simulation and the Monte Carlo Method RUBINSTEIN and MELAMED  Modern Simulation and Modeling RYAN  Modern Regression Methods RYAN  Statistical Methods for Quality Improvement, Second Edition SALTELLI, CHAN, and SCOTT (editors)  Sensitivity Analysis *SCHEFFE  The Analysis of Variance SCHIMEK  Smoothing and Regression: Approaches, Computation, and Application SCHOTT  Matrix Analysis for Statistics SCHUSS  Theory and Applications of Stochastic Differential Equations SCOTT  Multivariate Density Estimation: Theory, Practice, and Visualization *SEARLE  Linear Models SEARLE  Linear Models for Unbalanced Data *Now available in a lower priced paperback edition in the Wiley Classics Library.

p&s-cp.qxd 3/25/03 9:47 AM Page 8 SEARLE  Matrix Algebra Useful for Statistics SEARLE, CASELLA, and McCULLOCH  Variance Components SEARLE and WILLETT  Matrix Algebra for Applied Economics SEBER and LEE  Linear Regression Analysis, Second Edition SEBER  Multivariate Observations SEBER and WILD  Nonlinear Regression SENNOTT  Stochastic Dynamic Programming and the Control of Queueing Systems *SERFLING  Approximation Theorems of Mathematical Statistics SHAFER and VOVK  Probability and Finance: Its Only a Game!

SMALL and MCLEISH  Hilbert Space Methods in Probability and Statistical Inference SRIVASTAVA  Methods of Multivariate Statistics STAPLETON  Linear Statistical Models STAUDTE and SHEATHER  Robust Estimation and Testing STOYAN, KENDALL, and MECKE  Stochastic Geometry and Its Applications, Second Edition STOYAN and STOYAN  Fractals, Random Shapes and Point Fields: Methods of Geometrical Statistics STYAN  The Collected Papers of T. W. Anderson: 19431985 SUTTON, ABRAMS, JONES, SHELDON, and SONG  Methods for Meta-Analysis in Medical Research TANAKA  Time Series Analysis: Nonstationary and Noninvertible Distribution Theory THOMPSON  Empirical Model Building THOMPSON  Sampling, Second Edition THOMPSON  Simulation: A Modelers Approach THOMPSON and SEBER  Adaptive Sampling THOMPSON, WILLIAMS, and FINDLAY  Models for Investors in Real World Markets TIAO, BISGAARD, HILL, PEA, and STIGLER (editors)  Box on Quality and Discovery: with Design, Control, and Robustness TIERNEY  LISP-STAT: An Object-Oriented Environment for Statistical Computing and Dynamic Graphics TSAY  Analysis of Financial Time Series UPTON and FINGLETON  Spatial Data Analysis by Example, Volume II: Categorical and Directional Data VAN BELLE  Statistical Rules of Thumb VIDAKOVIC  Statistical Modeling by Wavelets WEISBERG  Applied Linear Regression, Second Edition WELSH  Aspects of Statistical Inference WESTFALL and YOUNG  Resampling-Based Multiple Testing: Examples and Methods for p-Value Adjustment WHITTAKER  Graphical Models in Applied Multivariate Statistics WINKER  Optimization Heuristics in Economics: Applications of Threshold Accepting WONNACOTT and WONNACOTT  Econometrics, Second Edition WOODING  Planning Pharmaceutical Clinical Trials: Basic Statistical Principles WOOLSON and CLARKE  Statistical Methods for the Analysis of Biomedical Data, Second Edition WU and HAMADA  Experiments: Planning, Analysis, and Parameter Design Optimization YANG  The Construction Theory of Denumerable Markov Processes *ZELLNER  An Introduction to Bayesian Inference in Econometrics ZHOU, OBUCHOWSKI, and MCCLISH  Statistical Methods in Diagnostic Medicine *Now available in a lower priced paperback edition in the Wiley Classics Library.

Document Outline Statistical Methods for Survival Data Analysis (3rd Ed.) Copyright Contents Preface Ch1 Introduction Ch2 Functions of Survival Time Ch3 Examples of Survival Data Analysis Ch4 Nonparametric Methods of Estimating Survival Functions Ch5 Nonparametric Methods for Comparing Survival Distributions Ch6 Some Well-Known Parametric Survival Distributions & their Applications Ch7 Estimation Procedures for Parametric Survival Distributions without Covariates Ch8 Graphical Methods for Survival Distribution Fitting Ch9 Tests of Goodness of Fit & Distribution Selection Ch10 Parametric Methods for Comparing Two Survival Distributions Ch11 Parametric Methods for Regression Model Fitting & Identification of Prognostic Factors Ch12 Identification of Prognostic Factors related to Survival Time: Cox Proportional Hazards Model Ch13 Identification of Prognostic Factors related to Survival Time: Nonproportional Hazards Models Ch14 Identification of Risk Factors Related to Dichotomous & Polychotomous Outcomes AppA Newton-Raphson Method AppB Statistical Tables References Index Wiley Series in Probability & Statistics Backcover